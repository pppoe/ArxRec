<!DOCTYPE html>
<html lang="en">
  <head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V34CNNDP8V"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-V34CNNDP8V');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arxiv Paper Selection</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
    }
    header {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      background-color: #ffffff;
      color: black;
      padding: 10px;
      text-align: center;
      z-index: 1000;
      border-bottom: 1px solid #ddd;
    }
    header div {
      display: block;
      margin: 10px auto;
    }

    #home-icon {
      display: block;
      float: left;
      margin: 5px;
      text-decoration: none;
      color: black;
    }

    main {
      margin-top: 60px; /* Adjusted margin to account for fixed header */
      padding: 20px;
    }

    .post {
      background-color: white;
      border: 1px solid #ddd;
      border-radius: 5px;
      margin-bottom: 10px;
      padding: 10px 20px;
      max-height: 2000px;
      overflow: scroll;
    }
    .post img {
      display: block;
      margin-top: 5px;
      max-width: auto;
      max-height: 100px;
    }
    .post .clear {
      clear: both;
      display: block;
    }
    .post a {
      text-decoration: none;
    }
    .post a:hover {
      color: #0056b3;
    }
    .post a:visited {
      color: #0056b3;
    }
    .post div.comment {
      text-align: right;
    }
    .post div.comment a {
      margin: 1em;
    }
    .post .text {
      margin: 1em 0em;
      padding: 0;
    }
    .post .text .title {
    }
    .post .text .author {
    }
    .post .text .abstract {
    }
    .post .topK {
      display: block;
      margin: 0.5em;
    }
    .post .date {
      margin: 0;
      padding: 0;
      text-size: small; 
      color: gray;
    }
    .post .link {
      margin: 0;
      padding: 0;
    }
    @media screen and (max-width: 600px) {
      body {
        max-width: 100%; 
      }
      #home-icon {
        float: none;
        display: block;
        text-align: center;
        margin-bottom: 10px;
      }
    }
    footer {
      width: 100%;
      background-color: #ddd;
      text-align: center;
      z-index: 1000;
      padding: 20px 0px;
      margin-bottom: 20px;
      left: 0;
    }

    #next-btn,
    #prev-btn {
      background-color: #4CAF50;
      color: white;
      padding: 8px 16px;
      margin: 0 50px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }

    .links {
      padding: 20px;
    }
    .links a {
      text-decoration: none;
    }
    .links a:hover {
      color: #0056b3;
    }
    .links a:visited {
      color: #0056b3;
    }

    #page-index {
      font-size: small;
    }
    .ads {
      width: 100%;
    }
    #prev-btn {
      background-color: #4CAF50;
      color: white;
      padding: 8px 16px;
      margin: 0 50px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    </style>
  </head>
  <body>

    <header>
      <a id="prev-btn" href="daily20250123.html"><i class="fas fa-chevron-left"></i></a>
      <a href="https://haoxiang.org/">About</a>
    </header>

    <main id="content">
      <!-- Posts will be dynamically added here using JavaScript -->
    </main>

    <script>
      // Dummy data for posts
      const posts = [
{"title": "Trick-GS: A Balanced Bag of Tricks for Efficient Gaussian Splatting", "author": "Anil Armagan and Albert Sa\u00e0-Garriga and Bruno Manganelli and Mateusz Nowak and Mehmet Kerim Yucel", "abstract": "  Gaussian splatting (GS) for 3D reconstruction has become quite popular due to\ntheir fast training, inference speeds and high quality reconstruction. However,\nGS-based reconstructions generally consist of millions of Gaussians, which\nmakes them hard to use on computationally constrained devices such as\nsmartphones. In this paper, we first propose a principled analysis of advances\nin efficient GS methods. Then, we propose Trick-GS, which is a careful\ncombination of several strategies including (1) progressive training with\nresolution, noise and Gaussian scales, (2) learning to prune and mask\nprimitives and SH bands by their significance, and (3) accelerated GS training\nframework. Trick-GS takes a large step towards resource-constrained GS, where\nfaster run-time, smaller and faster-convergence of models is of paramount\nconcern. Our results on three datasets show that Trick-GS achieves up to 2x\nfaster training, 40x smaller disk size and 2x faster rendering speed compared\nto vanilla GS, while having comparable accuracy.\n", "link": "http://arxiv.org/abs/2501.14534v1", "date": "2025-01-24", "relevancy": 3.4041, "topK": [{"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.7193}, {"title": "GST: Precise 3D Human Body from a Single Image with Gaussian Splatting\n  Transformers", "link": "http://arxiv.org/abs/2409.04196v1", "similarity": 0.6887}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.6346}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Trick-GS%3A%20A%20Balanced%20Bag%20of%20Tricks%20for%20Efficient%20Gaussian%20Splatting&body=Title%3A%20Trick-GS%3A%20A%20Balanced%20Bag%20of%20Tricks%20for%20Efficient%20Gaussian%20Splatting%0AAuthor%3A%20Anil%20Armagan%20and%20Albert%20Sa%C3%A0-Garriga%20and%20Bruno%20Manganelli%20and%20Mateusz%20Nowak%20and%20Mehmet%20Kerim%20Yucel%0AAbstract%3A%20%20%20Gaussian%20splatting%20%28GS%29%20for%203D%20reconstruction%20has%20become%20quite%20popular%20due%20to%0Atheir%20fast%20training%2C%20inference%20speeds%20and%20high%20quality%20reconstruction.%20However%2C%0AGS-based%20reconstructions%20generally%20consist%20of%20millions%20of%20Gaussians%2C%20which%0Amakes%20them%20hard%20to%20use%20on%20computationally%20constrained%20devices%20such%20as%0Asmartphones.%20In%20this%20paper%2C%20we%20first%20propose%20a%20principled%20analysis%20of%20advances%0Ain%20efficient%20GS%20methods.%20Then%2C%20we%20propose%20Trick-GS%2C%20which%20is%20a%20careful%0Acombination%20of%20several%20strategies%20including%20%281%29%20progressive%20training%20with%0Aresolution%2C%20noise%20and%20Gaussian%20scales%2C%20%282%29%20learning%20to%20prune%20and%20mask%0Aprimitives%20and%20SH%20bands%20by%20their%20significance%2C%20and%20%283%29%20accelerated%20GS%20training%0Aframework.%20Trick-GS%20takes%20a%20large%20step%20towards%20resource-constrained%20GS%2C%20where%0Afaster%20run-time%2C%20smaller%20and%20faster-convergence%20of%20models%20is%20of%20paramount%0Aconcern.%20Our%20results%20on%20three%20datasets%20show%20that%20Trick-GS%20achieves%20up%20to%202x%0Afaster%20training%2C%2040x%20smaller%20disk%20size%20and%202x%20faster%20rendering%20speed%20compared%0Ato%20vanilla%20GS%2C%20while%20having%20comparable%20accuracy.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14534v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTrick-GS%253A%2520A%2520Balanced%2520Bag%2520of%2520Tricks%2520for%2520Efficient%2520Gaussian%2520Splatting%26entry.906535625%3DAnil%2520Armagan%2520and%2520Albert%2520Sa%25C3%25A0-Garriga%2520and%2520Bruno%2520Manganelli%2520and%2520Mateusz%2520Nowak%2520and%2520Mehmet%2520Kerim%2520Yucel%26entry.1292438233%3D%2520%2520Gaussian%2520splatting%2520%2528GS%2529%2520for%25203D%2520reconstruction%2520has%2520become%2520quite%2520popular%2520due%2520to%250Atheir%2520fast%2520training%252C%2520inference%2520speeds%2520and%2520high%2520quality%2520reconstruction.%2520However%252C%250AGS-based%2520reconstructions%2520generally%2520consist%2520of%2520millions%2520of%2520Gaussians%252C%2520which%250Amakes%2520them%2520hard%2520to%2520use%2520on%2520computationally%2520constrained%2520devices%2520such%2520as%250Asmartphones.%2520In%2520this%2520paper%252C%2520we%2520first%2520propose%2520a%2520principled%2520analysis%2520of%2520advances%250Ain%2520efficient%2520GS%2520methods.%2520Then%252C%2520we%2520propose%2520Trick-GS%252C%2520which%2520is%2520a%2520careful%250Acombination%2520of%2520several%2520strategies%2520including%2520%25281%2529%2520progressive%2520training%2520with%250Aresolution%252C%2520noise%2520and%2520Gaussian%2520scales%252C%2520%25282%2529%2520learning%2520to%2520prune%2520and%2520mask%250Aprimitives%2520and%2520SH%2520bands%2520by%2520their%2520significance%252C%2520and%2520%25283%2529%2520accelerated%2520GS%2520training%250Aframework.%2520Trick-GS%2520takes%2520a%2520large%2520step%2520towards%2520resource-constrained%2520GS%252C%2520where%250Afaster%2520run-time%252C%2520smaller%2520and%2520faster-convergence%2520of%2520models%2520is%2520of%2520paramount%250Aconcern.%2520Our%2520results%2520on%2520three%2520datasets%2520show%2520that%2520Trick-GS%2520achieves%2520up%2520to%25202x%250Afaster%2520training%252C%252040x%2520smaller%2520disk%2520size%2520and%25202x%2520faster%2520rendering%2520speed%2520compared%250Ato%2520vanilla%2520GS%252C%2520while%2520having%2520comparable%2520accuracy.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14534v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Trick-GS%3A%20A%20Balanced%20Bag%20of%20Tricks%20for%20Efficient%20Gaussian%20Splatting&entry.906535625=Anil%20Armagan%20and%20Albert%20Sa%C3%A0-Garriga%20and%20Bruno%20Manganelli%20and%20Mateusz%20Nowak%20and%20Mehmet%20Kerim%20Yucel&entry.1292438233=%20%20Gaussian%20splatting%20%28GS%29%20for%203D%20reconstruction%20has%20become%20quite%20popular%20due%20to%0Atheir%20fast%20training%2C%20inference%20speeds%20and%20high%20quality%20reconstruction.%20However%2C%0AGS-based%20reconstructions%20generally%20consist%20of%20millions%20of%20Gaussians%2C%20which%0Amakes%20them%20hard%20to%20use%20on%20computationally%20constrained%20devices%20such%20as%0Asmartphones.%20In%20this%20paper%2C%20we%20first%20propose%20a%20principled%20analysis%20of%20advances%0Ain%20efficient%20GS%20methods.%20Then%2C%20we%20propose%20Trick-GS%2C%20which%20is%20a%20careful%0Acombination%20of%20several%20strategies%20including%20%281%29%20progressive%20training%20with%0Aresolution%2C%20noise%20and%20Gaussian%20scales%2C%20%282%29%20learning%20to%20prune%20and%20mask%0Aprimitives%20and%20SH%20bands%20by%20their%20significance%2C%20and%20%283%29%20accelerated%20GS%20training%0Aframework.%20Trick-GS%20takes%20a%20large%20step%20towards%20resource-constrained%20GS%2C%20where%0Afaster%20run-time%2C%20smaller%20and%20faster-convergence%20of%20models%20is%20of%20paramount%0Aconcern.%20Our%20results%20on%20three%20datasets%20show%20that%20Trick-GS%20achieves%20up%20to%202x%0Afaster%20training%2C%2040x%20smaller%20disk%20size%20and%202x%20faster%20rendering%20speed%20compared%0Ato%20vanilla%20GS%2C%20while%20having%20comparable%20accuracy.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14534v1&entry.124074799=Read"},
{"title": "Relightable Full-Body Gaussian Codec Avatars", "author": "Shaofei Wang and Tomas Simon and Igor Santesteban and Timur Bagautdinov and Junxuan Li and Vasu Agrawal and Fabian Prada and Shoou-I Yu and Pace Nalbone and Matt Gramlich and Roman Lubachersky and Chenglei Wu and Javier Romero and Jason Saragih and Michael Zollhoefer and Andreas Geiger and Siyu Tang and Shunsuke Saito", "abstract": "  We propose Relightable Full-Body Gaussian Codec Avatars, a new approach for\nmodeling relightable full-body avatars with fine-grained details including face\nand hands. The unique challenge for relighting full-body avatars lies in the\nlarge deformations caused by body articulation and the resulting impact on\nappearance caused by light transport. Changes in body pose can dramatically\nchange the orientation of body surfaces with respect to lights, resulting in\nboth local appearance changes due to changes in local light transport\nfunctions, as well as non-local changes due to occlusion between body parts. To\naddress this, we decompose the light transport into local and non-local\neffects. Local appearance changes are modeled using learnable zonal harmonics\nfor diffuse radiance transfer. Unlike spherical harmonics, zonal harmonics are\nhighly efficient to rotate under articulation. This allows us to learn diffuse\nradiance transfer in a local coordinate frame, which disentangles the local\nradiance transfer from the articulation of the body. To account for non-local\nappearance changes, we introduce a shadow network that predicts shadows given\nprecomputed incoming irradiance on a base mesh. This facilitates the learning\nof non-local shadowing between the body parts. Finally, we use a deferred\nshading approach to model specular radiance transfer and better capture\nreflections and highlights such as eye glints. We demonstrate that our approach\nsuccessfully models both the local and non-local light transport required for\nrelightable full-body avatars, with a superior generalization ability under\nnovel illumination conditions and unseen poses.\n", "link": "http://arxiv.org/abs/2501.14726v1", "date": "2025-01-24", "relevancy": 3.326, "topK": [{"title": "3D Gaussian Blendshapes for Head Avatar Animation", "link": "http://arxiv.org/abs/2404.19398v2", "similarity": 0.6922}, {"title": "3D Gaussian Blendshapes for Head Avatar Animation", "link": "http://arxiv.org/abs/2404.19398v2", "similarity": 0.6922}, {"title": "Synthesizing Moving People with 3D Control", "link": "http://arxiv.org/abs/2401.10889v2", "similarity": 0.6112}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Relightable%20Full-Body%20Gaussian%20Codec%20Avatars&body=Title%3A%20Relightable%20Full-Body%20Gaussian%20Codec%20Avatars%0AAuthor%3A%20Shaofei%20Wang%20and%20Tomas%20Simon%20and%20Igor%20Santesteban%20and%20Timur%20Bagautdinov%20and%20Junxuan%20Li%20and%20Vasu%20Agrawal%20and%20Fabian%20Prada%20and%20Shoou-I%20Yu%20and%20Pace%20Nalbone%20and%20Matt%20Gramlich%20and%20Roman%20Lubachersky%20and%20Chenglei%20Wu%20and%20Javier%20Romero%20and%20Jason%20Saragih%20and%20Michael%20Zollhoefer%20and%20Andreas%20Geiger%20and%20Siyu%20Tang%20and%20Shunsuke%20Saito%0AAbstract%3A%20%20%20We%20propose%20Relightable%20Full-Body%20Gaussian%20Codec%20Avatars%2C%20a%20new%20approach%20for%0Amodeling%20relightable%20full-body%20avatars%20with%20fine-grained%20details%20including%20face%0Aand%20hands.%20The%20unique%20challenge%20for%20relighting%20full-body%20avatars%20lies%20in%20the%0Alarge%20deformations%20caused%20by%20body%20articulation%20and%20the%20resulting%20impact%20on%0Aappearance%20caused%20by%20light%20transport.%20Changes%20in%20body%20pose%20can%20dramatically%0Achange%20the%20orientation%20of%20body%20surfaces%20with%20respect%20to%20lights%2C%20resulting%20in%0Aboth%20local%20appearance%20changes%20due%20to%20changes%20in%20local%20light%20transport%0Afunctions%2C%20as%20well%20as%20non-local%20changes%20due%20to%20occlusion%20between%20body%20parts.%20To%0Aaddress%20this%2C%20we%20decompose%20the%20light%20transport%20into%20local%20and%20non-local%0Aeffects.%20Local%20appearance%20changes%20are%20modeled%20using%20learnable%20zonal%20harmonics%0Afor%20diffuse%20radiance%20transfer.%20Unlike%20spherical%20harmonics%2C%20zonal%20harmonics%20are%0Ahighly%20efficient%20to%20rotate%20under%20articulation.%20This%20allows%20us%20to%20learn%20diffuse%0Aradiance%20transfer%20in%20a%20local%20coordinate%20frame%2C%20which%20disentangles%20the%20local%0Aradiance%20transfer%20from%20the%20articulation%20of%20the%20body.%20To%20account%20for%20non-local%0Aappearance%20changes%2C%20we%20introduce%20a%20shadow%20network%20that%20predicts%20shadows%20given%0Aprecomputed%20incoming%20irradiance%20on%20a%20base%20mesh.%20This%20facilitates%20the%20learning%0Aof%20non-local%20shadowing%20between%20the%20body%20parts.%20Finally%2C%20we%20use%20a%20deferred%0Ashading%20approach%20to%20model%20specular%20radiance%20transfer%20and%20better%20capture%0Areflections%20and%20highlights%20such%20as%20eye%20glints.%20We%20demonstrate%20that%20our%20approach%0Asuccessfully%20models%20both%20the%20local%20and%20non-local%20light%20transport%20required%20for%0Arelightable%20full-body%20avatars%2C%20with%20a%20superior%20generalization%20ability%20under%0Anovel%20illumination%20conditions%20and%20unseen%20poses.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14726v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRelightable%2520Full-Body%2520Gaussian%2520Codec%2520Avatars%26entry.906535625%3DShaofei%2520Wang%2520and%2520Tomas%2520Simon%2520and%2520Igor%2520Santesteban%2520and%2520Timur%2520Bagautdinov%2520and%2520Junxuan%2520Li%2520and%2520Vasu%2520Agrawal%2520and%2520Fabian%2520Prada%2520and%2520Shoou-I%2520Yu%2520and%2520Pace%2520Nalbone%2520and%2520Matt%2520Gramlich%2520and%2520Roman%2520Lubachersky%2520and%2520Chenglei%2520Wu%2520and%2520Javier%2520Romero%2520and%2520Jason%2520Saragih%2520and%2520Michael%2520Zollhoefer%2520and%2520Andreas%2520Geiger%2520and%2520Siyu%2520Tang%2520and%2520Shunsuke%2520Saito%26entry.1292438233%3D%2520%2520We%2520propose%2520Relightable%2520Full-Body%2520Gaussian%2520Codec%2520Avatars%252C%2520a%2520new%2520approach%2520for%250Amodeling%2520relightable%2520full-body%2520avatars%2520with%2520fine-grained%2520details%2520including%2520face%250Aand%2520hands.%2520The%2520unique%2520challenge%2520for%2520relighting%2520full-body%2520avatars%2520lies%2520in%2520the%250Alarge%2520deformations%2520caused%2520by%2520body%2520articulation%2520and%2520the%2520resulting%2520impact%2520on%250Aappearance%2520caused%2520by%2520light%2520transport.%2520Changes%2520in%2520body%2520pose%2520can%2520dramatically%250Achange%2520the%2520orientation%2520of%2520body%2520surfaces%2520with%2520respect%2520to%2520lights%252C%2520resulting%2520in%250Aboth%2520local%2520appearance%2520changes%2520due%2520to%2520changes%2520in%2520local%2520light%2520transport%250Afunctions%252C%2520as%2520well%2520as%2520non-local%2520changes%2520due%2520to%2520occlusion%2520between%2520body%2520parts.%2520To%250Aaddress%2520this%252C%2520we%2520decompose%2520the%2520light%2520transport%2520into%2520local%2520and%2520non-local%250Aeffects.%2520Local%2520appearance%2520changes%2520are%2520modeled%2520using%2520learnable%2520zonal%2520harmonics%250Afor%2520diffuse%2520radiance%2520transfer.%2520Unlike%2520spherical%2520harmonics%252C%2520zonal%2520harmonics%2520are%250Ahighly%2520efficient%2520to%2520rotate%2520under%2520articulation.%2520This%2520allows%2520us%2520to%2520learn%2520diffuse%250Aradiance%2520transfer%2520in%2520a%2520local%2520coordinate%2520frame%252C%2520which%2520disentangles%2520the%2520local%250Aradiance%2520transfer%2520from%2520the%2520articulation%2520of%2520the%2520body.%2520To%2520account%2520for%2520non-local%250Aappearance%2520changes%252C%2520we%2520introduce%2520a%2520shadow%2520network%2520that%2520predicts%2520shadows%2520given%250Aprecomputed%2520incoming%2520irradiance%2520on%2520a%2520base%2520mesh.%2520This%2520facilitates%2520the%2520learning%250Aof%2520non-local%2520shadowing%2520between%2520the%2520body%2520parts.%2520Finally%252C%2520we%2520use%2520a%2520deferred%250Ashading%2520approach%2520to%2520model%2520specular%2520radiance%2520transfer%2520and%2520better%2520capture%250Areflections%2520and%2520highlights%2520such%2520as%2520eye%2520glints.%2520We%2520demonstrate%2520that%2520our%2520approach%250Asuccessfully%2520models%2520both%2520the%2520local%2520and%2520non-local%2520light%2520transport%2520required%2520for%250Arelightable%2520full-body%2520avatars%252C%2520with%2520a%2520superior%2520generalization%2520ability%2520under%250Anovel%2520illumination%2520conditions%2520and%2520unseen%2520poses.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14726v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Relightable%20Full-Body%20Gaussian%20Codec%20Avatars&entry.906535625=Shaofei%20Wang%20and%20Tomas%20Simon%20and%20Igor%20Santesteban%20and%20Timur%20Bagautdinov%20and%20Junxuan%20Li%20and%20Vasu%20Agrawal%20and%20Fabian%20Prada%20and%20Shoou-I%20Yu%20and%20Pace%20Nalbone%20and%20Matt%20Gramlich%20and%20Roman%20Lubachersky%20and%20Chenglei%20Wu%20and%20Javier%20Romero%20and%20Jason%20Saragih%20and%20Michael%20Zollhoefer%20and%20Andreas%20Geiger%20and%20Siyu%20Tang%20and%20Shunsuke%20Saito&entry.1292438233=%20%20We%20propose%20Relightable%20Full-Body%20Gaussian%20Codec%20Avatars%2C%20a%20new%20approach%20for%0Amodeling%20relightable%20full-body%20avatars%20with%20fine-grained%20details%20including%20face%0Aand%20hands.%20The%20unique%20challenge%20for%20relighting%20full-body%20avatars%20lies%20in%20the%0Alarge%20deformations%20caused%20by%20body%20articulation%20and%20the%20resulting%20impact%20on%0Aappearance%20caused%20by%20light%20transport.%20Changes%20in%20body%20pose%20can%20dramatically%0Achange%20the%20orientation%20of%20body%20surfaces%20with%20respect%20to%20lights%2C%20resulting%20in%0Aboth%20local%20appearance%20changes%20due%20to%20changes%20in%20local%20light%20transport%0Afunctions%2C%20as%20well%20as%20non-local%20changes%20due%20to%20occlusion%20between%20body%20parts.%20To%0Aaddress%20this%2C%20we%20decompose%20the%20light%20transport%20into%20local%20and%20non-local%0Aeffects.%20Local%20appearance%20changes%20are%20modeled%20using%20learnable%20zonal%20harmonics%0Afor%20diffuse%20radiance%20transfer.%20Unlike%20spherical%20harmonics%2C%20zonal%20harmonics%20are%0Ahighly%20efficient%20to%20rotate%20under%20articulation.%20This%20allows%20us%20to%20learn%20diffuse%0Aradiance%20transfer%20in%20a%20local%20coordinate%20frame%2C%20which%20disentangles%20the%20local%0Aradiance%20transfer%20from%20the%20articulation%20of%20the%20body.%20To%20account%20for%20non-local%0Aappearance%20changes%2C%20we%20introduce%20a%20shadow%20network%20that%20predicts%20shadows%20given%0Aprecomputed%20incoming%20irradiance%20on%20a%20base%20mesh.%20This%20facilitates%20the%20learning%0Aof%20non-local%20shadowing%20between%20the%20body%20parts.%20Finally%2C%20we%20use%20a%20deferred%0Ashading%20approach%20to%20model%20specular%20radiance%20transfer%20and%20better%20capture%0Areflections%20and%20highlights%20such%20as%20eye%20glints.%20We%20demonstrate%20that%20our%20approach%0Asuccessfully%20models%20both%20the%20local%20and%20non-local%20light%20transport%20required%20for%0Arelightable%20full-body%20avatars%2C%20with%20a%20superior%20generalization%20ability%20under%0Anovel%20illumination%20conditions%20and%20unseen%20poses.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14726v1&entry.124074799=Read"},
{"title": "SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human\n  Pose and Talking Head Animation", "author": "Yujian Liu and Shidang Xu and Jing Guo and Dingbin Wang and Zairan Wang and Xianfeng Tan and Xiaoli Liu", "abstract": "  Generating talking avatar driven by audio remains a significant challenge.\nExisting methods typically require high computational costs and often lack\nsufficient facial detail and realism, making them unsuitable for applications\nthat demand high real-time performance and visual quality. Additionally, while\nsome methods can synchronize lip movement, they still face issues with\nconsistency between facial expressions and upper body movement, particularly\nduring silent periods. In this paper, we introduce SyncAnimation, the first\nNeRF-based method that achieves audio-driven, stable, and real-time generation\nof speaking avatar by combining generalized audio-to-pose matching and\naudio-to-expression synchronization. By integrating AudioPose Syncer and\nAudioEmotion Syncer, SyncAnimation achieves high-precision poses and expression\ngeneration, progressively producing audio-synchronized upper body, head, and\nlip shapes. Furthermore, the High-Synchronization Human Renderer ensures\nseamless integration of the head and upper body, and achieves audio-sync lip.\nThe project page can be found at https://syncanimation.github.io\n", "link": "http://arxiv.org/abs/2501.14646v1", "date": "2025-01-24", "relevancy": 3.1024, "topK": [{"title": "Synthesizing Moving People with 3D Control", "link": "http://arxiv.org/abs/2401.10889v2", "similarity": 0.6325}, {"title": "3D Gaussian Blendshapes for Head Avatar Animation", "link": "http://arxiv.org/abs/2404.19398v2", "similarity": 0.6145}, {"title": "3D Gaussian Blendshapes for Head Avatar Animation", "link": "http://arxiv.org/abs/2404.19398v2", "similarity": 0.6145}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20SyncAnimation%3A%20A%20Real-Time%20End-to-End%20Framework%20for%20Audio-Driven%20Human%0A%20%20Pose%20and%20Talking%20Head%20Animation&body=Title%3A%20SyncAnimation%3A%20A%20Real-Time%20End-to-End%20Framework%20for%20Audio-Driven%20Human%0A%20%20Pose%20and%20Talking%20Head%20Animation%0AAuthor%3A%20Yujian%20Liu%20and%20Shidang%20Xu%20and%20Jing%20Guo%20and%20Dingbin%20Wang%20and%20Zairan%20Wang%20and%20Xianfeng%20Tan%20and%20Xiaoli%20Liu%0AAbstract%3A%20%20%20Generating%20talking%20avatar%20driven%20by%20audio%20remains%20a%20significant%20challenge.%0AExisting%20methods%20typically%20require%20high%20computational%20costs%20and%20often%20lack%0Asufficient%20facial%20detail%20and%20realism%2C%20making%20them%20unsuitable%20for%20applications%0Athat%20demand%20high%20real-time%20performance%20and%20visual%20quality.%20Additionally%2C%20while%0Asome%20methods%20can%20synchronize%20lip%20movement%2C%20they%20still%20face%20issues%20with%0Aconsistency%20between%20facial%20expressions%20and%20upper%20body%20movement%2C%20particularly%0Aduring%20silent%20periods.%20In%20this%20paper%2C%20we%20introduce%20SyncAnimation%2C%20the%20first%0ANeRF-based%20method%20that%20achieves%20audio-driven%2C%20stable%2C%20and%20real-time%20generation%0Aof%20speaking%20avatar%20by%20combining%20generalized%20audio-to-pose%20matching%20and%0Aaudio-to-expression%20synchronization.%20By%20integrating%20AudioPose%20Syncer%20and%0AAudioEmotion%20Syncer%2C%20SyncAnimation%20achieves%20high-precision%20poses%20and%20expression%0Ageneration%2C%20progressively%20producing%20audio-synchronized%20upper%20body%2C%20head%2C%20and%0Alip%20shapes.%20Furthermore%2C%20the%20High-Synchronization%20Human%20Renderer%20ensures%0Aseamless%20integration%20of%20the%20head%20and%20upper%20body%2C%20and%20achieves%20audio-sync%20lip.%0AThe%20project%20page%20can%20be%20found%20at%20https%3A//syncanimation.github.io%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14646v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSyncAnimation%253A%2520A%2520Real-Time%2520End-to-End%2520Framework%2520for%2520Audio-Driven%2520Human%250A%2520%2520Pose%2520and%2520Talking%2520Head%2520Animation%26entry.906535625%3DYujian%2520Liu%2520and%2520Shidang%2520Xu%2520and%2520Jing%2520Guo%2520and%2520Dingbin%2520Wang%2520and%2520Zairan%2520Wang%2520and%2520Xianfeng%2520Tan%2520and%2520Xiaoli%2520Liu%26entry.1292438233%3D%2520%2520Generating%2520talking%2520avatar%2520driven%2520by%2520audio%2520remains%2520a%2520significant%2520challenge.%250AExisting%2520methods%2520typically%2520require%2520high%2520computational%2520costs%2520and%2520often%2520lack%250Asufficient%2520facial%2520detail%2520and%2520realism%252C%2520making%2520them%2520unsuitable%2520for%2520applications%250Athat%2520demand%2520high%2520real-time%2520performance%2520and%2520visual%2520quality.%2520Additionally%252C%2520while%250Asome%2520methods%2520can%2520synchronize%2520lip%2520movement%252C%2520they%2520still%2520face%2520issues%2520with%250Aconsistency%2520between%2520facial%2520expressions%2520and%2520upper%2520body%2520movement%252C%2520particularly%250Aduring%2520silent%2520periods.%2520In%2520this%2520paper%252C%2520we%2520introduce%2520SyncAnimation%252C%2520the%2520first%250ANeRF-based%2520method%2520that%2520achieves%2520audio-driven%252C%2520stable%252C%2520and%2520real-time%2520generation%250Aof%2520speaking%2520avatar%2520by%2520combining%2520generalized%2520audio-to-pose%2520matching%2520and%250Aaudio-to-expression%2520synchronization.%2520By%2520integrating%2520AudioPose%2520Syncer%2520and%250AAudioEmotion%2520Syncer%252C%2520SyncAnimation%2520achieves%2520high-precision%2520poses%2520and%2520expression%250Ageneration%252C%2520progressively%2520producing%2520audio-synchronized%2520upper%2520body%252C%2520head%252C%2520and%250Alip%2520shapes.%2520Furthermore%252C%2520the%2520High-Synchronization%2520Human%2520Renderer%2520ensures%250Aseamless%2520integration%2520of%2520the%2520head%2520and%2520upper%2520body%252C%2520and%2520achieves%2520audio-sync%2520lip.%250AThe%2520project%2520page%2520can%2520be%2520found%2520at%2520https%253A//syncanimation.github.io%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14646v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=SyncAnimation%3A%20A%20Real-Time%20End-to-End%20Framework%20for%20Audio-Driven%20Human%0A%20%20Pose%20and%20Talking%20Head%20Animation&entry.906535625=Yujian%20Liu%20and%20Shidang%20Xu%20and%20Jing%20Guo%20and%20Dingbin%20Wang%20and%20Zairan%20Wang%20and%20Xianfeng%20Tan%20and%20Xiaoli%20Liu&entry.1292438233=%20%20Generating%20talking%20avatar%20driven%20by%20audio%20remains%20a%20significant%20challenge.%0AExisting%20methods%20typically%20require%20high%20computational%20costs%20and%20often%20lack%0Asufficient%20facial%20detail%20and%20realism%2C%20making%20them%20unsuitable%20for%20applications%0Athat%20demand%20high%20real-time%20performance%20and%20visual%20quality.%20Additionally%2C%20while%0Asome%20methods%20can%20synchronize%20lip%20movement%2C%20they%20still%20face%20issues%20with%0Aconsistency%20between%20facial%20expressions%20and%20upper%20body%20movement%2C%20particularly%0Aduring%20silent%20periods.%20In%20this%20paper%2C%20we%20introduce%20SyncAnimation%2C%20the%20first%0ANeRF-based%20method%20that%20achieves%20audio-driven%2C%20stable%2C%20and%20real-time%20generation%0Aof%20speaking%20avatar%20by%20combining%20generalized%20audio-to-pose%20matching%20and%0Aaudio-to-expression%20synchronization.%20By%20integrating%20AudioPose%20Syncer%20and%0AAudioEmotion%20Syncer%2C%20SyncAnimation%20achieves%20high-precision%20poses%20and%20expression%0Ageneration%2C%20progressively%20producing%20audio-synchronized%20upper%20body%2C%20head%2C%20and%0Alip%20shapes.%20Furthermore%2C%20the%20High-Synchronization%20Human%20Renderer%20ensures%0Aseamless%20integration%20of%20the%20head%20and%20upper%20body%2C%20and%20achieves%20audio-sync%20lip.%0AThe%20project%20page%20can%20be%20found%20at%20https%3A//syncanimation.github.io%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14646v1&entry.124074799=Read"},
{"title": "Towards Unified Structured Light Optimization", "author": "Tinglei Wan and Tonghua Su and Zhongjie Wang", "abstract": "  Structured light (SL) 3D reconstruction captures the precise surface shape of\nobjects, providing high-accuracy 3D data essential for industrial inspection\nand robotic vision systems. However, current research on optimizing projection\npatterns in SL 3D reconstruction faces two main limitations: each scene\nrequires separate training of calibration parameters, and optimization is\nrestricted to specific types of SL, which restricts their application range. To\ntackle these limitations, we present a unified framework for SL optimization,\nadaptable to diverse lighting conditions, object types, and different types of\nSL. Our framework quickly determines the optimal projection pattern using only\na single projected image. Key contributions include a novel global matching\nmethod for projectors, enabling precise projector-camera alignment with just\none projected image, and a new projection compensation model with a photometric\nadjustment module to reduce artifacts from out-of-gamut clipping. Experimental\nresults show our method achieves superior decoding accuracy across various\nobjects, SL patterns, and lighting conditions, significantly outperforming\nprevious methods.\n", "link": "http://arxiv.org/abs/2501.14659v1", "date": "2025-01-24", "relevancy": 2.9573, "topK": [{"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.612}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5812}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5812}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Towards%20Unified%20Structured%20Light%20Optimization&body=Title%3A%20Towards%20Unified%20Structured%20Light%20Optimization%0AAuthor%3A%20Tinglei%20Wan%20and%20Tonghua%20Su%20and%20Zhongjie%20Wang%0AAbstract%3A%20%20%20Structured%20light%20%28SL%29%203D%20reconstruction%20captures%20the%20precise%20surface%20shape%20of%0Aobjects%2C%20providing%20high-accuracy%203D%20data%20essential%20for%20industrial%20inspection%0Aand%20robotic%20vision%20systems.%20However%2C%20current%20research%20on%20optimizing%20projection%0Apatterns%20in%20SL%203D%20reconstruction%20faces%20two%20main%20limitations%3A%20each%20scene%0Arequires%20separate%20training%20of%20calibration%20parameters%2C%20and%20optimization%20is%0Arestricted%20to%20specific%20types%20of%20SL%2C%20which%20restricts%20their%20application%20range.%20To%0Atackle%20these%20limitations%2C%20we%20present%20a%20unified%20framework%20for%20SL%20optimization%2C%0Aadaptable%20to%20diverse%20lighting%20conditions%2C%20object%20types%2C%20and%20different%20types%20of%0ASL.%20Our%20framework%20quickly%20determines%20the%20optimal%20projection%20pattern%20using%20only%0Aa%20single%20projected%20image.%20Key%20contributions%20include%20a%20novel%20global%20matching%0Amethod%20for%20projectors%2C%20enabling%20precise%20projector-camera%20alignment%20with%20just%0Aone%20projected%20image%2C%20and%20a%20new%20projection%20compensation%20model%20with%20a%20photometric%0Aadjustment%20module%20to%20reduce%20artifacts%20from%20out-of-gamut%20clipping.%20Experimental%0Aresults%20show%20our%20method%20achieves%20superior%20decoding%20accuracy%20across%20various%0Aobjects%2C%20SL%20patterns%2C%20and%20lighting%20conditions%2C%20significantly%20outperforming%0Aprevious%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14659v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTowards%2520Unified%2520Structured%2520Light%2520Optimization%26entry.906535625%3DTinglei%2520Wan%2520and%2520Tonghua%2520Su%2520and%2520Zhongjie%2520Wang%26entry.1292438233%3D%2520%2520Structured%2520light%2520%2528SL%2529%25203D%2520reconstruction%2520captures%2520the%2520precise%2520surface%2520shape%2520of%250Aobjects%252C%2520providing%2520high-accuracy%25203D%2520data%2520essential%2520for%2520industrial%2520inspection%250Aand%2520robotic%2520vision%2520systems.%2520However%252C%2520current%2520research%2520on%2520optimizing%2520projection%250Apatterns%2520in%2520SL%25203D%2520reconstruction%2520faces%2520two%2520main%2520limitations%253A%2520each%2520scene%250Arequires%2520separate%2520training%2520of%2520calibration%2520parameters%252C%2520and%2520optimization%2520is%250Arestricted%2520to%2520specific%2520types%2520of%2520SL%252C%2520which%2520restricts%2520their%2520application%2520range.%2520To%250Atackle%2520these%2520limitations%252C%2520we%2520present%2520a%2520unified%2520framework%2520for%2520SL%2520optimization%252C%250Aadaptable%2520to%2520diverse%2520lighting%2520conditions%252C%2520object%2520types%252C%2520and%2520different%2520types%2520of%250ASL.%2520Our%2520framework%2520quickly%2520determines%2520the%2520optimal%2520projection%2520pattern%2520using%2520only%250Aa%2520single%2520projected%2520image.%2520Key%2520contributions%2520include%2520a%2520novel%2520global%2520matching%250Amethod%2520for%2520projectors%252C%2520enabling%2520precise%2520projector-camera%2520alignment%2520with%2520just%250Aone%2520projected%2520image%252C%2520and%2520a%2520new%2520projection%2520compensation%2520model%2520with%2520a%2520photometric%250Aadjustment%2520module%2520to%2520reduce%2520artifacts%2520from%2520out-of-gamut%2520clipping.%2520Experimental%250Aresults%2520show%2520our%2520method%2520achieves%2520superior%2520decoding%2520accuracy%2520across%2520various%250Aobjects%252C%2520SL%2520patterns%252C%2520and%2520lighting%2520conditions%252C%2520significantly%2520outperforming%250Aprevious%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14659v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Towards%20Unified%20Structured%20Light%20Optimization&entry.906535625=Tinglei%20Wan%20and%20Tonghua%20Su%20and%20Zhongjie%20Wang&entry.1292438233=%20%20Structured%20light%20%28SL%29%203D%20reconstruction%20captures%20the%20precise%20surface%20shape%20of%0Aobjects%2C%20providing%20high-accuracy%203D%20data%20essential%20for%20industrial%20inspection%0Aand%20robotic%20vision%20systems.%20However%2C%20current%20research%20on%20optimizing%20projection%0Apatterns%20in%20SL%203D%20reconstruction%20faces%20two%20main%20limitations%3A%20each%20scene%0Arequires%20separate%20training%20of%20calibration%20parameters%2C%20and%20optimization%20is%0Arestricted%20to%20specific%20types%20of%20SL%2C%20which%20restricts%20their%20application%20range.%20To%0Atackle%20these%20limitations%2C%20we%20present%20a%20unified%20framework%20for%20SL%20optimization%2C%0Aadaptable%20to%20diverse%20lighting%20conditions%2C%20object%20types%2C%20and%20different%20types%20of%0ASL.%20Our%20framework%20quickly%20determines%20the%20optimal%20projection%20pattern%20using%20only%0Aa%20single%20projected%20image.%20Key%20contributions%20include%20a%20novel%20global%20matching%0Amethod%20for%20projectors%2C%20enabling%20precise%20projector-camera%20alignment%20with%20just%0Aone%20projected%20image%2C%20and%20a%20new%20projection%20compensation%20model%20with%20a%20photometric%0Aadjustment%20module%20to%20reduce%20artifacts%20from%20out-of-gamut%20clipping.%20Experimental%0Aresults%20show%20our%20method%20achieves%20superior%20decoding%20accuracy%20across%20various%0Aobjects%2C%20SL%20patterns%2C%20and%20lighting%20conditions%2C%20significantly%20outperforming%0Aprevious%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14659v1&entry.124074799=Read"},
{"title": "Large-scale and Fine-grained Vision-language Pre-training for Enhanced\n  CT Image Understanding", "author": "Zhongyi Shui and Jianpeng Zhang and Weiwei Cao and Sinuo Wang and Ruizhe Guo and Le Lu and Lin Yang and Xianghua Ye and Tingbo Liang and Qi Zhang and Ling Zhang", "abstract": "  Artificial intelligence (AI) shows great potential in assisting radiologists\nto improve the efficiency and accuracy of medical image interpretation and\ndiagnosis. However, a versatile AI model requires large-scale data and\ncomprehensive annotations, which are often impractical in medical settings.\nRecent studies leverage radiology reports as a naturally high-quality\nsupervision for medical images, using contrastive language-image pre-training\n(CLIP) to develop language-informed models for radiological image\ninterpretation. Nonetheless, these approaches typically contrast entire images\nwith reports, neglecting the local associations between imaging regions and\nreport sentences, which may undermine model performance and interoperability.\nIn this paper, we propose a fine-grained vision-language model (fVLM) for\nanatomy-level CT image interpretation. Specifically, we explicitly match\nanatomical regions of CT images with corresponding descriptions in radiology\nreports and perform contrastive pre-training for each anatomy individually.\nFine-grained alignment, however, faces considerable false-negative challenges,\nmainly from the abundance of anatomy-level healthy samples and similarly\ndiseased abnormalities. To tackle this issue, we propose identifying false\nnegatives of both normal and abnormal samples and calibrating contrastive\nlearning from patient-level to disease-aware pairing. We curated the largest CT\ndataset to date, comprising imaging and report data from 69,086 patients, and\nconducted a comprehensive evaluation of 54 major and important disease\ndiagnosis tasks across 15 main anatomies. Experimental results demonstrate the\nsubstantial potential of fVLM in versatile medical image interpretation. In the\nzero-shot classification task, we achieved an average AUC of 81.3% on 54\ndiagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%,\nrespectively.\n", "link": "http://arxiv.org/abs/2501.14548v1", "date": "2025-01-24", "relevancy": 2.9064, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5903}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5767}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5767}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Large-scale%20and%20Fine-grained%20Vision-language%20Pre-training%20for%20Enhanced%0A%20%20CT%20Image%20Understanding&body=Title%3A%20Large-scale%20and%20Fine-grained%20Vision-language%20Pre-training%20for%20Enhanced%0A%20%20CT%20Image%20Understanding%0AAuthor%3A%20Zhongyi%20Shui%20and%20Jianpeng%20Zhang%20and%20Weiwei%20Cao%20and%20Sinuo%20Wang%20and%20Ruizhe%20Guo%20and%20Le%20Lu%20and%20Lin%20Yang%20and%20Xianghua%20Ye%20and%20Tingbo%20Liang%20and%20Qi%20Zhang%20and%20Ling%20Zhang%0AAbstract%3A%20%20%20Artificial%20intelligence%20%28AI%29%20shows%20great%20potential%20in%20assisting%20radiologists%0Ato%20improve%20the%20efficiency%20and%20accuracy%20of%20medical%20image%20interpretation%20and%0Adiagnosis.%20However%2C%20a%20versatile%20AI%20model%20requires%20large-scale%20data%20and%0Acomprehensive%20annotations%2C%20which%20are%20often%20impractical%20in%20medical%20settings.%0ARecent%20studies%20leverage%20radiology%20reports%20as%20a%20naturally%20high-quality%0Asupervision%20for%20medical%20images%2C%20using%20contrastive%20language-image%20pre-training%0A%28CLIP%29%20to%20develop%20language-informed%20models%20for%20radiological%20image%0Ainterpretation.%20Nonetheless%2C%20these%20approaches%20typically%20contrast%20entire%20images%0Awith%20reports%2C%20neglecting%20the%20local%20associations%20between%20imaging%20regions%20and%0Areport%20sentences%2C%20which%20may%20undermine%20model%20performance%20and%20interoperability.%0AIn%20this%20paper%2C%20we%20propose%20a%20fine-grained%20vision-language%20model%20%28fVLM%29%20for%0Aanatomy-level%20CT%20image%20interpretation.%20Specifically%2C%20we%20explicitly%20match%0Aanatomical%20regions%20of%20CT%20images%20with%20corresponding%20descriptions%20in%20radiology%0Areports%20and%20perform%20contrastive%20pre-training%20for%20each%20anatomy%20individually.%0AFine-grained%20alignment%2C%20however%2C%20faces%20considerable%20false-negative%20challenges%2C%0Amainly%20from%20the%20abundance%20of%20anatomy-level%20healthy%20samples%20and%20similarly%0Adiseased%20abnormalities.%20To%20tackle%20this%20issue%2C%20we%20propose%20identifying%20false%0Anegatives%20of%20both%20normal%20and%20abnormal%20samples%20and%20calibrating%20contrastive%0Alearning%20from%20patient-level%20to%20disease-aware%20pairing.%20We%20curated%20the%20largest%20CT%0Adataset%20to%20date%2C%20comprising%20imaging%20and%20report%20data%20from%2069%2C086%20patients%2C%20and%0Aconducted%20a%20comprehensive%20evaluation%20of%2054%20major%20and%20important%20disease%0Adiagnosis%20tasks%20across%2015%20main%20anatomies.%20Experimental%20results%20demonstrate%20the%0Asubstantial%20potential%20of%20fVLM%20in%20versatile%20medical%20image%20interpretation.%20In%20the%0Azero-shot%20classification%20task%2C%20we%20achieved%20an%20average%20AUC%20of%2081.3%25%20on%2054%0Adiagnosis%20tasks%2C%20surpassing%20CLIP%20and%20supervised%20methods%20by%2012.9%25%20and%208.0%25%2C%0Arespectively.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14548v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLarge-scale%2520and%2520Fine-grained%2520Vision-language%2520Pre-training%2520for%2520Enhanced%250A%2520%2520CT%2520Image%2520Understanding%26entry.906535625%3DZhongyi%2520Shui%2520and%2520Jianpeng%2520Zhang%2520and%2520Weiwei%2520Cao%2520and%2520Sinuo%2520Wang%2520and%2520Ruizhe%2520Guo%2520and%2520Le%2520Lu%2520and%2520Lin%2520Yang%2520and%2520Xianghua%2520Ye%2520and%2520Tingbo%2520Liang%2520and%2520Qi%2520Zhang%2520and%2520Ling%2520Zhang%26entry.1292438233%3D%2520%2520Artificial%2520intelligence%2520%2528AI%2529%2520shows%2520great%2520potential%2520in%2520assisting%2520radiologists%250Ato%2520improve%2520the%2520efficiency%2520and%2520accuracy%2520of%2520medical%2520image%2520interpretation%2520and%250Adiagnosis.%2520However%252C%2520a%2520versatile%2520AI%2520model%2520requires%2520large-scale%2520data%2520and%250Acomprehensive%2520annotations%252C%2520which%2520are%2520often%2520impractical%2520in%2520medical%2520settings.%250ARecent%2520studies%2520leverage%2520radiology%2520reports%2520as%2520a%2520naturally%2520high-quality%250Asupervision%2520for%2520medical%2520images%252C%2520using%2520contrastive%2520language-image%2520pre-training%250A%2528CLIP%2529%2520to%2520develop%2520language-informed%2520models%2520for%2520radiological%2520image%250Ainterpretation.%2520Nonetheless%252C%2520these%2520approaches%2520typically%2520contrast%2520entire%2520images%250Awith%2520reports%252C%2520neglecting%2520the%2520local%2520associations%2520between%2520imaging%2520regions%2520and%250Areport%2520sentences%252C%2520which%2520may%2520undermine%2520model%2520performance%2520and%2520interoperability.%250AIn%2520this%2520paper%252C%2520we%2520propose%2520a%2520fine-grained%2520vision-language%2520model%2520%2528fVLM%2529%2520for%250Aanatomy-level%2520CT%2520image%2520interpretation.%2520Specifically%252C%2520we%2520explicitly%2520match%250Aanatomical%2520regions%2520of%2520CT%2520images%2520with%2520corresponding%2520descriptions%2520in%2520radiology%250Areports%2520and%2520perform%2520contrastive%2520pre-training%2520for%2520each%2520anatomy%2520individually.%250AFine-grained%2520alignment%252C%2520however%252C%2520faces%2520considerable%2520false-negative%2520challenges%252C%250Amainly%2520from%2520the%2520abundance%2520of%2520anatomy-level%2520healthy%2520samples%2520and%2520similarly%250Adiseased%2520abnormalities.%2520To%2520tackle%2520this%2520issue%252C%2520we%2520propose%2520identifying%2520false%250Anegatives%2520of%2520both%2520normal%2520and%2520abnormal%2520samples%2520and%2520calibrating%2520contrastive%250Alearning%2520from%2520patient-level%2520to%2520disease-aware%2520pairing.%2520We%2520curated%2520the%2520largest%2520CT%250Adataset%2520to%2520date%252C%2520comprising%2520imaging%2520and%2520report%2520data%2520from%252069%252C086%2520patients%252C%2520and%250Aconducted%2520a%2520comprehensive%2520evaluation%2520of%252054%2520major%2520and%2520important%2520disease%250Adiagnosis%2520tasks%2520across%252015%2520main%2520anatomies.%2520Experimental%2520results%2520demonstrate%2520the%250Asubstantial%2520potential%2520of%2520fVLM%2520in%2520versatile%2520medical%2520image%2520interpretation.%2520In%2520the%250Azero-shot%2520classification%2520task%252C%2520we%2520achieved%2520an%2520average%2520AUC%2520of%252081.3%2525%2520on%252054%250Adiagnosis%2520tasks%252C%2520surpassing%2520CLIP%2520and%2520supervised%2520methods%2520by%252012.9%2525%2520and%25208.0%2525%252C%250Arespectively.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14548v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Large-scale%20and%20Fine-grained%20Vision-language%20Pre-training%20for%20Enhanced%0A%20%20CT%20Image%20Understanding&entry.906535625=Zhongyi%20Shui%20and%20Jianpeng%20Zhang%20and%20Weiwei%20Cao%20and%20Sinuo%20Wang%20and%20Ruizhe%20Guo%20and%20Le%20Lu%20and%20Lin%20Yang%20and%20Xianghua%20Ye%20and%20Tingbo%20Liang%20and%20Qi%20Zhang%20and%20Ling%20Zhang&entry.1292438233=%20%20Artificial%20intelligence%20%28AI%29%20shows%20great%20potential%20in%20assisting%20radiologists%0Ato%20improve%20the%20efficiency%20and%20accuracy%20of%20medical%20image%20interpretation%20and%0Adiagnosis.%20However%2C%20a%20versatile%20AI%20model%20requires%20large-scale%20data%20and%0Acomprehensive%20annotations%2C%20which%20are%20often%20impractical%20in%20medical%20settings.%0ARecent%20studies%20leverage%20radiology%20reports%20as%20a%20naturally%20high-quality%0Asupervision%20for%20medical%20images%2C%20using%20contrastive%20language-image%20pre-training%0A%28CLIP%29%20to%20develop%20language-informed%20models%20for%20radiological%20image%0Ainterpretation.%20Nonetheless%2C%20these%20approaches%20typically%20contrast%20entire%20images%0Awith%20reports%2C%20neglecting%20the%20local%20associations%20between%20imaging%20regions%20and%0Areport%20sentences%2C%20which%20may%20undermine%20model%20performance%20and%20interoperability.%0AIn%20this%20paper%2C%20we%20propose%20a%20fine-grained%20vision-language%20model%20%28fVLM%29%20for%0Aanatomy-level%20CT%20image%20interpretation.%20Specifically%2C%20we%20explicitly%20match%0Aanatomical%20regions%20of%20CT%20images%20with%20corresponding%20descriptions%20in%20radiology%0Areports%20and%20perform%20contrastive%20pre-training%20for%20each%20anatomy%20individually.%0AFine-grained%20alignment%2C%20however%2C%20faces%20considerable%20false-negative%20challenges%2C%0Amainly%20from%20the%20abundance%20of%20anatomy-level%20healthy%20samples%20and%20similarly%0Adiseased%20abnormalities.%20To%20tackle%20this%20issue%2C%20we%20propose%20identifying%20false%0Anegatives%20of%20both%20normal%20and%20abnormal%20samples%20and%20calibrating%20contrastive%0Alearning%20from%20patient-level%20to%20disease-aware%20pairing.%20We%20curated%20the%20largest%20CT%0Adataset%20to%20date%2C%20comprising%20imaging%20and%20report%20data%20from%2069%2C086%20patients%2C%20and%0Aconducted%20a%20comprehensive%20evaluation%20of%2054%20major%20and%20important%20disease%0Adiagnosis%20tasks%20across%2015%20main%20anatomies.%20Experimental%20results%20demonstrate%20the%0Asubstantial%20potential%20of%20fVLM%20in%20versatile%20medical%20image%20interpretation.%20In%20the%0Azero-shot%20classification%20task%2C%20we%20achieved%20an%20average%20AUC%20of%2081.3%25%20on%2054%0Adiagnosis%20tasks%2C%20surpassing%20CLIP%20and%20supervised%20methods%20by%2012.9%25%20and%208.0%25%2C%0Arespectively.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14548v1&entry.124074799=Read"},
{"title": "HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene\n  Understanding and Generation", "author": "Xin Zhou and Dingkang Liang and Sifan Tu and Xiwu Chen and Yikang Ding and Dingyuan Zhang and Feiyang Tan and Hengshuang Zhao and Xiang Bai", "abstract": "  Driving World Models (DWMs) have become essential for autonomous driving by\nenabling future scene prediction. However, existing DWMs are limited to scene\ngeneration and fail to incorporate scene understanding, which involves\ninterpreting and reasoning about the driving environment. In this paper, we\npresent a unified Driving World Model named HERMES. We seamlessly integrate 3D\nscene understanding and future scene evolution (generation) through a unified\nframework in driving scenarios. Specifically, HERMES leverages a Bird's-Eye\nView (BEV) representation to consolidate multi-view spatial information while\npreserving geometric relationships and interactions. We also introduce world\nqueries, which incorporate world knowledge into BEV features via causal\nattention in the Large Language Model (LLM), enabling contextual enrichment for\nunderstanding and generation tasks. We conduct comprehensive studies on\nnuScenes and OmniDrive-nuScenes datasets to validate the effectiveness of our\nmethod. HERMES achieves state-of-the-art performance, reducing generation error\nby 32.4% and improving understanding metrics such as CIDEr by 8.0%. The model\nand code will be publicly released at https://github.com/LMD0311/HERMES.\n", "link": "http://arxiv.org/abs/2501.14729v1", "date": "2025-01-24", "relevancy": 2.8291, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5831}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5831}, {"title": "Synthesizing Moving People with 3D Control", "link": "http://arxiv.org/abs/2401.10889v2", "similarity": 0.5313}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20HERMES%3A%20A%20Unified%20Self-Driving%20World%20Model%20for%20Simultaneous%203D%20Scene%0A%20%20Understanding%20and%20Generation&body=Title%3A%20HERMES%3A%20A%20Unified%20Self-Driving%20World%20Model%20for%20Simultaneous%203D%20Scene%0A%20%20Understanding%20and%20Generation%0AAuthor%3A%20Xin%20Zhou%20and%20Dingkang%20Liang%20and%20Sifan%20Tu%20and%20Xiwu%20Chen%20and%20Yikang%20Ding%20and%20Dingyuan%20Zhang%20and%20Feiyang%20Tan%20and%20Hengshuang%20Zhao%20and%20Xiang%20Bai%0AAbstract%3A%20%20%20Driving%20World%20Models%20%28DWMs%29%20have%20become%20essential%20for%20autonomous%20driving%20by%0Aenabling%20future%20scene%20prediction.%20However%2C%20existing%20DWMs%20are%20limited%20to%20scene%0Ageneration%20and%20fail%20to%20incorporate%20scene%20understanding%2C%20which%20involves%0Ainterpreting%20and%20reasoning%20about%20the%20driving%20environment.%20In%20this%20paper%2C%20we%0Apresent%20a%20unified%20Driving%20World%20Model%20named%20HERMES.%20We%20seamlessly%20integrate%203D%0Ascene%20understanding%20and%20future%20scene%20evolution%20%28generation%29%20through%20a%20unified%0Aframework%20in%20driving%20scenarios.%20Specifically%2C%20HERMES%20leverages%20a%20Bird%27s-Eye%0AView%20%28BEV%29%20representation%20to%20consolidate%20multi-view%20spatial%20information%20while%0Apreserving%20geometric%20relationships%20and%20interactions.%20We%20also%20introduce%20world%0Aqueries%2C%20which%20incorporate%20world%20knowledge%20into%20BEV%20features%20via%20causal%0Aattention%20in%20the%20Large%20Language%20Model%20%28LLM%29%2C%20enabling%20contextual%20enrichment%20for%0Aunderstanding%20and%20generation%20tasks.%20We%20conduct%20comprehensive%20studies%20on%0AnuScenes%20and%20OmniDrive-nuScenes%20datasets%20to%20validate%20the%20effectiveness%20of%20our%0Amethod.%20HERMES%20achieves%20state-of-the-art%20performance%2C%20reducing%20generation%20error%0Aby%2032.4%25%20and%20improving%20understanding%20metrics%20such%20as%20CIDEr%20by%208.0%25.%20The%20model%0Aand%20code%20will%20be%20publicly%20released%20at%20https%3A//github.com/LMD0311/HERMES.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14729v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DHERMES%253A%2520A%2520Unified%2520Self-Driving%2520World%2520Model%2520for%2520Simultaneous%25203D%2520Scene%250A%2520%2520Understanding%2520and%2520Generation%26entry.906535625%3DXin%2520Zhou%2520and%2520Dingkang%2520Liang%2520and%2520Sifan%2520Tu%2520and%2520Xiwu%2520Chen%2520and%2520Yikang%2520Ding%2520and%2520Dingyuan%2520Zhang%2520and%2520Feiyang%2520Tan%2520and%2520Hengshuang%2520Zhao%2520and%2520Xiang%2520Bai%26entry.1292438233%3D%2520%2520Driving%2520World%2520Models%2520%2528DWMs%2529%2520have%2520become%2520essential%2520for%2520autonomous%2520driving%2520by%250Aenabling%2520future%2520scene%2520prediction.%2520However%252C%2520existing%2520DWMs%2520are%2520limited%2520to%2520scene%250Ageneration%2520and%2520fail%2520to%2520incorporate%2520scene%2520understanding%252C%2520which%2520involves%250Ainterpreting%2520and%2520reasoning%2520about%2520the%2520driving%2520environment.%2520In%2520this%2520paper%252C%2520we%250Apresent%2520a%2520unified%2520Driving%2520World%2520Model%2520named%2520HERMES.%2520We%2520seamlessly%2520integrate%25203D%250Ascene%2520understanding%2520and%2520future%2520scene%2520evolution%2520%2528generation%2529%2520through%2520a%2520unified%250Aframework%2520in%2520driving%2520scenarios.%2520Specifically%252C%2520HERMES%2520leverages%2520a%2520Bird%2527s-Eye%250AView%2520%2528BEV%2529%2520representation%2520to%2520consolidate%2520multi-view%2520spatial%2520information%2520while%250Apreserving%2520geometric%2520relationships%2520and%2520interactions.%2520We%2520also%2520introduce%2520world%250Aqueries%252C%2520which%2520incorporate%2520world%2520knowledge%2520into%2520BEV%2520features%2520via%2520causal%250Aattention%2520in%2520the%2520Large%2520Language%2520Model%2520%2528LLM%2529%252C%2520enabling%2520contextual%2520enrichment%2520for%250Aunderstanding%2520and%2520generation%2520tasks.%2520We%2520conduct%2520comprehensive%2520studies%2520on%250AnuScenes%2520and%2520OmniDrive-nuScenes%2520datasets%2520to%2520validate%2520the%2520effectiveness%2520of%2520our%250Amethod.%2520HERMES%2520achieves%2520state-of-the-art%2520performance%252C%2520reducing%2520generation%2520error%250Aby%252032.4%2525%2520and%2520improving%2520understanding%2520metrics%2520such%2520as%2520CIDEr%2520by%25208.0%2525.%2520The%2520model%250Aand%2520code%2520will%2520be%2520publicly%2520released%2520at%2520https%253A//github.com/LMD0311/HERMES.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14729v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=HERMES%3A%20A%20Unified%20Self-Driving%20World%20Model%20for%20Simultaneous%203D%20Scene%0A%20%20Understanding%20and%20Generation&entry.906535625=Xin%20Zhou%20and%20Dingkang%20Liang%20and%20Sifan%20Tu%20and%20Xiwu%20Chen%20and%20Yikang%20Ding%20and%20Dingyuan%20Zhang%20and%20Feiyang%20Tan%20and%20Hengshuang%20Zhao%20and%20Xiang%20Bai&entry.1292438233=%20%20Driving%20World%20Models%20%28DWMs%29%20have%20become%20essential%20for%20autonomous%20driving%20by%0Aenabling%20future%20scene%20prediction.%20However%2C%20existing%20DWMs%20are%20limited%20to%20scene%0Ageneration%20and%20fail%20to%20incorporate%20scene%20understanding%2C%20which%20involves%0Ainterpreting%20and%20reasoning%20about%20the%20driving%20environment.%20In%20this%20paper%2C%20we%0Apresent%20a%20unified%20Driving%20World%20Model%20named%20HERMES.%20We%20seamlessly%20integrate%203D%0Ascene%20understanding%20and%20future%20scene%20evolution%20%28generation%29%20through%20a%20unified%0Aframework%20in%20driving%20scenarios.%20Specifically%2C%20HERMES%20leverages%20a%20Bird%27s-Eye%0AView%20%28BEV%29%20representation%20to%20consolidate%20multi-view%20spatial%20information%20while%0Apreserving%20geometric%20relationships%20and%20interactions.%20We%20also%20introduce%20world%0Aqueries%2C%20which%20incorporate%20world%20knowledge%20into%20BEV%20features%20via%20causal%0Aattention%20in%20the%20Large%20Language%20Model%20%28LLM%29%2C%20enabling%20contextual%20enrichment%20for%0Aunderstanding%20and%20generation%20tasks.%20We%20conduct%20comprehensive%20studies%20on%0AnuScenes%20and%20OmniDrive-nuScenes%20datasets%20to%20validate%20the%20effectiveness%20of%20our%0Amethod.%20HERMES%20achieves%20state-of-the-art%20performance%2C%20reducing%20generation%20error%0Aby%2032.4%25%20and%20improving%20understanding%20metrics%20such%20as%20CIDEr%20by%208.0%25.%20The%20model%0Aand%20code%20will%20be%20publicly%20released%20at%20https%3A//github.com/LMD0311/HERMES.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14729v1&entry.124074799=Read"},
{"title": "ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image\n  Captioning", "author": "Taewhan Kim and Soeun Lee and Si-Woo Kim and Dong-Jin Kim", "abstract": "  Recent lightweight image captioning models using retrieved data mainly focus\non text prompts. However, previous works only utilize the retrieved text as\ntext prompts, and the visual information relies only on the CLIP visual\nembedding. Because of this issue, there is a limitation that the image\ndescriptions inherent in the prompt are not sufficiently reflected in the\nvisual embedding space. To tackle this issue, we propose ViPCap, a novel\nretrieval text-based visual prompt for lightweight image captioning. ViPCap\nleverages the retrieved text with image information as visual prompts to\nenhance the ability of the model to capture relevant visual information. By\nmapping text prompts into the CLIP space and generating multiple randomized\nGaussian distributions, our method leverages sampling to explore randomly\naugmented distributions and effectively retrieves the semantic features that\ncontain image information. These retrieved features are integrated into the\nimage and designated as the visual prompt, leading to performance improvements\non the datasets such as COCO, Flickr30k, and NoCaps. Experimental results\ndemonstrate that ViPCap significantly outperforms prior lightweight captioning\nmodels in efficiency and effectiveness, demonstrating the potential for a\nplug-and-play solution. The source code is available at\nhttps://github.com/taewhankim/VIPCAP.\n", "link": "http://arxiv.org/abs/2412.19289v3", "date": "2025-01-24", "relevancy": 2.6963, "topK": [{"title": "Magic-Me: Identity-Specific Video Customized Diffusion", "link": "http://arxiv.org/abs/2402.09368v1", "similarity": 0.5572}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5359}, {"title": "VirtualModel: Generating Object-ID-retentive Human-object Interaction\n  Image by Diffusion Model for E-commerce Marketing", "link": "http://arxiv.org/abs/2405.09985v1", "similarity": 0.5247}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ViPCap%3A%20Retrieval%20Text-Based%20Visual%20Prompts%20for%20Lightweight%20Image%0A%20%20Captioning&body=Title%3A%20ViPCap%3A%20Retrieval%20Text-Based%20Visual%20Prompts%20for%20Lightweight%20Image%0A%20%20Captioning%0AAuthor%3A%20Taewhan%20Kim%20and%20Soeun%20Lee%20and%20Si-Woo%20Kim%20and%20Dong-Jin%20Kim%0AAbstract%3A%20%20%20Recent%20lightweight%20image%20captioning%20models%20using%20retrieved%20data%20mainly%20focus%0Aon%20text%20prompts.%20However%2C%20previous%20works%20only%20utilize%20the%20retrieved%20text%20as%0Atext%20prompts%2C%20and%20the%20visual%20information%20relies%20only%20on%20the%20CLIP%20visual%0Aembedding.%20Because%20of%20this%20issue%2C%20there%20is%20a%20limitation%20that%20the%20image%0Adescriptions%20inherent%20in%20the%20prompt%20are%20not%20sufficiently%20reflected%20in%20the%0Avisual%20embedding%20space.%20To%20tackle%20this%20issue%2C%20we%20propose%20ViPCap%2C%20a%20novel%0Aretrieval%20text-based%20visual%20prompt%20for%20lightweight%20image%20captioning.%20ViPCap%0Aleverages%20the%20retrieved%20text%20with%20image%20information%20as%20visual%20prompts%20to%0Aenhance%20the%20ability%20of%20the%20model%20to%20capture%20relevant%20visual%20information.%20By%0Amapping%20text%20prompts%20into%20the%20CLIP%20space%20and%20generating%20multiple%20randomized%0AGaussian%20distributions%2C%20our%20method%20leverages%20sampling%20to%20explore%20randomly%0Aaugmented%20distributions%20and%20effectively%20retrieves%20the%20semantic%20features%20that%0Acontain%20image%20information.%20These%20retrieved%20features%20are%20integrated%20into%20the%0Aimage%20and%20designated%20as%20the%20visual%20prompt%2C%20leading%20to%20performance%20improvements%0Aon%20the%20datasets%20such%20as%20COCO%2C%20Flickr30k%2C%20and%20NoCaps.%20Experimental%20results%0Ademonstrate%20that%20ViPCap%20significantly%20outperforms%20prior%20lightweight%20captioning%0Amodels%20in%20efficiency%20and%20effectiveness%2C%20demonstrating%20the%20potential%20for%20a%0Aplug-and-play%20solution.%20The%20source%20code%20is%20available%20at%0Ahttps%3A//github.com/taewhankim/VIPCAP.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2412.19289v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DViPCap%253A%2520Retrieval%2520Text-Based%2520Visual%2520Prompts%2520for%2520Lightweight%2520Image%250A%2520%2520Captioning%26entry.906535625%3DTaewhan%2520Kim%2520and%2520Soeun%2520Lee%2520and%2520Si-Woo%2520Kim%2520and%2520Dong-Jin%2520Kim%26entry.1292438233%3D%2520%2520Recent%2520lightweight%2520image%2520captioning%2520models%2520using%2520retrieved%2520data%2520mainly%2520focus%250Aon%2520text%2520prompts.%2520However%252C%2520previous%2520works%2520only%2520utilize%2520the%2520retrieved%2520text%2520as%250Atext%2520prompts%252C%2520and%2520the%2520visual%2520information%2520relies%2520only%2520on%2520the%2520CLIP%2520visual%250Aembedding.%2520Because%2520of%2520this%2520issue%252C%2520there%2520is%2520a%2520limitation%2520that%2520the%2520image%250Adescriptions%2520inherent%2520in%2520the%2520prompt%2520are%2520not%2520sufficiently%2520reflected%2520in%2520the%250Avisual%2520embedding%2520space.%2520To%2520tackle%2520this%2520issue%252C%2520we%2520propose%2520ViPCap%252C%2520a%2520novel%250Aretrieval%2520text-based%2520visual%2520prompt%2520for%2520lightweight%2520image%2520captioning.%2520ViPCap%250Aleverages%2520the%2520retrieved%2520text%2520with%2520image%2520information%2520as%2520visual%2520prompts%2520to%250Aenhance%2520the%2520ability%2520of%2520the%2520model%2520to%2520capture%2520relevant%2520visual%2520information.%2520By%250Amapping%2520text%2520prompts%2520into%2520the%2520CLIP%2520space%2520and%2520generating%2520multiple%2520randomized%250AGaussian%2520distributions%252C%2520our%2520method%2520leverages%2520sampling%2520to%2520explore%2520randomly%250Aaugmented%2520distributions%2520and%2520effectively%2520retrieves%2520the%2520semantic%2520features%2520that%250Acontain%2520image%2520information.%2520These%2520retrieved%2520features%2520are%2520integrated%2520into%2520the%250Aimage%2520and%2520designated%2520as%2520the%2520visual%2520prompt%252C%2520leading%2520to%2520performance%2520improvements%250Aon%2520the%2520datasets%2520such%2520as%2520COCO%252C%2520Flickr30k%252C%2520and%2520NoCaps.%2520Experimental%2520results%250Ademonstrate%2520that%2520ViPCap%2520significantly%2520outperforms%2520prior%2520lightweight%2520captioning%250Amodels%2520in%2520efficiency%2520and%2520effectiveness%252C%2520demonstrating%2520the%2520potential%2520for%2520a%250Aplug-and-play%2520solution.%2520The%2520source%2520code%2520is%2520available%2520at%250Ahttps%253A//github.com/taewhankim/VIPCAP.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2412.19289v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ViPCap%3A%20Retrieval%20Text-Based%20Visual%20Prompts%20for%20Lightweight%20Image%0A%20%20Captioning&entry.906535625=Taewhan%20Kim%20and%20Soeun%20Lee%20and%20Si-Woo%20Kim%20and%20Dong-Jin%20Kim&entry.1292438233=%20%20Recent%20lightweight%20image%20captioning%20models%20using%20retrieved%20data%20mainly%20focus%0Aon%20text%20prompts.%20However%2C%20previous%20works%20only%20utilize%20the%20retrieved%20text%20as%0Atext%20prompts%2C%20and%20the%20visual%20information%20relies%20only%20on%20the%20CLIP%20visual%0Aembedding.%20Because%20of%20this%20issue%2C%20there%20is%20a%20limitation%20that%20the%20image%0Adescriptions%20inherent%20in%20the%20prompt%20are%20not%20sufficiently%20reflected%20in%20the%0Avisual%20embedding%20space.%20To%20tackle%20this%20issue%2C%20we%20propose%20ViPCap%2C%20a%20novel%0Aretrieval%20text-based%20visual%20prompt%20for%20lightweight%20image%20captioning.%20ViPCap%0Aleverages%20the%20retrieved%20text%20with%20image%20information%20as%20visual%20prompts%20to%0Aenhance%20the%20ability%20of%20the%20model%20to%20capture%20relevant%20visual%20information.%20By%0Amapping%20text%20prompts%20into%20the%20CLIP%20space%20and%20generating%20multiple%20randomized%0AGaussian%20distributions%2C%20our%20method%20leverages%20sampling%20to%20explore%20randomly%0Aaugmented%20distributions%20and%20effectively%20retrieves%20the%20semantic%20features%20that%0Acontain%20image%20information.%20These%20retrieved%20features%20are%20integrated%20into%20the%0Aimage%20and%20designated%20as%20the%20visual%20prompt%2C%20leading%20to%20performance%20improvements%0Aon%20the%20datasets%20such%20as%20COCO%2C%20Flickr30k%2C%20and%20NoCaps.%20Experimental%20results%0Ademonstrate%20that%20ViPCap%20significantly%20outperforms%20prior%20lightweight%20captioning%0Amodels%20in%20efficiency%20and%20effectiveness%2C%20demonstrating%20the%20potential%20for%20a%0Aplug-and-play%20solution.%20The%20source%20code%20is%20available%20at%0Ahttps%3A//github.com/taewhankim/VIPCAP.%0A&entry.1838667208=http%3A//arxiv.org/abs/2412.19289v3&entry.124074799=Read"},
{"title": "Federated Domain Generalization with Data-free On-server Gradient\n  Matching", "author": "Trong-Binh Nguyen and Minh-Duong Nguyen and Jinsun Park and Quoc-Viet Pham and Won Joo Hwang", "abstract": "  Domain Generalization (DG) aims to learn from multiple known source domains a\nmodel that can generalize well to unknown target domains. One of the key\napproaches in DG is training an encoder which generates domain-invariant\nrepresentations. However, this approach is not applicable in Federated Domain\nGeneralization (FDG), where data from various domains are distributed across\ndifferent clients. In this paper, we introduce a novel approach, dubbed\nFederated Learning via On-server Matching Gradient (FedOMG), which can\n\\emph{efficiently leverage domain information from distributed domains}.\nSpecifically, we utilize the local gradients as information about the\ndistributed models to find an invariant gradient direction across all domains\nthrough gradient inner product maximization. The advantages are two-fold: 1)\nFedOMG can aggregate the characteristics of distributed models on the\ncentralized server without incurring any additional communication cost, and 2)\nFedOMG is orthogonal to many existing FL/FDG methods, allowing for additional\nperformance improvements by being seamlessly integrated with them. Extensive\nexperimental evaluations on various settings to demonstrate the robustness of\nFedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA\nbaselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and\nCIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).\n", "link": "http://arxiv.org/abs/2501.14653v1", "date": "2025-01-24", "relevancy": 2.6053, "topK": [{"title": "UGG: Unified Generative Grasping", "link": "https://arxiv.org/abs/2311.16917", "similarity": 0.5325}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.5198}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.5108}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Federated%20Domain%20Generalization%20with%20Data-free%20On-server%20Gradient%0A%20%20Matching&body=Title%3A%20Federated%20Domain%20Generalization%20with%20Data-free%20On-server%20Gradient%0A%20%20Matching%0AAuthor%3A%20Trong-Binh%20Nguyen%20and%20Minh-Duong%20Nguyen%20and%20Jinsun%20Park%20and%20Quoc-Viet%20Pham%20and%20Won%20Joo%20Hwang%0AAbstract%3A%20%20%20Domain%20Generalization%20%28DG%29%20aims%20to%20learn%20from%20multiple%20known%20source%20domains%20a%0Amodel%20that%20can%20generalize%20well%20to%20unknown%20target%20domains.%20One%20of%20the%20key%0Aapproaches%20in%20DG%20is%20training%20an%20encoder%20which%20generates%20domain-invariant%0Arepresentations.%20However%2C%20this%20approach%20is%20not%20applicable%20in%20Federated%20Domain%0AGeneralization%20%28FDG%29%2C%20where%20data%20from%20various%20domains%20are%20distributed%20across%0Adifferent%20clients.%20In%20this%20paper%2C%20we%20introduce%20a%20novel%20approach%2C%20dubbed%0AFederated%20Learning%20via%20On-server%20Matching%20Gradient%20%28FedOMG%29%2C%20which%20can%0A%5Cemph%7Befficiently%20leverage%20domain%20information%20from%20distributed%20domains%7D.%0ASpecifically%2C%20we%20utilize%20the%20local%20gradients%20as%20information%20about%20the%0Adistributed%20models%20to%20find%20an%20invariant%20gradient%20direction%20across%20all%20domains%0Athrough%20gradient%20inner%20product%20maximization.%20The%20advantages%20are%20two-fold%3A%201%29%0AFedOMG%20can%20aggregate%20the%20characteristics%20of%20distributed%20models%20on%20the%0Acentralized%20server%20without%20incurring%20any%20additional%20communication%20cost%2C%20and%202%29%0AFedOMG%20is%20orthogonal%20to%20many%20existing%20FL/FDG%20methods%2C%20allowing%20for%20additional%0Aperformance%20improvements%20by%20being%20seamlessly%20integrated%20with%20them.%20Extensive%0Aexperimental%20evaluations%20on%20various%20settings%20to%20demonstrate%20the%20robustness%20of%0AFedOMG%20compared%20to%20other%20FL/FDG%20baselines.%20Our%20method%20outperforms%20recent%20SOTA%0Abaselines%20on%20four%20FL%20benchmark%20datasets%20%28MNIST%2C%20EMNIST%2C%20CIFAR-10%2C%20and%0ACIFAR-100%29%2C%20and%20three%20FDG%20benchmark%20datasets%20%28PACS%2C%20VLCS%2C%20and%20OfficeHome%29.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14653v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DFederated%2520Domain%2520Generalization%2520with%2520Data-free%2520On-server%2520Gradient%250A%2520%2520Matching%26entry.906535625%3DTrong-Binh%2520Nguyen%2520and%2520Minh-Duong%2520Nguyen%2520and%2520Jinsun%2520Park%2520and%2520Quoc-Viet%2520Pham%2520and%2520Won%2520Joo%2520Hwang%26entry.1292438233%3D%2520%2520Domain%2520Generalization%2520%2528DG%2529%2520aims%2520to%2520learn%2520from%2520multiple%2520known%2520source%2520domains%2520a%250Amodel%2520that%2520can%2520generalize%2520well%2520to%2520unknown%2520target%2520domains.%2520One%2520of%2520the%2520key%250Aapproaches%2520in%2520DG%2520is%2520training%2520an%2520encoder%2520which%2520generates%2520domain-invariant%250Arepresentations.%2520However%252C%2520this%2520approach%2520is%2520not%2520applicable%2520in%2520Federated%2520Domain%250AGeneralization%2520%2528FDG%2529%252C%2520where%2520data%2520from%2520various%2520domains%2520are%2520distributed%2520across%250Adifferent%2520clients.%2520In%2520this%2520paper%252C%2520we%2520introduce%2520a%2520novel%2520approach%252C%2520dubbed%250AFederated%2520Learning%2520via%2520On-server%2520Matching%2520Gradient%2520%2528FedOMG%2529%252C%2520which%2520can%250A%255Cemph%257Befficiently%2520leverage%2520domain%2520information%2520from%2520distributed%2520domains%257D.%250ASpecifically%252C%2520we%2520utilize%2520the%2520local%2520gradients%2520as%2520information%2520about%2520the%250Adistributed%2520models%2520to%2520find%2520an%2520invariant%2520gradient%2520direction%2520across%2520all%2520domains%250Athrough%2520gradient%2520inner%2520product%2520maximization.%2520The%2520advantages%2520are%2520two-fold%253A%25201%2529%250AFedOMG%2520can%2520aggregate%2520the%2520characteristics%2520of%2520distributed%2520models%2520on%2520the%250Acentralized%2520server%2520without%2520incurring%2520any%2520additional%2520communication%2520cost%252C%2520and%25202%2529%250AFedOMG%2520is%2520orthogonal%2520to%2520many%2520existing%2520FL/FDG%2520methods%252C%2520allowing%2520for%2520additional%250Aperformance%2520improvements%2520by%2520being%2520seamlessly%2520integrated%2520with%2520them.%2520Extensive%250Aexperimental%2520evaluations%2520on%2520various%2520settings%2520to%2520demonstrate%2520the%2520robustness%2520of%250AFedOMG%2520compared%2520to%2520other%2520FL/FDG%2520baselines.%2520Our%2520method%2520outperforms%2520recent%2520SOTA%250Abaselines%2520on%2520four%2520FL%2520benchmark%2520datasets%2520%2528MNIST%252C%2520EMNIST%252C%2520CIFAR-10%252C%2520and%250ACIFAR-100%2529%252C%2520and%2520three%2520FDG%2520benchmark%2520datasets%2520%2528PACS%252C%2520VLCS%252C%2520and%2520OfficeHome%2529.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14653v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Federated%20Domain%20Generalization%20with%20Data-free%20On-server%20Gradient%0A%20%20Matching&entry.906535625=Trong-Binh%20Nguyen%20and%20Minh-Duong%20Nguyen%20and%20Jinsun%20Park%20and%20Quoc-Viet%20Pham%20and%20Won%20Joo%20Hwang&entry.1292438233=%20%20Domain%20Generalization%20%28DG%29%20aims%20to%20learn%20from%20multiple%20known%20source%20domains%20a%0Amodel%20that%20can%20generalize%20well%20to%20unknown%20target%20domains.%20One%20of%20the%20key%0Aapproaches%20in%20DG%20is%20training%20an%20encoder%20which%20generates%20domain-invariant%0Arepresentations.%20However%2C%20this%20approach%20is%20not%20applicable%20in%20Federated%20Domain%0AGeneralization%20%28FDG%29%2C%20where%20data%20from%20various%20domains%20are%20distributed%20across%0Adifferent%20clients.%20In%20this%20paper%2C%20we%20introduce%20a%20novel%20approach%2C%20dubbed%0AFederated%20Learning%20via%20On-server%20Matching%20Gradient%20%28FedOMG%29%2C%20which%20can%0A%5Cemph%7Befficiently%20leverage%20domain%20information%20from%20distributed%20domains%7D.%0ASpecifically%2C%20we%20utilize%20the%20local%20gradients%20as%20information%20about%20the%0Adistributed%20models%20to%20find%20an%20invariant%20gradient%20direction%20across%20all%20domains%0Athrough%20gradient%20inner%20product%20maximization.%20The%20advantages%20are%20two-fold%3A%201%29%0AFedOMG%20can%20aggregate%20the%20characteristics%20of%20distributed%20models%20on%20the%0Acentralized%20server%20without%20incurring%20any%20additional%20communication%20cost%2C%20and%202%29%0AFedOMG%20is%20orthogonal%20to%20many%20existing%20FL/FDG%20methods%2C%20allowing%20for%20additional%0Aperformance%20improvements%20by%20being%20seamlessly%20integrated%20with%20them.%20Extensive%0Aexperimental%20evaluations%20on%20various%20settings%20to%20demonstrate%20the%20robustness%20of%0AFedOMG%20compared%20to%20other%20FL/FDG%20baselines.%20Our%20method%20outperforms%20recent%20SOTA%0Abaselines%20on%20four%20FL%20benchmark%20datasets%20%28MNIST%2C%20EMNIST%2C%20CIFAR-10%2C%20and%0ACIFAR-100%29%2C%20and%20three%20FDG%20benchmark%20datasets%20%28PACS%2C%20VLCS%2C%20and%20OfficeHome%29.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14653v1&entry.124074799=Read"},
{"title": "Extracting Problem Structure with LLMs for Optimized SAT Local Search", "author": "Andr\u00e9 Schilder and Stefan Szeider", "abstract": "  Local search preprocessing makes Conflict-Driven Clause Learning (CDCL)\nsolvers faster by providing high-quality starting points and modern SAT solvers\nhave incorporated this technique into their preprocessing steps. However, these\ntools rely on basic strategies that miss the structural patterns in problems.\nWe present a method that applies Large Language Models (LLMs) to analyze\nPython-based encoding code. This reveals hidden structural patterns in how\nproblems convert into SAT. Our method automatically generates specialized local\nsearch algorithms that find these patterns and use them to create strong\ninitial assignments. This works for any problem instance from the same encoding\ntype. Our tests show encouraging results, achieving faster solving times\ncompared to baseline preprocessing systems.\n", "link": "http://arxiv.org/abs/2501.14630v1", "date": "2025-01-24", "relevancy": 2.5313, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5219}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5219}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.4749}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Extracting%20Problem%20Structure%20with%20LLMs%20for%20Optimized%20SAT%20Local%20Search&body=Title%3A%20Extracting%20Problem%20Structure%20with%20LLMs%20for%20Optimized%20SAT%20Local%20Search%0AAuthor%3A%20Andr%C3%A9%20Schilder%20and%20Stefan%20Szeider%0AAbstract%3A%20%20%20Local%20search%20preprocessing%20makes%20Conflict-Driven%20Clause%20Learning%20%28CDCL%29%0Asolvers%20faster%20by%20providing%20high-quality%20starting%20points%20and%20modern%20SAT%20solvers%0Ahave%20incorporated%20this%20technique%20into%20their%20preprocessing%20steps.%20However%2C%20these%0Atools%20rely%20on%20basic%20strategies%20that%20miss%20the%20structural%20patterns%20in%20problems.%0AWe%20present%20a%20method%20that%20applies%20Large%20Language%20Models%20%28LLMs%29%20to%20analyze%0APython-based%20encoding%20code.%20This%20reveals%20hidden%20structural%20patterns%20in%20how%0Aproblems%20convert%20into%20SAT.%20Our%20method%20automatically%20generates%20specialized%20local%0Asearch%20algorithms%20that%20find%20these%20patterns%20and%20use%20them%20to%20create%20strong%0Ainitial%20assignments.%20This%20works%20for%20any%20problem%20instance%20from%20the%20same%20encoding%0Atype.%20Our%20tests%20show%20encouraging%20results%2C%20achieving%20faster%20solving%20times%0Acompared%20to%20baseline%20preprocessing%20systems.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14630v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DExtracting%2520Problem%2520Structure%2520with%2520LLMs%2520for%2520Optimized%2520SAT%2520Local%2520Search%26entry.906535625%3DAndr%25C3%25A9%2520Schilder%2520and%2520Stefan%2520Szeider%26entry.1292438233%3D%2520%2520Local%2520search%2520preprocessing%2520makes%2520Conflict-Driven%2520Clause%2520Learning%2520%2528CDCL%2529%250Asolvers%2520faster%2520by%2520providing%2520high-quality%2520starting%2520points%2520and%2520modern%2520SAT%2520solvers%250Ahave%2520incorporated%2520this%2520technique%2520into%2520their%2520preprocessing%2520steps.%2520However%252C%2520these%250Atools%2520rely%2520on%2520basic%2520strategies%2520that%2520miss%2520the%2520structural%2520patterns%2520in%2520problems.%250AWe%2520present%2520a%2520method%2520that%2520applies%2520Large%2520Language%2520Models%2520%2528LLMs%2529%2520to%2520analyze%250APython-based%2520encoding%2520code.%2520This%2520reveals%2520hidden%2520structural%2520patterns%2520in%2520how%250Aproblems%2520convert%2520into%2520SAT.%2520Our%2520method%2520automatically%2520generates%2520specialized%2520local%250Asearch%2520algorithms%2520that%2520find%2520these%2520patterns%2520and%2520use%2520them%2520to%2520create%2520strong%250Ainitial%2520assignments.%2520This%2520works%2520for%2520any%2520problem%2520instance%2520from%2520the%2520same%2520encoding%250Atype.%2520Our%2520tests%2520show%2520encouraging%2520results%252C%2520achieving%2520faster%2520solving%2520times%250Acompared%2520to%2520baseline%2520preprocessing%2520systems.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14630v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Extracting%20Problem%20Structure%20with%20LLMs%20for%20Optimized%20SAT%20Local%20Search&entry.906535625=Andr%C3%A9%20Schilder%20and%20Stefan%20Szeider&entry.1292438233=%20%20Local%20search%20preprocessing%20makes%20Conflict-Driven%20Clause%20Learning%20%28CDCL%29%0Asolvers%20faster%20by%20providing%20high-quality%20starting%20points%20and%20modern%20SAT%20solvers%0Ahave%20incorporated%20this%20technique%20into%20their%20preprocessing%20steps.%20However%2C%20these%0Atools%20rely%20on%20basic%20strategies%20that%20miss%20the%20structural%20patterns%20in%20problems.%0AWe%20present%20a%20method%20that%20applies%20Large%20Language%20Models%20%28LLMs%29%20to%20analyze%0APython-based%20encoding%20code.%20This%20reveals%20hidden%20structural%20patterns%20in%20how%0Aproblems%20convert%20into%20SAT.%20Our%20method%20automatically%20generates%20specialized%20local%0Asearch%20algorithms%20that%20find%20these%20patterns%20and%20use%20them%20to%20create%20strong%0Ainitial%20assignments.%20This%20works%20for%20any%20problem%20instance%20from%20the%20same%20encoding%0Atype.%20Our%20tests%20show%20encouraging%20results%2C%20achieving%20faster%20solving%20times%0Acompared%20to%20baseline%20preprocessing%20systems.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14630v1&entry.124074799=Read"},
{"title": "ReferDINO: Referring Video Object Segmentation with Visual Grounding\n  Foundations", "author": "Tianming Liang and Kun-Yu Lin and Chaolei Tan and Jianguo Zhang and Wei-Shi Zheng and Jian-Fang Hu", "abstract": "  Referring video object segmentation (RVOS) aims to segment target objects\nthroughout a video based on a text description. Despite notable progress in\nrecent years, current RVOS models remain struggle to handle complicated object\ndescriptions due to their limited video-language understanding. To address this\nlimitation, we present \\textbf{ReferDINO}, an end-to-end RVOS model that\ninherits strong vision-language understanding from the pretrained visual\ngrounding foundation models, and is further endowed with effective temporal\nunderstanding and object segmentation capabilities. In ReferDINO, we contribute\nthree technical innovations for effectively adapting the foundation models to\nRVOS: 1) an object-consistent temporal enhancer that capitalizes on the\npretrained object-text representations to enhance temporal understanding and\nobject consistency; 2) a grounding-guided deformable mask decoder that\nintegrates text and grounding conditions to generate accurate object masks; 3)\na confidence-aware query pruning strategy that significantly improves the\nobject decoding efficiency without compromising performance. We conduct\nextensive experiments on five public RVOS benchmarks to demonstrate that our\nproposed ReferDINO outperforms state-of-the-art methods significantly. Project\npage: \\url{https://isee-laboratory.github.io/ReferDINO}\n", "link": "http://arxiv.org/abs/2501.14607v1", "date": "2025-01-24", "relevancy": 2.5062, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.6444}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.6444}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5374}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ReferDINO%3A%20Referring%20Video%20Object%20Segmentation%20with%20Visual%20Grounding%0A%20%20Foundations&body=Title%3A%20ReferDINO%3A%20Referring%20Video%20Object%20Segmentation%20with%20Visual%20Grounding%0A%20%20Foundations%0AAuthor%3A%20Tianming%20Liang%20and%20Kun-Yu%20Lin%20and%20Chaolei%20Tan%20and%20Jianguo%20Zhang%20and%20Wei-Shi%20Zheng%20and%20Jian-Fang%20Hu%0AAbstract%3A%20%20%20Referring%20video%20object%20segmentation%20%28RVOS%29%20aims%20to%20segment%20target%20objects%0Athroughout%20a%20video%20based%20on%20a%20text%20description.%20Despite%20notable%20progress%20in%0Arecent%20years%2C%20current%20RVOS%20models%20remain%20struggle%20to%20handle%20complicated%20object%0Adescriptions%20due%20to%20their%20limited%20video-language%20understanding.%20To%20address%20this%0Alimitation%2C%20we%20present%20%5Ctextbf%7BReferDINO%7D%2C%20an%20end-to-end%20RVOS%20model%20that%0Ainherits%20strong%20vision-language%20understanding%20from%20the%20pretrained%20visual%0Agrounding%20foundation%20models%2C%20and%20is%20further%20endowed%20with%20effective%20temporal%0Aunderstanding%20and%20object%20segmentation%20capabilities.%20In%20ReferDINO%2C%20we%20contribute%0Athree%20technical%20innovations%20for%20effectively%20adapting%20the%20foundation%20models%20to%0ARVOS%3A%201%29%20an%20object-consistent%20temporal%20enhancer%20that%20capitalizes%20on%20the%0Apretrained%20object-text%20representations%20to%20enhance%20temporal%20understanding%20and%0Aobject%20consistency%3B%202%29%20a%20grounding-guided%20deformable%20mask%20decoder%20that%0Aintegrates%20text%20and%20grounding%20conditions%20to%20generate%20accurate%20object%20masks%3B%203%29%0Aa%20confidence-aware%20query%20pruning%20strategy%20that%20significantly%20improves%20the%0Aobject%20decoding%20efficiency%20without%20compromising%20performance.%20We%20conduct%0Aextensive%20experiments%20on%20five%20public%20RVOS%20benchmarks%20to%20demonstrate%20that%20our%0Aproposed%20ReferDINO%20outperforms%20state-of-the-art%20methods%20significantly.%20Project%0Apage%3A%20%5Curl%7Bhttps%3A//isee-laboratory.github.io/ReferDINO%7D%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14607v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DReferDINO%253A%2520Referring%2520Video%2520Object%2520Segmentation%2520with%2520Visual%2520Grounding%250A%2520%2520Foundations%26entry.906535625%3DTianming%2520Liang%2520and%2520Kun-Yu%2520Lin%2520and%2520Chaolei%2520Tan%2520and%2520Jianguo%2520Zhang%2520and%2520Wei-Shi%2520Zheng%2520and%2520Jian-Fang%2520Hu%26entry.1292438233%3D%2520%2520Referring%2520video%2520object%2520segmentation%2520%2528RVOS%2529%2520aims%2520to%2520segment%2520target%2520objects%250Athroughout%2520a%2520video%2520based%2520on%2520a%2520text%2520description.%2520Despite%2520notable%2520progress%2520in%250Arecent%2520years%252C%2520current%2520RVOS%2520models%2520remain%2520struggle%2520to%2520handle%2520complicated%2520object%250Adescriptions%2520due%2520to%2520their%2520limited%2520video-language%2520understanding.%2520To%2520address%2520this%250Alimitation%252C%2520we%2520present%2520%255Ctextbf%257BReferDINO%257D%252C%2520an%2520end-to-end%2520RVOS%2520model%2520that%250Ainherits%2520strong%2520vision-language%2520understanding%2520from%2520the%2520pretrained%2520visual%250Agrounding%2520foundation%2520models%252C%2520and%2520is%2520further%2520endowed%2520with%2520effective%2520temporal%250Aunderstanding%2520and%2520object%2520segmentation%2520capabilities.%2520In%2520ReferDINO%252C%2520we%2520contribute%250Athree%2520technical%2520innovations%2520for%2520effectively%2520adapting%2520the%2520foundation%2520models%2520to%250ARVOS%253A%25201%2529%2520an%2520object-consistent%2520temporal%2520enhancer%2520that%2520capitalizes%2520on%2520the%250Apretrained%2520object-text%2520representations%2520to%2520enhance%2520temporal%2520understanding%2520and%250Aobject%2520consistency%253B%25202%2529%2520a%2520grounding-guided%2520deformable%2520mask%2520decoder%2520that%250Aintegrates%2520text%2520and%2520grounding%2520conditions%2520to%2520generate%2520accurate%2520object%2520masks%253B%25203%2529%250Aa%2520confidence-aware%2520query%2520pruning%2520strategy%2520that%2520significantly%2520improves%2520the%250Aobject%2520decoding%2520efficiency%2520without%2520compromising%2520performance.%2520We%2520conduct%250Aextensive%2520experiments%2520on%2520five%2520public%2520RVOS%2520benchmarks%2520to%2520demonstrate%2520that%2520our%250Aproposed%2520ReferDINO%2520outperforms%2520state-of-the-art%2520methods%2520significantly.%2520Project%250Apage%253A%2520%255Curl%257Bhttps%253A//isee-laboratory.github.io/ReferDINO%257D%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14607v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ReferDINO%3A%20Referring%20Video%20Object%20Segmentation%20with%20Visual%20Grounding%0A%20%20Foundations&entry.906535625=Tianming%20Liang%20and%20Kun-Yu%20Lin%20and%20Chaolei%20Tan%20and%20Jianguo%20Zhang%20and%20Wei-Shi%20Zheng%20and%20Jian-Fang%20Hu&entry.1292438233=%20%20Referring%20video%20object%20segmentation%20%28RVOS%29%20aims%20to%20segment%20target%20objects%0Athroughout%20a%20video%20based%20on%20a%20text%20description.%20Despite%20notable%20progress%20in%0Arecent%20years%2C%20current%20RVOS%20models%20remain%20struggle%20to%20handle%20complicated%20object%0Adescriptions%20due%20to%20their%20limited%20video-language%20understanding.%20To%20address%20this%0Alimitation%2C%20we%20present%20%5Ctextbf%7BReferDINO%7D%2C%20an%20end-to-end%20RVOS%20model%20that%0Ainherits%20strong%20vision-language%20understanding%20from%20the%20pretrained%20visual%0Agrounding%20foundation%20models%2C%20and%20is%20further%20endowed%20with%20effective%20temporal%0Aunderstanding%20and%20object%20segmentation%20capabilities.%20In%20ReferDINO%2C%20we%20contribute%0Athree%20technical%20innovations%20for%20effectively%20adapting%20the%20foundation%20models%20to%0ARVOS%3A%201%29%20an%20object-consistent%20temporal%20enhancer%20that%20capitalizes%20on%20the%0Apretrained%20object-text%20representations%20to%20enhance%20temporal%20understanding%20and%0Aobject%20consistency%3B%202%29%20a%20grounding-guided%20deformable%20mask%20decoder%20that%0Aintegrates%20text%20and%20grounding%20conditions%20to%20generate%20accurate%20object%20masks%3B%203%29%0Aa%20confidence-aware%20query%20pruning%20strategy%20that%20significantly%20improves%20the%0Aobject%20decoding%20efficiency%20without%20compromising%20performance.%20We%20conduct%0Aextensive%20experiments%20on%20five%20public%20RVOS%20benchmarks%20to%20demonstrate%20that%20our%0Aproposed%20ReferDINO%20outperforms%20state-of-the-art%20methods%20significantly.%20Project%0Apage%3A%20%5Curl%7Bhttps%3A//isee-laboratory.github.io/ReferDINO%7D%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14607v1&entry.124074799=Read"},
{"title": "Decoding Generalization from Memorization in Deep Neural Networks", "author": "Simran Ketha and Venkatakrishnan Ramaswamy", "abstract": "  Overparameterized Deep Neural Networks that generalize well have been key to\nthe dramatic success of Deep Learning in recent years. The reasons for their\nremarkable ability to generalize are not well understood yet. It has also been\nknown that deep networks possess the ability to memorize training data, as\nevidenced by perfect or high training accuracies on models trained with\ncorrupted data that have class labels shuffled to varying degrees.\nConcomitantly, such models are known to generalize poorly, i.e. they suffer\nfrom poor test accuracies, due to which it is thought that the act of\nmemorizing substantially degrades the ability to generalize. It has, however,\nbeen unclear why the poor generalization that accompanies such memorization,\ncomes about. One possibility is that in the process of training with corrupted\ndata, the layers of the network irretrievably reorganize their representations\nin a manner that makes generalization difficult. The other possibility is that\nthe network retains significant ability to generalize, but the trained network\nsomehow chooses to readout in a manner that is detrimental to generalization.\nHere, we provide evidence for the latter possibility by demonstrating,\nempirically, that such models possess information in their representations for\nsubstantially improved generalization, even in the face of memorization.\nFurthermore, such generalization abilities can be easily decoded from the\ninternals of the trained model, and we build a technique to do so from the\noutputs of specific layers of the network. We demonstrate results on multiple\nmodels trained with a number of standard datasets.\n", "link": "http://arxiv.org/abs/2501.14687v1", "date": "2025-01-24", "relevancy": 2.5027, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.5181}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4918}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4918}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Decoding%20Generalization%20from%20Memorization%20in%20Deep%20Neural%20Networks&body=Title%3A%20Decoding%20Generalization%20from%20Memorization%20in%20Deep%20Neural%20Networks%0AAuthor%3A%20Simran%20Ketha%20and%20Venkatakrishnan%20Ramaswamy%0AAbstract%3A%20%20%20Overparameterized%20Deep%20Neural%20Networks%20that%20generalize%20well%20have%20been%20key%20to%0Athe%20dramatic%20success%20of%20Deep%20Learning%20in%20recent%20years.%20The%20reasons%20for%20their%0Aremarkable%20ability%20to%20generalize%20are%20not%20well%20understood%20yet.%20It%20has%20also%20been%0Aknown%20that%20deep%20networks%20possess%20the%20ability%20to%20memorize%20training%20data%2C%20as%0Aevidenced%20by%20perfect%20or%20high%20training%20accuracies%20on%20models%20trained%20with%0Acorrupted%20data%20that%20have%20class%20labels%20shuffled%20to%20varying%20degrees.%0AConcomitantly%2C%20such%20models%20are%20known%20to%20generalize%20poorly%2C%20i.e.%20they%20suffer%0Afrom%20poor%20test%20accuracies%2C%20due%20to%20which%20it%20is%20thought%20that%20the%20act%20of%0Amemorizing%20substantially%20degrades%20the%20ability%20to%20generalize.%20It%20has%2C%20however%2C%0Abeen%20unclear%20why%20the%20poor%20generalization%20that%20accompanies%20such%20memorization%2C%0Acomes%20about.%20One%20possibility%20is%20that%20in%20the%20process%20of%20training%20with%20corrupted%0Adata%2C%20the%20layers%20of%20the%20network%20irretrievably%20reorganize%20their%20representations%0Ain%20a%20manner%20that%20makes%20generalization%20difficult.%20The%20other%20possibility%20is%20that%0Athe%20network%20retains%20significant%20ability%20to%20generalize%2C%20but%20the%20trained%20network%0Asomehow%20chooses%20to%20readout%20in%20a%20manner%20that%20is%20detrimental%20to%20generalization.%0AHere%2C%20we%20provide%20evidence%20for%20the%20latter%20possibility%20by%20demonstrating%2C%0Aempirically%2C%20that%20such%20models%20possess%20information%20in%20their%20representations%20for%0Asubstantially%20improved%20generalization%2C%20even%20in%20the%20face%20of%20memorization.%0AFurthermore%2C%20such%20generalization%20abilities%20can%20be%20easily%20decoded%20from%20the%0Ainternals%20of%20the%20trained%20model%2C%20and%20we%20build%20a%20technique%20to%20do%20so%20from%20the%0Aoutputs%20of%20specific%20layers%20of%20the%20network.%20We%20demonstrate%20results%20on%20multiple%0Amodels%20trained%20with%20a%20number%20of%20standard%20datasets.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14687v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDecoding%2520Generalization%2520from%2520Memorization%2520in%2520Deep%2520Neural%2520Networks%26entry.906535625%3DSimran%2520Ketha%2520and%2520Venkatakrishnan%2520Ramaswamy%26entry.1292438233%3D%2520%2520Overparameterized%2520Deep%2520Neural%2520Networks%2520that%2520generalize%2520well%2520have%2520been%2520key%2520to%250Athe%2520dramatic%2520success%2520of%2520Deep%2520Learning%2520in%2520recent%2520years.%2520The%2520reasons%2520for%2520their%250Aremarkable%2520ability%2520to%2520generalize%2520are%2520not%2520well%2520understood%2520yet.%2520It%2520has%2520also%2520been%250Aknown%2520that%2520deep%2520networks%2520possess%2520the%2520ability%2520to%2520memorize%2520training%2520data%252C%2520as%250Aevidenced%2520by%2520perfect%2520or%2520high%2520training%2520accuracies%2520on%2520models%2520trained%2520with%250Acorrupted%2520data%2520that%2520have%2520class%2520labels%2520shuffled%2520to%2520varying%2520degrees.%250AConcomitantly%252C%2520such%2520models%2520are%2520known%2520to%2520generalize%2520poorly%252C%2520i.e.%2520they%2520suffer%250Afrom%2520poor%2520test%2520accuracies%252C%2520due%2520to%2520which%2520it%2520is%2520thought%2520that%2520the%2520act%2520of%250Amemorizing%2520substantially%2520degrades%2520the%2520ability%2520to%2520generalize.%2520It%2520has%252C%2520however%252C%250Abeen%2520unclear%2520why%2520the%2520poor%2520generalization%2520that%2520accompanies%2520such%2520memorization%252C%250Acomes%2520about.%2520One%2520possibility%2520is%2520that%2520in%2520the%2520process%2520of%2520training%2520with%2520corrupted%250Adata%252C%2520the%2520layers%2520of%2520the%2520network%2520irretrievably%2520reorganize%2520their%2520representations%250Ain%2520a%2520manner%2520that%2520makes%2520generalization%2520difficult.%2520The%2520other%2520possibility%2520is%2520that%250Athe%2520network%2520retains%2520significant%2520ability%2520to%2520generalize%252C%2520but%2520the%2520trained%2520network%250Asomehow%2520chooses%2520to%2520readout%2520in%2520a%2520manner%2520that%2520is%2520detrimental%2520to%2520generalization.%250AHere%252C%2520we%2520provide%2520evidence%2520for%2520the%2520latter%2520possibility%2520by%2520demonstrating%252C%250Aempirically%252C%2520that%2520such%2520models%2520possess%2520information%2520in%2520their%2520representations%2520for%250Asubstantially%2520improved%2520generalization%252C%2520even%2520in%2520the%2520face%2520of%2520memorization.%250AFurthermore%252C%2520such%2520generalization%2520abilities%2520can%2520be%2520easily%2520decoded%2520from%2520the%250Ainternals%2520of%2520the%2520trained%2520model%252C%2520and%2520we%2520build%2520a%2520technique%2520to%2520do%2520so%2520from%2520the%250Aoutputs%2520of%2520specific%2520layers%2520of%2520the%2520network.%2520We%2520demonstrate%2520results%2520on%2520multiple%250Amodels%2520trained%2520with%2520a%2520number%2520of%2520standard%2520datasets.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14687v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Decoding%20Generalization%20from%20Memorization%20in%20Deep%20Neural%20Networks&entry.906535625=Simran%20Ketha%20and%20Venkatakrishnan%20Ramaswamy&entry.1292438233=%20%20Overparameterized%20Deep%20Neural%20Networks%20that%20generalize%20well%20have%20been%20key%20to%0Athe%20dramatic%20success%20of%20Deep%20Learning%20in%20recent%20years.%20The%20reasons%20for%20their%0Aremarkable%20ability%20to%20generalize%20are%20not%20well%20understood%20yet.%20It%20has%20also%20been%0Aknown%20that%20deep%20networks%20possess%20the%20ability%20to%20memorize%20training%20data%2C%20as%0Aevidenced%20by%20perfect%20or%20high%20training%20accuracies%20on%20models%20trained%20with%0Acorrupted%20data%20that%20have%20class%20labels%20shuffled%20to%20varying%20degrees.%0AConcomitantly%2C%20such%20models%20are%20known%20to%20generalize%20poorly%2C%20i.e.%20they%20suffer%0Afrom%20poor%20test%20accuracies%2C%20due%20to%20which%20it%20is%20thought%20that%20the%20act%20of%0Amemorizing%20substantially%20degrades%20the%20ability%20to%20generalize.%20It%20has%2C%20however%2C%0Abeen%20unclear%20why%20the%20poor%20generalization%20that%20accompanies%20such%20memorization%2C%0Acomes%20about.%20One%20possibility%20is%20that%20in%20the%20process%20of%20training%20with%20corrupted%0Adata%2C%20the%20layers%20of%20the%20network%20irretrievably%20reorganize%20their%20representations%0Ain%20a%20manner%20that%20makes%20generalization%20difficult.%20The%20other%20possibility%20is%20that%0Athe%20network%20retains%20significant%20ability%20to%20generalize%2C%20but%20the%20trained%20network%0Asomehow%20chooses%20to%20readout%20in%20a%20manner%20that%20is%20detrimental%20to%20generalization.%0AHere%2C%20we%20provide%20evidence%20for%20the%20latter%20possibility%20by%20demonstrating%2C%0Aempirically%2C%20that%20such%20models%20possess%20information%20in%20their%20representations%20for%0Asubstantially%20improved%20generalization%2C%20even%20in%20the%20face%20of%20memorization.%0AFurthermore%2C%20such%20generalization%20abilities%20can%20be%20easily%20decoded%20from%20the%0Ainternals%20of%20the%20trained%20model%2C%20and%20we%20build%20a%20technique%20to%20do%20so%20from%20the%0Aoutputs%20of%20specific%20layers%20of%20the%20network.%20We%20demonstrate%20results%20on%20multiple%0Amodels%20trained%20with%20a%20number%20of%20standard%20datasets.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14687v1&entry.124074799=Read"},
{"title": "Geometric Mean Improves Loss For Few-Shot Learning", "author": "Tong Wu and Takumi Kobayashi", "abstract": "  Few-shot learning (FSL) is a challenging task in machine learning, demanding\na model to render discriminative classification by using only a few labeled\nsamples. In the literature of FSL, deep models are trained in a manner of\nmetric learning to provide metric in a feature space which is well\ngeneralizable to classify samples of novel classes; in the space, even a few\namount of labeled training examples can construct an effective classifier. In\nthis paper, we propose a novel FSL loss based on \\emph{geometric mean} to embed\ndiscriminative metric into deep features. In contrast to the other losses such\nas utilizing arithmetic mean in softmax-based formulation, the proposed method\nleverages geometric mean to aggregate pair-wise relationships among samples for\nenhancing discriminative metric across class categories. The proposed loss is\nnot only formulated in a simple form but also is thoroughly analyzed in\ntheoretical ways to reveal its favorable characteristics which are favorable\nfor learning feature metric in FSL. In the experiments on few-shot image\nclassification tasks, the method produces competitive performance in comparison\nto the other losses.\n", "link": "http://arxiv.org/abs/2501.14593v1", "date": "2025-01-24", "relevancy": 2.4558, "topK": [{"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.4973}, {"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.4917}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4845}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Geometric%20Mean%20Improves%20Loss%20For%20Few-Shot%20Learning&body=Title%3A%20Geometric%20Mean%20Improves%20Loss%20For%20Few-Shot%20Learning%0AAuthor%3A%20Tong%20Wu%20and%20Takumi%20Kobayashi%0AAbstract%3A%20%20%20Few-shot%20learning%20%28FSL%29%20is%20a%20challenging%20task%20in%20machine%20learning%2C%20demanding%0Aa%20model%20to%20render%20discriminative%20classification%20by%20using%20only%20a%20few%20labeled%0Asamples.%20In%20the%20literature%20of%20FSL%2C%20deep%20models%20are%20trained%20in%20a%20manner%20of%0Ametric%20learning%20to%20provide%20metric%20in%20a%20feature%20space%20which%20is%20well%0Ageneralizable%20to%20classify%20samples%20of%20novel%20classes%3B%20in%20the%20space%2C%20even%20a%20few%0Aamount%20of%20labeled%20training%20examples%20can%20construct%20an%20effective%20classifier.%20In%0Athis%20paper%2C%20we%20propose%20a%20novel%20FSL%20loss%20based%20on%20%5Cemph%7Bgeometric%20mean%7D%20to%20embed%0Adiscriminative%20metric%20into%20deep%20features.%20In%20contrast%20to%20the%20other%20losses%20such%0Aas%20utilizing%20arithmetic%20mean%20in%20softmax-based%20formulation%2C%20the%20proposed%20method%0Aleverages%20geometric%20mean%20to%20aggregate%20pair-wise%20relationships%20among%20samples%20for%0Aenhancing%20discriminative%20metric%20across%20class%20categories.%20The%20proposed%20loss%20is%0Anot%20only%20formulated%20in%20a%20simple%20form%20but%20also%20is%20thoroughly%20analyzed%20in%0Atheoretical%20ways%20to%20reveal%20its%20favorable%20characteristics%20which%20are%20favorable%0Afor%20learning%20feature%20metric%20in%20FSL.%20In%20the%20experiments%20on%20few-shot%20image%0Aclassification%20tasks%2C%20the%20method%20produces%20competitive%20performance%20in%20comparison%0Ato%20the%20other%20losses.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14593v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DGeometric%2520Mean%2520Improves%2520Loss%2520For%2520Few-Shot%2520Learning%26entry.906535625%3DTong%2520Wu%2520and%2520Takumi%2520Kobayashi%26entry.1292438233%3D%2520%2520Few-shot%2520learning%2520%2528FSL%2529%2520is%2520a%2520challenging%2520task%2520in%2520machine%2520learning%252C%2520demanding%250Aa%2520model%2520to%2520render%2520discriminative%2520classification%2520by%2520using%2520only%2520a%2520few%2520labeled%250Asamples.%2520In%2520the%2520literature%2520of%2520FSL%252C%2520deep%2520models%2520are%2520trained%2520in%2520a%2520manner%2520of%250Ametric%2520learning%2520to%2520provide%2520metric%2520in%2520a%2520feature%2520space%2520which%2520is%2520well%250Ageneralizable%2520to%2520classify%2520samples%2520of%2520novel%2520classes%253B%2520in%2520the%2520space%252C%2520even%2520a%2520few%250Aamount%2520of%2520labeled%2520training%2520examples%2520can%2520construct%2520an%2520effective%2520classifier.%2520In%250Athis%2520paper%252C%2520we%2520propose%2520a%2520novel%2520FSL%2520loss%2520based%2520on%2520%255Cemph%257Bgeometric%2520mean%257D%2520to%2520embed%250Adiscriminative%2520metric%2520into%2520deep%2520features.%2520In%2520contrast%2520to%2520the%2520other%2520losses%2520such%250Aas%2520utilizing%2520arithmetic%2520mean%2520in%2520softmax-based%2520formulation%252C%2520the%2520proposed%2520method%250Aleverages%2520geometric%2520mean%2520to%2520aggregate%2520pair-wise%2520relationships%2520among%2520samples%2520for%250Aenhancing%2520discriminative%2520metric%2520across%2520class%2520categories.%2520The%2520proposed%2520loss%2520is%250Anot%2520only%2520formulated%2520in%2520a%2520simple%2520form%2520but%2520also%2520is%2520thoroughly%2520analyzed%2520in%250Atheoretical%2520ways%2520to%2520reveal%2520its%2520favorable%2520characteristics%2520which%2520are%2520favorable%250Afor%2520learning%2520feature%2520metric%2520in%2520FSL.%2520In%2520the%2520experiments%2520on%2520few-shot%2520image%250Aclassification%2520tasks%252C%2520the%2520method%2520produces%2520competitive%2520performance%2520in%2520comparison%250Ato%2520the%2520other%2520losses.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14593v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Geometric%20Mean%20Improves%20Loss%20For%20Few-Shot%20Learning&entry.906535625=Tong%20Wu%20and%20Takumi%20Kobayashi&entry.1292438233=%20%20Few-shot%20learning%20%28FSL%29%20is%20a%20challenging%20task%20in%20machine%20learning%2C%20demanding%0Aa%20model%20to%20render%20discriminative%20classification%20by%20using%20only%20a%20few%20labeled%0Asamples.%20In%20the%20literature%20of%20FSL%2C%20deep%20models%20are%20trained%20in%20a%20manner%20of%0Ametric%20learning%20to%20provide%20metric%20in%20a%20feature%20space%20which%20is%20well%0Ageneralizable%20to%20classify%20samples%20of%20novel%20classes%3B%20in%20the%20space%2C%20even%20a%20few%0Aamount%20of%20labeled%20training%20examples%20can%20construct%20an%20effective%20classifier.%20In%0Athis%20paper%2C%20we%20propose%20a%20novel%20FSL%20loss%20based%20on%20%5Cemph%7Bgeometric%20mean%7D%20to%20embed%0Adiscriminative%20metric%20into%20deep%20features.%20In%20contrast%20to%20the%20other%20losses%20such%0Aas%20utilizing%20arithmetic%20mean%20in%20softmax-based%20formulation%2C%20the%20proposed%20method%0Aleverages%20geometric%20mean%20to%20aggregate%20pair-wise%20relationships%20among%20samples%20for%0Aenhancing%20discriminative%20metric%20across%20class%20categories.%20The%20proposed%20loss%20is%0Anot%20only%20formulated%20in%20a%20simple%20form%20but%20also%20is%20thoroughly%20analyzed%20in%0Atheoretical%20ways%20to%20reveal%20its%20favorable%20characteristics%20which%20are%20favorable%0Afor%20learning%20feature%20metric%20in%20FSL.%20In%20the%20experiments%20on%20few-shot%20image%0Aclassification%20tasks%2C%20the%20method%20produces%20competitive%20performance%20in%20comparison%0Ato%20the%20other%20losses.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14593v1&entry.124074799=Read"},
{"title": "Scene Understanding Enabled Semantic Communication with Open Channel\n  Coding", "author": "Zhe Xiang and Fei Yu and Quan Deng and Yuandi Li and Zhiguo Wan", "abstract": "  As communication systems transition from symbol transmission to conveying\nmeaningful information, sixth-generation (6G) networks emphasize semantic\ncommunication. This approach prioritizes high-level semantic information,\nimproving robustness and reducing redundancy across modalities like text,\nspeech, and images. However, traditional semantic communication faces\nlimitations, including static coding strategies, poor generalization, and\nreliance on task-specific knowledge bases that hinder adaptability. To overcome\nthese challenges, we propose a novel system combining scene understanding,\nLarge Language Models (LLMs), and open channel coding, named \\textbf{OpenSC}.\nTraditional systems rely on fixed domain-specific knowledge bases, limiting\ntheir ability to generalize. Our open channel coding approach leverages shared,\npublicly available knowledge, enabling flexible, adaptive encoding. This\ndynamic system reduces reliance on static task-specific data, enhancing\nadaptability across diverse tasks and environments. Additionally, we use scene\ngraphs for structured semantic encoding, capturing object relationships and\ncontext to improve tasks like Visual Question Answering (VQA). Our approach\nselectively encodes key semantic elements, minimizing redundancy and improving\ntransmission efficiency. Experimental results show significant improvements in\nboth semantic understanding and efficiency, advancing the potential of\nadaptive, generalizable semantic communication in 6G networks.\n", "link": "http://arxiv.org/abs/2501.14520v1", "date": "2025-01-24", "relevancy": 2.4545, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.6336}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.6336}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5136}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Scene%20Understanding%20Enabled%20Semantic%20Communication%20with%20Open%20Channel%0A%20%20Coding&body=Title%3A%20Scene%20Understanding%20Enabled%20Semantic%20Communication%20with%20Open%20Channel%0A%20%20Coding%0AAuthor%3A%20Zhe%20Xiang%20and%20Fei%20Yu%20and%20Quan%20Deng%20and%20Yuandi%20Li%20and%20Zhiguo%20Wan%0AAbstract%3A%20%20%20As%20communication%20systems%20transition%20from%20symbol%20transmission%20to%20conveying%0Ameaningful%20information%2C%20sixth-generation%20%286G%29%20networks%20emphasize%20semantic%0Acommunication.%20This%20approach%20prioritizes%20high-level%20semantic%20information%2C%0Aimproving%20robustness%20and%20reducing%20redundancy%20across%20modalities%20like%20text%2C%0Aspeech%2C%20and%20images.%20However%2C%20traditional%20semantic%20communication%20faces%0Alimitations%2C%20including%20static%20coding%20strategies%2C%20poor%20generalization%2C%20and%0Areliance%20on%20task-specific%20knowledge%20bases%20that%20hinder%20adaptability.%20To%20overcome%0Athese%20challenges%2C%20we%20propose%20a%20novel%20system%20combining%20scene%20understanding%2C%0ALarge%20Language%20Models%20%28LLMs%29%2C%20and%20open%20channel%20coding%2C%20named%20%5Ctextbf%7BOpenSC%7D.%0ATraditional%20systems%20rely%20on%20fixed%20domain-specific%20knowledge%20bases%2C%20limiting%0Atheir%20ability%20to%20generalize.%20Our%20open%20channel%20coding%20approach%20leverages%20shared%2C%0Apublicly%20available%20knowledge%2C%20enabling%20flexible%2C%20adaptive%20encoding.%20This%0Adynamic%20system%20reduces%20reliance%20on%20static%20task-specific%20data%2C%20enhancing%0Aadaptability%20across%20diverse%20tasks%20and%20environments.%20Additionally%2C%20we%20use%20scene%0Agraphs%20for%20structured%20semantic%20encoding%2C%20capturing%20object%20relationships%20and%0Acontext%20to%20improve%20tasks%20like%20Visual%20Question%20Answering%20%28VQA%29.%20Our%20approach%0Aselectively%20encodes%20key%20semantic%20elements%2C%20minimizing%20redundancy%20and%20improving%0Atransmission%20efficiency.%20Experimental%20results%20show%20significant%20improvements%20in%0Aboth%20semantic%20understanding%20and%20efficiency%2C%20advancing%20the%20potential%20of%0Aadaptive%2C%20generalizable%20semantic%20communication%20in%206G%20networks.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14520v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DScene%2520Understanding%2520Enabled%2520Semantic%2520Communication%2520with%2520Open%2520Channel%250A%2520%2520Coding%26entry.906535625%3DZhe%2520Xiang%2520and%2520Fei%2520Yu%2520and%2520Quan%2520Deng%2520and%2520Yuandi%2520Li%2520and%2520Zhiguo%2520Wan%26entry.1292438233%3D%2520%2520As%2520communication%2520systems%2520transition%2520from%2520symbol%2520transmission%2520to%2520conveying%250Ameaningful%2520information%252C%2520sixth-generation%2520%25286G%2529%2520networks%2520emphasize%2520semantic%250Acommunication.%2520This%2520approach%2520prioritizes%2520high-level%2520semantic%2520information%252C%250Aimproving%2520robustness%2520and%2520reducing%2520redundancy%2520across%2520modalities%2520like%2520text%252C%250Aspeech%252C%2520and%2520images.%2520However%252C%2520traditional%2520semantic%2520communication%2520faces%250Alimitations%252C%2520including%2520static%2520coding%2520strategies%252C%2520poor%2520generalization%252C%2520and%250Areliance%2520on%2520task-specific%2520knowledge%2520bases%2520that%2520hinder%2520adaptability.%2520To%2520overcome%250Athese%2520challenges%252C%2520we%2520propose%2520a%2520novel%2520system%2520combining%2520scene%2520understanding%252C%250ALarge%2520Language%2520Models%2520%2528LLMs%2529%252C%2520and%2520open%2520channel%2520coding%252C%2520named%2520%255Ctextbf%257BOpenSC%257D.%250ATraditional%2520systems%2520rely%2520on%2520fixed%2520domain-specific%2520knowledge%2520bases%252C%2520limiting%250Atheir%2520ability%2520to%2520generalize.%2520Our%2520open%2520channel%2520coding%2520approach%2520leverages%2520shared%252C%250Apublicly%2520available%2520knowledge%252C%2520enabling%2520flexible%252C%2520adaptive%2520encoding.%2520This%250Adynamic%2520system%2520reduces%2520reliance%2520on%2520static%2520task-specific%2520data%252C%2520enhancing%250Aadaptability%2520across%2520diverse%2520tasks%2520and%2520environments.%2520Additionally%252C%2520we%2520use%2520scene%250Agraphs%2520for%2520structured%2520semantic%2520encoding%252C%2520capturing%2520object%2520relationships%2520and%250Acontext%2520to%2520improve%2520tasks%2520like%2520Visual%2520Question%2520Answering%2520%2528VQA%2529.%2520Our%2520approach%250Aselectively%2520encodes%2520key%2520semantic%2520elements%252C%2520minimizing%2520redundancy%2520and%2520improving%250Atransmission%2520efficiency.%2520Experimental%2520results%2520show%2520significant%2520improvements%2520in%250Aboth%2520semantic%2520understanding%2520and%2520efficiency%252C%2520advancing%2520the%2520potential%2520of%250Aadaptive%252C%2520generalizable%2520semantic%2520communication%2520in%25206G%2520networks.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14520v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Scene%20Understanding%20Enabled%20Semantic%20Communication%20with%20Open%20Channel%0A%20%20Coding&entry.906535625=Zhe%20Xiang%20and%20Fei%20Yu%20and%20Quan%20Deng%20and%20Yuandi%20Li%20and%20Zhiguo%20Wan&entry.1292438233=%20%20As%20communication%20systems%20transition%20from%20symbol%20transmission%20to%20conveying%0Ameaningful%20information%2C%20sixth-generation%20%286G%29%20networks%20emphasize%20semantic%0Acommunication.%20This%20approach%20prioritizes%20high-level%20semantic%20information%2C%0Aimproving%20robustness%20and%20reducing%20redundancy%20across%20modalities%20like%20text%2C%0Aspeech%2C%20and%20images.%20However%2C%20traditional%20semantic%20communication%20faces%0Alimitations%2C%20including%20static%20coding%20strategies%2C%20poor%20generalization%2C%20and%0Areliance%20on%20task-specific%20knowledge%20bases%20that%20hinder%20adaptability.%20To%20overcome%0Athese%20challenges%2C%20we%20propose%20a%20novel%20system%20combining%20scene%20understanding%2C%0ALarge%20Language%20Models%20%28LLMs%29%2C%20and%20open%20channel%20coding%2C%20named%20%5Ctextbf%7BOpenSC%7D.%0ATraditional%20systems%20rely%20on%20fixed%20domain-specific%20knowledge%20bases%2C%20limiting%0Atheir%20ability%20to%20generalize.%20Our%20open%20channel%20coding%20approach%20leverages%20shared%2C%0Apublicly%20available%20knowledge%2C%20enabling%20flexible%2C%20adaptive%20encoding.%20This%0Adynamic%20system%20reduces%20reliance%20on%20static%20task-specific%20data%2C%20enhancing%0Aadaptability%20across%20diverse%20tasks%20and%20environments.%20Additionally%2C%20we%20use%20scene%0Agraphs%20for%20structured%20semantic%20encoding%2C%20capturing%20object%20relationships%20and%0Acontext%20to%20improve%20tasks%20like%20Visual%20Question%20Answering%20%28VQA%29.%20Our%20approach%0Aselectively%20encodes%20key%20semantic%20elements%2C%20minimizing%20redundancy%20and%20improving%0Atransmission%20efficiency.%20Experimental%20results%20show%20significant%20improvements%20in%0Aboth%20semantic%20understanding%20and%20efficiency%2C%20advancing%20the%20potential%20of%0Aadaptive%2C%20generalizable%20semantic%20communication%20in%206G%20networks.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14520v1&entry.124074799=Read"},
{"title": "Fair Decentralized Learning", "author": "Sayan Biswas and Anne-Marie Kermarrec and Rishi Sharma and Thibaud Trinca and Martijn de Vos", "abstract": "  Decentralized learning (DL) is an emerging approach that enables nodes to\ncollaboratively train a machine learning model without sharing raw data. In\nmany application domains, such as healthcare, this approach faces challenges\ndue to the high level of heterogeneity in the training data's feature space.\nSuch feature heterogeneity lowers model utility and negatively impacts\nfairness, particularly for nodes with under-represented training data. In this\npaper, we introduce \\textsc{Facade}, a clustering-based DL algorithm\nspecifically designed for fair model training when the training data exhibits\nseveral distinct features. The challenge of \\textsc{Facade} is to assign nodes\nto clusters, one for each feature, based on the similarity in the features of\ntheir local data, without requiring individual nodes to know apriori which\ncluster they belong to. \\textsc{Facade} (1) dynamically assigns nodes to their\nappropriate clusters over time, and (2) enables nodes to collaboratively train\na specialized model for each cluster in a fully decentralized manner. We\ntheoretically prove the convergence of \\textsc{Facade}, implement our\nalgorithm, and compare it against three state-of-the-art baselines. Our\nexperimental results on three datasets demonstrate the superiority of our\napproach in terms of model accuracy and fairness compared to all three\ncompetitors. Compared to the best-performing baseline, \\textsc{Facade} on the\nCIFAR-10 dataset also reduces communication costs by 32.3\\% to reach a target\naccuracy when cluster sizes are imbalanced.\n", "link": "http://arxiv.org/abs/2410.02541v3", "date": "2025-01-24", "relevancy": 2.448, "topK": [{"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4944}, {"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4905}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.4839}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Fair%20Decentralized%20Learning&body=Title%3A%20Fair%20Decentralized%20Learning%0AAuthor%3A%20Sayan%20Biswas%20and%20Anne-Marie%20Kermarrec%20and%20Rishi%20Sharma%20and%20Thibaud%20Trinca%20and%20Martijn%20de%20Vos%0AAbstract%3A%20%20%20Decentralized%20learning%20%28DL%29%20is%20an%20emerging%20approach%20that%20enables%20nodes%20to%0Acollaboratively%20train%20a%20machine%20learning%20model%20without%20sharing%20raw%20data.%20In%0Amany%20application%20domains%2C%20such%20as%20healthcare%2C%20this%20approach%20faces%20challenges%0Adue%20to%20the%20high%20level%20of%20heterogeneity%20in%20the%20training%20data%27s%20feature%20space.%0ASuch%20feature%20heterogeneity%20lowers%20model%20utility%20and%20negatively%20impacts%0Afairness%2C%20particularly%20for%20nodes%20with%20under-represented%20training%20data.%20In%20this%0Apaper%2C%20we%20introduce%20%5Ctextsc%7BFacade%7D%2C%20a%20clustering-based%20DL%20algorithm%0Aspecifically%20designed%20for%20fair%20model%20training%20when%20the%20training%20data%20exhibits%0Aseveral%20distinct%20features.%20The%20challenge%20of%20%5Ctextsc%7BFacade%7D%20is%20to%20assign%20nodes%0Ato%20clusters%2C%20one%20for%20each%20feature%2C%20based%20on%20the%20similarity%20in%20the%20features%20of%0Atheir%20local%20data%2C%20without%20requiring%20individual%20nodes%20to%20know%20apriori%20which%0Acluster%20they%20belong%20to.%20%5Ctextsc%7BFacade%7D%20%281%29%20dynamically%20assigns%20nodes%20to%20their%0Aappropriate%20clusters%20over%20time%2C%20and%20%282%29%20enables%20nodes%20to%20collaboratively%20train%0Aa%20specialized%20model%20for%20each%20cluster%20in%20a%20fully%20decentralized%20manner.%20We%0Atheoretically%20prove%20the%20convergence%20of%20%5Ctextsc%7BFacade%7D%2C%20implement%20our%0Aalgorithm%2C%20and%20compare%20it%20against%20three%20state-of-the-art%20baselines.%20Our%0Aexperimental%20results%20on%20three%20datasets%20demonstrate%20the%20superiority%20of%20our%0Aapproach%20in%20terms%20of%20model%20accuracy%20and%20fairness%20compared%20to%20all%20three%0Acompetitors.%20Compared%20to%20the%20best-performing%20baseline%2C%20%5Ctextsc%7BFacade%7D%20on%20the%0ACIFAR-10%20dataset%20also%20reduces%20communication%20costs%20by%2032.3%5C%25%20to%20reach%20a%20target%0Aaccuracy%20when%20cluster%20sizes%20are%20imbalanced.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2410.02541v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DFair%2520Decentralized%2520Learning%26entry.906535625%3DSayan%2520Biswas%2520and%2520Anne-Marie%2520Kermarrec%2520and%2520Rishi%2520Sharma%2520and%2520Thibaud%2520Trinca%2520and%2520Martijn%2520de%2520Vos%26entry.1292438233%3D%2520%2520Decentralized%2520learning%2520%2528DL%2529%2520is%2520an%2520emerging%2520approach%2520that%2520enables%2520nodes%2520to%250Acollaboratively%2520train%2520a%2520machine%2520learning%2520model%2520without%2520sharing%2520raw%2520data.%2520In%250Amany%2520application%2520domains%252C%2520such%2520as%2520healthcare%252C%2520this%2520approach%2520faces%2520challenges%250Adue%2520to%2520the%2520high%2520level%2520of%2520heterogeneity%2520in%2520the%2520training%2520data%2527s%2520feature%2520space.%250ASuch%2520feature%2520heterogeneity%2520lowers%2520model%2520utility%2520and%2520negatively%2520impacts%250Afairness%252C%2520particularly%2520for%2520nodes%2520with%2520under-represented%2520training%2520data.%2520In%2520this%250Apaper%252C%2520we%2520introduce%2520%255Ctextsc%257BFacade%257D%252C%2520a%2520clustering-based%2520DL%2520algorithm%250Aspecifically%2520designed%2520for%2520fair%2520model%2520training%2520when%2520the%2520training%2520data%2520exhibits%250Aseveral%2520distinct%2520features.%2520The%2520challenge%2520of%2520%255Ctextsc%257BFacade%257D%2520is%2520to%2520assign%2520nodes%250Ato%2520clusters%252C%2520one%2520for%2520each%2520feature%252C%2520based%2520on%2520the%2520similarity%2520in%2520the%2520features%2520of%250Atheir%2520local%2520data%252C%2520without%2520requiring%2520individual%2520nodes%2520to%2520know%2520apriori%2520which%250Acluster%2520they%2520belong%2520to.%2520%255Ctextsc%257BFacade%257D%2520%25281%2529%2520dynamically%2520assigns%2520nodes%2520to%2520their%250Aappropriate%2520clusters%2520over%2520time%252C%2520and%2520%25282%2529%2520enables%2520nodes%2520to%2520collaboratively%2520train%250Aa%2520specialized%2520model%2520for%2520each%2520cluster%2520in%2520a%2520fully%2520decentralized%2520manner.%2520We%250Atheoretically%2520prove%2520the%2520convergence%2520of%2520%255Ctextsc%257BFacade%257D%252C%2520implement%2520our%250Aalgorithm%252C%2520and%2520compare%2520it%2520against%2520three%2520state-of-the-art%2520baselines.%2520Our%250Aexperimental%2520results%2520on%2520three%2520datasets%2520demonstrate%2520the%2520superiority%2520of%2520our%250Aapproach%2520in%2520terms%2520of%2520model%2520accuracy%2520and%2520fairness%2520compared%2520to%2520all%2520three%250Acompetitors.%2520Compared%2520to%2520the%2520best-performing%2520baseline%252C%2520%255Ctextsc%257BFacade%257D%2520on%2520the%250ACIFAR-10%2520dataset%2520also%2520reduces%2520communication%2520costs%2520by%252032.3%255C%2525%2520to%2520reach%2520a%2520target%250Aaccuracy%2520when%2520cluster%2520sizes%2520are%2520imbalanced.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2410.02541v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Fair%20Decentralized%20Learning&entry.906535625=Sayan%20Biswas%20and%20Anne-Marie%20Kermarrec%20and%20Rishi%20Sharma%20and%20Thibaud%20Trinca%20and%20Martijn%20de%20Vos&entry.1292438233=%20%20Decentralized%20learning%20%28DL%29%20is%20an%20emerging%20approach%20that%20enables%20nodes%20to%0Acollaboratively%20train%20a%20machine%20learning%20model%20without%20sharing%20raw%20data.%20In%0Amany%20application%20domains%2C%20such%20as%20healthcare%2C%20this%20approach%20faces%20challenges%0Adue%20to%20the%20high%20level%20of%20heterogeneity%20in%20the%20training%20data%27s%20feature%20space.%0ASuch%20feature%20heterogeneity%20lowers%20model%20utility%20and%20negatively%20impacts%0Afairness%2C%20particularly%20for%20nodes%20with%20under-represented%20training%20data.%20In%20this%0Apaper%2C%20we%20introduce%20%5Ctextsc%7BFacade%7D%2C%20a%20clustering-based%20DL%20algorithm%0Aspecifically%20designed%20for%20fair%20model%20training%20when%20the%20training%20data%20exhibits%0Aseveral%20distinct%20features.%20The%20challenge%20of%20%5Ctextsc%7BFacade%7D%20is%20to%20assign%20nodes%0Ato%20clusters%2C%20one%20for%20each%20feature%2C%20based%20on%20the%20similarity%20in%20the%20features%20of%0Atheir%20local%20data%2C%20without%20requiring%20individual%20nodes%20to%20know%20apriori%20which%0Acluster%20they%20belong%20to.%20%5Ctextsc%7BFacade%7D%20%281%29%20dynamically%20assigns%20nodes%20to%20their%0Aappropriate%20clusters%20over%20time%2C%20and%20%282%29%20enables%20nodes%20to%20collaboratively%20train%0Aa%20specialized%20model%20for%20each%20cluster%20in%20a%20fully%20decentralized%20manner.%20We%0Atheoretically%20prove%20the%20convergence%20of%20%5Ctextsc%7BFacade%7D%2C%20implement%20our%0Aalgorithm%2C%20and%20compare%20it%20against%20three%20state-of-the-art%20baselines.%20Our%0Aexperimental%20results%20on%20three%20datasets%20demonstrate%20the%20superiority%20of%20our%0Aapproach%20in%20terms%20of%20model%20accuracy%20and%20fairness%20compared%20to%20all%20three%0Acompetitors.%20Compared%20to%20the%20best-performing%20baseline%2C%20%5Ctextsc%7BFacade%7D%20on%20the%0ACIFAR-10%20dataset%20also%20reduces%20communication%20costs%20by%2032.3%5C%25%20to%20reach%20a%20target%0Aaccuracy%20when%20cluster%20sizes%20are%20imbalanced.%0A&entry.1838667208=http%3A//arxiv.org/abs/2410.02541v3&entry.124074799=Read"},
{"title": "ConsistentFeature: A Plug-and-Play Component for Neural Network\n  Regularization", "author": "RuiZhe Jiang and Haotian Lei", "abstract": "  Over-parameterized neural network models often lead to significant\nperformance discrepancies between training and test sets, a phenomenon known as\noverfitting. To address this, researchers have proposed numerous regularization\ntechniques tailored to various tasks and model architectures. In this paper, we\nintroduce a simple perspective on overfitting: models learn different\nrepresentations in different i.i.d. datasets. Based on this viewpoint, we\npropose an adaptive method, ConsistentFeature, that regularizes the model by\nconstraining feature differences across random subsets of the same training\nset. Due to minimal prior assumptions, this approach is applicable to almost\nany architecture and task. Our experiments show that it effectively reduces\noverfitting, with low sensitivity to hyperparameters and minimal computational\ncost. It demonstrates particularly strong memory suppression and promotes\nnormal convergence, even when the model has already started to overfit. Even in\nthe absence of significant overfitting, our method consistently improves\naccuracy and reduces validation loss.\n", "link": "http://arxiv.org/abs/2412.01476v2", "date": "2025-01-24", "relevancy": 2.3672, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4983}, {"title": "Tuning-Free Noise Rectification for High Fidelity Image-to-Video\n  Generation", "link": "http://arxiv.org/abs/2403.02827v1", "similarity": 0.4688}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4533}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ConsistentFeature%3A%20A%20Plug-and-Play%20Component%20for%20Neural%20Network%0A%20%20Regularization&body=Title%3A%20ConsistentFeature%3A%20A%20Plug-and-Play%20Component%20for%20Neural%20Network%0A%20%20Regularization%0AAuthor%3A%20RuiZhe%20Jiang%20and%20Haotian%20Lei%0AAbstract%3A%20%20%20Over-parameterized%20neural%20network%20models%20often%20lead%20to%20significant%0Aperformance%20discrepancies%20between%20training%20and%20test%20sets%2C%20a%20phenomenon%20known%20as%0Aoverfitting.%20To%20address%20this%2C%20researchers%20have%20proposed%20numerous%20regularization%0Atechniques%20tailored%20to%20various%20tasks%20and%20model%20architectures.%20In%20this%20paper%2C%20we%0Aintroduce%20a%20simple%20perspective%20on%20overfitting%3A%20models%20learn%20different%0Arepresentations%20in%20different%20i.i.d.%20datasets.%20Based%20on%20this%20viewpoint%2C%20we%0Apropose%20an%20adaptive%20method%2C%20ConsistentFeature%2C%20that%20regularizes%20the%20model%20by%0Aconstraining%20feature%20differences%20across%20random%20subsets%20of%20the%20same%20training%0Aset.%20Due%20to%20minimal%20prior%20assumptions%2C%20this%20approach%20is%20applicable%20to%20almost%0Aany%20architecture%20and%20task.%20Our%20experiments%20show%20that%20it%20effectively%20reduces%0Aoverfitting%2C%20with%20low%20sensitivity%20to%20hyperparameters%20and%20minimal%20computational%0Acost.%20It%20demonstrates%20particularly%20strong%20memory%20suppression%20and%20promotes%0Anormal%20convergence%2C%20even%20when%20the%20model%20has%20already%20started%20to%20overfit.%20Even%20in%0Athe%20absence%20of%20significant%20overfitting%2C%20our%20method%20consistently%20improves%0Aaccuracy%20and%20reduces%20validation%20loss.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2412.01476v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DConsistentFeature%253A%2520A%2520Plug-and-Play%2520Component%2520for%2520Neural%2520Network%250A%2520%2520Regularization%26entry.906535625%3DRuiZhe%2520Jiang%2520and%2520Haotian%2520Lei%26entry.1292438233%3D%2520%2520Over-parameterized%2520neural%2520network%2520models%2520often%2520lead%2520to%2520significant%250Aperformance%2520discrepancies%2520between%2520training%2520and%2520test%2520sets%252C%2520a%2520phenomenon%2520known%2520as%250Aoverfitting.%2520To%2520address%2520this%252C%2520researchers%2520have%2520proposed%2520numerous%2520regularization%250Atechniques%2520tailored%2520to%2520various%2520tasks%2520and%2520model%2520architectures.%2520In%2520this%2520paper%252C%2520we%250Aintroduce%2520a%2520simple%2520perspective%2520on%2520overfitting%253A%2520models%2520learn%2520different%250Arepresentations%2520in%2520different%2520i.i.d.%2520datasets.%2520Based%2520on%2520this%2520viewpoint%252C%2520we%250Apropose%2520an%2520adaptive%2520method%252C%2520ConsistentFeature%252C%2520that%2520regularizes%2520the%2520model%2520by%250Aconstraining%2520feature%2520differences%2520across%2520random%2520subsets%2520of%2520the%2520same%2520training%250Aset.%2520Due%2520to%2520minimal%2520prior%2520assumptions%252C%2520this%2520approach%2520is%2520applicable%2520to%2520almost%250Aany%2520architecture%2520and%2520task.%2520Our%2520experiments%2520show%2520that%2520it%2520effectively%2520reduces%250Aoverfitting%252C%2520with%2520low%2520sensitivity%2520to%2520hyperparameters%2520and%2520minimal%2520computational%250Acost.%2520It%2520demonstrates%2520particularly%2520strong%2520memory%2520suppression%2520and%2520promotes%250Anormal%2520convergence%252C%2520even%2520when%2520the%2520model%2520has%2520already%2520started%2520to%2520overfit.%2520Even%2520in%250Athe%2520absence%2520of%2520significant%2520overfitting%252C%2520our%2520method%2520consistently%2520improves%250Aaccuracy%2520and%2520reduces%2520validation%2520loss.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2412.01476v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ConsistentFeature%3A%20A%20Plug-and-Play%20Component%20for%20Neural%20Network%0A%20%20Regularization&entry.906535625=RuiZhe%20Jiang%20and%20Haotian%20Lei&entry.1292438233=%20%20Over-parameterized%20neural%20network%20models%20often%20lead%20to%20significant%0Aperformance%20discrepancies%20between%20training%20and%20test%20sets%2C%20a%20phenomenon%20known%20as%0Aoverfitting.%20To%20address%20this%2C%20researchers%20have%20proposed%20numerous%20regularization%0Atechniques%20tailored%20to%20various%20tasks%20and%20model%20architectures.%20In%20this%20paper%2C%20we%0Aintroduce%20a%20simple%20perspective%20on%20overfitting%3A%20models%20learn%20different%0Arepresentations%20in%20different%20i.i.d.%20datasets.%20Based%20on%20this%20viewpoint%2C%20we%0Apropose%20an%20adaptive%20method%2C%20ConsistentFeature%2C%20that%20regularizes%20the%20model%20by%0Aconstraining%20feature%20differences%20across%20random%20subsets%20of%20the%20same%20training%0Aset.%20Due%20to%20minimal%20prior%20assumptions%2C%20this%20approach%20is%20applicable%20to%20almost%0Aany%20architecture%20and%20task.%20Our%20experiments%20show%20that%20it%20effectively%20reduces%0Aoverfitting%2C%20with%20low%20sensitivity%20to%20hyperparameters%20and%20minimal%20computational%0Acost.%20It%20demonstrates%20particularly%20strong%20memory%20suppression%20and%20promotes%0Anormal%20convergence%2C%20even%20when%20the%20model%20has%20already%20started%20to%20overfit.%20Even%20in%0Athe%20absence%20of%20significant%20overfitting%2C%20our%20method%20consistently%20improves%0Aaccuracy%20and%20reduces%20validation%20loss.%0A&entry.1838667208=http%3A//arxiv.org/abs/2412.01476v2&entry.124074799=Read"},
{"title": "Stroke classification using Virtual Hybrid Edge Detection from in silico\n  electrical impedance tomography data", "author": "Juan Pablo Agnelli and Fernando S. Moura and Siiri Rautio and Melody Alsaker and Rashmi Murthy and Matti Lassas and Samuli Siltanen", "abstract": "  Electrical impedance tomography (EIT) is a non-invasive imaging method for\nrecovering the internal conductivity of a physical body from electric boundary\nmeasurements. EIT combined with machine learning has shown promise for the\nclassification of strokes. However, most previous works have used raw EIT\nvoltage data as network inputs. We build upon a recent development which\nsuggested the use of special noise-robust Virtual Hybrid Edge Detection (VHED)\nfunctions as network inputs, although that work used only highly simplified and\nmathematically ideal models. In this work we strengthen the case for the use of\nEIT, and VHED functions especially, for stroke classification. We design models\nwith high detail and mathematical realism to test the use of VHED functions as\ninputs. Virtual patients are created using a physically detailed 2D head model\nwhich includes features known to create challenges in real-world imaging\nscenarios. Conductivity values are drawn from statistically realistic\ndistributions, and phantoms are afflicted with either hemorrhagic or ischemic\nstrokes of various shapes and sizes. Simulated noisy EIT electrode data,\ngenerated using the realistic Complete Electrode Model (CEM) as opposed to the\nmathematically ideal continuum model, is processed to obtain VHED functions. We\ncompare the use of VHED functions as inputs against the alternative paradigm of\nusing raw EIT voltages. Our results show that (i) stroke classification can be\nperformed with high accuracy using 2D EIT data from physically detailed and\nmathematically realistic models, and (ii) in the presence of noise, VHED\nfunctions outperform raw data as network inputs.\n", "link": "http://arxiv.org/abs/2501.14704v1", "date": "2025-01-24", "relevancy": 2.3663, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4776}, {"title": "VirtualModel: Generating Object-ID-retentive Human-object Interaction\n  Image by Diffusion Model for E-commerce Marketing", "link": "http://arxiv.org/abs/2405.09985v1", "similarity": 0.4733}, {"title": "Tuning-Free Noise Rectification for High Fidelity Image-to-Video\n  Generation", "link": "http://arxiv.org/abs/2403.02827v1", "similarity": 0.4688}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Stroke%20classification%20using%20Virtual%20Hybrid%20Edge%20Detection%20from%20in%20silico%0A%20%20electrical%20impedance%20tomography%20data&body=Title%3A%20Stroke%20classification%20using%20Virtual%20Hybrid%20Edge%20Detection%20from%20in%20silico%0A%20%20electrical%20impedance%20tomography%20data%0AAuthor%3A%20Juan%20Pablo%20Agnelli%20and%20Fernando%20S.%20Moura%20and%20Siiri%20Rautio%20and%20Melody%20Alsaker%20and%20Rashmi%20Murthy%20and%20Matti%20Lassas%20and%20Samuli%20Siltanen%0AAbstract%3A%20%20%20Electrical%20impedance%20tomography%20%28EIT%29%20is%20a%20non-invasive%20imaging%20method%20for%0Arecovering%20the%20internal%20conductivity%20of%20a%20physical%20body%20from%20electric%20boundary%0Ameasurements.%20EIT%20combined%20with%20machine%20learning%20has%20shown%20promise%20for%20the%0Aclassification%20of%20strokes.%20However%2C%20most%20previous%20works%20have%20used%20raw%20EIT%0Avoltage%20data%20as%20network%20inputs.%20We%20build%20upon%20a%20recent%20development%20which%0Asuggested%20the%20use%20of%20special%20noise-robust%20Virtual%20Hybrid%20Edge%20Detection%20%28VHED%29%0Afunctions%20as%20network%20inputs%2C%20although%20that%20work%20used%20only%20highly%20simplified%20and%0Amathematically%20ideal%20models.%20In%20this%20work%20we%20strengthen%20the%20case%20for%20the%20use%20of%0AEIT%2C%20and%20VHED%20functions%20especially%2C%20for%20stroke%20classification.%20We%20design%20models%0Awith%20high%20detail%20and%20mathematical%20realism%20to%20test%20the%20use%20of%20VHED%20functions%20as%0Ainputs.%20Virtual%20patients%20are%20created%20using%20a%20physically%20detailed%202D%20head%20model%0Awhich%20includes%20features%20known%20to%20create%20challenges%20in%20real-world%20imaging%0Ascenarios.%20Conductivity%20values%20are%20drawn%20from%20statistically%20realistic%0Adistributions%2C%20and%20phantoms%20are%20afflicted%20with%20either%20hemorrhagic%20or%20ischemic%0Astrokes%20of%20various%20shapes%20and%20sizes.%20Simulated%20noisy%20EIT%20electrode%20data%2C%0Agenerated%20using%20the%20realistic%20Complete%20Electrode%20Model%20%28CEM%29%20as%20opposed%20to%20the%0Amathematically%20ideal%20continuum%20model%2C%20is%20processed%20to%20obtain%20VHED%20functions.%20We%0Acompare%20the%20use%20of%20VHED%20functions%20as%20inputs%20against%20the%20alternative%20paradigm%20of%0Ausing%20raw%20EIT%20voltages.%20Our%20results%20show%20that%20%28i%29%20stroke%20classification%20can%20be%0Aperformed%20with%20high%20accuracy%20using%202D%20EIT%20data%20from%20physically%20detailed%20and%0Amathematically%20realistic%20models%2C%20and%20%28ii%29%20in%20the%20presence%20of%20noise%2C%20VHED%0Afunctions%20outperform%20raw%20data%20as%20network%20inputs.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14704v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DStroke%2520classification%2520using%2520Virtual%2520Hybrid%2520Edge%2520Detection%2520from%2520in%2520silico%250A%2520%2520electrical%2520impedance%2520tomography%2520data%26entry.906535625%3DJuan%2520Pablo%2520Agnelli%2520and%2520Fernando%2520S.%2520Moura%2520and%2520Siiri%2520Rautio%2520and%2520Melody%2520Alsaker%2520and%2520Rashmi%2520Murthy%2520and%2520Matti%2520Lassas%2520and%2520Samuli%2520Siltanen%26entry.1292438233%3D%2520%2520Electrical%2520impedance%2520tomography%2520%2528EIT%2529%2520is%2520a%2520non-invasive%2520imaging%2520method%2520for%250Arecovering%2520the%2520internal%2520conductivity%2520of%2520a%2520physical%2520body%2520from%2520electric%2520boundary%250Ameasurements.%2520EIT%2520combined%2520with%2520machine%2520learning%2520has%2520shown%2520promise%2520for%2520the%250Aclassification%2520of%2520strokes.%2520However%252C%2520most%2520previous%2520works%2520have%2520used%2520raw%2520EIT%250Avoltage%2520data%2520as%2520network%2520inputs.%2520We%2520build%2520upon%2520a%2520recent%2520development%2520which%250Asuggested%2520the%2520use%2520of%2520special%2520noise-robust%2520Virtual%2520Hybrid%2520Edge%2520Detection%2520%2528VHED%2529%250Afunctions%2520as%2520network%2520inputs%252C%2520although%2520that%2520work%2520used%2520only%2520highly%2520simplified%2520and%250Amathematically%2520ideal%2520models.%2520In%2520this%2520work%2520we%2520strengthen%2520the%2520case%2520for%2520the%2520use%2520of%250AEIT%252C%2520and%2520VHED%2520functions%2520especially%252C%2520for%2520stroke%2520classification.%2520We%2520design%2520models%250Awith%2520high%2520detail%2520and%2520mathematical%2520realism%2520to%2520test%2520the%2520use%2520of%2520VHED%2520functions%2520as%250Ainputs.%2520Virtual%2520patients%2520are%2520created%2520using%2520a%2520physically%2520detailed%25202D%2520head%2520model%250Awhich%2520includes%2520features%2520known%2520to%2520create%2520challenges%2520in%2520real-world%2520imaging%250Ascenarios.%2520Conductivity%2520values%2520are%2520drawn%2520from%2520statistically%2520realistic%250Adistributions%252C%2520and%2520phantoms%2520are%2520afflicted%2520with%2520either%2520hemorrhagic%2520or%2520ischemic%250Astrokes%2520of%2520various%2520shapes%2520and%2520sizes.%2520Simulated%2520noisy%2520EIT%2520electrode%2520data%252C%250Agenerated%2520using%2520the%2520realistic%2520Complete%2520Electrode%2520Model%2520%2528CEM%2529%2520as%2520opposed%2520to%2520the%250Amathematically%2520ideal%2520continuum%2520model%252C%2520is%2520processed%2520to%2520obtain%2520VHED%2520functions.%2520We%250Acompare%2520the%2520use%2520of%2520VHED%2520functions%2520as%2520inputs%2520against%2520the%2520alternative%2520paradigm%2520of%250Ausing%2520raw%2520EIT%2520voltages.%2520Our%2520results%2520show%2520that%2520%2528i%2529%2520stroke%2520classification%2520can%2520be%250Aperformed%2520with%2520high%2520accuracy%2520using%25202D%2520EIT%2520data%2520from%2520physically%2520detailed%2520and%250Amathematically%2520realistic%2520models%252C%2520and%2520%2528ii%2529%2520in%2520the%2520presence%2520of%2520noise%252C%2520VHED%250Afunctions%2520outperform%2520raw%2520data%2520as%2520network%2520inputs.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14704v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Stroke%20classification%20using%20Virtual%20Hybrid%20Edge%20Detection%20from%20in%20silico%0A%20%20electrical%20impedance%20tomography%20data&entry.906535625=Juan%20Pablo%20Agnelli%20and%20Fernando%20S.%20Moura%20and%20Siiri%20Rautio%20and%20Melody%20Alsaker%20and%20Rashmi%20Murthy%20and%20Matti%20Lassas%20and%20Samuli%20Siltanen&entry.1292438233=%20%20Electrical%20impedance%20tomography%20%28EIT%29%20is%20a%20non-invasive%20imaging%20method%20for%0Arecovering%20the%20internal%20conductivity%20of%20a%20physical%20body%20from%20electric%20boundary%0Ameasurements.%20EIT%20combined%20with%20machine%20learning%20has%20shown%20promise%20for%20the%0Aclassification%20of%20strokes.%20However%2C%20most%20previous%20works%20have%20used%20raw%20EIT%0Avoltage%20data%20as%20network%20inputs.%20We%20build%20upon%20a%20recent%20development%20which%0Asuggested%20the%20use%20of%20special%20noise-robust%20Virtual%20Hybrid%20Edge%20Detection%20%28VHED%29%0Afunctions%20as%20network%20inputs%2C%20although%20that%20work%20used%20only%20highly%20simplified%20and%0Amathematically%20ideal%20models.%20In%20this%20work%20we%20strengthen%20the%20case%20for%20the%20use%20of%0AEIT%2C%20and%20VHED%20functions%20especially%2C%20for%20stroke%20classification.%20We%20design%20models%0Awith%20high%20detail%20and%20mathematical%20realism%20to%20test%20the%20use%20of%20VHED%20functions%20as%0Ainputs.%20Virtual%20patients%20are%20created%20using%20a%20physically%20detailed%202D%20head%20model%0Awhich%20includes%20features%20known%20to%20create%20challenges%20in%20real-world%20imaging%0Ascenarios.%20Conductivity%20values%20are%20drawn%20from%20statistically%20realistic%0Adistributions%2C%20and%20phantoms%20are%20afflicted%20with%20either%20hemorrhagic%20or%20ischemic%0Astrokes%20of%20various%20shapes%20and%20sizes.%20Simulated%20noisy%20EIT%20electrode%20data%2C%0Agenerated%20using%20the%20realistic%20Complete%20Electrode%20Model%20%28CEM%29%20as%20opposed%20to%20the%0Amathematically%20ideal%20continuum%20model%2C%20is%20processed%20to%20obtain%20VHED%20functions.%20We%0Acompare%20the%20use%20of%20VHED%20functions%20as%20inputs%20against%20the%20alternative%20paradigm%20of%0Ausing%20raw%20EIT%20voltages.%20Our%20results%20show%20that%20%28i%29%20stroke%20classification%20can%20be%0Aperformed%20with%20high%20accuracy%20using%202D%20EIT%20data%20from%20physically%20detailed%20and%0Amathematically%20realistic%20models%2C%20and%20%28ii%29%20in%20the%20presence%20of%20noise%2C%20VHED%0Afunctions%20outperform%20raw%20data%20as%20network%20inputs.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14704v1&entry.124074799=Read"},
{"title": "Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions", "author": "Moran Yanuka and Assaf Ben Kish and Yonatan Bitton and Idan Szpektor and Raja Giryes", "abstract": "  Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.\n", "link": "http://arxiv.org/abs/2411.09018v2", "date": "2025-01-24", "relevancy": 2.3623, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5915}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5915}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.586}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Bridging%20the%20Visual%20Gap%3A%20Fine-Tuning%20Multimodal%20Models%20with%0A%20%20Knowledge-Adapted%20Captions&body=Title%3A%20Bridging%20the%20Visual%20Gap%3A%20Fine-Tuning%20Multimodal%20Models%20with%0A%20%20Knowledge-Adapted%20Captions%0AAuthor%3A%20Moran%20Yanuka%20and%20Assaf%20Ben%20Kish%20and%20Yonatan%20Bitton%20and%20Idan%20Szpektor%20and%20Raja%20Giryes%0AAbstract%3A%20%20%20Recent%20research%20increasingly%20focuses%20on%20training%20vision-language%20models%0A%28VLMs%29%20with%20long%2C%20detailed%20image%20captions.%20However%2C%20small-scale%20VLMs%20often%0Astruggle%20to%20balance%20the%20richness%20of%20these%20captions%20with%20the%20risk%20of%0Ahallucinating%20content%20during%20fine-tuning.%20In%20this%20paper%2C%20we%20explore%20how%20well%0AVLMs%20adapt%20to%20such%20captions.%20To%20quantify%20caption%20quality%2C%20we%20propose%20Decomposed%0ANLI%20%28DNLI%29%2C%20an%20evaluation%20framework%20that%20breaks%20down%20generated%20captions%20into%0Aindividual%20propositions%2C%20assessing%20each%20in%20isolation.%20This%20fine-grained%0Aanalysis%20reveals%20a%20critical%20balance%20between%20capturing%20descriptive%20details%20and%0Apreventing%20hallucinations.%20Our%20findings%20show%20that%20simply%20reducing%20caption%0Acomplexity%20or%20employing%20standard%20data%20curation%20techniques%20does%20not%20effectively%0Aresolve%20this%20issue.%20To%20tackle%20this%20challenge%2C%20we%20introduce%20Knowledge%20Adapted%0A%28KnowAda%29%20fine-tuning%2C%20a%20data-centric%20approach%20that%20automatically%20adapts%0Atraining%20data%20with%20the%20model%27s%20existing%20knowledge%20and%20visual%20understanding.%0AKnowAda%20minimizes%20hallucinations%20while%20preserving%20high%20descriptiveness.%20We%0Avalidate%20this%20approach%20across%20several%20small-scale%20VLMs%20%28up%20to%207B%20parameters%29%0Aand%20dense%20caption%20datasets%2C%20demonstrating%20that%20KnowAda%20effectively%20balances%0Ahallucination%20reduction%20and%20descriptiveness.%20Our%20results%20show%20that%20KnowAda%0Aoutperforms%20various%20baselines%20in%20both%20automatic%20metrics%20and%20human%20evaluations.%0AWe%20will%20release%20our%20code%20and%20models.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2411.09018v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DBridging%2520the%2520Visual%2520Gap%253A%2520Fine-Tuning%2520Multimodal%2520Models%2520with%250A%2520%2520Knowledge-Adapted%2520Captions%26entry.906535625%3DMoran%2520Yanuka%2520and%2520Assaf%2520Ben%2520Kish%2520and%2520Yonatan%2520Bitton%2520and%2520Idan%2520Szpektor%2520and%2520Raja%2520Giryes%26entry.1292438233%3D%2520%2520Recent%2520research%2520increasingly%2520focuses%2520on%2520training%2520vision-language%2520models%250A%2528VLMs%2529%2520with%2520long%252C%2520detailed%2520image%2520captions.%2520However%252C%2520small-scale%2520VLMs%2520often%250Astruggle%2520to%2520balance%2520the%2520richness%2520of%2520these%2520captions%2520with%2520the%2520risk%2520of%250Ahallucinating%2520content%2520during%2520fine-tuning.%2520In%2520this%2520paper%252C%2520we%2520explore%2520how%2520well%250AVLMs%2520adapt%2520to%2520such%2520captions.%2520To%2520quantify%2520caption%2520quality%252C%2520we%2520propose%2520Decomposed%250ANLI%2520%2528DNLI%2529%252C%2520an%2520evaluation%2520framework%2520that%2520breaks%2520down%2520generated%2520captions%2520into%250Aindividual%2520propositions%252C%2520assessing%2520each%2520in%2520isolation.%2520This%2520fine-grained%250Aanalysis%2520reveals%2520a%2520critical%2520balance%2520between%2520capturing%2520descriptive%2520details%2520and%250Apreventing%2520hallucinations.%2520Our%2520findings%2520show%2520that%2520simply%2520reducing%2520caption%250Acomplexity%2520or%2520employing%2520standard%2520data%2520curation%2520techniques%2520does%2520not%2520effectively%250Aresolve%2520this%2520issue.%2520To%2520tackle%2520this%2520challenge%252C%2520we%2520introduce%2520Knowledge%2520Adapted%250A%2528KnowAda%2529%2520fine-tuning%252C%2520a%2520data-centric%2520approach%2520that%2520automatically%2520adapts%250Atraining%2520data%2520with%2520the%2520model%2527s%2520existing%2520knowledge%2520and%2520visual%2520understanding.%250AKnowAda%2520minimizes%2520hallucinations%2520while%2520preserving%2520high%2520descriptiveness.%2520We%250Avalidate%2520this%2520approach%2520across%2520several%2520small-scale%2520VLMs%2520%2528up%2520to%25207B%2520parameters%2529%250Aand%2520dense%2520caption%2520datasets%252C%2520demonstrating%2520that%2520KnowAda%2520effectively%2520balances%250Ahallucination%2520reduction%2520and%2520descriptiveness.%2520Our%2520results%2520show%2520that%2520KnowAda%250Aoutperforms%2520various%2520baselines%2520in%2520both%2520automatic%2520metrics%2520and%2520human%2520evaluations.%250AWe%2520will%2520release%2520our%2520code%2520and%2520models.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2411.09018v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Bridging%20the%20Visual%20Gap%3A%20Fine-Tuning%20Multimodal%20Models%20with%0A%20%20Knowledge-Adapted%20Captions&entry.906535625=Moran%20Yanuka%20and%20Assaf%20Ben%20Kish%20and%20Yonatan%20Bitton%20and%20Idan%20Szpektor%20and%20Raja%20Giryes&entry.1292438233=%20%20Recent%20research%20increasingly%20focuses%20on%20training%20vision-language%20models%0A%28VLMs%29%20with%20long%2C%20detailed%20image%20captions.%20However%2C%20small-scale%20VLMs%20often%0Astruggle%20to%20balance%20the%20richness%20of%20these%20captions%20with%20the%20risk%20of%0Ahallucinating%20content%20during%20fine-tuning.%20In%20this%20paper%2C%20we%20explore%20how%20well%0AVLMs%20adapt%20to%20such%20captions.%20To%20quantify%20caption%20quality%2C%20we%20propose%20Decomposed%0ANLI%20%28DNLI%29%2C%20an%20evaluation%20framework%20that%20breaks%20down%20generated%20captions%20into%0Aindividual%20propositions%2C%20assessing%20each%20in%20isolation.%20This%20fine-grained%0Aanalysis%20reveals%20a%20critical%20balance%20between%20capturing%20descriptive%20details%20and%0Apreventing%20hallucinations.%20Our%20findings%20show%20that%20simply%20reducing%20caption%0Acomplexity%20or%20employing%20standard%20data%20curation%20techniques%20does%20not%20effectively%0Aresolve%20this%20issue.%20To%20tackle%20this%20challenge%2C%20we%20introduce%20Knowledge%20Adapted%0A%28KnowAda%29%20fine-tuning%2C%20a%20data-centric%20approach%20that%20automatically%20adapts%0Atraining%20data%20with%20the%20model%27s%20existing%20knowledge%20and%20visual%20understanding.%0AKnowAda%20minimizes%20hallucinations%20while%20preserving%20high%20descriptiveness.%20We%0Avalidate%20this%20approach%20across%20several%20small-scale%20VLMs%20%28up%20to%207B%20parameters%29%0Aand%20dense%20caption%20datasets%2C%20demonstrating%20that%20KnowAda%20effectively%20balances%0Ahallucination%20reduction%20and%20descriptiveness.%20Our%20results%20show%20that%20KnowAda%0Aoutperforms%20various%20baselines%20in%20both%20automatic%20metrics%20and%20human%20evaluations.%0AWe%20will%20release%20our%20code%20and%20models.%0A&entry.1838667208=http%3A//arxiv.org/abs/2411.09018v2&entry.124074799=Read"},
{"title": "Signature Methods in Machine Learning", "author": "Terry Lyons and Andrew D. McLeod", "abstract": "  Signature-based techniques give mathematical insight into the interactions\nbetween complex streams of evolving data. These insights can be quite naturally\ntranslated into numerical approaches to understanding streamed data, and\nperhaps because of their mathematical precision, have proved useful in\nanalysing streamed data in situations where the data is irregular, and not\nstationary, and the dimension of the data and the sample sizes are both\nmoderate. Understanding streamed multi-modal data is exponential: a word in $n$\nletters from an alphabet of size $d$ can be any one of $d^n$ messages.\nSignatures remove the exponential amount of noise that arises from sampling\nirregularity, but an exponential amount of information still remain. This\nsurvey aims to stay in the domain where that exponential scaling can be managed\ndirectly. Scalability issues are an important challenge in many problems but\nwould require another survey article and further ideas. This survey describes a\nrange of contexts where the data sets are small enough to remove the\npossibility of massive machine learning, and the existence of small sets of\ncontext free and principled features can be used effectively. The mathematical\nnature of the tools can make their use intimidating to non-mathematicians. The\nexamples presented in this article are intended to bridge this communication\ngap and provide tractable working examples drawn from the machine learning\ncontext. Notebooks are available online for several of these examples. This\nsurvey builds on the earlier paper of Ilya Chevryev and Andrey Kormilitzin\nwhich had broadly similar aims at an earlier point in the development of this\nmachinery. This article illustrates how the theoretical insights offered by\nsignatures are simply realised in the analysis of application data in a way\nthat is largely agnostic to the data type.\n", "link": "http://arxiv.org/abs/2206.14674v6", "date": "2025-01-24", "relevancy": 2.3048, "topK": [{"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.5013}, {"title": "Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance", "link": "http://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html", "similarity": 0.4462}, {"title": "Magic-Me: Identity-Specific Video Customized Diffusion", "link": "http://arxiv.org/abs/2402.09368v1", "similarity": 0.4353}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Signature%20Methods%20in%20Machine%20Learning&body=Title%3A%20Signature%20Methods%20in%20Machine%20Learning%0AAuthor%3A%20Terry%20Lyons%20and%20Andrew%20D.%20McLeod%0AAbstract%3A%20%20%20Signature-based%20techniques%20give%20mathematical%20insight%20into%20the%20interactions%0Abetween%20complex%20streams%20of%20evolving%20data.%20These%20insights%20can%20be%20quite%20naturally%0Atranslated%20into%20numerical%20approaches%20to%20understanding%20streamed%20data%2C%20and%0Aperhaps%20because%20of%20their%20mathematical%20precision%2C%20have%20proved%20useful%20in%0Aanalysing%20streamed%20data%20in%20situations%20where%20the%20data%20is%20irregular%2C%20and%20not%0Astationary%2C%20and%20the%20dimension%20of%20the%20data%20and%20the%20sample%20sizes%20are%20both%0Amoderate.%20Understanding%20streamed%20multi-modal%20data%20is%20exponential%3A%20a%20word%20in%20%24n%24%0Aletters%20from%20an%20alphabet%20of%20size%20%24d%24%20can%20be%20any%20one%20of%20%24d%5En%24%20messages.%0ASignatures%20remove%20the%20exponential%20amount%20of%20noise%20that%20arises%20from%20sampling%0Airregularity%2C%20but%20an%20exponential%20amount%20of%20information%20still%20remain.%20This%0Asurvey%20aims%20to%20stay%20in%20the%20domain%20where%20that%20exponential%20scaling%20can%20be%20managed%0Adirectly.%20Scalability%20issues%20are%20an%20important%20challenge%20in%20many%20problems%20but%0Awould%20require%20another%20survey%20article%20and%20further%20ideas.%20This%20survey%20describes%20a%0Arange%20of%20contexts%20where%20the%20data%20sets%20are%20small%20enough%20to%20remove%20the%0Apossibility%20of%20massive%20machine%20learning%2C%20and%20the%20existence%20of%20small%20sets%20of%0Acontext%20free%20and%20principled%20features%20can%20be%20used%20effectively.%20The%20mathematical%0Anature%20of%20the%20tools%20can%20make%20their%20use%20intimidating%20to%20non-mathematicians.%20The%0Aexamples%20presented%20in%20this%20article%20are%20intended%20to%20bridge%20this%20communication%0Agap%20and%20provide%20tractable%20working%20examples%20drawn%20from%20the%20machine%20learning%0Acontext.%20Notebooks%20are%20available%20online%20for%20several%20of%20these%20examples.%20This%0Asurvey%20builds%20on%20the%20earlier%20paper%20of%20Ilya%20Chevryev%20and%20Andrey%20Kormilitzin%0Awhich%20had%20broadly%20similar%20aims%20at%20an%20earlier%20point%20in%20the%20development%20of%20this%0Amachinery.%20This%20article%20illustrates%20how%20the%20theoretical%20insights%20offered%20by%0Asignatures%20are%20simply%20realised%20in%20the%20analysis%20of%20application%20data%20in%20a%20way%0Athat%20is%20largely%20agnostic%20to%20the%20data%20type.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2206.14674v6%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSignature%2520Methods%2520in%2520Machine%2520Learning%26entry.906535625%3DTerry%2520Lyons%2520and%2520Andrew%2520D.%2520McLeod%26entry.1292438233%3D%2520%2520Signature-based%2520techniques%2520give%2520mathematical%2520insight%2520into%2520the%2520interactions%250Abetween%2520complex%2520streams%2520of%2520evolving%2520data.%2520These%2520insights%2520can%2520be%2520quite%2520naturally%250Atranslated%2520into%2520numerical%2520approaches%2520to%2520understanding%2520streamed%2520data%252C%2520and%250Aperhaps%2520because%2520of%2520their%2520mathematical%2520precision%252C%2520have%2520proved%2520useful%2520in%250Aanalysing%2520streamed%2520data%2520in%2520situations%2520where%2520the%2520data%2520is%2520irregular%252C%2520and%2520not%250Astationary%252C%2520and%2520the%2520dimension%2520of%2520the%2520data%2520and%2520the%2520sample%2520sizes%2520are%2520both%250Amoderate.%2520Understanding%2520streamed%2520multi-modal%2520data%2520is%2520exponential%253A%2520a%2520word%2520in%2520%2524n%2524%250Aletters%2520from%2520an%2520alphabet%2520of%2520size%2520%2524d%2524%2520can%2520be%2520any%2520one%2520of%2520%2524d%255En%2524%2520messages.%250ASignatures%2520remove%2520the%2520exponential%2520amount%2520of%2520noise%2520that%2520arises%2520from%2520sampling%250Airregularity%252C%2520but%2520an%2520exponential%2520amount%2520of%2520information%2520still%2520remain.%2520This%250Asurvey%2520aims%2520to%2520stay%2520in%2520the%2520domain%2520where%2520that%2520exponential%2520scaling%2520can%2520be%2520managed%250Adirectly.%2520Scalability%2520issues%2520are%2520an%2520important%2520challenge%2520in%2520many%2520problems%2520but%250Awould%2520require%2520another%2520survey%2520article%2520and%2520further%2520ideas.%2520This%2520survey%2520describes%2520a%250Arange%2520of%2520contexts%2520where%2520the%2520data%2520sets%2520are%2520small%2520enough%2520to%2520remove%2520the%250Apossibility%2520of%2520massive%2520machine%2520learning%252C%2520and%2520the%2520existence%2520of%2520small%2520sets%2520of%250Acontext%2520free%2520and%2520principled%2520features%2520can%2520be%2520used%2520effectively.%2520The%2520mathematical%250Anature%2520of%2520the%2520tools%2520can%2520make%2520their%2520use%2520intimidating%2520to%2520non-mathematicians.%2520The%250Aexamples%2520presented%2520in%2520this%2520article%2520are%2520intended%2520to%2520bridge%2520this%2520communication%250Agap%2520and%2520provide%2520tractable%2520working%2520examples%2520drawn%2520from%2520the%2520machine%2520learning%250Acontext.%2520Notebooks%2520are%2520available%2520online%2520for%2520several%2520of%2520these%2520examples.%2520This%250Asurvey%2520builds%2520on%2520the%2520earlier%2520paper%2520of%2520Ilya%2520Chevryev%2520and%2520Andrey%2520Kormilitzin%250Awhich%2520had%2520broadly%2520similar%2520aims%2520at%2520an%2520earlier%2520point%2520in%2520the%2520development%2520of%2520this%250Amachinery.%2520This%2520article%2520illustrates%2520how%2520the%2520theoretical%2520insights%2520offered%2520by%250Asignatures%2520are%2520simply%2520realised%2520in%2520the%2520analysis%2520of%2520application%2520data%2520in%2520a%2520way%250Athat%2520is%2520largely%2520agnostic%2520to%2520the%2520data%2520type.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2206.14674v6%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Signature%20Methods%20in%20Machine%20Learning&entry.906535625=Terry%20Lyons%20and%20Andrew%20D.%20McLeod&entry.1292438233=%20%20Signature-based%20techniques%20give%20mathematical%20insight%20into%20the%20interactions%0Abetween%20complex%20streams%20of%20evolving%20data.%20These%20insights%20can%20be%20quite%20naturally%0Atranslated%20into%20numerical%20approaches%20to%20understanding%20streamed%20data%2C%20and%0Aperhaps%20because%20of%20their%20mathematical%20precision%2C%20have%20proved%20useful%20in%0Aanalysing%20streamed%20data%20in%20situations%20where%20the%20data%20is%20irregular%2C%20and%20not%0Astationary%2C%20and%20the%20dimension%20of%20the%20data%20and%20the%20sample%20sizes%20are%20both%0Amoderate.%20Understanding%20streamed%20multi-modal%20data%20is%20exponential%3A%20a%20word%20in%20%24n%24%0Aletters%20from%20an%20alphabet%20of%20size%20%24d%24%20can%20be%20any%20one%20of%20%24d%5En%24%20messages.%0ASignatures%20remove%20the%20exponential%20amount%20of%20noise%20that%20arises%20from%20sampling%0Airregularity%2C%20but%20an%20exponential%20amount%20of%20information%20still%20remain.%20This%0Asurvey%20aims%20to%20stay%20in%20the%20domain%20where%20that%20exponential%20scaling%20can%20be%20managed%0Adirectly.%20Scalability%20issues%20are%20an%20important%20challenge%20in%20many%20problems%20but%0Awould%20require%20another%20survey%20article%20and%20further%20ideas.%20This%20survey%20describes%20a%0Arange%20of%20contexts%20where%20the%20data%20sets%20are%20small%20enough%20to%20remove%20the%0Apossibility%20of%20massive%20machine%20learning%2C%20and%20the%20existence%20of%20small%20sets%20of%0Acontext%20free%20and%20principled%20features%20can%20be%20used%20effectively.%20The%20mathematical%0Anature%20of%20the%20tools%20can%20make%20their%20use%20intimidating%20to%20non-mathematicians.%20The%0Aexamples%20presented%20in%20this%20article%20are%20intended%20to%20bridge%20this%20communication%0Agap%20and%20provide%20tractable%20working%20examples%20drawn%20from%20the%20machine%20learning%0Acontext.%20Notebooks%20are%20available%20online%20for%20several%20of%20these%20examples.%20This%0Asurvey%20builds%20on%20the%20earlier%20paper%20of%20Ilya%20Chevryev%20and%20Andrey%20Kormilitzin%0Awhich%20had%20broadly%20similar%20aims%20at%20an%20earlier%20point%20in%20the%20development%20of%20this%0Amachinery.%20This%20article%20illustrates%20how%20the%20theoretical%20insights%20offered%20by%0Asignatures%20are%20simply%20realised%20in%20the%20analysis%20of%20application%20data%20in%20a%20way%0Athat%20is%20largely%20agnostic%20to%20the%20data%20type.%0A&entry.1838667208=http%3A//arxiv.org/abs/2206.14674v6&entry.124074799=Read"},
{"title": "Optimizing Grasping Precision for Industrial Pick-and-Place Tasks\n  Through a Novel Visual Servoing Approach", "author": "Khairidine Benali", "abstract": "  The integration of robotic arm manipulators into industrial manufacturing\nlines has become common, thanks to their efficiency and effectiveness in\nexecuting specific tasks. With advancements in camera technology, visual\nsensors and perception systems have been incorporated to address more complex\noperations. This study introduces a novel visual serving control system\ndesigned for robotic operations in challenging environments, where accurate\nobject pose estimation is hindered by factors such as vibrations, tool path\ndeviations, and machining marks. To overcome these obstacles, our solution\nfocuses on enhancing the accuracy of picking and placing tasks, ensuring\nreliable performance across various scenarios. This is accomplished by a novel\nvisual servoing method based on the integration of two complementary\nmethodologies: a technique for object localization and a separate approach for\nprecise control through visual feedback, leveraging their strengths to address\nthe challenges posed by the industrial context and thereby improving overall\ngrasping accuracy. Our method employ feedback from perception sensors to adjust\nthe control loop efficiently, enabling the robotic system to adeptly pick and\nplace objects. We have introduced a controller capable of seamlessly managing\nthe detection and manipulation of various shapes and types of objects within an\nindustrial context, addressing numerous challenges that arise in such\nenvironments.\n", "link": "http://arxiv.org/abs/2501.14557v1", "date": "2025-01-24", "relevancy": 2.2942, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5902}, {"title": "Egocentric Computer Vision for Hands-Free Robotic Wheelchair Navigation", "link": "https://link.springer.com/article/10.1007/s10846-023-01807-4", "similarity": 0.5721}, {"title": "UGG: Unified Generative Grasping", "link": "https://arxiv.org/abs/2311.16917", "similarity": 0.5683}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Optimizing%20Grasping%20Precision%20for%20Industrial%20Pick-and-Place%20Tasks%0A%20%20Through%20a%20Novel%20Visual%20Servoing%20Approach&body=Title%3A%20Optimizing%20Grasping%20Precision%20for%20Industrial%20Pick-and-Place%20Tasks%0A%20%20Through%20a%20Novel%20Visual%20Servoing%20Approach%0AAuthor%3A%20Khairidine%20Benali%0AAbstract%3A%20%20%20The%20integration%20of%20robotic%20arm%20manipulators%20into%20industrial%20manufacturing%0Alines%20has%20become%20common%2C%20thanks%20to%20their%20efficiency%20and%20effectiveness%20in%0Aexecuting%20specific%20tasks.%20With%20advancements%20in%20camera%20technology%2C%20visual%0Asensors%20and%20perception%20systems%20have%20been%20incorporated%20to%20address%20more%20complex%0Aoperations.%20This%20study%20introduces%20a%20novel%20visual%20serving%20control%20system%0Adesigned%20for%20robotic%20operations%20in%20challenging%20environments%2C%20where%20accurate%0Aobject%20pose%20estimation%20is%20hindered%20by%20factors%20such%20as%20vibrations%2C%20tool%20path%0Adeviations%2C%20and%20machining%20marks.%20To%20overcome%20these%20obstacles%2C%20our%20solution%0Afocuses%20on%20enhancing%20the%20accuracy%20of%20picking%20and%20placing%20tasks%2C%20ensuring%0Areliable%20performance%20across%20various%20scenarios.%20This%20is%20accomplished%20by%20a%20novel%0Avisual%20servoing%20method%20based%20on%20the%20integration%20of%20two%20complementary%0Amethodologies%3A%20a%20technique%20for%20object%20localization%20and%20a%20separate%20approach%20for%0Aprecise%20control%20through%20visual%20feedback%2C%20leveraging%20their%20strengths%20to%20address%0Athe%20challenges%20posed%20by%20the%20industrial%20context%20and%20thereby%20improving%20overall%0Agrasping%20accuracy.%20Our%20method%20employ%20feedback%20from%20perception%20sensors%20to%20adjust%0Athe%20control%20loop%20efficiently%2C%20enabling%20the%20robotic%20system%20to%20adeptly%20pick%20and%0Aplace%20objects.%20We%20have%20introduced%20a%20controller%20capable%20of%20seamlessly%20managing%0Athe%20detection%20and%20manipulation%20of%20various%20shapes%20and%20types%20of%20objects%20within%20an%0Aindustrial%20context%2C%20addressing%20numerous%20challenges%20that%20arise%20in%20such%0Aenvironments.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14557v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DOptimizing%2520Grasping%2520Precision%2520for%2520Industrial%2520Pick-and-Place%2520Tasks%250A%2520%2520Through%2520a%2520Novel%2520Visual%2520Servoing%2520Approach%26entry.906535625%3DKhairidine%2520Benali%26entry.1292438233%3D%2520%2520The%2520integration%2520of%2520robotic%2520arm%2520manipulators%2520into%2520industrial%2520manufacturing%250Alines%2520has%2520become%2520common%252C%2520thanks%2520to%2520their%2520efficiency%2520and%2520effectiveness%2520in%250Aexecuting%2520specific%2520tasks.%2520With%2520advancements%2520in%2520camera%2520technology%252C%2520visual%250Asensors%2520and%2520perception%2520systems%2520have%2520been%2520incorporated%2520to%2520address%2520more%2520complex%250Aoperations.%2520This%2520study%2520introduces%2520a%2520novel%2520visual%2520serving%2520control%2520system%250Adesigned%2520for%2520robotic%2520operations%2520in%2520challenging%2520environments%252C%2520where%2520accurate%250Aobject%2520pose%2520estimation%2520is%2520hindered%2520by%2520factors%2520such%2520as%2520vibrations%252C%2520tool%2520path%250Adeviations%252C%2520and%2520machining%2520marks.%2520To%2520overcome%2520these%2520obstacles%252C%2520our%2520solution%250Afocuses%2520on%2520enhancing%2520the%2520accuracy%2520of%2520picking%2520and%2520placing%2520tasks%252C%2520ensuring%250Areliable%2520performance%2520across%2520various%2520scenarios.%2520This%2520is%2520accomplished%2520by%2520a%2520novel%250Avisual%2520servoing%2520method%2520based%2520on%2520the%2520integration%2520of%2520two%2520complementary%250Amethodologies%253A%2520a%2520technique%2520for%2520object%2520localization%2520and%2520a%2520separate%2520approach%2520for%250Aprecise%2520control%2520through%2520visual%2520feedback%252C%2520leveraging%2520their%2520strengths%2520to%2520address%250Athe%2520challenges%2520posed%2520by%2520the%2520industrial%2520context%2520and%2520thereby%2520improving%2520overall%250Agrasping%2520accuracy.%2520Our%2520method%2520employ%2520feedback%2520from%2520perception%2520sensors%2520to%2520adjust%250Athe%2520control%2520loop%2520efficiently%252C%2520enabling%2520the%2520robotic%2520system%2520to%2520adeptly%2520pick%2520and%250Aplace%2520objects.%2520We%2520have%2520introduced%2520a%2520controller%2520capable%2520of%2520seamlessly%2520managing%250Athe%2520detection%2520and%2520manipulation%2520of%2520various%2520shapes%2520and%2520types%2520of%2520objects%2520within%2520an%250Aindustrial%2520context%252C%2520addressing%2520numerous%2520challenges%2520that%2520arise%2520in%2520such%250Aenvironments.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14557v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Optimizing%20Grasping%20Precision%20for%20Industrial%20Pick-and-Place%20Tasks%0A%20%20Through%20a%20Novel%20Visual%20Servoing%20Approach&entry.906535625=Khairidine%20Benali&entry.1292438233=%20%20The%20integration%20of%20robotic%20arm%20manipulators%20into%20industrial%20manufacturing%0Alines%20has%20become%20common%2C%20thanks%20to%20their%20efficiency%20and%20effectiveness%20in%0Aexecuting%20specific%20tasks.%20With%20advancements%20in%20camera%20technology%2C%20visual%0Asensors%20and%20perception%20systems%20have%20been%20incorporated%20to%20address%20more%20complex%0Aoperations.%20This%20study%20introduces%20a%20novel%20visual%20serving%20control%20system%0Adesigned%20for%20robotic%20operations%20in%20challenging%20environments%2C%20where%20accurate%0Aobject%20pose%20estimation%20is%20hindered%20by%20factors%20such%20as%20vibrations%2C%20tool%20path%0Adeviations%2C%20and%20machining%20marks.%20To%20overcome%20these%20obstacles%2C%20our%20solution%0Afocuses%20on%20enhancing%20the%20accuracy%20of%20picking%20and%20placing%20tasks%2C%20ensuring%0Areliable%20performance%20across%20various%20scenarios.%20This%20is%20accomplished%20by%20a%20novel%0Avisual%20servoing%20method%20based%20on%20the%20integration%20of%20two%20complementary%0Amethodologies%3A%20a%20technique%20for%20object%20localization%20and%20a%20separate%20approach%20for%0Aprecise%20control%20through%20visual%20feedback%2C%20leveraging%20their%20strengths%20to%20address%0Athe%20challenges%20posed%20by%20the%20industrial%20context%20and%20thereby%20improving%20overall%0Agrasping%20accuracy.%20Our%20method%20employ%20feedback%20from%20perception%20sensors%20to%20adjust%0Athe%20control%20loop%20efficiently%2C%20enabling%20the%20robotic%20system%20to%20adeptly%20pick%20and%0Aplace%20objects.%20We%20have%20introduced%20a%20controller%20capable%20of%20seamlessly%20managing%0Athe%20detection%20and%20manipulation%20of%20various%20shapes%20and%20types%20of%20objects%20within%20an%0Aindustrial%20context%2C%20addressing%20numerous%20challenges%20that%20arise%20in%20such%0Aenvironments.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14557v1&entry.124074799=Read"},
{"title": "Self-playing Adversarial Language Game Enhances LLM Reasoning", "author": "Pengyu Cheng and Tianhao Hu and Han Xu and Zhisong Zhang and Zheng Yuan and Yong Dai and Lei Han and Nan Du and Xiaolong Li", "abstract": "  We explore the potential of self-play training for large language models\n(LLMs) in a two-player adversarial language game called Adversarial Taboo. In\nthis game, an attacker and a defender communicate around a target word only\nvisible to the attacker. The attacker aims to induce the defender to speak the\ntarget word unconsciously, while the defender tries to infer the target word\nfrom the attacker's utterances. To win the game, both players must have\nsufficient knowledge about the target word and high-level reasoning ability to\ninfer and express in this information-reserved conversation. Hence, we are\ncurious about whether LLMs' reasoning ability can be further enhanced by\nSelf-Playing this Adversarial language Game (SPAG). With this goal, we select\nseveral open-source LLMs and let each act as the attacker and play with a copy\nof itself as the defender on an extensive range of target words. Through\nreinforcement learning on the game outcomes, we observe that the LLMs'\nperformances uniformly improve on a broad range of reasoning benchmarks.\nFurthermore, iteratively adopting this self-play process can continuously\npromote LLMs' reasoning abilities. The code is available at\nhttps://github.com/Linear95/SPAG.\n", "link": "http://arxiv.org/abs/2404.10642v3", "date": "2025-01-24", "relevancy": 2.288, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4705}, {"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.4574}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.4449}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Self-playing%20Adversarial%20Language%20Game%20Enhances%20LLM%20Reasoning&body=Title%3A%20Self-playing%20Adversarial%20Language%20Game%20Enhances%20LLM%20Reasoning%0AAuthor%3A%20Pengyu%20Cheng%20and%20Tianhao%20Hu%20and%20Han%20Xu%20and%20Zhisong%20Zhang%20and%20Zheng%20Yuan%20and%20Yong%20Dai%20and%20Lei%20Han%20and%20Nan%20Du%20and%20Xiaolong%20Li%0AAbstract%3A%20%20%20We%20explore%20the%20potential%20of%20self-play%20training%20for%20large%20language%20models%0A%28LLMs%29%20in%20a%20two-player%20adversarial%20language%20game%20called%20Adversarial%20Taboo.%20In%0Athis%20game%2C%20an%20attacker%20and%20a%20defender%20communicate%20around%20a%20target%20word%20only%0Avisible%20to%20the%20attacker.%20The%20attacker%20aims%20to%20induce%20the%20defender%20to%20speak%20the%0Atarget%20word%20unconsciously%2C%20while%20the%20defender%20tries%20to%20infer%20the%20target%20word%0Afrom%20the%20attacker%27s%20utterances.%20To%20win%20the%20game%2C%20both%20players%20must%20have%0Asufficient%20knowledge%20about%20the%20target%20word%20and%20high-level%20reasoning%20ability%20to%0Ainfer%20and%20express%20in%20this%20information-reserved%20conversation.%20Hence%2C%20we%20are%0Acurious%20about%20whether%20LLMs%27%20reasoning%20ability%20can%20be%20further%20enhanced%20by%0ASelf-Playing%20this%20Adversarial%20language%20Game%20%28SPAG%29.%20With%20this%20goal%2C%20we%20select%0Aseveral%20open-source%20LLMs%20and%20let%20each%20act%20as%20the%20attacker%20and%20play%20with%20a%20copy%0Aof%20itself%20as%20the%20defender%20on%20an%20extensive%20range%20of%20target%20words.%20Through%0Areinforcement%20learning%20on%20the%20game%20outcomes%2C%20we%20observe%20that%20the%20LLMs%27%0Aperformances%20uniformly%20improve%20on%20a%20broad%20range%20of%20reasoning%20benchmarks.%0AFurthermore%2C%20iteratively%20adopting%20this%20self-play%20process%20can%20continuously%0Apromote%20LLMs%27%20reasoning%20abilities.%20The%20code%20is%20available%20at%0Ahttps%3A//github.com/Linear95/SPAG.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2404.10642v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSelf-playing%2520Adversarial%2520Language%2520Game%2520Enhances%2520LLM%2520Reasoning%26entry.906535625%3DPengyu%2520Cheng%2520and%2520Tianhao%2520Hu%2520and%2520Han%2520Xu%2520and%2520Zhisong%2520Zhang%2520and%2520Zheng%2520Yuan%2520and%2520Yong%2520Dai%2520and%2520Lei%2520Han%2520and%2520Nan%2520Du%2520and%2520Xiaolong%2520Li%26entry.1292438233%3D%2520%2520We%2520explore%2520the%2520potential%2520of%2520self-play%2520training%2520for%2520large%2520language%2520models%250A%2528LLMs%2529%2520in%2520a%2520two-player%2520adversarial%2520language%2520game%2520called%2520Adversarial%2520Taboo.%2520In%250Athis%2520game%252C%2520an%2520attacker%2520and%2520a%2520defender%2520communicate%2520around%2520a%2520target%2520word%2520only%250Avisible%2520to%2520the%2520attacker.%2520The%2520attacker%2520aims%2520to%2520induce%2520the%2520defender%2520to%2520speak%2520the%250Atarget%2520word%2520unconsciously%252C%2520while%2520the%2520defender%2520tries%2520to%2520infer%2520the%2520target%2520word%250Afrom%2520the%2520attacker%2527s%2520utterances.%2520To%2520win%2520the%2520game%252C%2520both%2520players%2520must%2520have%250Asufficient%2520knowledge%2520about%2520the%2520target%2520word%2520and%2520high-level%2520reasoning%2520ability%2520to%250Ainfer%2520and%2520express%2520in%2520this%2520information-reserved%2520conversation.%2520Hence%252C%2520we%2520are%250Acurious%2520about%2520whether%2520LLMs%2527%2520reasoning%2520ability%2520can%2520be%2520further%2520enhanced%2520by%250ASelf-Playing%2520this%2520Adversarial%2520language%2520Game%2520%2528SPAG%2529.%2520With%2520this%2520goal%252C%2520we%2520select%250Aseveral%2520open-source%2520LLMs%2520and%2520let%2520each%2520act%2520as%2520the%2520attacker%2520and%2520play%2520with%2520a%2520copy%250Aof%2520itself%2520as%2520the%2520defender%2520on%2520an%2520extensive%2520range%2520of%2520target%2520words.%2520Through%250Areinforcement%2520learning%2520on%2520the%2520game%2520outcomes%252C%2520we%2520observe%2520that%2520the%2520LLMs%2527%250Aperformances%2520uniformly%2520improve%2520on%2520a%2520broad%2520range%2520of%2520reasoning%2520benchmarks.%250AFurthermore%252C%2520iteratively%2520adopting%2520this%2520self-play%2520process%2520can%2520continuously%250Apromote%2520LLMs%2527%2520reasoning%2520abilities.%2520The%2520code%2520is%2520available%2520at%250Ahttps%253A//github.com/Linear95/SPAG.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2404.10642v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Self-playing%20Adversarial%20Language%20Game%20Enhances%20LLM%20Reasoning&entry.906535625=Pengyu%20Cheng%20and%20Tianhao%20Hu%20and%20Han%20Xu%20and%20Zhisong%20Zhang%20and%20Zheng%20Yuan%20and%20Yong%20Dai%20and%20Lei%20Han%20and%20Nan%20Du%20and%20Xiaolong%20Li&entry.1292438233=%20%20We%20explore%20the%20potential%20of%20self-play%20training%20for%20large%20language%20models%0A%28LLMs%29%20in%20a%20two-player%20adversarial%20language%20game%20called%20Adversarial%20Taboo.%20In%0Athis%20game%2C%20an%20attacker%20and%20a%20defender%20communicate%20around%20a%20target%20word%20only%0Avisible%20to%20the%20attacker.%20The%20attacker%20aims%20to%20induce%20the%20defender%20to%20speak%20the%0Atarget%20word%20unconsciously%2C%20while%20the%20defender%20tries%20to%20infer%20the%20target%20word%0Afrom%20the%20attacker%27s%20utterances.%20To%20win%20the%20game%2C%20both%20players%20must%20have%0Asufficient%20knowledge%20about%20the%20target%20word%20and%20high-level%20reasoning%20ability%20to%0Ainfer%20and%20express%20in%20this%20information-reserved%20conversation.%20Hence%2C%20we%20are%0Acurious%20about%20whether%20LLMs%27%20reasoning%20ability%20can%20be%20further%20enhanced%20by%0ASelf-Playing%20this%20Adversarial%20language%20Game%20%28SPAG%29.%20With%20this%20goal%2C%20we%20select%0Aseveral%20open-source%20LLMs%20and%20let%20each%20act%20as%20the%20attacker%20and%20play%20with%20a%20copy%0Aof%20itself%20as%20the%20defender%20on%20an%20extensive%20range%20of%20target%20words.%20Through%0Areinforcement%20learning%20on%20the%20game%20outcomes%2C%20we%20observe%20that%20the%20LLMs%27%0Aperformances%20uniformly%20improve%20on%20a%20broad%20range%20of%20reasoning%20benchmarks.%0AFurthermore%2C%20iteratively%20adopting%20this%20self-play%20process%20can%20continuously%0Apromote%20LLMs%27%20reasoning%20abilities.%20The%20code%20is%20available%20at%0Ahttps%3A//github.com/Linear95/SPAG.%0A&entry.1838667208=http%3A//arxiv.org/abs/2404.10642v3&entry.124074799=Read"},
{"title": "VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic\n  Reasoning", "author": "Benjamin Callewaert and Simon Vandevelde and Joost Vennekens", "abstract": "  A recent approach to neurosymbolic reasoning is to explicitly combine the\nstrengths of large language models (LLMs) and symbolic solvers to tackle\ncomplex reasoning tasks. However, current approaches face significant\nlimitations, including poor generalizability due to task-specific prompts,\ninefficiencies caused by the lack of separation between knowledge and queries,\nand restricted inferential capabilities. These shortcomings hinder their\nscalability and applicability across diverse domains. In this paper, we\nintroduce VERUS-LM, a novel framework designed to address these challenges.\nVERUS-LM employs a generic prompting mechanism, clearly separates domain\nknowledge from queries, and supports a wide range of different logical\nreasoning tasks. This framework enhances adaptability, reduces computational\ncost, and allows for richer forms of reasoning, such as optimization and\nconstraint satisfaction. We show that our approach succeeds in diverse\nreasoning on a novel dataset, markedly outperforming LLMs. Additionally, our\nsystem achieves competitive results on common reasoning benchmarks when\ncompared to other state-of-the-art approaches, and significantly surpasses them\non the difficult AR-LSAT dataset. By pushing the boundaries of hybrid\nreasoning, VERUS-LM represents a significant step towards more versatile\nneurosymbolic AI systems\n", "link": "http://arxiv.org/abs/2501.14540v1", "date": "2025-01-24", "relevancy": 2.2617, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5762}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5762}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5115}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20VERUS-LM%3A%20a%20Versatile%20Framework%20for%20Combining%20LLMs%20with%20Symbolic%0A%20%20Reasoning&body=Title%3A%20VERUS-LM%3A%20a%20Versatile%20Framework%20for%20Combining%20LLMs%20with%20Symbolic%0A%20%20Reasoning%0AAuthor%3A%20Benjamin%20Callewaert%20and%20Simon%20Vandevelde%20and%20Joost%20Vennekens%0AAbstract%3A%20%20%20A%20recent%20approach%20to%20neurosymbolic%20reasoning%20is%20to%20explicitly%20combine%20the%0Astrengths%20of%20large%20language%20models%20%28LLMs%29%20and%20symbolic%20solvers%20to%20tackle%0Acomplex%20reasoning%20tasks.%20However%2C%20current%20approaches%20face%20significant%0Alimitations%2C%20including%20poor%20generalizability%20due%20to%20task-specific%20prompts%2C%0Ainefficiencies%20caused%20by%20the%20lack%20of%20separation%20between%20knowledge%20and%20queries%2C%0Aand%20restricted%20inferential%20capabilities.%20These%20shortcomings%20hinder%20their%0Ascalability%20and%20applicability%20across%20diverse%20domains.%20In%20this%20paper%2C%20we%0Aintroduce%20VERUS-LM%2C%20a%20novel%20framework%20designed%20to%20address%20these%20challenges.%0AVERUS-LM%20employs%20a%20generic%20prompting%20mechanism%2C%20clearly%20separates%20domain%0Aknowledge%20from%20queries%2C%20and%20supports%20a%20wide%20range%20of%20different%20logical%0Areasoning%20tasks.%20This%20framework%20enhances%20adaptability%2C%20reduces%20computational%0Acost%2C%20and%20allows%20for%20richer%20forms%20of%20reasoning%2C%20such%20as%20optimization%20and%0Aconstraint%20satisfaction.%20We%20show%20that%20our%20approach%20succeeds%20in%20diverse%0Areasoning%20on%20a%20novel%20dataset%2C%20markedly%20outperforming%20LLMs.%20Additionally%2C%20our%0Asystem%20achieves%20competitive%20results%20on%20common%20reasoning%20benchmarks%20when%0Acompared%20to%20other%20state-of-the-art%20approaches%2C%20and%20significantly%20surpasses%20them%0Aon%20the%20difficult%20AR-LSAT%20dataset.%20By%20pushing%20the%20boundaries%20of%20hybrid%0Areasoning%2C%20VERUS-LM%20represents%20a%20significant%20step%20towards%20more%20versatile%0Aneurosymbolic%20AI%20systems%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14540v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DVERUS-LM%253A%2520a%2520Versatile%2520Framework%2520for%2520Combining%2520LLMs%2520with%2520Symbolic%250A%2520%2520Reasoning%26entry.906535625%3DBenjamin%2520Callewaert%2520and%2520Simon%2520Vandevelde%2520and%2520Joost%2520Vennekens%26entry.1292438233%3D%2520%2520A%2520recent%2520approach%2520to%2520neurosymbolic%2520reasoning%2520is%2520to%2520explicitly%2520combine%2520the%250Astrengths%2520of%2520large%2520language%2520models%2520%2528LLMs%2529%2520and%2520symbolic%2520solvers%2520to%2520tackle%250Acomplex%2520reasoning%2520tasks.%2520However%252C%2520current%2520approaches%2520face%2520significant%250Alimitations%252C%2520including%2520poor%2520generalizability%2520due%2520to%2520task-specific%2520prompts%252C%250Ainefficiencies%2520caused%2520by%2520the%2520lack%2520of%2520separation%2520between%2520knowledge%2520and%2520queries%252C%250Aand%2520restricted%2520inferential%2520capabilities.%2520These%2520shortcomings%2520hinder%2520their%250Ascalability%2520and%2520applicability%2520across%2520diverse%2520domains.%2520In%2520this%2520paper%252C%2520we%250Aintroduce%2520VERUS-LM%252C%2520a%2520novel%2520framework%2520designed%2520to%2520address%2520these%2520challenges.%250AVERUS-LM%2520employs%2520a%2520generic%2520prompting%2520mechanism%252C%2520clearly%2520separates%2520domain%250Aknowledge%2520from%2520queries%252C%2520and%2520supports%2520a%2520wide%2520range%2520of%2520different%2520logical%250Areasoning%2520tasks.%2520This%2520framework%2520enhances%2520adaptability%252C%2520reduces%2520computational%250Acost%252C%2520and%2520allows%2520for%2520richer%2520forms%2520of%2520reasoning%252C%2520such%2520as%2520optimization%2520and%250Aconstraint%2520satisfaction.%2520We%2520show%2520that%2520our%2520approach%2520succeeds%2520in%2520diverse%250Areasoning%2520on%2520a%2520novel%2520dataset%252C%2520markedly%2520outperforming%2520LLMs.%2520Additionally%252C%2520our%250Asystem%2520achieves%2520competitive%2520results%2520on%2520common%2520reasoning%2520benchmarks%2520when%250Acompared%2520to%2520other%2520state-of-the-art%2520approaches%252C%2520and%2520significantly%2520surpasses%2520them%250Aon%2520the%2520difficult%2520AR-LSAT%2520dataset.%2520By%2520pushing%2520the%2520boundaries%2520of%2520hybrid%250Areasoning%252C%2520VERUS-LM%2520represents%2520a%2520significant%2520step%2520towards%2520more%2520versatile%250Aneurosymbolic%2520AI%2520systems%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14540v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=VERUS-LM%3A%20a%20Versatile%20Framework%20for%20Combining%20LLMs%20with%20Symbolic%0A%20%20Reasoning&entry.906535625=Benjamin%20Callewaert%20and%20Simon%20Vandevelde%20and%20Joost%20Vennekens&entry.1292438233=%20%20A%20recent%20approach%20to%20neurosymbolic%20reasoning%20is%20to%20explicitly%20combine%20the%0Astrengths%20of%20large%20language%20models%20%28LLMs%29%20and%20symbolic%20solvers%20to%20tackle%0Acomplex%20reasoning%20tasks.%20However%2C%20current%20approaches%20face%20significant%0Alimitations%2C%20including%20poor%20generalizability%20due%20to%20task-specific%20prompts%2C%0Ainefficiencies%20caused%20by%20the%20lack%20of%20separation%20between%20knowledge%20and%20queries%2C%0Aand%20restricted%20inferential%20capabilities.%20These%20shortcomings%20hinder%20their%0Ascalability%20and%20applicability%20across%20diverse%20domains.%20In%20this%20paper%2C%20we%0Aintroduce%20VERUS-LM%2C%20a%20novel%20framework%20designed%20to%20address%20these%20challenges.%0AVERUS-LM%20employs%20a%20generic%20prompting%20mechanism%2C%20clearly%20separates%20domain%0Aknowledge%20from%20queries%2C%20and%20supports%20a%20wide%20range%20of%20different%20logical%0Areasoning%20tasks.%20This%20framework%20enhances%20adaptability%2C%20reduces%20computational%0Acost%2C%20and%20allows%20for%20richer%20forms%20of%20reasoning%2C%20such%20as%20optimization%20and%0Aconstraint%20satisfaction.%20We%20show%20that%20our%20approach%20succeeds%20in%20diverse%0Areasoning%20on%20a%20novel%20dataset%2C%20markedly%20outperforming%20LLMs.%20Additionally%2C%20our%0Asystem%20achieves%20competitive%20results%20on%20common%20reasoning%20benchmarks%20when%0Acompared%20to%20other%20state-of-the-art%20approaches%2C%20and%20significantly%20surpasses%20them%0Aon%20the%20difficult%20AR-LSAT%20dataset.%20By%20pushing%20the%20boundaries%20of%20hybrid%0Areasoning%2C%20VERUS-LM%20represents%20a%20significant%20step%20towards%20more%20versatile%0Aneurosymbolic%20AI%20systems%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14540v1&entry.124074799=Read"},
{"title": "Backdoor Attack on Vertical Federated Graph Neural Network Learning", "author": "Jirui Yang and Peng Chen and Zhihui Lu and Ruijun Deng and Qiang Duan and Jianping Zeng", "abstract": "  Federated Graph Neural Network (FedGNN) integrate federated learning (FL)\nwith graph neural networks (GNNs) to enable privacy-preserving training on\ndistributed graph data. Vertical Federated Graph Neural Network (VFGNN), a key\nbranch of FedGNN, handles scenarios where data features and labels are\ndistributed among participants. Despite the robust privacy-preserving design of\nVFGNN, we have found that it still faces the risk of backdoor attacks, even in\nsituations where labels are inaccessible. This paper proposes BVG, a novel\nbackdoor attack method that leverages multi-hop triggers and backdoor\nretention, requiring only four target-class nodes to execute effective attacks.\nExperimental results demonstrate that BVG achieves nearly 100% attack success\nrates across three commonly used datasets and three GNN models, with minimal\nimpact on the main task accuracy. We also evaluated various defense methods,\nand the BVG method maintained high attack effectiveness even under existing\ndefenses. This finding highlights the need for advanced defense mechanisms to\ncounter sophisticated backdoor attacks in practical VFGNN applications.\n", "link": "http://arxiv.org/abs/2410.11290v2", "date": "2025-01-24", "relevancy": 2.2614, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.485}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.4414}, {"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.4304}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Backdoor%20Attack%20on%20Vertical%20Federated%20Graph%20Neural%20Network%20Learning&body=Title%3A%20Backdoor%20Attack%20on%20Vertical%20Federated%20Graph%20Neural%20Network%20Learning%0AAuthor%3A%20Jirui%20Yang%20and%20Peng%20Chen%20and%20Zhihui%20Lu%20and%20Ruijun%20Deng%20and%20Qiang%20Duan%20and%20Jianping%20Zeng%0AAbstract%3A%20%20%20Federated%20Graph%20Neural%20Network%20%28FedGNN%29%20integrate%20federated%20learning%20%28FL%29%0Awith%20graph%20neural%20networks%20%28GNNs%29%20to%20enable%20privacy-preserving%20training%20on%0Adistributed%20graph%20data.%20Vertical%20Federated%20Graph%20Neural%20Network%20%28VFGNN%29%2C%20a%20key%0Abranch%20of%20FedGNN%2C%20handles%20scenarios%20where%20data%20features%20and%20labels%20are%0Adistributed%20among%20participants.%20Despite%20the%20robust%20privacy-preserving%20design%20of%0AVFGNN%2C%20we%20have%20found%20that%20it%20still%20faces%20the%20risk%20of%20backdoor%20attacks%2C%20even%20in%0Asituations%20where%20labels%20are%20inaccessible.%20This%20paper%20proposes%20BVG%2C%20a%20novel%0Abackdoor%20attack%20method%20that%20leverages%20multi-hop%20triggers%20and%20backdoor%0Aretention%2C%20requiring%20only%20four%20target-class%20nodes%20to%20execute%20effective%20attacks.%0AExperimental%20results%20demonstrate%20that%20BVG%20achieves%20nearly%20100%25%20attack%20success%0Arates%20across%20three%20commonly%20used%20datasets%20and%20three%20GNN%20models%2C%20with%20minimal%0Aimpact%20on%20the%20main%20task%20accuracy.%20We%20also%20evaluated%20various%20defense%20methods%2C%0Aand%20the%20BVG%20method%20maintained%20high%20attack%20effectiveness%20even%20under%20existing%0Adefenses.%20This%20finding%20highlights%20the%20need%20for%20advanced%20defense%20mechanisms%20to%0Acounter%20sophisticated%20backdoor%20attacks%20in%20practical%20VFGNN%20applications.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2410.11290v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DBackdoor%2520Attack%2520on%2520Vertical%2520Federated%2520Graph%2520Neural%2520Network%2520Learning%26entry.906535625%3DJirui%2520Yang%2520and%2520Peng%2520Chen%2520and%2520Zhihui%2520Lu%2520and%2520Ruijun%2520Deng%2520and%2520Qiang%2520Duan%2520and%2520Jianping%2520Zeng%26entry.1292438233%3D%2520%2520Federated%2520Graph%2520Neural%2520Network%2520%2528FedGNN%2529%2520integrate%2520federated%2520learning%2520%2528FL%2529%250Awith%2520graph%2520neural%2520networks%2520%2528GNNs%2529%2520to%2520enable%2520privacy-preserving%2520training%2520on%250Adistributed%2520graph%2520data.%2520Vertical%2520Federated%2520Graph%2520Neural%2520Network%2520%2528VFGNN%2529%252C%2520a%2520key%250Abranch%2520of%2520FedGNN%252C%2520handles%2520scenarios%2520where%2520data%2520features%2520and%2520labels%2520are%250Adistributed%2520among%2520participants.%2520Despite%2520the%2520robust%2520privacy-preserving%2520design%2520of%250AVFGNN%252C%2520we%2520have%2520found%2520that%2520it%2520still%2520faces%2520the%2520risk%2520of%2520backdoor%2520attacks%252C%2520even%2520in%250Asituations%2520where%2520labels%2520are%2520inaccessible.%2520This%2520paper%2520proposes%2520BVG%252C%2520a%2520novel%250Abackdoor%2520attack%2520method%2520that%2520leverages%2520multi-hop%2520triggers%2520and%2520backdoor%250Aretention%252C%2520requiring%2520only%2520four%2520target-class%2520nodes%2520to%2520execute%2520effective%2520attacks.%250AExperimental%2520results%2520demonstrate%2520that%2520BVG%2520achieves%2520nearly%2520100%2525%2520attack%2520success%250Arates%2520across%2520three%2520commonly%2520used%2520datasets%2520and%2520three%2520GNN%2520models%252C%2520with%2520minimal%250Aimpact%2520on%2520the%2520main%2520task%2520accuracy.%2520We%2520also%2520evaluated%2520various%2520defense%2520methods%252C%250Aand%2520the%2520BVG%2520method%2520maintained%2520high%2520attack%2520effectiveness%2520even%2520under%2520existing%250Adefenses.%2520This%2520finding%2520highlights%2520the%2520need%2520for%2520advanced%2520defense%2520mechanisms%2520to%250Acounter%2520sophisticated%2520backdoor%2520attacks%2520in%2520practical%2520VFGNN%2520applications.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2410.11290v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Backdoor%20Attack%20on%20Vertical%20Federated%20Graph%20Neural%20Network%20Learning&entry.906535625=Jirui%20Yang%20and%20Peng%20Chen%20and%20Zhihui%20Lu%20and%20Ruijun%20Deng%20and%20Qiang%20Duan%20and%20Jianping%20Zeng&entry.1292438233=%20%20Federated%20Graph%20Neural%20Network%20%28FedGNN%29%20integrate%20federated%20learning%20%28FL%29%0Awith%20graph%20neural%20networks%20%28GNNs%29%20to%20enable%20privacy-preserving%20training%20on%0Adistributed%20graph%20data.%20Vertical%20Federated%20Graph%20Neural%20Network%20%28VFGNN%29%2C%20a%20key%0Abranch%20of%20FedGNN%2C%20handles%20scenarios%20where%20data%20features%20and%20labels%20are%0Adistributed%20among%20participants.%20Despite%20the%20robust%20privacy-preserving%20design%20of%0AVFGNN%2C%20we%20have%20found%20that%20it%20still%20faces%20the%20risk%20of%20backdoor%20attacks%2C%20even%20in%0Asituations%20where%20labels%20are%20inaccessible.%20This%20paper%20proposes%20BVG%2C%20a%20novel%0Abackdoor%20attack%20method%20that%20leverages%20multi-hop%20triggers%20and%20backdoor%0Aretention%2C%20requiring%20only%20four%20target-class%20nodes%20to%20execute%20effective%20attacks.%0AExperimental%20results%20demonstrate%20that%20BVG%20achieves%20nearly%20100%25%20attack%20success%0Arates%20across%20three%20commonly%20used%20datasets%20and%20three%20GNN%20models%2C%20with%20minimal%0Aimpact%20on%20the%20main%20task%20accuracy.%20We%20also%20evaluated%20various%20defense%20methods%2C%0Aand%20the%20BVG%20method%20maintained%20high%20attack%20effectiveness%20even%20under%20existing%0Adefenses.%20This%20finding%20highlights%20the%20need%20for%20advanced%20defense%20mechanisms%20to%0Acounter%20sophisticated%20backdoor%20attacks%20in%20practical%20VFGNN%20applications.%0A&entry.1838667208=http%3A//arxiv.org/abs/2410.11290v2&entry.124074799=Read"},
{"title": "MatAnyone: Stable Video Matting with Consistent Memory Propagation", "author": "Peiqing Yang and Shangchen Zhou and Jixin Zhao and Qingyi Tao and Chen Change Loy", "abstract": "  Auxiliary-free human video matting methods, which rely solely on input\nframes, often struggle with complex or ambiguous backgrounds. To address this,\nwe propose MatAnyone, a robust framework tailored for target-assigned video\nmatting. Specifically, building on a memory-based paradigm, we introduce a\nconsistent memory propagation module via region-adaptive memory fusion, which\nadaptively integrates memory from the previous frame. This ensures semantic\nstability in core regions while preserving fine-grained details along object\nboundaries. For robust training, we present a larger, high-quality, and diverse\ndataset for video matting. Additionally, we incorporate a novel training\nstrategy that efficiently leverages large-scale segmentation data, boosting\nmatting stability. With this new network design, dataset, and training\nstrategy, MatAnyone delivers robust and accurate video matting results in\ndiverse real-world scenarios, outperforming existing methods.\n", "link": "http://arxiv.org/abs/2501.14677v1", "date": "2025-01-24", "relevancy": 2.26, "topK": [{"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.5669}, {"title": "Customize-A-Video: One-Shot Motion Customization of Text-to-Video\n  Diffusion Models", "link": "http://arxiv.org/abs/2402.14780v1", "similarity": 0.5639}, {"title": "Magic-Me: Identity-Specific Video Customized Diffusion", "link": "http://arxiv.org/abs/2402.09368v1", "similarity": 0.5636}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20MatAnyone%3A%20Stable%20Video%20Matting%20with%20Consistent%20Memory%20Propagation&body=Title%3A%20MatAnyone%3A%20Stable%20Video%20Matting%20with%20Consistent%20Memory%20Propagation%0AAuthor%3A%20Peiqing%20Yang%20and%20Shangchen%20Zhou%20and%20Jixin%20Zhao%20and%20Qingyi%20Tao%20and%20Chen%20Change%20Loy%0AAbstract%3A%20%20%20Auxiliary-free%20human%20video%20matting%20methods%2C%20which%20rely%20solely%20on%20input%0Aframes%2C%20often%20struggle%20with%20complex%20or%20ambiguous%20backgrounds.%20To%20address%20this%2C%0Awe%20propose%20MatAnyone%2C%20a%20robust%20framework%20tailored%20for%20target-assigned%20video%0Amatting.%20Specifically%2C%20building%20on%20a%20memory-based%20paradigm%2C%20we%20introduce%20a%0Aconsistent%20memory%20propagation%20module%20via%20region-adaptive%20memory%20fusion%2C%20which%0Aadaptively%20integrates%20memory%20from%20the%20previous%20frame.%20This%20ensures%20semantic%0Astability%20in%20core%20regions%20while%20preserving%20fine-grained%20details%20along%20object%0Aboundaries.%20For%20robust%20training%2C%20we%20present%20a%20larger%2C%20high-quality%2C%20and%20diverse%0Adataset%20for%20video%20matting.%20Additionally%2C%20we%20incorporate%20a%20novel%20training%0Astrategy%20that%20efficiently%20leverages%20large-scale%20segmentation%20data%2C%20boosting%0Amatting%20stability.%20With%20this%20new%20network%20design%2C%20dataset%2C%20and%20training%0Astrategy%2C%20MatAnyone%20delivers%20robust%20and%20accurate%20video%20matting%20results%20in%0Adiverse%20real-world%20scenarios%2C%20outperforming%20existing%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14677v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DMatAnyone%253A%2520Stable%2520Video%2520Matting%2520with%2520Consistent%2520Memory%2520Propagation%26entry.906535625%3DPeiqing%2520Yang%2520and%2520Shangchen%2520Zhou%2520and%2520Jixin%2520Zhao%2520and%2520Qingyi%2520Tao%2520and%2520Chen%2520Change%2520Loy%26entry.1292438233%3D%2520%2520Auxiliary-free%2520human%2520video%2520matting%2520methods%252C%2520which%2520rely%2520solely%2520on%2520input%250Aframes%252C%2520often%2520struggle%2520with%2520complex%2520or%2520ambiguous%2520backgrounds.%2520To%2520address%2520this%252C%250Awe%2520propose%2520MatAnyone%252C%2520a%2520robust%2520framework%2520tailored%2520for%2520target-assigned%2520video%250Amatting.%2520Specifically%252C%2520building%2520on%2520a%2520memory-based%2520paradigm%252C%2520we%2520introduce%2520a%250Aconsistent%2520memory%2520propagation%2520module%2520via%2520region-adaptive%2520memory%2520fusion%252C%2520which%250Aadaptively%2520integrates%2520memory%2520from%2520the%2520previous%2520frame.%2520This%2520ensures%2520semantic%250Astability%2520in%2520core%2520regions%2520while%2520preserving%2520fine-grained%2520details%2520along%2520object%250Aboundaries.%2520For%2520robust%2520training%252C%2520we%2520present%2520a%2520larger%252C%2520high-quality%252C%2520and%2520diverse%250Adataset%2520for%2520video%2520matting.%2520Additionally%252C%2520we%2520incorporate%2520a%2520novel%2520training%250Astrategy%2520that%2520efficiently%2520leverages%2520large-scale%2520segmentation%2520data%252C%2520boosting%250Amatting%2520stability.%2520With%2520this%2520new%2520network%2520design%252C%2520dataset%252C%2520and%2520training%250Astrategy%252C%2520MatAnyone%2520delivers%2520robust%2520and%2520accurate%2520video%2520matting%2520results%2520in%250Adiverse%2520real-world%2520scenarios%252C%2520outperforming%2520existing%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14677v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=MatAnyone%3A%20Stable%20Video%20Matting%20with%20Consistent%20Memory%20Propagation&entry.906535625=Peiqing%20Yang%20and%20Shangchen%20Zhou%20and%20Jixin%20Zhao%20and%20Qingyi%20Tao%20and%20Chen%20Change%20Loy&entry.1292438233=%20%20Auxiliary-free%20human%20video%20matting%20methods%2C%20which%20rely%20solely%20on%20input%0Aframes%2C%20often%20struggle%20with%20complex%20or%20ambiguous%20backgrounds.%20To%20address%20this%2C%0Awe%20propose%20MatAnyone%2C%20a%20robust%20framework%20tailored%20for%20target-assigned%20video%0Amatting.%20Specifically%2C%20building%20on%20a%20memory-based%20paradigm%2C%20we%20introduce%20a%0Aconsistent%20memory%20propagation%20module%20via%20region-adaptive%20memory%20fusion%2C%20which%0Aadaptively%20integrates%20memory%20from%20the%20previous%20frame.%20This%20ensures%20semantic%0Astability%20in%20core%20regions%20while%20preserving%20fine-grained%20details%20along%20object%0Aboundaries.%20For%20robust%20training%2C%20we%20present%20a%20larger%2C%20high-quality%2C%20and%20diverse%0Adataset%20for%20video%20matting.%20Additionally%2C%20we%20incorporate%20a%20novel%20training%0Astrategy%20that%20efficiently%20leverages%20large-scale%20segmentation%20data%2C%20boosting%0Amatting%20stability.%20With%20this%20new%20network%20design%2C%20dataset%2C%20and%20training%0Astrategy%2C%20MatAnyone%20delivers%20robust%20and%20accurate%20video%20matting%20results%20in%0Adiverse%20real-world%20scenarios%2C%20outperforming%20existing%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14677v1&entry.124074799=Read"},
{"title": "Surface Vision Mamba: Leveraging Bidirectional State Space Model for\n  Efficient Spherical Manifold Representation", "author": "Rongzhao He and Weihao Zheng", "abstract": "  Attention-based methods have demonstrated exceptional performance in\nmodelling long-range dependencies on spherical cortical surfaces, surpassing\ntraditional Geometric Deep Learning (GDL) models. However, their extensive\ninference time and high memory demands pose challenges for application to large\ndatasets with limited computing resources. Inspired by the state space model in\ncomputer vision, we introduce the attention-free Vision Mamba (Vim) to\nspherical surfaces, presenting a domain-agnostic architecture for analyzing\ndata on spherical manifolds. Our method achieves surface patching by\nrepresenting spherical data as a sequence of triangular patches derived from a\nsubdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on\nmultiple neurodevelopmental phenotype regression tasks using cortical surface\nmetrics from neonatal brains. Experimental results demonstrate that SiM\noutperforms both attention- and GDL-based methods, delivering 4.8 times faster\ninference and achieving 91.7% lower memory consumption compared to the Surface\nVision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity\nanalysis further underscores the potential of SiM to identify subtle cognitive\ndevelopmental patterns. The code is available at\nhttps://github.com/Rongzhao-He/surface-vision-mamba.\n", "link": "http://arxiv.org/abs/2501.14679v1", "date": "2025-01-24", "relevancy": 2.2524, "topK": [{"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.5642}, {"title": "GST: Precise 3D Human Body from a Single Image with Gaussian Splatting\n  Transformers", "link": "http://arxiv.org/abs/2409.04196v1", "similarity": 0.5637}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5588}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Surface%20Vision%20Mamba%3A%20Leveraging%20Bidirectional%20State%20Space%20Model%20for%0A%20%20Efficient%20Spherical%20Manifold%20Representation&body=Title%3A%20Surface%20Vision%20Mamba%3A%20Leveraging%20Bidirectional%20State%20Space%20Model%20for%0A%20%20Efficient%20Spherical%20Manifold%20Representation%0AAuthor%3A%20Rongzhao%20He%20and%20Weihao%20Zheng%0AAbstract%3A%20%20%20Attention-based%20methods%20have%20demonstrated%20exceptional%20performance%20in%0Amodelling%20long-range%20dependencies%20on%20spherical%20cortical%20surfaces%2C%20surpassing%0Atraditional%20Geometric%20Deep%20Learning%20%28GDL%29%20models.%20However%2C%20their%20extensive%0Ainference%20time%20and%20high%20memory%20demands%20pose%20challenges%20for%20application%20to%20large%0Adatasets%20with%20limited%20computing%20resources.%20Inspired%20by%20the%20state%20space%20model%20in%0Acomputer%20vision%2C%20we%20introduce%20the%20attention-free%20Vision%20Mamba%20%28Vim%29%20to%0Aspherical%20surfaces%2C%20presenting%20a%20domain-agnostic%20architecture%20for%20analyzing%0Adata%20on%20spherical%20manifolds.%20Our%20method%20achieves%20surface%20patching%20by%0Arepresenting%20spherical%20data%20as%20a%20sequence%20of%20triangular%20patches%20derived%20from%20a%0Asubdivided%20icosphere.%20The%20proposed%20Surface%20Vision%20Mamba%20%28SiM%29%20is%20evaluated%20on%0Amultiple%20neurodevelopmental%20phenotype%20regression%20tasks%20using%20cortical%20surface%0Ametrics%20from%20neonatal%20brains.%20Experimental%20results%20demonstrate%20that%20SiM%0Aoutperforms%20both%20attention-%20and%20GDL-based%20methods%2C%20delivering%204.8%20times%20faster%0Ainference%20and%20achieving%2091.7%25%20lower%20memory%20consumption%20compared%20to%20the%20Surface%0AVision%20Transformer%20%28SiT%29%20under%20the%20Ico-4%20grid%20partitioning.%20Sensitivity%0Aanalysis%20further%20underscores%20the%20potential%20of%20SiM%20to%20identify%20subtle%20cognitive%0Adevelopmental%20patterns.%20The%20code%20is%20available%20at%0Ahttps%3A//github.com/Rongzhao-He/surface-vision-mamba.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14679v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSurface%2520Vision%2520Mamba%253A%2520Leveraging%2520Bidirectional%2520State%2520Space%2520Model%2520for%250A%2520%2520Efficient%2520Spherical%2520Manifold%2520Representation%26entry.906535625%3DRongzhao%2520He%2520and%2520Weihao%2520Zheng%26entry.1292438233%3D%2520%2520Attention-based%2520methods%2520have%2520demonstrated%2520exceptional%2520performance%2520in%250Amodelling%2520long-range%2520dependencies%2520on%2520spherical%2520cortical%2520surfaces%252C%2520surpassing%250Atraditional%2520Geometric%2520Deep%2520Learning%2520%2528GDL%2529%2520models.%2520However%252C%2520their%2520extensive%250Ainference%2520time%2520and%2520high%2520memory%2520demands%2520pose%2520challenges%2520for%2520application%2520to%2520large%250Adatasets%2520with%2520limited%2520computing%2520resources.%2520Inspired%2520by%2520the%2520state%2520space%2520model%2520in%250Acomputer%2520vision%252C%2520we%2520introduce%2520the%2520attention-free%2520Vision%2520Mamba%2520%2528Vim%2529%2520to%250Aspherical%2520surfaces%252C%2520presenting%2520a%2520domain-agnostic%2520architecture%2520for%2520analyzing%250Adata%2520on%2520spherical%2520manifolds.%2520Our%2520method%2520achieves%2520surface%2520patching%2520by%250Arepresenting%2520spherical%2520data%2520as%2520a%2520sequence%2520of%2520triangular%2520patches%2520derived%2520from%2520a%250Asubdivided%2520icosphere.%2520The%2520proposed%2520Surface%2520Vision%2520Mamba%2520%2528SiM%2529%2520is%2520evaluated%2520on%250Amultiple%2520neurodevelopmental%2520phenotype%2520regression%2520tasks%2520using%2520cortical%2520surface%250Ametrics%2520from%2520neonatal%2520brains.%2520Experimental%2520results%2520demonstrate%2520that%2520SiM%250Aoutperforms%2520both%2520attention-%2520and%2520GDL-based%2520methods%252C%2520delivering%25204.8%2520times%2520faster%250Ainference%2520and%2520achieving%252091.7%2525%2520lower%2520memory%2520consumption%2520compared%2520to%2520the%2520Surface%250AVision%2520Transformer%2520%2528SiT%2529%2520under%2520the%2520Ico-4%2520grid%2520partitioning.%2520Sensitivity%250Aanalysis%2520further%2520underscores%2520the%2520potential%2520of%2520SiM%2520to%2520identify%2520subtle%2520cognitive%250Adevelopmental%2520patterns.%2520The%2520code%2520is%2520available%2520at%250Ahttps%253A//github.com/Rongzhao-He/surface-vision-mamba.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14679v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Surface%20Vision%20Mamba%3A%20Leveraging%20Bidirectional%20State%20Space%20Model%20for%0A%20%20Efficient%20Spherical%20Manifold%20Representation&entry.906535625=Rongzhao%20He%20and%20Weihao%20Zheng&entry.1292438233=%20%20Attention-based%20methods%20have%20demonstrated%20exceptional%20performance%20in%0Amodelling%20long-range%20dependencies%20on%20spherical%20cortical%20surfaces%2C%20surpassing%0Atraditional%20Geometric%20Deep%20Learning%20%28GDL%29%20models.%20However%2C%20their%20extensive%0Ainference%20time%20and%20high%20memory%20demands%20pose%20challenges%20for%20application%20to%20large%0Adatasets%20with%20limited%20computing%20resources.%20Inspired%20by%20the%20state%20space%20model%20in%0Acomputer%20vision%2C%20we%20introduce%20the%20attention-free%20Vision%20Mamba%20%28Vim%29%20to%0Aspherical%20surfaces%2C%20presenting%20a%20domain-agnostic%20architecture%20for%20analyzing%0Adata%20on%20spherical%20manifolds.%20Our%20method%20achieves%20surface%20patching%20by%0Arepresenting%20spherical%20data%20as%20a%20sequence%20of%20triangular%20patches%20derived%20from%20a%0Asubdivided%20icosphere.%20The%20proposed%20Surface%20Vision%20Mamba%20%28SiM%29%20is%20evaluated%20on%0Amultiple%20neurodevelopmental%20phenotype%20regression%20tasks%20using%20cortical%20surface%0Ametrics%20from%20neonatal%20brains.%20Experimental%20results%20demonstrate%20that%20SiM%0Aoutperforms%20both%20attention-%20and%20GDL-based%20methods%2C%20delivering%204.8%20times%20faster%0Ainference%20and%20achieving%2091.7%25%20lower%20memory%20consumption%20compared%20to%20the%20Surface%0AVision%20Transformer%20%28SiT%29%20under%20the%20Ico-4%20grid%20partitioning.%20Sensitivity%0Aanalysis%20further%20underscores%20the%20potential%20of%20SiM%20to%20identify%20subtle%20cognitive%0Adevelopmental%20patterns.%20The%20code%20is%20available%20at%0Ahttps%3A//github.com/Rongzhao-He/surface-vision-mamba.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14679v1&entry.124074799=Read"},
{"title": "3DLabelProp: Geometric-Driven Domain Generalization for LiDAR Semantic\n  Segmentation in Autonomous Driving", "author": "Jules Sanchez and Jean-Emmanuel Deschaud and Fran\u00e7ois Goulette", "abstract": "  Domain generalization aims to find ways for deep learning models to maintain\ntheir performance despite significant domain shifts between training and\ninference datasets. This is particularly important for models that need to be\nrobust or are costly to train. LiDAR perception in autonomous driving is\nimpacted by both of these concerns, leading to the emergence of various\napproaches. This work addresses the challenge by proposing a geometry-based\napproach, leveraging the sequential structure of LiDAR sensors, which sets it\napart from the learning-based methods commonly found in the literature. The\nproposed method, called 3DLabelProp, is applied on the task of LiDAR Semantic\nSegmentation (LSS). Through extensive experimentation on seven datasets, it is\ndemonstrated to be a state-of-the-art approach, outperforming both naive and\nother domain generalization methods.\n", "link": "http://arxiv.org/abs/2501.14605v1", "date": "2025-01-24", "relevancy": 2.2275, "topK": [{"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.5642}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5564}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.5498}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%203DLabelProp%3A%20Geometric-Driven%20Domain%20Generalization%20for%20LiDAR%20Semantic%0A%20%20Segmentation%20in%20Autonomous%20Driving&body=Title%3A%203DLabelProp%3A%20Geometric-Driven%20Domain%20Generalization%20for%20LiDAR%20Semantic%0A%20%20Segmentation%20in%20Autonomous%20Driving%0AAuthor%3A%20Jules%20Sanchez%20and%20Jean-Emmanuel%20Deschaud%20and%20Fran%C3%A7ois%20Goulette%0AAbstract%3A%20%20%20Domain%20generalization%20aims%20to%20find%20ways%20for%20deep%20learning%20models%20to%20maintain%0Atheir%20performance%20despite%20significant%20domain%20shifts%20between%20training%20and%0Ainference%20datasets.%20This%20is%20particularly%20important%20for%20models%20that%20need%20to%20be%0Arobust%20or%20are%20costly%20to%20train.%20LiDAR%20perception%20in%20autonomous%20driving%20is%0Aimpacted%20by%20both%20of%20these%20concerns%2C%20leading%20to%20the%20emergence%20of%20various%0Aapproaches.%20This%20work%20addresses%20the%20challenge%20by%20proposing%20a%20geometry-based%0Aapproach%2C%20leveraging%20the%20sequential%20structure%20of%20LiDAR%20sensors%2C%20which%20sets%20it%0Aapart%20from%20the%20learning-based%20methods%20commonly%20found%20in%20the%20literature.%20The%0Aproposed%20method%2C%20called%203DLabelProp%2C%20is%20applied%20on%20the%20task%20of%20LiDAR%20Semantic%0ASegmentation%20%28LSS%29.%20Through%20extensive%20experimentation%20on%20seven%20datasets%2C%20it%20is%0Ademonstrated%20to%20be%20a%20state-of-the-art%20approach%2C%20outperforming%20both%20naive%20and%0Aother%20domain%20generalization%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14605v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3D3DLabelProp%253A%2520Geometric-Driven%2520Domain%2520Generalization%2520for%2520LiDAR%2520Semantic%250A%2520%2520Segmentation%2520in%2520Autonomous%2520Driving%26entry.906535625%3DJules%2520Sanchez%2520and%2520Jean-Emmanuel%2520Deschaud%2520and%2520Fran%25C3%25A7ois%2520Goulette%26entry.1292438233%3D%2520%2520Domain%2520generalization%2520aims%2520to%2520find%2520ways%2520for%2520deep%2520learning%2520models%2520to%2520maintain%250Atheir%2520performance%2520despite%2520significant%2520domain%2520shifts%2520between%2520training%2520and%250Ainference%2520datasets.%2520This%2520is%2520particularly%2520important%2520for%2520models%2520that%2520need%2520to%2520be%250Arobust%2520or%2520are%2520costly%2520to%2520train.%2520LiDAR%2520perception%2520in%2520autonomous%2520driving%2520is%250Aimpacted%2520by%2520both%2520of%2520these%2520concerns%252C%2520leading%2520to%2520the%2520emergence%2520of%2520various%250Aapproaches.%2520This%2520work%2520addresses%2520the%2520challenge%2520by%2520proposing%2520a%2520geometry-based%250Aapproach%252C%2520leveraging%2520the%2520sequential%2520structure%2520of%2520LiDAR%2520sensors%252C%2520which%2520sets%2520it%250Aapart%2520from%2520the%2520learning-based%2520methods%2520commonly%2520found%2520in%2520the%2520literature.%2520The%250Aproposed%2520method%252C%2520called%25203DLabelProp%252C%2520is%2520applied%2520on%2520the%2520task%2520of%2520LiDAR%2520Semantic%250ASegmentation%2520%2528LSS%2529.%2520Through%2520extensive%2520experimentation%2520on%2520seven%2520datasets%252C%2520it%2520is%250Ademonstrated%2520to%2520be%2520a%2520state-of-the-art%2520approach%252C%2520outperforming%2520both%2520naive%2520and%250Aother%2520domain%2520generalization%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14605v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=3DLabelProp%3A%20Geometric-Driven%20Domain%20Generalization%20for%20LiDAR%20Semantic%0A%20%20Segmentation%20in%20Autonomous%20Driving&entry.906535625=Jules%20Sanchez%20and%20Jean-Emmanuel%20Deschaud%20and%20Fran%C3%A7ois%20Goulette&entry.1292438233=%20%20Domain%20generalization%20aims%20to%20find%20ways%20for%20deep%20learning%20models%20to%20maintain%0Atheir%20performance%20despite%20significant%20domain%20shifts%20between%20training%20and%0Ainference%20datasets.%20This%20is%20particularly%20important%20for%20models%20that%20need%20to%20be%0Arobust%20or%20are%20costly%20to%20train.%20LiDAR%20perception%20in%20autonomous%20driving%20is%0Aimpacted%20by%20both%20of%20these%20concerns%2C%20leading%20to%20the%20emergence%20of%20various%0Aapproaches.%20This%20work%20addresses%20the%20challenge%20by%20proposing%20a%20geometry-based%0Aapproach%2C%20leveraging%20the%20sequential%20structure%20of%20LiDAR%20sensors%2C%20which%20sets%20it%0Aapart%20from%20the%20learning-based%20methods%20commonly%20found%20in%20the%20literature.%20The%0Aproposed%20method%2C%20called%203DLabelProp%2C%20is%20applied%20on%20the%20task%20of%20LiDAR%20Semantic%0ASegmentation%20%28LSS%29.%20Through%20extensive%20experimentation%20on%20seven%20datasets%2C%20it%20is%0Ademonstrated%20to%20be%20a%20state-of-the-art%20approach%2C%20outperforming%20both%20naive%20and%0Aother%20domain%20generalization%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14605v1&entry.124074799=Read"},
{"title": "Rethinking Encoder-Decoder Flow Through Shared Structures", "author": "Frederik Laboyrie and Mehmet Kerim Yucel and Albert Saa-Garriga", "abstract": "  Dense prediction tasks have enjoyed a growing complexity of encoder\narchitectures, decoders, however, have remained largely the same. They rely on\nindividual blocks decoding intermediate feature maps sequentially. We introduce\nbanks, shared structures that are used by each decoding block to provide\nadditional context in the decoding process. These structures, through applying\nthem via resampling and feature fusion, improve performance on depth estimation\nfor state-of-the-art transformer-based architectures on natural and synthetic\nimages whilst training on large-scale datasets.\n", "link": "http://arxiv.org/abs/2501.14535v1", "date": "2025-01-24", "relevancy": 2.201, "topK": [{"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.6007}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5401}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5401}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Rethinking%20Encoder-Decoder%20Flow%20Through%20Shared%20Structures&body=Title%3A%20Rethinking%20Encoder-Decoder%20Flow%20Through%20Shared%20Structures%0AAuthor%3A%20Frederik%20Laboyrie%20and%20Mehmet%20Kerim%20Yucel%20and%20Albert%20Saa-Garriga%0AAbstract%3A%20%20%20Dense%20prediction%20tasks%20have%20enjoyed%20a%20growing%20complexity%20of%20encoder%0Aarchitectures%2C%20decoders%2C%20however%2C%20have%20remained%20largely%20the%20same.%20They%20rely%20on%0Aindividual%20blocks%20decoding%20intermediate%20feature%20maps%20sequentially.%20We%20introduce%0Abanks%2C%20shared%20structures%20that%20are%20used%20by%20each%20decoding%20block%20to%20provide%0Aadditional%20context%20in%20the%20decoding%20process.%20These%20structures%2C%20through%20applying%0Athem%20via%20resampling%20and%20feature%20fusion%2C%20improve%20performance%20on%20depth%20estimation%0Afor%20state-of-the-art%20transformer-based%20architectures%20on%20natural%20and%20synthetic%0Aimages%20whilst%20training%20on%20large-scale%20datasets.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14535v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRethinking%2520Encoder-Decoder%2520Flow%2520Through%2520Shared%2520Structures%26entry.906535625%3DFrederik%2520Laboyrie%2520and%2520Mehmet%2520Kerim%2520Yucel%2520and%2520Albert%2520Saa-Garriga%26entry.1292438233%3D%2520%2520Dense%2520prediction%2520tasks%2520have%2520enjoyed%2520a%2520growing%2520complexity%2520of%2520encoder%250Aarchitectures%252C%2520decoders%252C%2520however%252C%2520have%2520remained%2520largely%2520the%2520same.%2520They%2520rely%2520on%250Aindividual%2520blocks%2520decoding%2520intermediate%2520feature%2520maps%2520sequentially.%2520We%2520introduce%250Abanks%252C%2520shared%2520structures%2520that%2520are%2520used%2520by%2520each%2520decoding%2520block%2520to%2520provide%250Aadditional%2520context%2520in%2520the%2520decoding%2520process.%2520These%2520structures%252C%2520through%2520applying%250Athem%2520via%2520resampling%2520and%2520feature%2520fusion%252C%2520improve%2520performance%2520on%2520depth%2520estimation%250Afor%2520state-of-the-art%2520transformer-based%2520architectures%2520on%2520natural%2520and%2520synthetic%250Aimages%2520whilst%2520training%2520on%2520large-scale%2520datasets.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14535v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Rethinking%20Encoder-Decoder%20Flow%20Through%20Shared%20Structures&entry.906535625=Frederik%20Laboyrie%20and%20Mehmet%20Kerim%20Yucel%20and%20Albert%20Saa-Garriga&entry.1292438233=%20%20Dense%20prediction%20tasks%20have%20enjoyed%20a%20growing%20complexity%20of%20encoder%0Aarchitectures%2C%20decoders%2C%20however%2C%20have%20remained%20largely%20the%20same.%20They%20rely%20on%0Aindividual%20blocks%20decoding%20intermediate%20feature%20maps%20sequentially.%20We%20introduce%0Abanks%2C%20shared%20structures%20that%20are%20used%20by%20each%20decoding%20block%20to%20provide%0Aadditional%20context%20in%20the%20decoding%20process.%20These%20structures%2C%20through%20applying%0Athem%20via%20resampling%20and%20feature%20fusion%2C%20improve%20performance%20on%20depth%20estimation%0Afor%20state-of-the-art%20transformer-based%20architectures%20on%20natural%20and%20synthetic%0Aimages%20whilst%20training%20on%20large-scale%20datasets.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14535v1&entry.124074799=Read"},
{"title": "PARASIDE: An Automatic Paranasal Sinus Segmentation and Structure\n  Analysis Tool for MRI", "author": "Hendrik M\u00f6ller and Lukas Krautschick and Matan Atad and Robert Graf and Chia-Jung Busch and Achim Beule and Christian Scharf and Lars Kaderali and Bjoern Menze and Daniel Rueckert and Jan Kirschke and Fabian Schwitzing", "abstract": "  Chronic rhinosinusitis (CRS) is a common and persistent sinus imflammation\nthat affects 5 - 12\\% of the general population. It significantly impacts\nquality of life and is often difficult to assess due to its subjective nature\nin clinical evaluation. We introduce PARASIDE, an automatic tool for segmenting\nair and soft tissue volumes of the structures of the sinus maxillaris,\nfrontalis, sphenodalis and ethmoidalis in T1 MRI. By utilizing that\nsegmentation, we can quantify feature relations that have been observed only\nmanually and subjectively before. We performed an exemplary study and showed\nboth volume and intensity relations between structures and radiology reports.\nWhile the soft tissue segmentation is good, the automated annotations of the\nair volumes are excellent. The average intensity over air structures are\nconsistently below those of the soft tissues, close to perfect separability.\nHealthy subjects exhibit lower soft tissue volumes and lower intensities. Our\ndeveloped system is the first automated whole nasal segmentation of 16\nstructures, and capable of calculating medical relevant features such as the\nLund-Mackay score.\n", "link": "http://arxiv.org/abs/2501.14514v1", "date": "2025-01-24", "relevancy": 2.1993, "topK": [{"title": "CAT3D: Create Anything in 3D with Multi-View Diffusion Models", "link": "http://arxiv.org/abs/2405.10314v1", "similarity": 0.4411}, {"title": "CAT3D: Create Anything in 3D with Multi-View Diffusion Models", "link": "http://arxiv.org/abs/2405.10314v1", "similarity": 0.4411}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4375}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20PARASIDE%3A%20An%20Automatic%20Paranasal%20Sinus%20Segmentation%20and%20Structure%0A%20%20Analysis%20Tool%20for%20MRI&body=Title%3A%20PARASIDE%3A%20An%20Automatic%20Paranasal%20Sinus%20Segmentation%20and%20Structure%0A%20%20Analysis%20Tool%20for%20MRI%0AAuthor%3A%20Hendrik%20M%C3%B6ller%20and%20Lukas%20Krautschick%20and%20Matan%20Atad%20and%20Robert%20Graf%20and%20Chia-Jung%20Busch%20and%20Achim%20Beule%20and%20Christian%20Scharf%20and%20Lars%20Kaderali%20and%20Bjoern%20Menze%20and%20Daniel%20Rueckert%20and%20Jan%20Kirschke%20and%20Fabian%20Schwitzing%0AAbstract%3A%20%20%20Chronic%20rhinosinusitis%20%28CRS%29%20is%20a%20common%20and%20persistent%20sinus%20imflammation%0Athat%20affects%205%20-%2012%5C%25%20of%20the%20general%20population.%20It%20significantly%20impacts%0Aquality%20of%20life%20and%20is%20often%20difficult%20to%20assess%20due%20to%20its%20subjective%20nature%0Ain%20clinical%20evaluation.%20We%20introduce%20PARASIDE%2C%20an%20automatic%20tool%20for%20segmenting%0Aair%20and%20soft%20tissue%20volumes%20of%20the%20structures%20of%20the%20sinus%20maxillaris%2C%0Afrontalis%2C%20sphenodalis%20and%20ethmoidalis%20in%20T1%20MRI.%20By%20utilizing%20that%0Asegmentation%2C%20we%20can%20quantify%20feature%20relations%20that%20have%20been%20observed%20only%0Amanually%20and%20subjectively%20before.%20We%20performed%20an%20exemplary%20study%20and%20showed%0Aboth%20volume%20and%20intensity%20relations%20between%20structures%20and%20radiology%20reports.%0AWhile%20the%20soft%20tissue%20segmentation%20is%20good%2C%20the%20automated%20annotations%20of%20the%0Aair%20volumes%20are%20excellent.%20The%20average%20intensity%20over%20air%20structures%20are%0Aconsistently%20below%20those%20of%20the%20soft%20tissues%2C%20close%20to%20perfect%20separability.%0AHealthy%20subjects%20exhibit%20lower%20soft%20tissue%20volumes%20and%20lower%20intensities.%20Our%0Adeveloped%20system%20is%20the%20first%20automated%20whole%20nasal%20segmentation%20of%2016%0Astructures%2C%20and%20capable%20of%20calculating%20medical%20relevant%20features%20such%20as%20the%0ALund-Mackay%20score.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14514v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DPARASIDE%253A%2520An%2520Automatic%2520Paranasal%2520Sinus%2520Segmentation%2520and%2520Structure%250A%2520%2520Analysis%2520Tool%2520for%2520MRI%26entry.906535625%3DHendrik%2520M%25C3%25B6ller%2520and%2520Lukas%2520Krautschick%2520and%2520Matan%2520Atad%2520and%2520Robert%2520Graf%2520and%2520Chia-Jung%2520Busch%2520and%2520Achim%2520Beule%2520and%2520Christian%2520Scharf%2520and%2520Lars%2520Kaderali%2520and%2520Bjoern%2520Menze%2520and%2520Daniel%2520Rueckert%2520and%2520Jan%2520Kirschke%2520and%2520Fabian%2520Schwitzing%26entry.1292438233%3D%2520%2520Chronic%2520rhinosinusitis%2520%2528CRS%2529%2520is%2520a%2520common%2520and%2520persistent%2520sinus%2520imflammation%250Athat%2520affects%25205%2520-%252012%255C%2525%2520of%2520the%2520general%2520population.%2520It%2520significantly%2520impacts%250Aquality%2520of%2520life%2520and%2520is%2520often%2520difficult%2520to%2520assess%2520due%2520to%2520its%2520subjective%2520nature%250Ain%2520clinical%2520evaluation.%2520We%2520introduce%2520PARASIDE%252C%2520an%2520automatic%2520tool%2520for%2520segmenting%250Aair%2520and%2520soft%2520tissue%2520volumes%2520of%2520the%2520structures%2520of%2520the%2520sinus%2520maxillaris%252C%250Afrontalis%252C%2520sphenodalis%2520and%2520ethmoidalis%2520in%2520T1%2520MRI.%2520By%2520utilizing%2520that%250Asegmentation%252C%2520we%2520can%2520quantify%2520feature%2520relations%2520that%2520have%2520been%2520observed%2520only%250Amanually%2520and%2520subjectively%2520before.%2520We%2520performed%2520an%2520exemplary%2520study%2520and%2520showed%250Aboth%2520volume%2520and%2520intensity%2520relations%2520between%2520structures%2520and%2520radiology%2520reports.%250AWhile%2520the%2520soft%2520tissue%2520segmentation%2520is%2520good%252C%2520the%2520automated%2520annotations%2520of%2520the%250Aair%2520volumes%2520are%2520excellent.%2520The%2520average%2520intensity%2520over%2520air%2520structures%2520are%250Aconsistently%2520below%2520those%2520of%2520the%2520soft%2520tissues%252C%2520close%2520to%2520perfect%2520separability.%250AHealthy%2520subjects%2520exhibit%2520lower%2520soft%2520tissue%2520volumes%2520and%2520lower%2520intensities.%2520Our%250Adeveloped%2520system%2520is%2520the%2520first%2520automated%2520whole%2520nasal%2520segmentation%2520of%252016%250Astructures%252C%2520and%2520capable%2520of%2520calculating%2520medical%2520relevant%2520features%2520such%2520as%2520the%250ALund-Mackay%2520score.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14514v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=PARASIDE%3A%20An%20Automatic%20Paranasal%20Sinus%20Segmentation%20and%20Structure%0A%20%20Analysis%20Tool%20for%20MRI&entry.906535625=Hendrik%20M%C3%B6ller%20and%20Lukas%20Krautschick%20and%20Matan%20Atad%20and%20Robert%20Graf%20and%20Chia-Jung%20Busch%20and%20Achim%20Beule%20and%20Christian%20Scharf%20and%20Lars%20Kaderali%20and%20Bjoern%20Menze%20and%20Daniel%20Rueckert%20and%20Jan%20Kirschke%20and%20Fabian%20Schwitzing&entry.1292438233=%20%20Chronic%20rhinosinusitis%20%28CRS%29%20is%20a%20common%20and%20persistent%20sinus%20imflammation%0Athat%20affects%205%20-%2012%5C%25%20of%20the%20general%20population.%20It%20significantly%20impacts%0Aquality%20of%20life%20and%20is%20often%20difficult%20to%20assess%20due%20to%20its%20subjective%20nature%0Ain%20clinical%20evaluation.%20We%20introduce%20PARASIDE%2C%20an%20automatic%20tool%20for%20segmenting%0Aair%20and%20soft%20tissue%20volumes%20of%20the%20structures%20of%20the%20sinus%20maxillaris%2C%0Afrontalis%2C%20sphenodalis%20and%20ethmoidalis%20in%20T1%20MRI.%20By%20utilizing%20that%0Asegmentation%2C%20we%20can%20quantify%20feature%20relations%20that%20have%20been%20observed%20only%0Amanually%20and%20subjectively%20before.%20We%20performed%20an%20exemplary%20study%20and%20showed%0Aboth%20volume%20and%20intensity%20relations%20between%20structures%20and%20radiology%20reports.%0AWhile%20the%20soft%20tissue%20segmentation%20is%20good%2C%20the%20automated%20annotations%20of%20the%0Aair%20volumes%20are%20excellent.%20The%20average%20intensity%20over%20air%20structures%20are%0Aconsistently%20below%20those%20of%20the%20soft%20tissues%2C%20close%20to%20perfect%20separability.%0AHealthy%20subjects%20exhibit%20lower%20soft%20tissue%20volumes%20and%20lower%20intensities.%20Our%0Adeveloped%20system%20is%20the%20first%20automated%20whole%20nasal%20segmentation%20of%2016%0Astructures%2C%20and%20capable%20of%20calculating%20medical%20relevant%20features%20such%20as%20the%0ALund-Mackay%20score.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14514v1&entry.124074799=Read"},
{"title": "Rethinking Foundation Models for Medical Image Classification through a\n  Benchmark Study on MedMNIST", "author": "Fuping Wu and Bartlomiej W. Papiez", "abstract": "  Foundation models are widely employed in medical image analysis, due to their\nhigh adaptability and generalizability for downstream tasks. With the\nincreasing number of foundation models being released, model selection has\nbecome an important issue. In this work, we study the capabilities of\nfoundation models in medical image classification tasks by conducting a\nbenchmark study on the MedMNIST dataset. Specifically, we adopt various\nfoundation models ranging from convolutional to Transformer-based models and\nimplement both end-to-end training and linear probing for all classification\ntasks. The results demonstrate the significant potential of these pre-trained\nmodels when transferred for medical image classification. We further conduct\nexperiments with different image sizes and various sizes of training data. By\nanalyzing all the results, we provide preliminary, yet useful insights and\nconclusions on this topic.\n", "link": "http://arxiv.org/abs/2501.14685v1", "date": "2025-01-24", "relevancy": 2.1771, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5514}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5514}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.5088}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Rethinking%20Foundation%20Models%20for%20Medical%20Image%20Classification%20through%20a%0A%20%20Benchmark%20Study%20on%20MedMNIST&body=Title%3A%20Rethinking%20Foundation%20Models%20for%20Medical%20Image%20Classification%20through%20a%0A%20%20Benchmark%20Study%20on%20MedMNIST%0AAuthor%3A%20Fuping%20Wu%20and%20Bartlomiej%20W.%20Papiez%0AAbstract%3A%20%20%20Foundation%20models%20are%20widely%20employed%20in%20medical%20image%20analysis%2C%20due%20to%20their%0Ahigh%20adaptability%20and%20generalizability%20for%20downstream%20tasks.%20With%20the%0Aincreasing%20number%20of%20foundation%20models%20being%20released%2C%20model%20selection%20has%0Abecome%20an%20important%20issue.%20In%20this%20work%2C%20we%20study%20the%20capabilities%20of%0Afoundation%20models%20in%20medical%20image%20classification%20tasks%20by%20conducting%20a%0Abenchmark%20study%20on%20the%20MedMNIST%20dataset.%20Specifically%2C%20we%20adopt%20various%0Afoundation%20models%20ranging%20from%20convolutional%20to%20Transformer-based%20models%20and%0Aimplement%20both%20end-to-end%20training%20and%20linear%20probing%20for%20all%20classification%0Atasks.%20The%20results%20demonstrate%20the%20significant%20potential%20of%20these%20pre-trained%0Amodels%20when%20transferred%20for%20medical%20image%20classification.%20We%20further%20conduct%0Aexperiments%20with%20different%20image%20sizes%20and%20various%20sizes%20of%20training%20data.%20By%0Aanalyzing%20all%20the%20results%2C%20we%20provide%20preliminary%2C%20yet%20useful%20insights%20and%0Aconclusions%20on%20this%20topic.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14685v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRethinking%2520Foundation%2520Models%2520for%2520Medical%2520Image%2520Classification%2520through%2520a%250A%2520%2520Benchmark%2520Study%2520on%2520MedMNIST%26entry.906535625%3DFuping%2520Wu%2520and%2520Bartlomiej%2520W.%2520Papiez%26entry.1292438233%3D%2520%2520Foundation%2520models%2520are%2520widely%2520employed%2520in%2520medical%2520image%2520analysis%252C%2520due%2520to%2520their%250Ahigh%2520adaptability%2520and%2520generalizability%2520for%2520downstream%2520tasks.%2520With%2520the%250Aincreasing%2520number%2520of%2520foundation%2520models%2520being%2520released%252C%2520model%2520selection%2520has%250Abecome%2520an%2520important%2520issue.%2520In%2520this%2520work%252C%2520we%2520study%2520the%2520capabilities%2520of%250Afoundation%2520models%2520in%2520medical%2520image%2520classification%2520tasks%2520by%2520conducting%2520a%250Abenchmark%2520study%2520on%2520the%2520MedMNIST%2520dataset.%2520Specifically%252C%2520we%2520adopt%2520various%250Afoundation%2520models%2520ranging%2520from%2520convolutional%2520to%2520Transformer-based%2520models%2520and%250Aimplement%2520both%2520end-to-end%2520training%2520and%2520linear%2520probing%2520for%2520all%2520classification%250Atasks.%2520The%2520results%2520demonstrate%2520the%2520significant%2520potential%2520of%2520these%2520pre-trained%250Amodels%2520when%2520transferred%2520for%2520medical%2520image%2520classification.%2520We%2520further%2520conduct%250Aexperiments%2520with%2520different%2520image%2520sizes%2520and%2520various%2520sizes%2520of%2520training%2520data.%2520By%250Aanalyzing%2520all%2520the%2520results%252C%2520we%2520provide%2520preliminary%252C%2520yet%2520useful%2520insights%2520and%250Aconclusions%2520on%2520this%2520topic.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14685v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Rethinking%20Foundation%20Models%20for%20Medical%20Image%20Classification%20through%20a%0A%20%20Benchmark%20Study%20on%20MedMNIST&entry.906535625=Fuping%20Wu%20and%20Bartlomiej%20W.%20Papiez&entry.1292438233=%20%20Foundation%20models%20are%20widely%20employed%20in%20medical%20image%20analysis%2C%20due%20to%20their%0Ahigh%20adaptability%20and%20generalizability%20for%20downstream%20tasks.%20With%20the%0Aincreasing%20number%20of%20foundation%20models%20being%20released%2C%20model%20selection%20has%0Abecome%20an%20important%20issue.%20In%20this%20work%2C%20we%20study%20the%20capabilities%20of%0Afoundation%20models%20in%20medical%20image%20classification%20tasks%20by%20conducting%20a%0Abenchmark%20study%20on%20the%20MedMNIST%20dataset.%20Specifically%2C%20we%20adopt%20various%0Afoundation%20models%20ranging%20from%20convolutional%20to%20Transformer-based%20models%20and%0Aimplement%20both%20end-to-end%20training%20and%20linear%20probing%20for%20all%20classification%0Atasks.%20The%20results%20demonstrate%20the%20significant%20potential%20of%20these%20pre-trained%0Amodels%20when%20transferred%20for%20medical%20image%20classification.%20We%20further%20conduct%0Aexperiments%20with%20different%20image%20sizes%20and%20various%20sizes%20of%20training%20data.%20By%0Aanalyzing%20all%20the%20results%2C%20we%20provide%20preliminary%2C%20yet%20useful%20insights%20and%0Aconclusions%20on%20this%20topic.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14685v1&entry.124074799=Read"},
{"title": "Gaussian-Process-based Adaptive Tracking Control with Dynamic Active\n  Learning for Autonomous Ground Vehicles", "author": "Krist\u00f3f Floch and Tam\u00e1s P\u00e9ni and Roland T\u00f3th", "abstract": "  This article proposes an active-learning-based adaptive trajectory tracking\ncontrol method for autonomous ground vehicles to compensate for modeling errors\nand unmodeled dynamics. The nominal vehicle model is decoupled into lateral and\nlongitudinal subsystems, which are augmented with online Gaussian Processes\n(GPs), using measurement data. The estimated mean functions of the GPs are used\nto construct a feedback compensator, which, together with an LPV state feedback\ncontroller designed for the nominal system, gives the adaptive control\nstructure. To assist exploration of the dynamics, the paper proposes a new,\ndynamic active learning method to collect the most informative samples to\naccelerate the training process. To analyze the performance of the overall\nlearning tool-chain provided controller, a novel iterative,\ncounterexample-based algorithm is proposed for calculating the induced L2 gain\nbetween the reference trajectory and the tracking error. The analysis can be\nexecuted for a set of possible realizations of the to-be-controlled system,\ngiving robust performance certificate of the learning method under variation of\nthe vehicle dynamics. The efficiency of the proposed control approach is shown\non a high-fidelity physics simulator and in real experiments using a 1/10 scale\nF1TENTH electric car.\n", "link": "http://arxiv.org/abs/2501.14672v1", "date": "2025-01-24", "relevancy": 2.1275, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5397}, {"title": "Safe and efficient training of a control agent", "link": "https://patents.google.com/patent/US11709462B2/en", "similarity": 0.5361}, {"title": "Egocentric Computer Vision for Hands-Free Robotic Wheelchair Navigation", "link": "https://link.springer.com/article/10.1007/s10846-023-01807-4", "similarity": 0.5245}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Gaussian-Process-based%20Adaptive%20Tracking%20Control%20with%20Dynamic%20Active%0A%20%20Learning%20for%20Autonomous%20Ground%20Vehicles&body=Title%3A%20Gaussian-Process-based%20Adaptive%20Tracking%20Control%20with%20Dynamic%20Active%0A%20%20Learning%20for%20Autonomous%20Ground%20Vehicles%0AAuthor%3A%20Krist%C3%B3f%20Floch%20and%20Tam%C3%A1s%20P%C3%A9ni%20and%20Roland%20T%C3%B3th%0AAbstract%3A%20%20%20This%20article%20proposes%20an%20active-learning-based%20adaptive%20trajectory%20tracking%0Acontrol%20method%20for%20autonomous%20ground%20vehicles%20to%20compensate%20for%20modeling%20errors%0Aand%20unmodeled%20dynamics.%20The%20nominal%20vehicle%20model%20is%20decoupled%20into%20lateral%20and%0Alongitudinal%20subsystems%2C%20which%20are%20augmented%20with%20online%20Gaussian%20Processes%0A%28GPs%29%2C%20using%20measurement%20data.%20The%20estimated%20mean%20functions%20of%20the%20GPs%20are%20used%0Ato%20construct%20a%20feedback%20compensator%2C%20which%2C%20together%20with%20an%20LPV%20state%20feedback%0Acontroller%20designed%20for%20the%20nominal%20system%2C%20gives%20the%20adaptive%20control%0Astructure.%20To%20assist%20exploration%20of%20the%20dynamics%2C%20the%20paper%20proposes%20a%20new%2C%0Adynamic%20active%20learning%20method%20to%20collect%20the%20most%20informative%20samples%20to%0Aaccelerate%20the%20training%20process.%20To%20analyze%20the%20performance%20of%20the%20overall%0Alearning%20tool-chain%20provided%20controller%2C%20a%20novel%20iterative%2C%0Acounterexample-based%20algorithm%20is%20proposed%20for%20calculating%20the%20induced%20L2%20gain%0Abetween%20the%20reference%20trajectory%20and%20the%20tracking%20error.%20The%20analysis%20can%20be%0Aexecuted%20for%20a%20set%20of%20possible%20realizations%20of%20the%20to-be-controlled%20system%2C%0Agiving%20robust%20performance%20certificate%20of%20the%20learning%20method%20under%20variation%20of%0Athe%20vehicle%20dynamics.%20The%20efficiency%20of%20the%20proposed%20control%20approach%20is%20shown%0Aon%20a%20high-fidelity%20physics%20simulator%20and%20in%20real%20experiments%20using%20a%201/10%20scale%0AF1TENTH%20electric%20car.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14672v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DGaussian-Process-based%2520Adaptive%2520Tracking%2520Control%2520with%2520Dynamic%2520Active%250A%2520%2520Learning%2520for%2520Autonomous%2520Ground%2520Vehicles%26entry.906535625%3DKrist%25C3%25B3f%2520Floch%2520and%2520Tam%25C3%25A1s%2520P%25C3%25A9ni%2520and%2520Roland%2520T%25C3%25B3th%26entry.1292438233%3D%2520%2520This%2520article%2520proposes%2520an%2520active-learning-based%2520adaptive%2520trajectory%2520tracking%250Acontrol%2520method%2520for%2520autonomous%2520ground%2520vehicles%2520to%2520compensate%2520for%2520modeling%2520errors%250Aand%2520unmodeled%2520dynamics.%2520The%2520nominal%2520vehicle%2520model%2520is%2520decoupled%2520into%2520lateral%2520and%250Alongitudinal%2520subsystems%252C%2520which%2520are%2520augmented%2520with%2520online%2520Gaussian%2520Processes%250A%2528GPs%2529%252C%2520using%2520measurement%2520data.%2520The%2520estimated%2520mean%2520functions%2520of%2520the%2520GPs%2520are%2520used%250Ato%2520construct%2520a%2520feedback%2520compensator%252C%2520which%252C%2520together%2520with%2520an%2520LPV%2520state%2520feedback%250Acontroller%2520designed%2520for%2520the%2520nominal%2520system%252C%2520gives%2520the%2520adaptive%2520control%250Astructure.%2520To%2520assist%2520exploration%2520of%2520the%2520dynamics%252C%2520the%2520paper%2520proposes%2520a%2520new%252C%250Adynamic%2520active%2520learning%2520method%2520to%2520collect%2520the%2520most%2520informative%2520samples%2520to%250Aaccelerate%2520the%2520training%2520process.%2520To%2520analyze%2520the%2520performance%2520of%2520the%2520overall%250Alearning%2520tool-chain%2520provided%2520controller%252C%2520a%2520novel%2520iterative%252C%250Acounterexample-based%2520algorithm%2520is%2520proposed%2520for%2520calculating%2520the%2520induced%2520L2%2520gain%250Abetween%2520the%2520reference%2520trajectory%2520and%2520the%2520tracking%2520error.%2520The%2520analysis%2520can%2520be%250Aexecuted%2520for%2520a%2520set%2520of%2520possible%2520realizations%2520of%2520the%2520to-be-controlled%2520system%252C%250Agiving%2520robust%2520performance%2520certificate%2520of%2520the%2520learning%2520method%2520under%2520variation%2520of%250Athe%2520vehicle%2520dynamics.%2520The%2520efficiency%2520of%2520the%2520proposed%2520control%2520approach%2520is%2520shown%250Aon%2520a%2520high-fidelity%2520physics%2520simulator%2520and%2520in%2520real%2520experiments%2520using%2520a%25201/10%2520scale%250AF1TENTH%2520electric%2520car.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14672v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Gaussian-Process-based%20Adaptive%20Tracking%20Control%20with%20Dynamic%20Active%0A%20%20Learning%20for%20Autonomous%20Ground%20Vehicles&entry.906535625=Krist%C3%B3f%20Floch%20and%20Tam%C3%A1s%20P%C3%A9ni%20and%20Roland%20T%C3%B3th&entry.1292438233=%20%20This%20article%20proposes%20an%20active-learning-based%20adaptive%20trajectory%20tracking%0Acontrol%20method%20for%20autonomous%20ground%20vehicles%20to%20compensate%20for%20modeling%20errors%0Aand%20unmodeled%20dynamics.%20The%20nominal%20vehicle%20model%20is%20decoupled%20into%20lateral%20and%0Alongitudinal%20subsystems%2C%20which%20are%20augmented%20with%20online%20Gaussian%20Processes%0A%28GPs%29%2C%20using%20measurement%20data.%20The%20estimated%20mean%20functions%20of%20the%20GPs%20are%20used%0Ato%20construct%20a%20feedback%20compensator%2C%20which%2C%20together%20with%20an%20LPV%20state%20feedback%0Acontroller%20designed%20for%20the%20nominal%20system%2C%20gives%20the%20adaptive%20control%0Astructure.%20To%20assist%20exploration%20of%20the%20dynamics%2C%20the%20paper%20proposes%20a%20new%2C%0Adynamic%20active%20learning%20method%20to%20collect%20the%20most%20informative%20samples%20to%0Aaccelerate%20the%20training%20process.%20To%20analyze%20the%20performance%20of%20the%20overall%0Alearning%20tool-chain%20provided%20controller%2C%20a%20novel%20iterative%2C%0Acounterexample-based%20algorithm%20is%20proposed%20for%20calculating%20the%20induced%20L2%20gain%0Abetween%20the%20reference%20trajectory%20and%20the%20tracking%20error.%20The%20analysis%20can%20be%0Aexecuted%20for%20a%20set%20of%20possible%20realizations%20of%20the%20to-be-controlled%20system%2C%0Agiving%20robust%20performance%20certificate%20of%20the%20learning%20method%20under%20variation%20of%0Athe%20vehicle%20dynamics.%20The%20efficiency%20of%20the%20proposed%20control%20approach%20is%20shown%0Aon%20a%20high-fidelity%20physics%20simulator%20and%20in%20real%20experiments%20using%20a%201/10%20scale%0AF1TENTH%20electric%20car.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14672v1&entry.124074799=Read"},
{"title": "Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering\n  Tasks", "author": "Zihao Wang and Zhe Wu", "abstract": "  Computational efficiency and robustness are essential in process modeling,\noptimization, and control for real-world engineering applications. While neural\nnetwork-based approaches have gained significant attention in recent years,\nconventional neural networks often fail to address these two critical aspects\nsimultaneously or even independently. Inspired by natural physical systems and\nestablished literature, input convex architectures are known to enhance\ncomputational efficiency in optimization tasks, whereas Lipschitz-constrained\narchitectures improve robustness. However, combining these properties within a\nsingle model requires careful review, as inappropriate methods for enforcing\none property can undermine the other. To overcome this, we introduce a novel\nnetwork architecture, termed Input Convex Lipschitz Recurrent Neural Networks\n(ICLRNNs). This architecture seamlessly integrates the benefits of convexity\nand Lipschitz continuity, enabling fast and robust neural network-based\nmodeling and optimization. The ICLRNN outperforms existing recurrent units in\nboth computational efficiency and robustness. Additionally, it has been\nsuccessfully applied to practical engineering scenarios, such as modeling and\ncontrol of chemical process and the modeling and real-world solar irradiance\nprediction for solar PV system planning at LHT Holdings in Singapore. Source\ncode is available at https://github.com/killingbear999/ICLRNN.\n", "link": "http://arxiv.org/abs/2401.07494v5", "date": "2025-01-24", "relevancy": 2.1141, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.5418}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5303}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5145}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Input%20Convex%20Lipschitz%20RNN%3A%20A%20Fast%20and%20Robust%20Approach%20for%20Engineering%0A%20%20Tasks&body=Title%3A%20Input%20Convex%20Lipschitz%20RNN%3A%20A%20Fast%20and%20Robust%20Approach%20for%20Engineering%0A%20%20Tasks%0AAuthor%3A%20Zihao%20Wang%20and%20Zhe%20Wu%0AAbstract%3A%20%20%20Computational%20efficiency%20and%20robustness%20are%20essential%20in%20process%20modeling%2C%0Aoptimization%2C%20and%20control%20for%20real-world%20engineering%20applications.%20While%20neural%0Anetwork-based%20approaches%20have%20gained%20significant%20attention%20in%20recent%20years%2C%0Aconventional%20neural%20networks%20often%20fail%20to%20address%20these%20two%20critical%20aspects%0Asimultaneously%20or%20even%20independently.%20Inspired%20by%20natural%20physical%20systems%20and%0Aestablished%20literature%2C%20input%20convex%20architectures%20are%20known%20to%20enhance%0Acomputational%20efficiency%20in%20optimization%20tasks%2C%20whereas%20Lipschitz-constrained%0Aarchitectures%20improve%20robustness.%20However%2C%20combining%20these%20properties%20within%20a%0Asingle%20model%20requires%20careful%20review%2C%20as%20inappropriate%20methods%20for%20enforcing%0Aone%20property%20can%20undermine%20the%20other.%20To%20overcome%20this%2C%20we%20introduce%20a%20novel%0Anetwork%20architecture%2C%20termed%20Input%20Convex%20Lipschitz%20Recurrent%20Neural%20Networks%0A%28ICLRNNs%29.%20This%20architecture%20seamlessly%20integrates%20the%20benefits%20of%20convexity%0Aand%20Lipschitz%20continuity%2C%20enabling%20fast%20and%20robust%20neural%20network-based%0Amodeling%20and%20optimization.%20The%20ICLRNN%20outperforms%20existing%20recurrent%20units%20in%0Aboth%20computational%20efficiency%20and%20robustness.%20Additionally%2C%20it%20has%20been%0Asuccessfully%20applied%20to%20practical%20engineering%20scenarios%2C%20such%20as%20modeling%20and%0Acontrol%20of%20chemical%20process%20and%20the%20modeling%20and%20real-world%20solar%20irradiance%0Aprediction%20for%20solar%20PV%20system%20planning%20at%20LHT%20Holdings%20in%20Singapore.%20Source%0Acode%20is%20available%20at%20https%3A//github.com/killingbear999/ICLRNN.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2401.07494v5%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DInput%2520Convex%2520Lipschitz%2520RNN%253A%2520A%2520Fast%2520and%2520Robust%2520Approach%2520for%2520Engineering%250A%2520%2520Tasks%26entry.906535625%3DZihao%2520Wang%2520and%2520Zhe%2520Wu%26entry.1292438233%3D%2520%2520Computational%2520efficiency%2520and%2520robustness%2520are%2520essential%2520in%2520process%2520modeling%252C%250Aoptimization%252C%2520and%2520control%2520for%2520real-world%2520engineering%2520applications.%2520While%2520neural%250Anetwork-based%2520approaches%2520have%2520gained%2520significant%2520attention%2520in%2520recent%2520years%252C%250Aconventional%2520neural%2520networks%2520often%2520fail%2520to%2520address%2520these%2520two%2520critical%2520aspects%250Asimultaneously%2520or%2520even%2520independently.%2520Inspired%2520by%2520natural%2520physical%2520systems%2520and%250Aestablished%2520literature%252C%2520input%2520convex%2520architectures%2520are%2520known%2520to%2520enhance%250Acomputational%2520efficiency%2520in%2520optimization%2520tasks%252C%2520whereas%2520Lipschitz-constrained%250Aarchitectures%2520improve%2520robustness.%2520However%252C%2520combining%2520these%2520properties%2520within%2520a%250Asingle%2520model%2520requires%2520careful%2520review%252C%2520as%2520inappropriate%2520methods%2520for%2520enforcing%250Aone%2520property%2520can%2520undermine%2520the%2520other.%2520To%2520overcome%2520this%252C%2520we%2520introduce%2520a%2520novel%250Anetwork%2520architecture%252C%2520termed%2520Input%2520Convex%2520Lipschitz%2520Recurrent%2520Neural%2520Networks%250A%2528ICLRNNs%2529.%2520This%2520architecture%2520seamlessly%2520integrates%2520the%2520benefits%2520of%2520convexity%250Aand%2520Lipschitz%2520continuity%252C%2520enabling%2520fast%2520and%2520robust%2520neural%2520network-based%250Amodeling%2520and%2520optimization.%2520The%2520ICLRNN%2520outperforms%2520existing%2520recurrent%2520units%2520in%250Aboth%2520computational%2520efficiency%2520and%2520robustness.%2520Additionally%252C%2520it%2520has%2520been%250Asuccessfully%2520applied%2520to%2520practical%2520engineering%2520scenarios%252C%2520such%2520as%2520modeling%2520and%250Acontrol%2520of%2520chemical%2520process%2520and%2520the%2520modeling%2520and%2520real-world%2520solar%2520irradiance%250Aprediction%2520for%2520solar%2520PV%2520system%2520planning%2520at%2520LHT%2520Holdings%2520in%2520Singapore.%2520Source%250Acode%2520is%2520available%2520at%2520https%253A//github.com/killingbear999/ICLRNN.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2401.07494v5%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Input%20Convex%20Lipschitz%20RNN%3A%20A%20Fast%20and%20Robust%20Approach%20for%20Engineering%0A%20%20Tasks&entry.906535625=Zihao%20Wang%20and%20Zhe%20Wu&entry.1292438233=%20%20Computational%20efficiency%20and%20robustness%20are%20essential%20in%20process%20modeling%2C%0Aoptimization%2C%20and%20control%20for%20real-world%20engineering%20applications.%20While%20neural%0Anetwork-based%20approaches%20have%20gained%20significant%20attention%20in%20recent%20years%2C%0Aconventional%20neural%20networks%20often%20fail%20to%20address%20these%20two%20critical%20aspects%0Asimultaneously%20or%20even%20independently.%20Inspired%20by%20natural%20physical%20systems%20and%0Aestablished%20literature%2C%20input%20convex%20architectures%20are%20known%20to%20enhance%0Acomputational%20efficiency%20in%20optimization%20tasks%2C%20whereas%20Lipschitz-constrained%0Aarchitectures%20improve%20robustness.%20However%2C%20combining%20these%20properties%20within%20a%0Asingle%20model%20requires%20careful%20review%2C%20as%20inappropriate%20methods%20for%20enforcing%0Aone%20property%20can%20undermine%20the%20other.%20To%20overcome%20this%2C%20we%20introduce%20a%20novel%0Anetwork%20architecture%2C%20termed%20Input%20Convex%20Lipschitz%20Recurrent%20Neural%20Networks%0A%28ICLRNNs%29.%20This%20architecture%20seamlessly%20integrates%20the%20benefits%20of%20convexity%0Aand%20Lipschitz%20continuity%2C%20enabling%20fast%20and%20robust%20neural%20network-based%0Amodeling%20and%20optimization.%20The%20ICLRNN%20outperforms%20existing%20recurrent%20units%20in%0Aboth%20computational%20efficiency%20and%20robustness.%20Additionally%2C%20it%20has%20been%0Asuccessfully%20applied%20to%20practical%20engineering%20scenarios%2C%20such%20as%20modeling%20and%0Acontrol%20of%20chemical%20process%20and%20the%20modeling%20and%20real-world%20solar%20irradiance%0Aprediction%20for%20solar%20PV%20system%20planning%20at%20LHT%20Holdings%20in%20Singapore.%20Source%0Acode%20is%20available%20at%20https%3A//github.com/killingbear999/ICLRNN.%0A&entry.1838667208=http%3A//arxiv.org/abs/2401.07494v5&entry.124074799=Read"},
{"title": "A Paired Autoencoder Framework for Inverse Problems via Bayes Risk\n  Minimization", "author": "Emma Hart and Julianne Chung and Matthias Chung", "abstract": "  In this work, we describe a new data-driven approach for inverse problems\nthat exploits technologies from machine learning, in particular autoencoder\nnetwork structures. We consider a paired autoencoder framework, where two\nautoencoders are used to efficiently represent the input and target spaces\nseparately and optimal mappings are learned between latent spaces, thus\nenabling forward and inverse surrogate mappings. We focus on interpretations\nusing Bayes risk and empirical Bayes risk minimization, and we provide various\ntheoretical results and connections to existing works on low-rank matrix\napproximations. Similar to end-to-end approaches, our paired approach creates a\nsurrogate model for forward propagation and regularized inversion. However, our\napproach outperforms existing approaches in scenarios where training data for\nunsupervised learning are readily available but training pairs for supervised\nlearning are scarce. Furthermore, we show that cheaply computable evaluation\nmetrics are available through this framework and can be used to predict whether\nthe solution for a new sample should be predicted well.\n", "link": "http://arxiv.org/abs/2501.14636v1", "date": "2025-01-24", "relevancy": 2.1075, "topK": [{"title": "IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation Learning", "link": "https://arxiv.org/abs/2201.00785", "similarity": 0.5539}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5331}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.4974}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20A%20Paired%20Autoencoder%20Framework%20for%20Inverse%20Problems%20via%20Bayes%20Risk%0A%20%20Minimization&body=Title%3A%20A%20Paired%20Autoencoder%20Framework%20for%20Inverse%20Problems%20via%20Bayes%20Risk%0A%20%20Minimization%0AAuthor%3A%20Emma%20Hart%20and%20Julianne%20Chung%20and%20Matthias%20Chung%0AAbstract%3A%20%20%20In%20this%20work%2C%20we%20describe%20a%20new%20data-driven%20approach%20for%20inverse%20problems%0Athat%20exploits%20technologies%20from%20machine%20learning%2C%20in%20particular%20autoencoder%0Anetwork%20structures.%20We%20consider%20a%20paired%20autoencoder%20framework%2C%20where%20two%0Aautoencoders%20are%20used%20to%20efficiently%20represent%20the%20input%20and%20target%20spaces%0Aseparately%20and%20optimal%20mappings%20are%20learned%20between%20latent%20spaces%2C%20thus%0Aenabling%20forward%20and%20inverse%20surrogate%20mappings.%20We%20focus%20on%20interpretations%0Ausing%20Bayes%20risk%20and%20empirical%20Bayes%20risk%20minimization%2C%20and%20we%20provide%20various%0Atheoretical%20results%20and%20connections%20to%20existing%20works%20on%20low-rank%20matrix%0Aapproximations.%20Similar%20to%20end-to-end%20approaches%2C%20our%20paired%20approach%20creates%20a%0Asurrogate%20model%20for%20forward%20propagation%20and%20regularized%20inversion.%20However%2C%20our%0Aapproach%20outperforms%20existing%20approaches%20in%20scenarios%20where%20training%20data%20for%0Aunsupervised%20learning%20are%20readily%20available%20but%20training%20pairs%20for%20supervised%0Alearning%20are%20scarce.%20Furthermore%2C%20we%20show%20that%20cheaply%20computable%20evaluation%0Ametrics%20are%20available%20through%20this%20framework%20and%20can%20be%20used%20to%20predict%20whether%0Athe%20solution%20for%20a%20new%20sample%20should%20be%20predicted%20well.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14636v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DA%2520Paired%2520Autoencoder%2520Framework%2520for%2520Inverse%2520Problems%2520via%2520Bayes%2520Risk%250A%2520%2520Minimization%26entry.906535625%3DEmma%2520Hart%2520and%2520Julianne%2520Chung%2520and%2520Matthias%2520Chung%26entry.1292438233%3D%2520%2520In%2520this%2520work%252C%2520we%2520describe%2520a%2520new%2520data-driven%2520approach%2520for%2520inverse%2520problems%250Athat%2520exploits%2520technologies%2520from%2520machine%2520learning%252C%2520in%2520particular%2520autoencoder%250Anetwork%2520structures.%2520We%2520consider%2520a%2520paired%2520autoencoder%2520framework%252C%2520where%2520two%250Aautoencoders%2520are%2520used%2520to%2520efficiently%2520represent%2520the%2520input%2520and%2520target%2520spaces%250Aseparately%2520and%2520optimal%2520mappings%2520are%2520learned%2520between%2520latent%2520spaces%252C%2520thus%250Aenabling%2520forward%2520and%2520inverse%2520surrogate%2520mappings.%2520We%2520focus%2520on%2520interpretations%250Ausing%2520Bayes%2520risk%2520and%2520empirical%2520Bayes%2520risk%2520minimization%252C%2520and%2520we%2520provide%2520various%250Atheoretical%2520results%2520and%2520connections%2520to%2520existing%2520works%2520on%2520low-rank%2520matrix%250Aapproximations.%2520Similar%2520to%2520end-to-end%2520approaches%252C%2520our%2520paired%2520approach%2520creates%2520a%250Asurrogate%2520model%2520for%2520forward%2520propagation%2520and%2520regularized%2520inversion.%2520However%252C%2520our%250Aapproach%2520outperforms%2520existing%2520approaches%2520in%2520scenarios%2520where%2520training%2520data%2520for%250Aunsupervised%2520learning%2520are%2520readily%2520available%2520but%2520training%2520pairs%2520for%2520supervised%250Alearning%2520are%2520scarce.%2520Furthermore%252C%2520we%2520show%2520that%2520cheaply%2520computable%2520evaluation%250Ametrics%2520are%2520available%2520through%2520this%2520framework%2520and%2520can%2520be%2520used%2520to%2520predict%2520whether%250Athe%2520solution%2520for%2520a%2520new%2520sample%2520should%2520be%2520predicted%2520well.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14636v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=A%20Paired%20Autoencoder%20Framework%20for%20Inverse%20Problems%20via%20Bayes%20Risk%0A%20%20Minimization&entry.906535625=Emma%20Hart%20and%20Julianne%20Chung%20and%20Matthias%20Chung&entry.1292438233=%20%20In%20this%20work%2C%20we%20describe%20a%20new%20data-driven%20approach%20for%20inverse%20problems%0Athat%20exploits%20technologies%20from%20machine%20learning%2C%20in%20particular%20autoencoder%0Anetwork%20structures.%20We%20consider%20a%20paired%20autoencoder%20framework%2C%20where%20two%0Aautoencoders%20are%20used%20to%20efficiently%20represent%20the%20input%20and%20target%20spaces%0Aseparately%20and%20optimal%20mappings%20are%20learned%20between%20latent%20spaces%2C%20thus%0Aenabling%20forward%20and%20inverse%20surrogate%20mappings.%20We%20focus%20on%20interpretations%0Ausing%20Bayes%20risk%20and%20empirical%20Bayes%20risk%20minimization%2C%20and%20we%20provide%20various%0Atheoretical%20results%20and%20connections%20to%20existing%20works%20on%20low-rank%20matrix%0Aapproximations.%20Similar%20to%20end-to-end%20approaches%2C%20our%20paired%20approach%20creates%20a%0Asurrogate%20model%20for%20forward%20propagation%20and%20regularized%20inversion.%20However%2C%20our%0Aapproach%20outperforms%20existing%20approaches%20in%20scenarios%20where%20training%20data%20for%0Aunsupervised%20learning%20are%20readily%20available%20but%20training%20pairs%20for%20supervised%0Alearning%20are%20scarce.%20Furthermore%2C%20we%20show%20that%20cheaply%20computable%20evaluation%0Ametrics%20are%20available%20through%20this%20framework%20and%20can%20be%20used%20to%20predict%20whether%0Athe%20solution%20for%20a%20new%20sample%20should%20be%20predicted%20well.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14636v1&entry.124074799=Read"},
{"title": "Towards Scalable Topological Regularizers", "author": "Hiu-Tung Wong and Darrick Lee and Hong Yan", "abstract": "  Latent space matching, which consists of matching distributions of features\nin latent space, is a crucial component for tasks such as adversarial attacks\nand defenses, domain adaptation, and generative modelling. Metrics for\nprobability measures, such as Wasserstein and maximum mean discrepancy, are\ncommonly used to quantify the differences between such distributions. However,\nthese are often costly to compute, or do not appropriately take the geometric\nand topological features of the distributions into consideration. Persistent\nhomology is a tool from topological data analysis which quantifies the\nmulti-scale topological structure of point clouds, and has recently been used\nas a topological regularizer in learning tasks. However, computation costs\npreclude larger scale computations, and discontinuities in the gradient lead to\nunstable training behavior such as in adversarial tasks. We propose the use of\nprincipal persistence measures, based on computing the persistent homology of a\nlarge number of small subsamples, as a topological regularizer. We provide a\nparallelized GPU implementation of this regularizer, and prove that gradients\nare continuous for smooth densities. Furthermore, we demonstrate the efficacy\nof this regularizer on shape matching, image generation, and semi-supervised\nlearning tasks, opening the door towards a scalable regularizer for topological\nfeatures.\n", "link": "http://arxiv.org/abs/2501.14641v1", "date": "2025-01-24", "relevancy": 2.0937, "topK": [{"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.5273}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.5251}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.5189}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Towards%20Scalable%20Topological%20Regularizers&body=Title%3A%20Towards%20Scalable%20Topological%20Regularizers%0AAuthor%3A%20Hiu-Tung%20Wong%20and%20Darrick%20Lee%20and%20Hong%20Yan%0AAbstract%3A%20%20%20Latent%20space%20matching%2C%20which%20consists%20of%20matching%20distributions%20of%20features%0Ain%20latent%20space%2C%20is%20a%20crucial%20component%20for%20tasks%20such%20as%20adversarial%20attacks%0Aand%20defenses%2C%20domain%20adaptation%2C%20and%20generative%20modelling.%20Metrics%20for%0Aprobability%20measures%2C%20such%20as%20Wasserstein%20and%20maximum%20mean%20discrepancy%2C%20are%0Acommonly%20used%20to%20quantify%20the%20differences%20between%20such%20distributions.%20However%2C%0Athese%20are%20often%20costly%20to%20compute%2C%20or%20do%20not%20appropriately%20take%20the%20geometric%0Aand%20topological%20features%20of%20the%20distributions%20into%20consideration.%20Persistent%0Ahomology%20is%20a%20tool%20from%20topological%20data%20analysis%20which%20quantifies%20the%0Amulti-scale%20topological%20structure%20of%20point%20clouds%2C%20and%20has%20recently%20been%20used%0Aas%20a%20topological%20regularizer%20in%20learning%20tasks.%20However%2C%20computation%20costs%0Apreclude%20larger%20scale%20computations%2C%20and%20discontinuities%20in%20the%20gradient%20lead%20to%0Aunstable%20training%20behavior%20such%20as%20in%20adversarial%20tasks.%20We%20propose%20the%20use%20of%0Aprincipal%20persistence%20measures%2C%20based%20on%20computing%20the%20persistent%20homology%20of%20a%0Alarge%20number%20of%20small%20subsamples%2C%20as%20a%20topological%20regularizer.%20We%20provide%20a%0Aparallelized%20GPU%20implementation%20of%20this%20regularizer%2C%20and%20prove%20that%20gradients%0Aare%20continuous%20for%20smooth%20densities.%20Furthermore%2C%20we%20demonstrate%20the%20efficacy%0Aof%20this%20regularizer%20on%20shape%20matching%2C%20image%20generation%2C%20and%20semi-supervised%0Alearning%20tasks%2C%20opening%20the%20door%20towards%20a%20scalable%20regularizer%20for%20topological%0Afeatures.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14641v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTowards%2520Scalable%2520Topological%2520Regularizers%26entry.906535625%3DHiu-Tung%2520Wong%2520and%2520Darrick%2520Lee%2520and%2520Hong%2520Yan%26entry.1292438233%3D%2520%2520Latent%2520space%2520matching%252C%2520which%2520consists%2520of%2520matching%2520distributions%2520of%2520features%250Ain%2520latent%2520space%252C%2520is%2520a%2520crucial%2520component%2520for%2520tasks%2520such%2520as%2520adversarial%2520attacks%250Aand%2520defenses%252C%2520domain%2520adaptation%252C%2520and%2520generative%2520modelling.%2520Metrics%2520for%250Aprobability%2520measures%252C%2520such%2520as%2520Wasserstein%2520and%2520maximum%2520mean%2520discrepancy%252C%2520are%250Acommonly%2520used%2520to%2520quantify%2520the%2520differences%2520between%2520such%2520distributions.%2520However%252C%250Athese%2520are%2520often%2520costly%2520to%2520compute%252C%2520or%2520do%2520not%2520appropriately%2520take%2520the%2520geometric%250Aand%2520topological%2520features%2520of%2520the%2520distributions%2520into%2520consideration.%2520Persistent%250Ahomology%2520is%2520a%2520tool%2520from%2520topological%2520data%2520analysis%2520which%2520quantifies%2520the%250Amulti-scale%2520topological%2520structure%2520of%2520point%2520clouds%252C%2520and%2520has%2520recently%2520been%2520used%250Aas%2520a%2520topological%2520regularizer%2520in%2520learning%2520tasks.%2520However%252C%2520computation%2520costs%250Apreclude%2520larger%2520scale%2520computations%252C%2520and%2520discontinuities%2520in%2520the%2520gradient%2520lead%2520to%250Aunstable%2520training%2520behavior%2520such%2520as%2520in%2520adversarial%2520tasks.%2520We%2520propose%2520the%2520use%2520of%250Aprincipal%2520persistence%2520measures%252C%2520based%2520on%2520computing%2520the%2520persistent%2520homology%2520of%2520a%250Alarge%2520number%2520of%2520small%2520subsamples%252C%2520as%2520a%2520topological%2520regularizer.%2520We%2520provide%2520a%250Aparallelized%2520GPU%2520implementation%2520of%2520this%2520regularizer%252C%2520and%2520prove%2520that%2520gradients%250Aare%2520continuous%2520for%2520smooth%2520densities.%2520Furthermore%252C%2520we%2520demonstrate%2520the%2520efficacy%250Aof%2520this%2520regularizer%2520on%2520shape%2520matching%252C%2520image%2520generation%252C%2520and%2520semi-supervised%250Alearning%2520tasks%252C%2520opening%2520the%2520door%2520towards%2520a%2520scalable%2520regularizer%2520for%2520topological%250Afeatures.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14641v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Towards%20Scalable%20Topological%20Regularizers&entry.906535625=Hiu-Tung%20Wong%20and%20Darrick%20Lee%20and%20Hong%20Yan&entry.1292438233=%20%20Latent%20space%20matching%2C%20which%20consists%20of%20matching%20distributions%20of%20features%0Ain%20latent%20space%2C%20is%20a%20crucial%20component%20for%20tasks%20such%20as%20adversarial%20attacks%0Aand%20defenses%2C%20domain%20adaptation%2C%20and%20generative%20modelling.%20Metrics%20for%0Aprobability%20measures%2C%20such%20as%20Wasserstein%20and%20maximum%20mean%20discrepancy%2C%20are%0Acommonly%20used%20to%20quantify%20the%20differences%20between%20such%20distributions.%20However%2C%0Athese%20are%20often%20costly%20to%20compute%2C%20or%20do%20not%20appropriately%20take%20the%20geometric%0Aand%20topological%20features%20of%20the%20distributions%20into%20consideration.%20Persistent%0Ahomology%20is%20a%20tool%20from%20topological%20data%20analysis%20which%20quantifies%20the%0Amulti-scale%20topological%20structure%20of%20point%20clouds%2C%20and%20has%20recently%20been%20used%0Aas%20a%20topological%20regularizer%20in%20learning%20tasks.%20However%2C%20computation%20costs%0Apreclude%20larger%20scale%20computations%2C%20and%20discontinuities%20in%20the%20gradient%20lead%20to%0Aunstable%20training%20behavior%20such%20as%20in%20adversarial%20tasks.%20We%20propose%20the%20use%20of%0Aprincipal%20persistence%20measures%2C%20based%20on%20computing%20the%20persistent%20homology%20of%20a%0Alarge%20number%20of%20small%20subsamples%2C%20as%20a%20topological%20regularizer.%20We%20provide%20a%0Aparallelized%20GPU%20implementation%20of%20this%20regularizer%2C%20and%20prove%20that%20gradients%0Aare%20continuous%20for%20smooth%20densities.%20Furthermore%2C%20we%20demonstrate%20the%20efficacy%0Aof%20this%20regularizer%20on%20shape%20matching%2C%20image%20generation%2C%20and%20semi-supervised%0Alearning%20tasks%2C%20opening%20the%20door%20towards%20a%20scalable%20regularizer%20for%20topological%0Afeatures.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14641v1&entry.124074799=Read"},
{"title": "Single-neuron deep generative model uncovers underlying physics of\n  neuronal activity in Ca imaging data", "author": "Jordi Abante and Angelo Piga and Berta Ros and Clara F L\u00f3pez-Le\u00f3n and Josep M Canals and Jordi Soriano", "abstract": "  Calcium imaging has become a powerful alternative to electrophysiology for\nstudying neuronal activity, offering spatial resolution and the ability to\nmeasure large populations of neurons in a minimally invasive manner. This\ntechnique has broad applications in neuroscience, neuroengineering, and\nmedicine, enabling researchers to explore the relationship between neuron\nlocation and activity. Recent advancements in deep generative models (DGMs)\nhave facilitated the modeling of neuronal population dynamics, uncovering\nlatent representations that provide insights into behavior prediction and\nneuronal variance. However, these models often rely on spike inference\nalgorithms and primarily focus on population-level dynamics, limiting their\napplicability for single-neuron analyses. To address this gap, we propose a\nnovel framework for single-neuron representation learning using autoregressive\nvariational autoencoders (AVAEs). Our approach embeds individual neurons'\nspatiotemporal signals into a reduced-dimensional space without the need for\nspike inference algorithms. The AVAE excels over traditional linear methods by\ngenerating more informative and discriminative latent representations,\nimproving tasks such as visualization, clustering, and the understanding of\nneuronal activity. Additionally, the reconstruction performance of the AVAE\noutperforms the state of the art, demonstrating its ability to accurately\nrecover the original fluorescence signal from the learned representation. Using\nrealistic simulations, we show that our model captures underlying physical\nproperties and connectivity patterns, enabling it to distinguish between\ndifferent firing and connectivity types. These findings position the AVAE as a\nversatile and powerful tool for advancing single-neuron analysis and lays the\ngroundwork for future integration of multimodal single-cell datasets in\nneuroscience.\n", "link": "http://arxiv.org/abs/2501.14615v1", "date": "2025-01-24", "relevancy": 2.0933, "topK": [{"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.5383}, {"title": "IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation Learning", "link": "https://arxiv.org/abs/2201.00785", "similarity": 0.5261}, {"title": "Genie: Generative Interactive Environments", "link": "http://arxiv.org/abs/2402.15391v1", "similarity": 0.5145}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Single-neuron%20deep%20generative%20model%20uncovers%20underlying%20physics%20of%0A%20%20neuronal%20activity%20in%20Ca%20imaging%20data&body=Title%3A%20Single-neuron%20deep%20generative%20model%20uncovers%20underlying%20physics%20of%0A%20%20neuronal%20activity%20in%20Ca%20imaging%20data%0AAuthor%3A%20Jordi%20Abante%20and%20Angelo%20Piga%20and%20Berta%20Ros%20and%20Clara%20F%20L%C3%B3pez-Le%C3%B3n%20and%20Josep%20M%20Canals%20and%20Jordi%20Soriano%0AAbstract%3A%20%20%20Calcium%20imaging%20has%20become%20a%20powerful%20alternative%20to%20electrophysiology%20for%0Astudying%20neuronal%20activity%2C%20offering%20spatial%20resolution%20and%20the%20ability%20to%0Ameasure%20large%20populations%20of%20neurons%20in%20a%20minimally%20invasive%20manner.%20This%0Atechnique%20has%20broad%20applications%20in%20neuroscience%2C%20neuroengineering%2C%20and%0Amedicine%2C%20enabling%20researchers%20to%20explore%20the%20relationship%20between%20neuron%0Alocation%20and%20activity.%20Recent%20advancements%20in%20deep%20generative%20models%20%28DGMs%29%0Ahave%20facilitated%20the%20modeling%20of%20neuronal%20population%20dynamics%2C%20uncovering%0Alatent%20representations%20that%20provide%20insights%20into%20behavior%20prediction%20and%0Aneuronal%20variance.%20However%2C%20these%20models%20often%20rely%20on%20spike%20inference%0Aalgorithms%20and%20primarily%20focus%20on%20population-level%20dynamics%2C%20limiting%20their%0Aapplicability%20for%20single-neuron%20analyses.%20To%20address%20this%20gap%2C%20we%20propose%20a%0Anovel%20framework%20for%20single-neuron%20representation%20learning%20using%20autoregressive%0Avariational%20autoencoders%20%28AVAEs%29.%20Our%20approach%20embeds%20individual%20neurons%27%0Aspatiotemporal%20signals%20into%20a%20reduced-dimensional%20space%20without%20the%20need%20for%0Aspike%20inference%20algorithms.%20The%20AVAE%20excels%20over%20traditional%20linear%20methods%20by%0Agenerating%20more%20informative%20and%20discriminative%20latent%20representations%2C%0Aimproving%20tasks%20such%20as%20visualization%2C%20clustering%2C%20and%20the%20understanding%20of%0Aneuronal%20activity.%20Additionally%2C%20the%20reconstruction%20performance%20of%20the%20AVAE%0Aoutperforms%20the%20state%20of%20the%20art%2C%20demonstrating%20its%20ability%20to%20accurately%0Arecover%20the%20original%20fluorescence%20signal%20from%20the%20learned%20representation.%20Using%0Arealistic%20simulations%2C%20we%20show%20that%20our%20model%20captures%20underlying%20physical%0Aproperties%20and%20connectivity%20patterns%2C%20enabling%20it%20to%20distinguish%20between%0Adifferent%20firing%20and%20connectivity%20types.%20These%20findings%20position%20the%20AVAE%20as%20a%0Aversatile%20and%20powerful%20tool%20for%20advancing%20single-neuron%20analysis%20and%20lays%20the%0Agroundwork%20for%20future%20integration%20of%20multimodal%20single-cell%20datasets%20in%0Aneuroscience.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14615v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSingle-neuron%2520deep%2520generative%2520model%2520uncovers%2520underlying%2520physics%2520of%250A%2520%2520neuronal%2520activity%2520in%2520Ca%2520imaging%2520data%26entry.906535625%3DJordi%2520Abante%2520and%2520Angelo%2520Piga%2520and%2520Berta%2520Ros%2520and%2520Clara%2520F%2520L%25C3%25B3pez-Le%25C3%25B3n%2520and%2520Josep%2520M%2520Canals%2520and%2520Jordi%2520Soriano%26entry.1292438233%3D%2520%2520Calcium%2520imaging%2520has%2520become%2520a%2520powerful%2520alternative%2520to%2520electrophysiology%2520for%250Astudying%2520neuronal%2520activity%252C%2520offering%2520spatial%2520resolution%2520and%2520the%2520ability%2520to%250Ameasure%2520large%2520populations%2520of%2520neurons%2520in%2520a%2520minimally%2520invasive%2520manner.%2520This%250Atechnique%2520has%2520broad%2520applications%2520in%2520neuroscience%252C%2520neuroengineering%252C%2520and%250Amedicine%252C%2520enabling%2520researchers%2520to%2520explore%2520the%2520relationship%2520between%2520neuron%250Alocation%2520and%2520activity.%2520Recent%2520advancements%2520in%2520deep%2520generative%2520models%2520%2528DGMs%2529%250Ahave%2520facilitated%2520the%2520modeling%2520of%2520neuronal%2520population%2520dynamics%252C%2520uncovering%250Alatent%2520representations%2520that%2520provide%2520insights%2520into%2520behavior%2520prediction%2520and%250Aneuronal%2520variance.%2520However%252C%2520these%2520models%2520often%2520rely%2520on%2520spike%2520inference%250Aalgorithms%2520and%2520primarily%2520focus%2520on%2520population-level%2520dynamics%252C%2520limiting%2520their%250Aapplicability%2520for%2520single-neuron%2520analyses.%2520To%2520address%2520this%2520gap%252C%2520we%2520propose%2520a%250Anovel%2520framework%2520for%2520single-neuron%2520representation%2520learning%2520using%2520autoregressive%250Avariational%2520autoencoders%2520%2528AVAEs%2529.%2520Our%2520approach%2520embeds%2520individual%2520neurons%2527%250Aspatiotemporal%2520signals%2520into%2520a%2520reduced-dimensional%2520space%2520without%2520the%2520need%2520for%250Aspike%2520inference%2520algorithms.%2520The%2520AVAE%2520excels%2520over%2520traditional%2520linear%2520methods%2520by%250Agenerating%2520more%2520informative%2520and%2520discriminative%2520latent%2520representations%252C%250Aimproving%2520tasks%2520such%2520as%2520visualization%252C%2520clustering%252C%2520and%2520the%2520understanding%2520of%250Aneuronal%2520activity.%2520Additionally%252C%2520the%2520reconstruction%2520performance%2520of%2520the%2520AVAE%250Aoutperforms%2520the%2520state%2520of%2520the%2520art%252C%2520demonstrating%2520its%2520ability%2520to%2520accurately%250Arecover%2520the%2520original%2520fluorescence%2520signal%2520from%2520the%2520learned%2520representation.%2520Using%250Arealistic%2520simulations%252C%2520we%2520show%2520that%2520our%2520model%2520captures%2520underlying%2520physical%250Aproperties%2520and%2520connectivity%2520patterns%252C%2520enabling%2520it%2520to%2520distinguish%2520between%250Adifferent%2520firing%2520and%2520connectivity%2520types.%2520These%2520findings%2520position%2520the%2520AVAE%2520as%2520a%250Aversatile%2520and%2520powerful%2520tool%2520for%2520advancing%2520single-neuron%2520analysis%2520and%2520lays%2520the%250Agroundwork%2520for%2520future%2520integration%2520of%2520multimodal%2520single-cell%2520datasets%2520in%250Aneuroscience.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14615v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Single-neuron%20deep%20generative%20model%20uncovers%20underlying%20physics%20of%0A%20%20neuronal%20activity%20in%20Ca%20imaging%20data&entry.906535625=Jordi%20Abante%20and%20Angelo%20Piga%20and%20Berta%20Ros%20and%20Clara%20F%20L%C3%B3pez-Le%C3%B3n%20and%20Josep%20M%20Canals%20and%20Jordi%20Soriano&entry.1292438233=%20%20Calcium%20imaging%20has%20become%20a%20powerful%20alternative%20to%20electrophysiology%20for%0Astudying%20neuronal%20activity%2C%20offering%20spatial%20resolution%20and%20the%20ability%20to%0Ameasure%20large%20populations%20of%20neurons%20in%20a%20minimally%20invasive%20manner.%20This%0Atechnique%20has%20broad%20applications%20in%20neuroscience%2C%20neuroengineering%2C%20and%0Amedicine%2C%20enabling%20researchers%20to%20explore%20the%20relationship%20between%20neuron%0Alocation%20and%20activity.%20Recent%20advancements%20in%20deep%20generative%20models%20%28DGMs%29%0Ahave%20facilitated%20the%20modeling%20of%20neuronal%20population%20dynamics%2C%20uncovering%0Alatent%20representations%20that%20provide%20insights%20into%20behavior%20prediction%20and%0Aneuronal%20variance.%20However%2C%20these%20models%20often%20rely%20on%20spike%20inference%0Aalgorithms%20and%20primarily%20focus%20on%20population-level%20dynamics%2C%20limiting%20their%0Aapplicability%20for%20single-neuron%20analyses.%20To%20address%20this%20gap%2C%20we%20propose%20a%0Anovel%20framework%20for%20single-neuron%20representation%20learning%20using%20autoregressive%0Avariational%20autoencoders%20%28AVAEs%29.%20Our%20approach%20embeds%20individual%20neurons%27%0Aspatiotemporal%20signals%20into%20a%20reduced-dimensional%20space%20without%20the%20need%20for%0Aspike%20inference%20algorithms.%20The%20AVAE%20excels%20over%20traditional%20linear%20methods%20by%0Agenerating%20more%20informative%20and%20discriminative%20latent%20representations%2C%0Aimproving%20tasks%20such%20as%20visualization%2C%20clustering%2C%20and%20the%20understanding%20of%0Aneuronal%20activity.%20Additionally%2C%20the%20reconstruction%20performance%20of%20the%20AVAE%0Aoutperforms%20the%20state%20of%20the%20art%2C%20demonstrating%20its%20ability%20to%20accurately%0Arecover%20the%20original%20fluorescence%20signal%20from%20the%20learned%20representation.%20Using%0Arealistic%20simulations%2C%20we%20show%20that%20our%20model%20captures%20underlying%20physical%0Aproperties%20and%20connectivity%20patterns%2C%20enabling%20it%20to%20distinguish%20between%0Adifferent%20firing%20and%20connectivity%20types.%20These%20findings%20position%20the%20AVAE%20as%20a%0Aversatile%20and%20powerful%20tool%20for%20advancing%20single-neuron%20analysis%20and%20lays%20the%0Agroundwork%20for%20future%20integration%20of%20multimodal%20single-cell%20datasets%20in%0Aneuroscience.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14615v1&entry.124074799=Read"},
{"title": "Approach to Designing CV Systems for Medical Applications: Data,\n  Architecture and AI", "author": "Dmitry Ryabtsev and Boris Vasilyev and Sergey Shershakov", "abstract": "  This paper introduces an innovative software system for fundus image analysis\nthat deliberately diverges from the conventional screening approach, opting not\nto predict specific diagnoses. Instead, our methodology mimics the diagnostic\nprocess by thoroughly analyzing both normal and pathological features of fundus\nstructures, leaving the ultimate decision-making authority in the hands of\nhealthcare professionals. Our initiative addresses the need for objective\nclinical analysis and seeks to automate and enhance the clinical workflow of\nfundus image examination. The system, from its overarching architecture to the\nmodular analysis design powered by artificial intelligence (AI) models, aligns\nseamlessly with ophthalmological practices. Our unique approach utilizes a\ncombination of state-of-the-art deep learning methods and traditional computer\nvision algorithms to provide a comprehensive and nuanced analysis of fundus\nstructures. We present a distinctive methodology for designing medical\napplications, using our system as an illustrative example. Comprehensive\nverification and validation results demonstrate the efficacy of our approach in\nrevolutionizing fundus image analysis, with potential applications across\nvarious medical domains.\n", "link": "http://arxiv.org/abs/2501.14689v1", "date": "2025-01-24", "relevancy": 2.078, "topK": [{"title": "Egocentric Computer Vision for Hands-Free Robotic Wheelchair Navigation", "link": "https://link.springer.com/article/10.1007/s10846-023-01807-4", "similarity": 0.5288}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.5199}, {"title": "CAT3D: Create Anything in 3D with Multi-View Diffusion Models", "link": "http://arxiv.org/abs/2405.10314v1", "similarity": 0.5101}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Approach%20to%20Designing%20CV%20Systems%20for%20Medical%20Applications%3A%20Data%2C%0A%20%20Architecture%20and%20AI&body=Title%3A%20Approach%20to%20Designing%20CV%20Systems%20for%20Medical%20Applications%3A%20Data%2C%0A%20%20Architecture%20and%20AI%0AAuthor%3A%20Dmitry%20Ryabtsev%20and%20Boris%20Vasilyev%20and%20Sergey%20Shershakov%0AAbstract%3A%20%20%20This%20paper%20introduces%20an%20innovative%20software%20system%20for%20fundus%20image%20analysis%0Athat%20deliberately%20diverges%20from%20the%20conventional%20screening%20approach%2C%20opting%20not%0Ato%20predict%20specific%20diagnoses.%20Instead%2C%20our%20methodology%20mimics%20the%20diagnostic%0Aprocess%20by%20thoroughly%20analyzing%20both%20normal%20and%20pathological%20features%20of%20fundus%0Astructures%2C%20leaving%20the%20ultimate%20decision-making%20authority%20in%20the%20hands%20of%0Ahealthcare%20professionals.%20Our%20initiative%20addresses%20the%20need%20for%20objective%0Aclinical%20analysis%20and%20seeks%20to%20automate%20and%20enhance%20the%20clinical%20workflow%20of%0Afundus%20image%20examination.%20The%20system%2C%20from%20its%20overarching%20architecture%20to%20the%0Amodular%20analysis%20design%20powered%20by%20artificial%20intelligence%20%28AI%29%20models%2C%20aligns%0Aseamlessly%20with%20ophthalmological%20practices.%20Our%20unique%20approach%20utilizes%20a%0Acombination%20of%20state-of-the-art%20deep%20learning%20methods%20and%20traditional%20computer%0Avision%20algorithms%20to%20provide%20a%20comprehensive%20and%20nuanced%20analysis%20of%20fundus%0Astructures.%20We%20present%20a%20distinctive%20methodology%20for%20designing%20medical%0Aapplications%2C%20using%20our%20system%20as%20an%20illustrative%20example.%20Comprehensive%0Averification%20and%20validation%20results%20demonstrate%20the%20efficacy%20of%20our%20approach%20in%0Arevolutionizing%20fundus%20image%20analysis%2C%20with%20potential%20applications%20across%0Avarious%20medical%20domains.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14689v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DApproach%2520to%2520Designing%2520CV%2520Systems%2520for%2520Medical%2520Applications%253A%2520Data%252C%250A%2520%2520Architecture%2520and%2520AI%26entry.906535625%3DDmitry%2520Ryabtsev%2520and%2520Boris%2520Vasilyev%2520and%2520Sergey%2520Shershakov%26entry.1292438233%3D%2520%2520This%2520paper%2520introduces%2520an%2520innovative%2520software%2520system%2520for%2520fundus%2520image%2520analysis%250Athat%2520deliberately%2520diverges%2520from%2520the%2520conventional%2520screening%2520approach%252C%2520opting%2520not%250Ato%2520predict%2520specific%2520diagnoses.%2520Instead%252C%2520our%2520methodology%2520mimics%2520the%2520diagnostic%250Aprocess%2520by%2520thoroughly%2520analyzing%2520both%2520normal%2520and%2520pathological%2520features%2520of%2520fundus%250Astructures%252C%2520leaving%2520the%2520ultimate%2520decision-making%2520authority%2520in%2520the%2520hands%2520of%250Ahealthcare%2520professionals.%2520Our%2520initiative%2520addresses%2520the%2520need%2520for%2520objective%250Aclinical%2520analysis%2520and%2520seeks%2520to%2520automate%2520and%2520enhance%2520the%2520clinical%2520workflow%2520of%250Afundus%2520image%2520examination.%2520The%2520system%252C%2520from%2520its%2520overarching%2520architecture%2520to%2520the%250Amodular%2520analysis%2520design%2520powered%2520by%2520artificial%2520intelligence%2520%2528AI%2529%2520models%252C%2520aligns%250Aseamlessly%2520with%2520ophthalmological%2520practices.%2520Our%2520unique%2520approach%2520utilizes%2520a%250Acombination%2520of%2520state-of-the-art%2520deep%2520learning%2520methods%2520and%2520traditional%2520computer%250Avision%2520algorithms%2520to%2520provide%2520a%2520comprehensive%2520and%2520nuanced%2520analysis%2520of%2520fundus%250Astructures.%2520We%2520present%2520a%2520distinctive%2520methodology%2520for%2520designing%2520medical%250Aapplications%252C%2520using%2520our%2520system%2520as%2520an%2520illustrative%2520example.%2520Comprehensive%250Averification%2520and%2520validation%2520results%2520demonstrate%2520the%2520efficacy%2520of%2520our%2520approach%2520in%250Arevolutionizing%2520fundus%2520image%2520analysis%252C%2520with%2520potential%2520applications%2520across%250Avarious%2520medical%2520domains.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14689v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Approach%20to%20Designing%20CV%20Systems%20for%20Medical%20Applications%3A%20Data%2C%0A%20%20Architecture%20and%20AI&entry.906535625=Dmitry%20Ryabtsev%20and%20Boris%20Vasilyev%20and%20Sergey%20Shershakov&entry.1292438233=%20%20This%20paper%20introduces%20an%20innovative%20software%20system%20for%20fundus%20image%20analysis%0Athat%20deliberately%20diverges%20from%20the%20conventional%20screening%20approach%2C%20opting%20not%0Ato%20predict%20specific%20diagnoses.%20Instead%2C%20our%20methodology%20mimics%20the%20diagnostic%0Aprocess%20by%20thoroughly%20analyzing%20both%20normal%20and%20pathological%20features%20of%20fundus%0Astructures%2C%20leaving%20the%20ultimate%20decision-making%20authority%20in%20the%20hands%20of%0Ahealthcare%20professionals.%20Our%20initiative%20addresses%20the%20need%20for%20objective%0Aclinical%20analysis%20and%20seeks%20to%20automate%20and%20enhance%20the%20clinical%20workflow%20of%0Afundus%20image%20examination.%20The%20system%2C%20from%20its%20overarching%20architecture%20to%20the%0Amodular%20analysis%20design%20powered%20by%20artificial%20intelligence%20%28AI%29%20models%2C%20aligns%0Aseamlessly%20with%20ophthalmological%20practices.%20Our%20unique%20approach%20utilizes%20a%0Acombination%20of%20state-of-the-art%20deep%20learning%20methods%20and%20traditional%20computer%0Avision%20algorithms%20to%20provide%20a%20comprehensive%20and%20nuanced%20analysis%20of%20fundus%0Astructures.%20We%20present%20a%20distinctive%20methodology%20for%20designing%20medical%0Aapplications%2C%20using%20our%20system%20as%20an%20illustrative%20example.%20Comprehensive%0Averification%20and%20validation%20results%20demonstrate%20the%20efficacy%20of%20our%20approach%20in%0Arevolutionizing%20fundus%20image%20analysis%2C%20with%20potential%20applications%20across%0Avarious%20medical%20domains.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14689v1&entry.124074799=Read"},
{"title": "Towards Automated Self-Supervised Learning for Truly Unsupervised Graph\n  Anomaly Detection", "author": "Zhong Li and Yuhang Wang and Matthijs van Leeuwen", "abstract": "  Self-supervised learning (SSL) is an emerging paradigm that exploits\nsupervisory signals generated from the data itself, and many recent studies\nhave leveraged SSL to conduct graph anomaly detection. However, we empirically\nfound that three important factors can substantially impact detection\nperformance across datasets: 1) the specific SSL strategy employed; 2) the\ntuning of the strategy's hyperparameters; and 3) the allocation of combination\nweights when using multiple strategies. Most SSL-based graph anomaly detection\nmethods circumvent these issues by arbitrarily or selectively (i.e., guided by\nlabel information) choosing SSL strategies, hyperparameter settings, and\ncombination weights. While an arbitrary choice may lead to subpar performance,\nusing label information in an unsupervised setting is label information leakage\nand leads to severe overestimation of a method's performance. Leakage has been\ncriticized as \"one of the top ten data mining mistakes\", yet many recent\nstudies on SSL-based graph anomaly detection have been using label information\nto select hyperparameters. To mitigate this issue, we propose to use an\ninternal evaluation strategy (with theoretical analysis) to select\nhyperparameters in SSL for unsupervised anomaly detection. We perform extensive\nexperiments using 10 recent SSL-based graph anomaly detection algorithms on\nvarious benchmark datasets, demonstrating both the prior issues with\nhyperparameter selection and the effectiveness of our proposed strategy.\n", "link": "http://arxiv.org/abs/2501.14694v1", "date": "2025-01-24", "relevancy": 2.0771, "topK": [{"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.5636}, {"title": "Weakly-guided self-supervised pretraining for temporal activity detection", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/25189", "similarity": 0.4964}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4657}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Towards%20Automated%20Self-Supervised%20Learning%20for%20Truly%20Unsupervised%20Graph%0A%20%20Anomaly%20Detection&body=Title%3A%20Towards%20Automated%20Self-Supervised%20Learning%20for%20Truly%20Unsupervised%20Graph%0A%20%20Anomaly%20Detection%0AAuthor%3A%20Zhong%20Li%20and%20Yuhang%20Wang%20and%20Matthijs%20van%20Leeuwen%0AAbstract%3A%20%20%20Self-supervised%20learning%20%28SSL%29%20is%20an%20emerging%20paradigm%20that%20exploits%0Asupervisory%20signals%20generated%20from%20the%20data%20itself%2C%20and%20many%20recent%20studies%0Ahave%20leveraged%20SSL%20to%20conduct%20graph%20anomaly%20detection.%20However%2C%20we%20empirically%0Afound%20that%20three%20important%20factors%20can%20substantially%20impact%20detection%0Aperformance%20across%20datasets%3A%201%29%20the%20specific%20SSL%20strategy%20employed%3B%202%29%20the%0Atuning%20of%20the%20strategy%27s%20hyperparameters%3B%20and%203%29%20the%20allocation%20of%20combination%0Aweights%20when%20using%20multiple%20strategies.%20Most%20SSL-based%20graph%20anomaly%20detection%0Amethods%20circumvent%20these%20issues%20by%20arbitrarily%20or%20selectively%20%28i.e.%2C%20guided%20by%0Alabel%20information%29%20choosing%20SSL%20strategies%2C%20hyperparameter%20settings%2C%20and%0Acombination%20weights.%20While%20an%20arbitrary%20choice%20may%20lead%20to%20subpar%20performance%2C%0Ausing%20label%20information%20in%20an%20unsupervised%20setting%20is%20label%20information%20leakage%0Aand%20leads%20to%20severe%20overestimation%20of%20a%20method%27s%20performance.%20Leakage%20has%20been%0Acriticized%20as%20%22one%20of%20the%20top%20ten%20data%20mining%20mistakes%22%2C%20yet%20many%20recent%0Astudies%20on%20SSL-based%20graph%20anomaly%20detection%20have%20been%20using%20label%20information%0Ato%20select%20hyperparameters.%20To%20mitigate%20this%20issue%2C%20we%20propose%20to%20use%20an%0Ainternal%20evaluation%20strategy%20%28with%20theoretical%20analysis%29%20to%20select%0Ahyperparameters%20in%20SSL%20for%20unsupervised%20anomaly%20detection.%20We%20perform%20extensive%0Aexperiments%20using%2010%20recent%20SSL-based%20graph%20anomaly%20detection%20algorithms%20on%0Avarious%20benchmark%20datasets%2C%20demonstrating%20both%20the%20prior%20issues%20with%0Ahyperparameter%20selection%20and%20the%20effectiveness%20of%20our%20proposed%20strategy.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14694v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTowards%2520Automated%2520Self-Supervised%2520Learning%2520for%2520Truly%2520Unsupervised%2520Graph%250A%2520%2520Anomaly%2520Detection%26entry.906535625%3DZhong%2520Li%2520and%2520Yuhang%2520Wang%2520and%2520Matthijs%2520van%2520Leeuwen%26entry.1292438233%3D%2520%2520Self-supervised%2520learning%2520%2528SSL%2529%2520is%2520an%2520emerging%2520paradigm%2520that%2520exploits%250Asupervisory%2520signals%2520generated%2520from%2520the%2520data%2520itself%252C%2520and%2520many%2520recent%2520studies%250Ahave%2520leveraged%2520SSL%2520to%2520conduct%2520graph%2520anomaly%2520detection.%2520However%252C%2520we%2520empirically%250Afound%2520that%2520three%2520important%2520factors%2520can%2520substantially%2520impact%2520detection%250Aperformance%2520across%2520datasets%253A%25201%2529%2520the%2520specific%2520SSL%2520strategy%2520employed%253B%25202%2529%2520the%250Atuning%2520of%2520the%2520strategy%2527s%2520hyperparameters%253B%2520and%25203%2529%2520the%2520allocation%2520of%2520combination%250Aweights%2520when%2520using%2520multiple%2520strategies.%2520Most%2520SSL-based%2520graph%2520anomaly%2520detection%250Amethods%2520circumvent%2520these%2520issues%2520by%2520arbitrarily%2520or%2520selectively%2520%2528i.e.%252C%2520guided%2520by%250Alabel%2520information%2529%2520choosing%2520SSL%2520strategies%252C%2520hyperparameter%2520settings%252C%2520and%250Acombination%2520weights.%2520While%2520an%2520arbitrary%2520choice%2520may%2520lead%2520to%2520subpar%2520performance%252C%250Ausing%2520label%2520information%2520in%2520an%2520unsupervised%2520setting%2520is%2520label%2520information%2520leakage%250Aand%2520leads%2520to%2520severe%2520overestimation%2520of%2520a%2520method%2527s%2520performance.%2520Leakage%2520has%2520been%250Acriticized%2520as%2520%2522one%2520of%2520the%2520top%2520ten%2520data%2520mining%2520mistakes%2522%252C%2520yet%2520many%2520recent%250Astudies%2520on%2520SSL-based%2520graph%2520anomaly%2520detection%2520have%2520been%2520using%2520label%2520information%250Ato%2520select%2520hyperparameters.%2520To%2520mitigate%2520this%2520issue%252C%2520we%2520propose%2520to%2520use%2520an%250Ainternal%2520evaluation%2520strategy%2520%2528with%2520theoretical%2520analysis%2529%2520to%2520select%250Ahyperparameters%2520in%2520SSL%2520for%2520unsupervised%2520anomaly%2520detection.%2520We%2520perform%2520extensive%250Aexperiments%2520using%252010%2520recent%2520SSL-based%2520graph%2520anomaly%2520detection%2520algorithms%2520on%250Avarious%2520benchmark%2520datasets%252C%2520demonstrating%2520both%2520the%2520prior%2520issues%2520with%250Ahyperparameter%2520selection%2520and%2520the%2520effectiveness%2520of%2520our%2520proposed%2520strategy.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14694v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Towards%20Automated%20Self-Supervised%20Learning%20for%20Truly%20Unsupervised%20Graph%0A%20%20Anomaly%20Detection&entry.906535625=Zhong%20Li%20and%20Yuhang%20Wang%20and%20Matthijs%20van%20Leeuwen&entry.1292438233=%20%20Self-supervised%20learning%20%28SSL%29%20is%20an%20emerging%20paradigm%20that%20exploits%0Asupervisory%20signals%20generated%20from%20the%20data%20itself%2C%20and%20many%20recent%20studies%0Ahave%20leveraged%20SSL%20to%20conduct%20graph%20anomaly%20detection.%20However%2C%20we%20empirically%0Afound%20that%20three%20important%20factors%20can%20substantially%20impact%20detection%0Aperformance%20across%20datasets%3A%201%29%20the%20specific%20SSL%20strategy%20employed%3B%202%29%20the%0Atuning%20of%20the%20strategy%27s%20hyperparameters%3B%20and%203%29%20the%20allocation%20of%20combination%0Aweights%20when%20using%20multiple%20strategies.%20Most%20SSL-based%20graph%20anomaly%20detection%0Amethods%20circumvent%20these%20issues%20by%20arbitrarily%20or%20selectively%20%28i.e.%2C%20guided%20by%0Alabel%20information%29%20choosing%20SSL%20strategies%2C%20hyperparameter%20settings%2C%20and%0Acombination%20weights.%20While%20an%20arbitrary%20choice%20may%20lead%20to%20subpar%20performance%2C%0Ausing%20label%20information%20in%20an%20unsupervised%20setting%20is%20label%20information%20leakage%0Aand%20leads%20to%20severe%20overestimation%20of%20a%20method%27s%20performance.%20Leakage%20has%20been%0Acriticized%20as%20%22one%20of%20the%20top%20ten%20data%20mining%20mistakes%22%2C%20yet%20many%20recent%0Astudies%20on%20SSL-based%20graph%20anomaly%20detection%20have%20been%20using%20label%20information%0Ato%20select%20hyperparameters.%20To%20mitigate%20this%20issue%2C%20we%20propose%20to%20use%20an%0Ainternal%20evaluation%20strategy%20%28with%20theoretical%20analysis%29%20to%20select%0Ahyperparameters%20in%20SSL%20for%20unsupervised%20anomaly%20detection.%20We%20perform%20extensive%0Aexperiments%20using%2010%20recent%20SSL-based%20graph%20anomaly%20detection%20algorithms%20on%0Avarious%20benchmark%20datasets%2C%20demonstrating%20both%20the%20prior%20issues%20with%0Ahyperparameter%20selection%20and%20the%20effectiveness%20of%20our%20proposed%20strategy.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14694v1&entry.124074799=Read"},
{"title": "Hierarchical Vector Quantization for Unsupervised Action Segmentation", "author": "Federico Spurio and Emad Bahrami and Gianpiero Francesca and Juergen Gall", "abstract": "  In this work, we address unsupervised temporal action segmentation, which\nsegments a set of long, untrimmed videos into semantically meaningful segments\nthat are consistent across videos. While recent approaches combine\nrepresentation learning and clustering in a single step for this task, they do\nnot cope with large variations within temporal segments of the same class. To\naddress this limitation, we propose a novel method, termed Hierarchical Vector\nQuantization (HVQ), that consists of two subsequent vector quantization\nmodules. This results in a hierarchical clustering where the additional\nsubclusters cover the variations within a cluster. We demonstrate that our\napproach captures the distribution of segment lengths much better than the\nstate of the art. To this end, we introduce a new metric based on the\nJensen-Shannon Distance (JSD) for unsupervised temporal action segmentation. We\nevaluate our approach on three public datasets, namely Breakfast, YouTube\nInstructional and IKEA ASM. Our approach outperforms the state of the art in\nterms of F1 score, recall and JSD.\n", "link": "http://arxiv.org/abs/2412.17640v2", "date": "2025-01-24", "relevancy": 2.064, "topK": [{"title": "Weakly-guided self-supervised pretraining for temporal activity detection", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/25189", "similarity": 0.5324}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.5051}, {"title": "Customize-A-Video: One-Shot Motion Customization of Text-to-Video\n  Diffusion Models", "link": "http://arxiv.org/abs/2402.14780v1", "similarity": 0.5023}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Hierarchical%20Vector%20Quantization%20for%20Unsupervised%20Action%20Segmentation&body=Title%3A%20Hierarchical%20Vector%20Quantization%20for%20Unsupervised%20Action%20Segmentation%0AAuthor%3A%20Federico%20Spurio%20and%20Emad%20Bahrami%20and%20Gianpiero%20Francesca%20and%20Juergen%20Gall%0AAbstract%3A%20%20%20In%20this%20work%2C%20we%20address%20unsupervised%20temporal%20action%20segmentation%2C%20which%0Asegments%20a%20set%20of%20long%2C%20untrimmed%20videos%20into%20semantically%20meaningful%20segments%0Athat%20are%20consistent%20across%20videos.%20While%20recent%20approaches%20combine%0Arepresentation%20learning%20and%20clustering%20in%20a%20single%20step%20for%20this%20task%2C%20they%20do%0Anot%20cope%20with%20large%20variations%20within%20temporal%20segments%20of%20the%20same%20class.%20To%0Aaddress%20this%20limitation%2C%20we%20propose%20a%20novel%20method%2C%20termed%20Hierarchical%20Vector%0AQuantization%20%28HVQ%29%2C%20that%20consists%20of%20two%20subsequent%20vector%20quantization%0Amodules.%20This%20results%20in%20a%20hierarchical%20clustering%20where%20the%20additional%0Asubclusters%20cover%20the%20variations%20within%20a%20cluster.%20We%20demonstrate%20that%20our%0Aapproach%20captures%20the%20distribution%20of%20segment%20lengths%20much%20better%20than%20the%0Astate%20of%20the%20art.%20To%20this%20end%2C%20we%20introduce%20a%20new%20metric%20based%20on%20the%0AJensen-Shannon%20Distance%20%28JSD%29%20for%20unsupervised%20temporal%20action%20segmentation.%20We%0Aevaluate%20our%20approach%20on%20three%20public%20datasets%2C%20namely%20Breakfast%2C%20YouTube%0AInstructional%20and%20IKEA%20ASM.%20Our%20approach%20outperforms%20the%20state%20of%20the%20art%20in%0Aterms%20of%20F1%20score%2C%20recall%20and%20JSD.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2412.17640v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DHierarchical%2520Vector%2520Quantization%2520for%2520Unsupervised%2520Action%2520Segmentation%26entry.906535625%3DFederico%2520Spurio%2520and%2520Emad%2520Bahrami%2520and%2520Gianpiero%2520Francesca%2520and%2520Juergen%2520Gall%26entry.1292438233%3D%2520%2520In%2520this%2520work%252C%2520we%2520address%2520unsupervised%2520temporal%2520action%2520segmentation%252C%2520which%250Asegments%2520a%2520set%2520of%2520long%252C%2520untrimmed%2520videos%2520into%2520semantically%2520meaningful%2520segments%250Athat%2520are%2520consistent%2520across%2520videos.%2520While%2520recent%2520approaches%2520combine%250Arepresentation%2520learning%2520and%2520clustering%2520in%2520a%2520single%2520step%2520for%2520this%2520task%252C%2520they%2520do%250Anot%2520cope%2520with%2520large%2520variations%2520within%2520temporal%2520segments%2520of%2520the%2520same%2520class.%2520To%250Aaddress%2520this%2520limitation%252C%2520we%2520propose%2520a%2520novel%2520method%252C%2520termed%2520Hierarchical%2520Vector%250AQuantization%2520%2528HVQ%2529%252C%2520that%2520consists%2520of%2520two%2520subsequent%2520vector%2520quantization%250Amodules.%2520This%2520results%2520in%2520a%2520hierarchical%2520clustering%2520where%2520the%2520additional%250Asubclusters%2520cover%2520the%2520variations%2520within%2520a%2520cluster.%2520We%2520demonstrate%2520that%2520our%250Aapproach%2520captures%2520the%2520distribution%2520of%2520segment%2520lengths%2520much%2520better%2520than%2520the%250Astate%2520of%2520the%2520art.%2520To%2520this%2520end%252C%2520we%2520introduce%2520a%2520new%2520metric%2520based%2520on%2520the%250AJensen-Shannon%2520Distance%2520%2528JSD%2529%2520for%2520unsupervised%2520temporal%2520action%2520segmentation.%2520We%250Aevaluate%2520our%2520approach%2520on%2520three%2520public%2520datasets%252C%2520namely%2520Breakfast%252C%2520YouTube%250AInstructional%2520and%2520IKEA%2520ASM.%2520Our%2520approach%2520outperforms%2520the%2520state%2520of%2520the%2520art%2520in%250Aterms%2520of%2520F1%2520score%252C%2520recall%2520and%2520JSD.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2412.17640v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Hierarchical%20Vector%20Quantization%20for%20Unsupervised%20Action%20Segmentation&entry.906535625=Federico%20Spurio%20and%20Emad%20Bahrami%20and%20Gianpiero%20Francesca%20and%20Juergen%20Gall&entry.1292438233=%20%20In%20this%20work%2C%20we%20address%20unsupervised%20temporal%20action%20segmentation%2C%20which%0Asegments%20a%20set%20of%20long%2C%20untrimmed%20videos%20into%20semantically%20meaningful%20segments%0Athat%20are%20consistent%20across%20videos.%20While%20recent%20approaches%20combine%0Arepresentation%20learning%20and%20clustering%20in%20a%20single%20step%20for%20this%20task%2C%20they%20do%0Anot%20cope%20with%20large%20variations%20within%20temporal%20segments%20of%20the%20same%20class.%20To%0Aaddress%20this%20limitation%2C%20we%20propose%20a%20novel%20method%2C%20termed%20Hierarchical%20Vector%0AQuantization%20%28HVQ%29%2C%20that%20consists%20of%20two%20subsequent%20vector%20quantization%0Amodules.%20This%20results%20in%20a%20hierarchical%20clustering%20where%20the%20additional%0Asubclusters%20cover%20the%20variations%20within%20a%20cluster.%20We%20demonstrate%20that%20our%0Aapproach%20captures%20the%20distribution%20of%20segment%20lengths%20much%20better%20than%20the%0Astate%20of%20the%20art.%20To%20this%20end%2C%20we%20introduce%20a%20new%20metric%20based%20on%20the%0AJensen-Shannon%20Distance%20%28JSD%29%20for%20unsupervised%20temporal%20action%20segmentation.%20We%0Aevaluate%20our%20approach%20on%20three%20public%20datasets%2C%20namely%20Breakfast%2C%20YouTube%0AInstructional%20and%20IKEA%20ASM.%20Our%20approach%20outperforms%20the%20state%20of%20the%20art%20in%0Aterms%20of%20F1%20score%2C%20recall%20and%20JSD.%0A&entry.1838667208=http%3A//arxiv.org/abs/2412.17640v2&entry.124074799=Read"},
{"title": "Robustified Time-optimal Point-to-point Motion Planning and Control\n  under Uncertainty", "author": "Shuhao Zhang and Jan Swevers", "abstract": "  This paper proposes a novel approach to formulate time-optimal point-to-point\nmotion planning and control under uncertainty. The approach defines a\nrobustified two-stage Optimal Control Problem (OCP), in which stage 1, with a\nfixed time grid, is seamlessly stitched with stage 2, which features a variable\ntime grid. Stage 1 optimizes not only the nominal trajectory, but also feedback\ngains and corresponding state covariances, which robustify constraints in both\nstages. The outcome is a minimized uncertainty in stage 1 and a minimized total\nmotion time for stage 2, both contributing to the time optimality and safety of\nthe total motion. A timely replanning strategy is employed to handle changes in\nconstraints and maintain feasibility, while a tailored iterative algorithm is\nproposed for efficient, real-time OCP execution.\n", "link": "http://arxiv.org/abs/2501.14526v1", "date": "2025-01-24", "relevancy": 2.0594, "topK": [{"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5492}, {"title": "Egocentric Computer Vision for Hands-Free Robotic Wheelchair Navigation", "link": "https://link.springer.com/article/10.1007/s10846-023-01807-4", "similarity": 0.4924}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4849}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Robustified%20Time-optimal%20Point-to-point%20Motion%20Planning%20and%20Control%0A%20%20under%20Uncertainty&body=Title%3A%20Robustified%20Time-optimal%20Point-to-point%20Motion%20Planning%20and%20Control%0A%20%20under%20Uncertainty%0AAuthor%3A%20Shuhao%20Zhang%20and%20Jan%20Swevers%0AAbstract%3A%20%20%20This%20paper%20proposes%20a%20novel%20approach%20to%20formulate%20time-optimal%20point-to-point%0Amotion%20planning%20and%20control%20under%20uncertainty.%20The%20approach%20defines%20a%0Arobustified%20two-stage%20Optimal%20Control%20Problem%20%28OCP%29%2C%20in%20which%20stage%201%2C%20with%20a%0Afixed%20time%20grid%2C%20is%20seamlessly%20stitched%20with%20stage%202%2C%20which%20features%20a%20variable%0Atime%20grid.%20Stage%201%20optimizes%20not%20only%20the%20nominal%20trajectory%2C%20but%20also%20feedback%0Agains%20and%20corresponding%20state%20covariances%2C%20which%20robustify%20constraints%20in%20both%0Astages.%20The%20outcome%20is%20a%20minimized%20uncertainty%20in%20stage%201%20and%20a%20minimized%20total%0Amotion%20time%20for%20stage%202%2C%20both%20contributing%20to%20the%20time%20optimality%20and%20safety%20of%0Athe%20total%20motion.%20A%20timely%20replanning%20strategy%20is%20employed%20to%20handle%20changes%20in%0Aconstraints%20and%20maintain%20feasibility%2C%20while%20a%20tailored%20iterative%20algorithm%20is%0Aproposed%20for%20efficient%2C%20real-time%20OCP%20execution.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14526v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRobustified%2520Time-optimal%2520Point-to-point%2520Motion%2520Planning%2520and%2520Control%250A%2520%2520under%2520Uncertainty%26entry.906535625%3DShuhao%2520Zhang%2520and%2520Jan%2520Swevers%26entry.1292438233%3D%2520%2520This%2520paper%2520proposes%2520a%2520novel%2520approach%2520to%2520formulate%2520time-optimal%2520point-to-point%250Amotion%2520planning%2520and%2520control%2520under%2520uncertainty.%2520The%2520approach%2520defines%2520a%250Arobustified%2520two-stage%2520Optimal%2520Control%2520Problem%2520%2528OCP%2529%252C%2520in%2520which%2520stage%25201%252C%2520with%2520a%250Afixed%2520time%2520grid%252C%2520is%2520seamlessly%2520stitched%2520with%2520stage%25202%252C%2520which%2520features%2520a%2520variable%250Atime%2520grid.%2520Stage%25201%2520optimizes%2520not%2520only%2520the%2520nominal%2520trajectory%252C%2520but%2520also%2520feedback%250Agains%2520and%2520corresponding%2520state%2520covariances%252C%2520which%2520robustify%2520constraints%2520in%2520both%250Astages.%2520The%2520outcome%2520is%2520a%2520minimized%2520uncertainty%2520in%2520stage%25201%2520and%2520a%2520minimized%2520total%250Amotion%2520time%2520for%2520stage%25202%252C%2520both%2520contributing%2520to%2520the%2520time%2520optimality%2520and%2520safety%2520of%250Athe%2520total%2520motion.%2520A%2520timely%2520replanning%2520strategy%2520is%2520employed%2520to%2520handle%2520changes%2520in%250Aconstraints%2520and%2520maintain%2520feasibility%252C%2520while%2520a%2520tailored%2520iterative%2520algorithm%2520is%250Aproposed%2520for%2520efficient%252C%2520real-time%2520OCP%2520execution.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14526v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Robustified%20Time-optimal%20Point-to-point%20Motion%20Planning%20and%20Control%0A%20%20under%20Uncertainty&entry.906535625=Shuhao%20Zhang%20and%20Jan%20Swevers&entry.1292438233=%20%20This%20paper%20proposes%20a%20novel%20approach%20to%20formulate%20time-optimal%20point-to-point%0Amotion%20planning%20and%20control%20under%20uncertainty.%20The%20approach%20defines%20a%0Arobustified%20two-stage%20Optimal%20Control%20Problem%20%28OCP%29%2C%20in%20which%20stage%201%2C%20with%20a%0Afixed%20time%20grid%2C%20is%20seamlessly%20stitched%20with%20stage%202%2C%20which%20features%20a%20variable%0Atime%20grid.%20Stage%201%20optimizes%20not%20only%20the%20nominal%20trajectory%2C%20but%20also%20feedback%0Agains%20and%20corresponding%20state%20covariances%2C%20which%20robustify%20constraints%20in%20both%0Astages.%20The%20outcome%20is%20a%20minimized%20uncertainty%20in%20stage%201%20and%20a%20minimized%20total%0Amotion%20time%20for%20stage%202%2C%20both%20contributing%20to%20the%20time%20optimality%20and%20safety%20of%0Athe%20total%20motion.%20A%20timely%20replanning%20strategy%20is%20employed%20to%20handle%20changes%20in%0Aconstraints%20and%20maintain%20feasibility%2C%20while%20a%20tailored%20iterative%20algorithm%20is%0Aproposed%20for%20efficient%2C%20real-time%20OCP%20execution.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14526v1&entry.124074799=Read"},
{"title": "Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite\n  Images by Poverty Level: Advancing Tools for Social Science Research", "author": "Hamid Sarmadi and Ola Hall and Thorsteinn R\u00f6gnvaldsson and Mattias Ohlsson", "abstract": "  This paper investigates the novel application of Large Language Models (LLMs)\nwith vision capabilities to analyze satellite imagery for village-level poverty\nprediction. Although LLMs were originally designed for natural language\nunderstanding, their adaptability to multimodal tasks, including geospatial\nanalysis, has opened new frontiers in data-driven research. By leveraging\nadvancements in vision-enabled LLMs, we assess their ability to provide\ninterpretable, scalable, and reliable insights into human poverty from\nsatellite images. Using a pairwise comparison approach, we demonstrate that\nChatGPT can rank satellite images based on poverty levels with accuracy\ncomparable to domain experts. These findings highlight both the promise and the\nlimitations of LLMs in socioeconomic research, providing a foundation for their\nintegration into poverty assessment workflows. This study contributes to the\nongoing exploration of unconventional data sources for welfare analysis and\nopens pathways for cost-effective, large-scale poverty monitoring.\n", "link": "http://arxiv.org/abs/2501.14546v1", "date": "2025-01-24", "relevancy": 2.055, "topK": [{"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5287}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5201}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4963}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Leveraging%20ChatGPT%27s%20Multimodal%20Vision%20Capabilities%20to%20Rank%20Satellite%0A%20%20Images%20by%20Poverty%20Level%3A%20Advancing%20Tools%20for%20Social%20Science%20Research&body=Title%3A%20Leveraging%20ChatGPT%27s%20Multimodal%20Vision%20Capabilities%20to%20Rank%20Satellite%0A%20%20Images%20by%20Poverty%20Level%3A%20Advancing%20Tools%20for%20Social%20Science%20Research%0AAuthor%3A%20Hamid%20Sarmadi%20and%20Ola%20Hall%20and%20Thorsteinn%20R%C3%B6gnvaldsson%20and%20Mattias%20Ohlsson%0AAbstract%3A%20%20%20This%20paper%20investigates%20the%20novel%20application%20of%20Large%20Language%20Models%20%28LLMs%29%0Awith%20vision%20capabilities%20to%20analyze%20satellite%20imagery%20for%20village-level%20poverty%0Aprediction.%20Although%20LLMs%20were%20originally%20designed%20for%20natural%20language%0Aunderstanding%2C%20their%20adaptability%20to%20multimodal%20tasks%2C%20including%20geospatial%0Aanalysis%2C%20has%20opened%20new%20frontiers%20in%20data-driven%20research.%20By%20leveraging%0Aadvancements%20in%20vision-enabled%20LLMs%2C%20we%20assess%20their%20ability%20to%20provide%0Ainterpretable%2C%20scalable%2C%20and%20reliable%20insights%20into%20human%20poverty%20from%0Asatellite%20images.%20Using%20a%20pairwise%20comparison%20approach%2C%20we%20demonstrate%20that%0AChatGPT%20can%20rank%20satellite%20images%20based%20on%20poverty%20levels%20with%20accuracy%0Acomparable%20to%20domain%20experts.%20These%20findings%20highlight%20both%20the%20promise%20and%20the%0Alimitations%20of%20LLMs%20in%20socioeconomic%20research%2C%20providing%20a%20foundation%20for%20their%0Aintegration%20into%20poverty%20assessment%20workflows.%20This%20study%20contributes%20to%20the%0Aongoing%20exploration%20of%20unconventional%20data%20sources%20for%20welfare%20analysis%20and%0Aopens%20pathways%20for%20cost-effective%2C%20large-scale%20poverty%20monitoring.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14546v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLeveraging%2520ChatGPT%2527s%2520Multimodal%2520Vision%2520Capabilities%2520to%2520Rank%2520Satellite%250A%2520%2520Images%2520by%2520Poverty%2520Level%253A%2520Advancing%2520Tools%2520for%2520Social%2520Science%2520Research%26entry.906535625%3DHamid%2520Sarmadi%2520and%2520Ola%2520Hall%2520and%2520Thorsteinn%2520R%25C3%25B6gnvaldsson%2520and%2520Mattias%2520Ohlsson%26entry.1292438233%3D%2520%2520This%2520paper%2520investigates%2520the%2520novel%2520application%2520of%2520Large%2520Language%2520Models%2520%2528LLMs%2529%250Awith%2520vision%2520capabilities%2520to%2520analyze%2520satellite%2520imagery%2520for%2520village-level%2520poverty%250Aprediction.%2520Although%2520LLMs%2520were%2520originally%2520designed%2520for%2520natural%2520language%250Aunderstanding%252C%2520their%2520adaptability%2520to%2520multimodal%2520tasks%252C%2520including%2520geospatial%250Aanalysis%252C%2520has%2520opened%2520new%2520frontiers%2520in%2520data-driven%2520research.%2520By%2520leveraging%250Aadvancements%2520in%2520vision-enabled%2520LLMs%252C%2520we%2520assess%2520their%2520ability%2520to%2520provide%250Ainterpretable%252C%2520scalable%252C%2520and%2520reliable%2520insights%2520into%2520human%2520poverty%2520from%250Asatellite%2520images.%2520Using%2520a%2520pairwise%2520comparison%2520approach%252C%2520we%2520demonstrate%2520that%250AChatGPT%2520can%2520rank%2520satellite%2520images%2520based%2520on%2520poverty%2520levels%2520with%2520accuracy%250Acomparable%2520to%2520domain%2520experts.%2520These%2520findings%2520highlight%2520both%2520the%2520promise%2520and%2520the%250Alimitations%2520of%2520LLMs%2520in%2520socioeconomic%2520research%252C%2520providing%2520a%2520foundation%2520for%2520their%250Aintegration%2520into%2520poverty%2520assessment%2520workflows.%2520This%2520study%2520contributes%2520to%2520the%250Aongoing%2520exploration%2520of%2520unconventional%2520data%2520sources%2520for%2520welfare%2520analysis%2520and%250Aopens%2520pathways%2520for%2520cost-effective%252C%2520large-scale%2520poverty%2520monitoring.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14546v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Leveraging%20ChatGPT%27s%20Multimodal%20Vision%20Capabilities%20to%20Rank%20Satellite%0A%20%20Images%20by%20Poverty%20Level%3A%20Advancing%20Tools%20for%20Social%20Science%20Research&entry.906535625=Hamid%20Sarmadi%20and%20Ola%20Hall%20and%20Thorsteinn%20R%C3%B6gnvaldsson%20and%20Mattias%20Ohlsson&entry.1292438233=%20%20This%20paper%20investigates%20the%20novel%20application%20of%20Large%20Language%20Models%20%28LLMs%29%0Awith%20vision%20capabilities%20to%20analyze%20satellite%20imagery%20for%20village-level%20poverty%0Aprediction.%20Although%20LLMs%20were%20originally%20designed%20for%20natural%20language%0Aunderstanding%2C%20their%20adaptability%20to%20multimodal%20tasks%2C%20including%20geospatial%0Aanalysis%2C%20has%20opened%20new%20frontiers%20in%20data-driven%20research.%20By%20leveraging%0Aadvancements%20in%20vision-enabled%20LLMs%2C%20we%20assess%20their%20ability%20to%20provide%0Ainterpretable%2C%20scalable%2C%20and%20reliable%20insights%20into%20human%20poverty%20from%0Asatellite%20images.%20Using%20a%20pairwise%20comparison%20approach%2C%20we%20demonstrate%20that%0AChatGPT%20can%20rank%20satellite%20images%20based%20on%20poverty%20levels%20with%20accuracy%0Acomparable%20to%20domain%20experts.%20These%20findings%20highlight%20both%20the%20promise%20and%20the%0Alimitations%20of%20LLMs%20in%20socioeconomic%20research%2C%20providing%20a%20foundation%20for%20their%0Aintegration%20into%20poverty%20assessment%20workflows.%20This%20study%20contributes%20to%20the%0Aongoing%20exploration%20of%20unconventional%20data%20sources%20for%20welfare%20analysis%20and%0Aopens%20pathways%20for%20cost-effective%2C%20large-scale%20poverty%20monitoring.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14546v1&entry.124074799=Read"},
{"title": "How VADER is your AI? Towards a definition of artificial intelligence\n  systems appropriate for regulation", "author": "Leonardo C. T. Bezerra and Alexander E. I. Brownlee and Luana Ferraz Alvarenga and Renan Cipriano Moioli and Thais Vasconcelos Batista", "abstract": "  Artificial intelligence (AI) has driven many information and communication\ntechnology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has\nexpanded far beyond AI since the Turing test proposal. Critically, recent AI\nregulation proposals adopt AI definitions affecting ICT techniques, approaches,\nand systems that are not AI. In some cases, even works from mathematics,\nstatistics, and engineering would be affected. Worryingly, AI misdefinitions\nare observed from Western societies to the Global South. In this paper, we\npropose a framework to score how validated as appropriately-defined for\nregulation (VADER) an AI definition is. Our online, publicly-available VADER\nframework scores the coverage of premises that should underlie AI definitions\nfor regulation, which aim to (i) reproduce principles observed in other\nsuccessful technology regulations, and (ii) include all AI techniques and\napproaches while excluding non-AI works. Regarding the latter, our score is\nbased on a dataset of representative AI, non-AI ICT, and non-ICT examples. We\ndemonstrate our contribution by reviewing the AI regulation proposals of key\nplayers, namely the United States, United Kingdom, European Union, and Brazil.\nImportantly, none of the proposals assessed achieve the appropriateness score,\nranging from a revision need to a concrete risk to ICT systems and works from\nother fields.\n", "link": "http://arxiv.org/abs/2402.05048v3", "date": "2025-01-24", "relevancy": 2.0468, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4132}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4132}, {"title": "Magic-Me: Identity-Specific Video Customized Diffusion", "link": "http://arxiv.org/abs/2402.09368v1", "similarity": 0.4016}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20How%20VADER%20is%20your%20AI%3F%20Towards%20a%20definition%20of%20artificial%20intelligence%0A%20%20systems%20appropriate%20for%20regulation&body=Title%3A%20How%20VADER%20is%20your%20AI%3F%20Towards%20a%20definition%20of%20artificial%20intelligence%0A%20%20systems%20appropriate%20for%20regulation%0AAuthor%3A%20Leonardo%20C.%20T.%20Bezerra%20and%20Alexander%20E.%20I.%20Brownlee%20and%20Luana%20Ferraz%20Alvarenga%20and%20Renan%20Cipriano%20Moioli%20and%20Thais%20Vasconcelos%20Batista%0AAbstract%3A%20%20%20Artificial%20intelligence%20%28AI%29%20has%20driven%20many%20information%20and%20communication%0Atechnology%20%28ICT%29%20breakthroughs.%20Nonetheless%2C%20the%20scope%20of%20ICT%20systems%20has%0Aexpanded%20far%20beyond%20AI%20since%20the%20Turing%20test%20proposal.%20Critically%2C%20recent%20AI%0Aregulation%20proposals%20adopt%20AI%20definitions%20affecting%20ICT%20techniques%2C%20approaches%2C%0Aand%20systems%20that%20are%20not%20AI.%20In%20some%20cases%2C%20even%20works%20from%20mathematics%2C%0Astatistics%2C%20and%20engineering%20would%20be%20affected.%20Worryingly%2C%20AI%20misdefinitions%0Aare%20observed%20from%20Western%20societies%20to%20the%20Global%20South.%20In%20this%20paper%2C%20we%0Apropose%20a%20framework%20to%20score%20how%20validated%20as%20appropriately-defined%20for%0Aregulation%20%28VADER%29%20an%20AI%20definition%20is.%20Our%20online%2C%20publicly-available%20VADER%0Aframework%20scores%20the%20coverage%20of%20premises%20that%20should%20underlie%20AI%20definitions%0Afor%20regulation%2C%20which%20aim%20to%20%28i%29%20reproduce%20principles%20observed%20in%20other%0Asuccessful%20technology%20regulations%2C%20and%20%28ii%29%20include%20all%20AI%20techniques%20and%0Aapproaches%20while%20excluding%20non-AI%20works.%20Regarding%20the%20latter%2C%20our%20score%20is%0Abased%20on%20a%20dataset%20of%20representative%20AI%2C%20non-AI%20ICT%2C%20and%20non-ICT%20examples.%20We%0Ademonstrate%20our%20contribution%20by%20reviewing%20the%20AI%20regulation%20proposals%20of%20key%0Aplayers%2C%20namely%20the%20United%20States%2C%20United%20Kingdom%2C%20European%20Union%2C%20and%20Brazil.%0AImportantly%2C%20none%20of%20the%20proposals%20assessed%20achieve%20the%20appropriateness%20score%2C%0Aranging%20from%20a%20revision%20need%20to%20a%20concrete%20risk%20to%20ICT%20systems%20and%20works%20from%0Aother%20fields.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2402.05048v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DHow%2520VADER%2520is%2520your%2520AI%253F%2520Towards%2520a%2520definition%2520of%2520artificial%2520intelligence%250A%2520%2520systems%2520appropriate%2520for%2520regulation%26entry.906535625%3DLeonardo%2520C.%2520T.%2520Bezerra%2520and%2520Alexander%2520E.%2520I.%2520Brownlee%2520and%2520Luana%2520Ferraz%2520Alvarenga%2520and%2520Renan%2520Cipriano%2520Moioli%2520and%2520Thais%2520Vasconcelos%2520Batista%26entry.1292438233%3D%2520%2520Artificial%2520intelligence%2520%2528AI%2529%2520has%2520driven%2520many%2520information%2520and%2520communication%250Atechnology%2520%2528ICT%2529%2520breakthroughs.%2520Nonetheless%252C%2520the%2520scope%2520of%2520ICT%2520systems%2520has%250Aexpanded%2520far%2520beyond%2520AI%2520since%2520the%2520Turing%2520test%2520proposal.%2520Critically%252C%2520recent%2520AI%250Aregulation%2520proposals%2520adopt%2520AI%2520definitions%2520affecting%2520ICT%2520techniques%252C%2520approaches%252C%250Aand%2520systems%2520that%2520are%2520not%2520AI.%2520In%2520some%2520cases%252C%2520even%2520works%2520from%2520mathematics%252C%250Astatistics%252C%2520and%2520engineering%2520would%2520be%2520affected.%2520Worryingly%252C%2520AI%2520misdefinitions%250Aare%2520observed%2520from%2520Western%2520societies%2520to%2520the%2520Global%2520South.%2520In%2520this%2520paper%252C%2520we%250Apropose%2520a%2520framework%2520to%2520score%2520how%2520validated%2520as%2520appropriately-defined%2520for%250Aregulation%2520%2528VADER%2529%2520an%2520AI%2520definition%2520is.%2520Our%2520online%252C%2520publicly-available%2520VADER%250Aframework%2520scores%2520the%2520coverage%2520of%2520premises%2520that%2520should%2520underlie%2520AI%2520definitions%250Afor%2520regulation%252C%2520which%2520aim%2520to%2520%2528i%2529%2520reproduce%2520principles%2520observed%2520in%2520other%250Asuccessful%2520technology%2520regulations%252C%2520and%2520%2528ii%2529%2520include%2520all%2520AI%2520techniques%2520and%250Aapproaches%2520while%2520excluding%2520non-AI%2520works.%2520Regarding%2520the%2520latter%252C%2520our%2520score%2520is%250Abased%2520on%2520a%2520dataset%2520of%2520representative%2520AI%252C%2520non-AI%2520ICT%252C%2520and%2520non-ICT%2520examples.%2520We%250Ademonstrate%2520our%2520contribution%2520by%2520reviewing%2520the%2520AI%2520regulation%2520proposals%2520of%2520key%250Aplayers%252C%2520namely%2520the%2520United%2520States%252C%2520United%2520Kingdom%252C%2520European%2520Union%252C%2520and%2520Brazil.%250AImportantly%252C%2520none%2520of%2520the%2520proposals%2520assessed%2520achieve%2520the%2520appropriateness%2520score%252C%250Aranging%2520from%2520a%2520revision%2520need%2520to%2520a%2520concrete%2520risk%2520to%2520ICT%2520systems%2520and%2520works%2520from%250Aother%2520fields.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2402.05048v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=How%20VADER%20is%20your%20AI%3F%20Towards%20a%20definition%20of%20artificial%20intelligence%0A%20%20systems%20appropriate%20for%20regulation&entry.906535625=Leonardo%20C.%20T.%20Bezerra%20and%20Alexander%20E.%20I.%20Brownlee%20and%20Luana%20Ferraz%20Alvarenga%20and%20Renan%20Cipriano%20Moioli%20and%20Thais%20Vasconcelos%20Batista&entry.1292438233=%20%20Artificial%20intelligence%20%28AI%29%20has%20driven%20many%20information%20and%20communication%0Atechnology%20%28ICT%29%20breakthroughs.%20Nonetheless%2C%20the%20scope%20of%20ICT%20systems%20has%0Aexpanded%20far%20beyond%20AI%20since%20the%20Turing%20test%20proposal.%20Critically%2C%20recent%20AI%0Aregulation%20proposals%20adopt%20AI%20definitions%20affecting%20ICT%20techniques%2C%20approaches%2C%0Aand%20systems%20that%20are%20not%20AI.%20In%20some%20cases%2C%20even%20works%20from%20mathematics%2C%0Astatistics%2C%20and%20engineering%20would%20be%20affected.%20Worryingly%2C%20AI%20misdefinitions%0Aare%20observed%20from%20Western%20societies%20to%20the%20Global%20South.%20In%20this%20paper%2C%20we%0Apropose%20a%20framework%20to%20score%20how%20validated%20as%20appropriately-defined%20for%0Aregulation%20%28VADER%29%20an%20AI%20definition%20is.%20Our%20online%2C%20publicly-available%20VADER%0Aframework%20scores%20the%20coverage%20of%20premises%20that%20should%20underlie%20AI%20definitions%0Afor%20regulation%2C%20which%20aim%20to%20%28i%29%20reproduce%20principles%20observed%20in%20other%0Asuccessful%20technology%20regulations%2C%20and%20%28ii%29%20include%20all%20AI%20techniques%20and%0Aapproaches%20while%20excluding%20non-AI%20works.%20Regarding%20the%20latter%2C%20our%20score%20is%0Abased%20on%20a%20dataset%20of%20representative%20AI%2C%20non-AI%20ICT%2C%20and%20non-ICT%20examples.%20We%0Ademonstrate%20our%20contribution%20by%20reviewing%20the%20AI%20regulation%20proposals%20of%20key%0Aplayers%2C%20namely%20the%20United%20States%2C%20United%20Kingdom%2C%20European%20Union%2C%20and%20Brazil.%0AImportantly%2C%20none%20of%20the%20proposals%20assessed%20achieve%20the%20appropriateness%20score%2C%0Aranging%20from%20a%20revision%20need%20to%20a%20concrete%20risk%20to%20ICT%20systems%20and%20works%20from%0Aother%20fields.%0A&entry.1838667208=http%3A//arxiv.org/abs/2402.05048v3&entry.124074799=Read"},
{"title": "Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently\n  Enhance Speech Separation in Real-World Listening Scenes", "author": "Feyisayo Olalere and Kiki van der Heijden and Christiaan H. Stronks and Jeroen Briaire and Johan HM Frijns and Marcel van Gerven", "abstract": "  Speech separation approaches for single-channel, dry speech mixtures have\nsignificantly improved. However, real-world spatial and reverberant acoustic\nenvironments remain challenging, limiting the effectiveness of these approaches\nfor assistive hearing devices like cochlear implants (CIs). To address this, we\nquantify the impact of real-world acoustic scenes on speech separation and\nexplore how spatial cues can enhance separation quality efficiently. We analyze\nperformance based on implicit spatial cues (inherent in the acoustic input and\nlearned by the model) and explicit spatial cues (manually calculated spatial\nfeatures added as auxiliary inputs). Our findings show that spatial cues (both\nimplicit and explicit) improve separation for mixtures with spatially separated\nand nearby talkers. Furthermore, spatial cues enhance separation when spectral\ncues are ambiguous, such as when voices are similar. Explicit spatial cues are\nparticularly beneficial when implicit spatial cues are weak. For instance,\nsingle CI microphone recordings provide weaker implicit spatial cues than\nbilateral CIs, but even single CIs benefit from explicit cues. These results\nemphasize the importance of training models on real-world data to improve\ngeneralizability in everyday listening scenarios. Additionally, our statistical\nanalyses offer insights into how data properties influence model performance,\nsupporting the development of efficient speech separation approaches for CIs\nand other assistive devices in real-world settings.\n", "link": "http://arxiv.org/abs/2501.14610v1", "date": "2025-01-24", "relevancy": 2.0436, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5167}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.5167}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4817}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Leveraging%20Spatial%20Cues%20from%20Cochlear%20Implant%20Microphones%20to%20Efficiently%0A%20%20Enhance%20Speech%20Separation%20in%20Real-World%20Listening%20Scenes&body=Title%3A%20Leveraging%20Spatial%20Cues%20from%20Cochlear%20Implant%20Microphones%20to%20Efficiently%0A%20%20Enhance%20Speech%20Separation%20in%20Real-World%20Listening%20Scenes%0AAuthor%3A%20Feyisayo%20Olalere%20and%20Kiki%20van%20der%20Heijden%20and%20Christiaan%20H.%20Stronks%20and%20Jeroen%20Briaire%20and%20Johan%20HM%20Frijns%20and%20Marcel%20van%20Gerven%0AAbstract%3A%20%20%20Speech%20separation%20approaches%20for%20single-channel%2C%20dry%20speech%20mixtures%20have%0Asignificantly%20improved.%20However%2C%20real-world%20spatial%20and%20reverberant%20acoustic%0Aenvironments%20remain%20challenging%2C%20limiting%20the%20effectiveness%20of%20these%20approaches%0Afor%20assistive%20hearing%20devices%20like%20cochlear%20implants%20%28CIs%29.%20To%20address%20this%2C%20we%0Aquantify%20the%20impact%20of%20real-world%20acoustic%20scenes%20on%20speech%20separation%20and%0Aexplore%20how%20spatial%20cues%20can%20enhance%20separation%20quality%20efficiently.%20We%20analyze%0Aperformance%20based%20on%20implicit%20spatial%20cues%20%28inherent%20in%20the%20acoustic%20input%20and%0Alearned%20by%20the%20model%29%20and%20explicit%20spatial%20cues%20%28manually%20calculated%20spatial%0Afeatures%20added%20as%20auxiliary%20inputs%29.%20Our%20findings%20show%20that%20spatial%20cues%20%28both%0Aimplicit%20and%20explicit%29%20improve%20separation%20for%20mixtures%20with%20spatially%20separated%0Aand%20nearby%20talkers.%20Furthermore%2C%20spatial%20cues%20enhance%20separation%20when%20spectral%0Acues%20are%20ambiguous%2C%20such%20as%20when%20voices%20are%20similar.%20Explicit%20spatial%20cues%20are%0Aparticularly%20beneficial%20when%20implicit%20spatial%20cues%20are%20weak.%20For%20instance%2C%0Asingle%20CI%20microphone%20recordings%20provide%20weaker%20implicit%20spatial%20cues%20than%0Abilateral%20CIs%2C%20but%20even%20single%20CIs%20benefit%20from%20explicit%20cues.%20These%20results%0Aemphasize%20the%20importance%20of%20training%20models%20on%20real-world%20data%20to%20improve%0Ageneralizability%20in%20everyday%20listening%20scenarios.%20Additionally%2C%20our%20statistical%0Aanalyses%20offer%20insights%20into%20how%20data%20properties%20influence%20model%20performance%2C%0Asupporting%20the%20development%20of%20efficient%20speech%20separation%20approaches%20for%20CIs%0Aand%20other%20assistive%20devices%20in%20real-world%20settings.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14610v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLeveraging%2520Spatial%2520Cues%2520from%2520Cochlear%2520Implant%2520Microphones%2520to%2520Efficiently%250A%2520%2520Enhance%2520Speech%2520Separation%2520in%2520Real-World%2520Listening%2520Scenes%26entry.906535625%3DFeyisayo%2520Olalere%2520and%2520Kiki%2520van%2520der%2520Heijden%2520and%2520Christiaan%2520H.%2520Stronks%2520and%2520Jeroen%2520Briaire%2520and%2520Johan%2520HM%2520Frijns%2520and%2520Marcel%2520van%2520Gerven%26entry.1292438233%3D%2520%2520Speech%2520separation%2520approaches%2520for%2520single-channel%252C%2520dry%2520speech%2520mixtures%2520have%250Asignificantly%2520improved.%2520However%252C%2520real-world%2520spatial%2520and%2520reverberant%2520acoustic%250Aenvironments%2520remain%2520challenging%252C%2520limiting%2520the%2520effectiveness%2520of%2520these%2520approaches%250Afor%2520assistive%2520hearing%2520devices%2520like%2520cochlear%2520implants%2520%2528CIs%2529.%2520To%2520address%2520this%252C%2520we%250Aquantify%2520the%2520impact%2520of%2520real-world%2520acoustic%2520scenes%2520on%2520speech%2520separation%2520and%250Aexplore%2520how%2520spatial%2520cues%2520can%2520enhance%2520separation%2520quality%2520efficiently.%2520We%2520analyze%250Aperformance%2520based%2520on%2520implicit%2520spatial%2520cues%2520%2528inherent%2520in%2520the%2520acoustic%2520input%2520and%250Alearned%2520by%2520the%2520model%2529%2520and%2520explicit%2520spatial%2520cues%2520%2528manually%2520calculated%2520spatial%250Afeatures%2520added%2520as%2520auxiliary%2520inputs%2529.%2520Our%2520findings%2520show%2520that%2520spatial%2520cues%2520%2528both%250Aimplicit%2520and%2520explicit%2529%2520improve%2520separation%2520for%2520mixtures%2520with%2520spatially%2520separated%250Aand%2520nearby%2520talkers.%2520Furthermore%252C%2520spatial%2520cues%2520enhance%2520separation%2520when%2520spectral%250Acues%2520are%2520ambiguous%252C%2520such%2520as%2520when%2520voices%2520are%2520similar.%2520Explicit%2520spatial%2520cues%2520are%250Aparticularly%2520beneficial%2520when%2520implicit%2520spatial%2520cues%2520are%2520weak.%2520For%2520instance%252C%250Asingle%2520CI%2520microphone%2520recordings%2520provide%2520weaker%2520implicit%2520spatial%2520cues%2520than%250Abilateral%2520CIs%252C%2520but%2520even%2520single%2520CIs%2520benefit%2520from%2520explicit%2520cues.%2520These%2520results%250Aemphasize%2520the%2520importance%2520of%2520training%2520models%2520on%2520real-world%2520data%2520to%2520improve%250Ageneralizability%2520in%2520everyday%2520listening%2520scenarios.%2520Additionally%252C%2520our%2520statistical%250Aanalyses%2520offer%2520insights%2520into%2520how%2520data%2520properties%2520influence%2520model%2520performance%252C%250Asupporting%2520the%2520development%2520of%2520efficient%2520speech%2520separation%2520approaches%2520for%2520CIs%250Aand%2520other%2520assistive%2520devices%2520in%2520real-world%2520settings.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14610v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Leveraging%20Spatial%20Cues%20from%20Cochlear%20Implant%20Microphones%20to%20Efficiently%0A%20%20Enhance%20Speech%20Separation%20in%20Real-World%20Listening%20Scenes&entry.906535625=Feyisayo%20Olalere%20and%20Kiki%20van%20der%20Heijden%20and%20Christiaan%20H.%20Stronks%20and%20Jeroen%20Briaire%20and%20Johan%20HM%20Frijns%20and%20Marcel%20van%20Gerven&entry.1292438233=%20%20Speech%20separation%20approaches%20for%20single-channel%2C%20dry%20speech%20mixtures%20have%0Asignificantly%20improved.%20However%2C%20real-world%20spatial%20and%20reverberant%20acoustic%0Aenvironments%20remain%20challenging%2C%20limiting%20the%20effectiveness%20of%20these%20approaches%0Afor%20assistive%20hearing%20devices%20like%20cochlear%20implants%20%28CIs%29.%20To%20address%20this%2C%20we%0Aquantify%20the%20impact%20of%20real-world%20acoustic%20scenes%20on%20speech%20separation%20and%0Aexplore%20how%20spatial%20cues%20can%20enhance%20separation%20quality%20efficiently.%20We%20analyze%0Aperformance%20based%20on%20implicit%20spatial%20cues%20%28inherent%20in%20the%20acoustic%20input%20and%0Alearned%20by%20the%20model%29%20and%20explicit%20spatial%20cues%20%28manually%20calculated%20spatial%0Afeatures%20added%20as%20auxiliary%20inputs%29.%20Our%20findings%20show%20that%20spatial%20cues%20%28both%0Aimplicit%20and%20explicit%29%20improve%20separation%20for%20mixtures%20with%20spatially%20separated%0Aand%20nearby%20talkers.%20Furthermore%2C%20spatial%20cues%20enhance%20separation%20when%20spectral%0Acues%20are%20ambiguous%2C%20such%20as%20when%20voices%20are%20similar.%20Explicit%20spatial%20cues%20are%0Aparticularly%20beneficial%20when%20implicit%20spatial%20cues%20are%20weak.%20For%20instance%2C%0Asingle%20CI%20microphone%20recordings%20provide%20weaker%20implicit%20spatial%20cues%20than%0Abilateral%20CIs%2C%20but%20even%20single%20CIs%20benefit%20from%20explicit%20cues.%20These%20results%0Aemphasize%20the%20importance%20of%20training%20models%20on%20real-world%20data%20to%20improve%0Ageneralizability%20in%20everyday%20listening%20scenarios.%20Additionally%2C%20our%20statistical%0Aanalyses%20offer%20insights%20into%20how%20data%20properties%20influence%20model%20performance%2C%0Asupporting%20the%20development%20of%20efficient%20speech%20separation%20approaches%20for%20CIs%0Aand%20other%20assistive%20devices%20in%20real-world%20settings.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14610v1&entry.124074799=Read"},
{"title": "An Interpretable X-ray Style Transfer via Trainable Local Laplacian\n  Filter", "author": "Dominik Eckert and Ludwig Ritschl and Christopher Syben and Christian H\u00fcmmer and Julia Wicklein and Marcel Beister and Steffen Kappler and Sebastian Stober", "abstract": "  Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al.\n", "link": "http://arxiv.org/abs/2411.07072v2", "date": "2025-01-24", "relevancy": 2.0338, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5163}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.5062}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4945}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20An%20Interpretable%20X-ray%20Style%20Transfer%20via%20Trainable%20Local%20Laplacian%0A%20%20Filter&body=Title%3A%20An%20Interpretable%20X-ray%20Style%20Transfer%20via%20Trainable%20Local%20Laplacian%0A%20%20Filter%0AAuthor%3A%20Dominik%20Eckert%20and%20Ludwig%20Ritschl%20and%20Christopher%20Syben%20and%20Christian%20H%C3%BCmmer%20and%20Julia%20Wicklein%20and%20Marcel%20Beister%20and%20Steffen%20Kappler%20and%20Sebastian%20Stober%0AAbstract%3A%20%20%20Radiologists%20have%20preferred%20visual%20impressions%20or%20%27styles%27%20of%20X-ray%20images%0Athat%20are%20manually%20adjusted%20to%20their%20needs%20to%20support%20their%20diagnostic%0Aperformance.%20In%20this%20work%2C%20we%20propose%20an%20automatic%20and%20interpretable%20X-ray%0Astyle%20transfer%20by%20introducing%20a%20trainable%20version%20of%20the%20Local%20Laplacian%20Filter%0A%28LLF%29.%20From%20the%20shape%20of%20the%20LLF%27s%20optimized%20remap%20function%2C%20the%0Acharacteristics%20of%20the%20style%20transfer%20can%20be%20inferred%20and%20reliability%20of%20the%0Aalgorithm%20can%20be%20ensured.%20Moreover%2C%20we%20enable%20the%20LLF%20to%20capture%20complex%20X-ray%0Astyle%20features%20by%20replacing%20the%20remap%20function%20with%20a%20Multi-Layer%20Perceptron%0A%28MLP%29%20and%20adding%20a%20trainable%20normalization%20layer.%20We%20demonstrate%20the%0Aeffectiveness%20of%20the%20proposed%20method%20by%20transforming%20unprocessed%20mammographic%0AX-ray%20images%20into%20images%20that%20match%20the%20style%20of%20target%20mammograms%20and%20achieve%0Aa%20Structural%20Similarity%20Index%20%28SSIM%29%20of%200.94%20compared%20to%200.82%20of%20the%20baseline%0ALLF%20style%20transfer%20method%20from%20Aubry%20et%20al.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2411.07072v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DAn%2520Interpretable%2520X-ray%2520Style%2520Transfer%2520via%2520Trainable%2520Local%2520Laplacian%250A%2520%2520Filter%26entry.906535625%3DDominik%2520Eckert%2520and%2520Ludwig%2520Ritschl%2520and%2520Christopher%2520Syben%2520and%2520Christian%2520H%25C3%25BCmmer%2520and%2520Julia%2520Wicklein%2520and%2520Marcel%2520Beister%2520and%2520Steffen%2520Kappler%2520and%2520Sebastian%2520Stober%26entry.1292438233%3D%2520%2520Radiologists%2520have%2520preferred%2520visual%2520impressions%2520or%2520%2527styles%2527%2520of%2520X-ray%2520images%250Athat%2520are%2520manually%2520adjusted%2520to%2520their%2520needs%2520to%2520support%2520their%2520diagnostic%250Aperformance.%2520In%2520this%2520work%252C%2520we%2520propose%2520an%2520automatic%2520and%2520interpretable%2520X-ray%250Astyle%2520transfer%2520by%2520introducing%2520a%2520trainable%2520version%2520of%2520the%2520Local%2520Laplacian%2520Filter%250A%2528LLF%2529.%2520From%2520the%2520shape%2520of%2520the%2520LLF%2527s%2520optimized%2520remap%2520function%252C%2520the%250Acharacteristics%2520of%2520the%2520style%2520transfer%2520can%2520be%2520inferred%2520and%2520reliability%2520of%2520the%250Aalgorithm%2520can%2520be%2520ensured.%2520Moreover%252C%2520we%2520enable%2520the%2520LLF%2520to%2520capture%2520complex%2520X-ray%250Astyle%2520features%2520by%2520replacing%2520the%2520remap%2520function%2520with%2520a%2520Multi-Layer%2520Perceptron%250A%2528MLP%2529%2520and%2520adding%2520a%2520trainable%2520normalization%2520layer.%2520We%2520demonstrate%2520the%250Aeffectiveness%2520of%2520the%2520proposed%2520method%2520by%2520transforming%2520unprocessed%2520mammographic%250AX-ray%2520images%2520into%2520images%2520that%2520match%2520the%2520style%2520of%2520target%2520mammograms%2520and%2520achieve%250Aa%2520Structural%2520Similarity%2520Index%2520%2528SSIM%2529%2520of%25200.94%2520compared%2520to%25200.82%2520of%2520the%2520baseline%250ALLF%2520style%2520transfer%2520method%2520from%2520Aubry%2520et%2520al.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2411.07072v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=An%20Interpretable%20X-ray%20Style%20Transfer%20via%20Trainable%20Local%20Laplacian%0A%20%20Filter&entry.906535625=Dominik%20Eckert%20and%20Ludwig%20Ritschl%20and%20Christopher%20Syben%20and%20Christian%20H%C3%BCmmer%20and%20Julia%20Wicklein%20and%20Marcel%20Beister%20and%20Steffen%20Kappler%20and%20Sebastian%20Stober&entry.1292438233=%20%20Radiologists%20have%20preferred%20visual%20impressions%20or%20%27styles%27%20of%20X-ray%20images%0Athat%20are%20manually%20adjusted%20to%20their%20needs%20to%20support%20their%20diagnostic%0Aperformance.%20In%20this%20work%2C%20we%20propose%20an%20automatic%20and%20interpretable%20X-ray%0Astyle%20transfer%20by%20introducing%20a%20trainable%20version%20of%20the%20Local%20Laplacian%20Filter%0A%28LLF%29.%20From%20the%20shape%20of%20the%20LLF%27s%20optimized%20remap%20function%2C%20the%0Acharacteristics%20of%20the%20style%20transfer%20can%20be%20inferred%20and%20reliability%20of%20the%0Aalgorithm%20can%20be%20ensured.%20Moreover%2C%20we%20enable%20the%20LLF%20to%20capture%20complex%20X-ray%0Astyle%20features%20by%20replacing%20the%20remap%20function%20with%20a%20Multi-Layer%20Perceptron%0A%28MLP%29%20and%20adding%20a%20trainable%20normalization%20layer.%20We%20demonstrate%20the%0Aeffectiveness%20of%20the%20proposed%20method%20by%20transforming%20unprocessed%20mammographic%0AX-ray%20images%20into%20images%20that%20match%20the%20style%20of%20target%20mammograms%20and%20achieve%0Aa%20Structural%20Similarity%20Index%20%28SSIM%29%20of%200.94%20compared%20to%200.82%20of%20the%20baseline%0ALLF%20style%20transfer%20method%20from%20Aubry%20et%20al.%0A&entry.1838667208=http%3A//arxiv.org/abs/2411.07072v2&entry.124074799=Read"},
{"title": "Improved Vessel Segmentation with Symmetric Rotation-Equivariant U-Net", "author": "Jiazhen Zhang and Yuexi Du and Nicha C. Dvornek and John A. Onofrey", "abstract": "  Automated segmentation plays a pivotal role in medical image analysis and\ncomputer-assisted interventions. Despite the promising performance of existing\nmethods based on convolutional neural networks (CNNs), they neglect useful\nequivariant properties for images, such as rotational and reflection\nequivariance. This limitation can decrease performance and lead to inconsistent\npredictions, especially in applications like vessel segmentation where explicit\norientation is absent. While existing equivariant learning approaches attempt\nto mitigate these issues, they substantially increase learning cost, model\nsize, or both. To overcome these challenges, we propose a novel application of\nan efficient symmetric rotation-equivariant (SRE) convolutional (SRE-Conv)\nkernel implementation to the U-Net architecture, to learn rotation and\nreflection-equivariant features, while also reducing the model size\ndramatically. We validate the effectiveness of our method through improved\nsegmentation performance on retina vessel fundus imaging. Our proposed SRE\nU-Net not only significantly surpasses standard U-Net in handling rotated\nimages, but also outperforms existing equivariant learning methods and does so\nwith a reduced number of trainable parameters and smaller memory cost. The code\nis available at https://github.com/OnofreyLab/sre_conv_segm_isbi2025.\n", "link": "http://arxiv.org/abs/2501.14592v1", "date": "2025-01-24", "relevancy": 2.0228, "topK": [{"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.52}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5103}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4954}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Improved%20Vessel%20Segmentation%20with%20Symmetric%20Rotation-Equivariant%20U-Net&body=Title%3A%20Improved%20Vessel%20Segmentation%20with%20Symmetric%20Rotation-Equivariant%20U-Net%0AAuthor%3A%20Jiazhen%20Zhang%20and%20Yuexi%20Du%20and%20Nicha%20C.%20Dvornek%20and%20John%20A.%20Onofrey%0AAbstract%3A%20%20%20Automated%20segmentation%20plays%20a%20pivotal%20role%20in%20medical%20image%20analysis%20and%0Acomputer-assisted%20interventions.%20Despite%20the%20promising%20performance%20of%20existing%0Amethods%20based%20on%20convolutional%20neural%20networks%20%28CNNs%29%2C%20they%20neglect%20useful%0Aequivariant%20properties%20for%20images%2C%20such%20as%20rotational%20and%20reflection%0Aequivariance.%20This%20limitation%20can%20decrease%20performance%20and%20lead%20to%20inconsistent%0Apredictions%2C%20especially%20in%20applications%20like%20vessel%20segmentation%20where%20explicit%0Aorientation%20is%20absent.%20While%20existing%20equivariant%20learning%20approaches%20attempt%0Ato%20mitigate%20these%20issues%2C%20they%20substantially%20increase%20learning%20cost%2C%20model%0Asize%2C%20or%20both.%20To%20overcome%20these%20challenges%2C%20we%20propose%20a%20novel%20application%20of%0Aan%20efficient%20symmetric%20rotation-equivariant%20%28SRE%29%20convolutional%20%28SRE-Conv%29%0Akernel%20implementation%20to%20the%20U-Net%20architecture%2C%20to%20learn%20rotation%20and%0Areflection-equivariant%20features%2C%20while%20also%20reducing%20the%20model%20size%0Adramatically.%20We%20validate%20the%20effectiveness%20of%20our%20method%20through%20improved%0Asegmentation%20performance%20on%20retina%20vessel%20fundus%20imaging.%20Our%20proposed%20SRE%0AU-Net%20not%20only%20significantly%20surpasses%20standard%20U-Net%20in%20handling%20rotated%0Aimages%2C%20but%20also%20outperforms%20existing%20equivariant%20learning%20methods%20and%20does%20so%0Awith%20a%20reduced%20number%20of%20trainable%20parameters%20and%20smaller%20memory%20cost.%20The%20code%0Ais%20available%20at%20https%3A//github.com/OnofreyLab/sre_conv_segm_isbi2025.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14592v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DImproved%2520Vessel%2520Segmentation%2520with%2520Symmetric%2520Rotation-Equivariant%2520U-Net%26entry.906535625%3DJiazhen%2520Zhang%2520and%2520Yuexi%2520Du%2520and%2520Nicha%2520C.%2520Dvornek%2520and%2520John%2520A.%2520Onofrey%26entry.1292438233%3D%2520%2520Automated%2520segmentation%2520plays%2520a%2520pivotal%2520role%2520in%2520medical%2520image%2520analysis%2520and%250Acomputer-assisted%2520interventions.%2520Despite%2520the%2520promising%2520performance%2520of%2520existing%250Amethods%2520based%2520on%2520convolutional%2520neural%2520networks%2520%2528CNNs%2529%252C%2520they%2520neglect%2520useful%250Aequivariant%2520properties%2520for%2520images%252C%2520such%2520as%2520rotational%2520and%2520reflection%250Aequivariance.%2520This%2520limitation%2520can%2520decrease%2520performance%2520and%2520lead%2520to%2520inconsistent%250Apredictions%252C%2520especially%2520in%2520applications%2520like%2520vessel%2520segmentation%2520where%2520explicit%250Aorientation%2520is%2520absent.%2520While%2520existing%2520equivariant%2520learning%2520approaches%2520attempt%250Ato%2520mitigate%2520these%2520issues%252C%2520they%2520substantially%2520increase%2520learning%2520cost%252C%2520model%250Asize%252C%2520or%2520both.%2520To%2520overcome%2520these%2520challenges%252C%2520we%2520propose%2520a%2520novel%2520application%2520of%250Aan%2520efficient%2520symmetric%2520rotation-equivariant%2520%2528SRE%2529%2520convolutional%2520%2528SRE-Conv%2529%250Akernel%2520implementation%2520to%2520the%2520U-Net%2520architecture%252C%2520to%2520learn%2520rotation%2520and%250Areflection-equivariant%2520features%252C%2520while%2520also%2520reducing%2520the%2520model%2520size%250Adramatically.%2520We%2520validate%2520the%2520effectiveness%2520of%2520our%2520method%2520through%2520improved%250Asegmentation%2520performance%2520on%2520retina%2520vessel%2520fundus%2520imaging.%2520Our%2520proposed%2520SRE%250AU-Net%2520not%2520only%2520significantly%2520surpasses%2520standard%2520U-Net%2520in%2520handling%2520rotated%250Aimages%252C%2520but%2520also%2520outperforms%2520existing%2520equivariant%2520learning%2520methods%2520and%2520does%2520so%250Awith%2520a%2520reduced%2520number%2520of%2520trainable%2520parameters%2520and%2520smaller%2520memory%2520cost.%2520The%2520code%250Ais%2520available%2520at%2520https%253A//github.com/OnofreyLab/sre_conv_segm_isbi2025.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14592v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Improved%20Vessel%20Segmentation%20with%20Symmetric%20Rotation-Equivariant%20U-Net&entry.906535625=Jiazhen%20Zhang%20and%20Yuexi%20Du%20and%20Nicha%20C.%20Dvornek%20and%20John%20A.%20Onofrey&entry.1292438233=%20%20Automated%20segmentation%20plays%20a%20pivotal%20role%20in%20medical%20image%20analysis%20and%0Acomputer-assisted%20interventions.%20Despite%20the%20promising%20performance%20of%20existing%0Amethods%20based%20on%20convolutional%20neural%20networks%20%28CNNs%29%2C%20they%20neglect%20useful%0Aequivariant%20properties%20for%20images%2C%20such%20as%20rotational%20and%20reflection%0Aequivariance.%20This%20limitation%20can%20decrease%20performance%20and%20lead%20to%20inconsistent%0Apredictions%2C%20especially%20in%20applications%20like%20vessel%20segmentation%20where%20explicit%0Aorientation%20is%20absent.%20While%20existing%20equivariant%20learning%20approaches%20attempt%0Ato%20mitigate%20these%20issues%2C%20they%20substantially%20increase%20learning%20cost%2C%20model%0Asize%2C%20or%20both.%20To%20overcome%20these%20challenges%2C%20we%20propose%20a%20novel%20application%20of%0Aan%20efficient%20symmetric%20rotation-equivariant%20%28SRE%29%20convolutional%20%28SRE-Conv%29%0Akernel%20implementation%20to%20the%20U-Net%20architecture%2C%20to%20learn%20rotation%20and%0Areflection-equivariant%20features%2C%20while%20also%20reducing%20the%20model%20size%0Adramatically.%20We%20validate%20the%20effectiveness%20of%20our%20method%20through%20improved%0Asegmentation%20performance%20on%20retina%20vessel%20fundus%20imaging.%20Our%20proposed%20SRE%0AU-Net%20not%20only%20significantly%20surpasses%20standard%20U-Net%20in%20handling%20rotated%0Aimages%2C%20but%20also%20outperforms%20existing%20equivariant%20learning%20methods%20and%20does%20so%0Awith%20a%20reduced%20number%20of%20trainable%20parameters%20and%20smaller%20memory%20cost.%20The%20code%0Ais%20available%20at%20https%3A//github.com/OnofreyLab/sre_conv_segm_isbi2025.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14592v1&entry.124074799=Read"},
{"title": "Relaxed Equivariance via Multitask Learning", "author": "Ahmed A. Elhag and T. Konstantin Rusch and Francesco Di Giovanni and Michael Bronstein", "abstract": "  Incorporating equivariance as an inductive bias into deep learning\narchitectures to take advantage of the data symmetry has been successful in\nmultiple applications, such as chemistry and dynamical systems. In particular,\nroto-translations are crucial for effectively modeling geometric graphs and\nmolecules, where understanding the 3D structures enhances generalization.\nHowever, equivariant models often pose challenges due to their high\ncomputational complexity. In this paper, we introduce REMUL, a training\nprocedure for approximating equivariance with multitask learning. We show that\nunconstrained models (which do not build equivariance into the architecture)\ncan learn approximate symmetries by minimizing an additional simple\nequivariance loss. By formulating equivariance as a new learning objective, we\ncan control the level of approximate equivariance in the model. Our method\nachieves competitive performance compared to equivariant baselines while being\n$10 \\times$ faster at inference and $2.5 \\times$ at training.\n", "link": "http://arxiv.org/abs/2410.17878v2", "date": "2025-01-24", "relevancy": 2.0191, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5249}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5069}, {"title": "Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance", "link": "http://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html", "similarity": 0.4946}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Relaxed%20Equivariance%20via%20Multitask%20Learning&body=Title%3A%20Relaxed%20Equivariance%20via%20Multitask%20Learning%0AAuthor%3A%20Ahmed%20A.%20Elhag%20and%20T.%20Konstantin%20Rusch%20and%20Francesco%20Di%20Giovanni%20and%20Michael%20Bronstein%0AAbstract%3A%20%20%20Incorporating%20equivariance%20as%20an%20inductive%20bias%20into%20deep%20learning%0Aarchitectures%20to%20take%20advantage%20of%20the%20data%20symmetry%20has%20been%20successful%20in%0Amultiple%20applications%2C%20such%20as%20chemistry%20and%20dynamical%20systems.%20In%20particular%2C%0Aroto-translations%20are%20crucial%20for%20effectively%20modeling%20geometric%20graphs%20and%0Amolecules%2C%20where%20understanding%20the%203D%20structures%20enhances%20generalization.%0AHowever%2C%20equivariant%20models%20often%20pose%20challenges%20due%20to%20their%20high%0Acomputational%20complexity.%20In%20this%20paper%2C%20we%20introduce%20REMUL%2C%20a%20training%0Aprocedure%20for%20approximating%20equivariance%20with%20multitask%20learning.%20We%20show%20that%0Aunconstrained%20models%20%28which%20do%20not%20build%20equivariance%20into%20the%20architecture%29%0Acan%20learn%20approximate%20symmetries%20by%20minimizing%20an%20additional%20simple%0Aequivariance%20loss.%20By%20formulating%20equivariance%20as%20a%20new%20learning%20objective%2C%20we%0Acan%20control%20the%20level%20of%20approximate%20equivariance%20in%20the%20model.%20Our%20method%0Aachieves%20competitive%20performance%20compared%20to%20equivariant%20baselines%20while%20being%0A%2410%20%5Ctimes%24%20faster%20at%20inference%20and%20%242.5%20%5Ctimes%24%20at%20training.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2410.17878v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRelaxed%2520Equivariance%2520via%2520Multitask%2520Learning%26entry.906535625%3DAhmed%2520A.%2520Elhag%2520and%2520T.%2520Konstantin%2520Rusch%2520and%2520Francesco%2520Di%2520Giovanni%2520and%2520Michael%2520Bronstein%26entry.1292438233%3D%2520%2520Incorporating%2520equivariance%2520as%2520an%2520inductive%2520bias%2520into%2520deep%2520learning%250Aarchitectures%2520to%2520take%2520advantage%2520of%2520the%2520data%2520symmetry%2520has%2520been%2520successful%2520in%250Amultiple%2520applications%252C%2520such%2520as%2520chemistry%2520and%2520dynamical%2520systems.%2520In%2520particular%252C%250Aroto-translations%2520are%2520crucial%2520for%2520effectively%2520modeling%2520geometric%2520graphs%2520and%250Amolecules%252C%2520where%2520understanding%2520the%25203D%2520structures%2520enhances%2520generalization.%250AHowever%252C%2520equivariant%2520models%2520often%2520pose%2520challenges%2520due%2520to%2520their%2520high%250Acomputational%2520complexity.%2520In%2520this%2520paper%252C%2520we%2520introduce%2520REMUL%252C%2520a%2520training%250Aprocedure%2520for%2520approximating%2520equivariance%2520with%2520multitask%2520learning.%2520We%2520show%2520that%250Aunconstrained%2520models%2520%2528which%2520do%2520not%2520build%2520equivariance%2520into%2520the%2520architecture%2529%250Acan%2520learn%2520approximate%2520symmetries%2520by%2520minimizing%2520an%2520additional%2520simple%250Aequivariance%2520loss.%2520By%2520formulating%2520equivariance%2520as%2520a%2520new%2520learning%2520objective%252C%2520we%250Acan%2520control%2520the%2520level%2520of%2520approximate%2520equivariance%2520in%2520the%2520model.%2520Our%2520method%250Aachieves%2520competitive%2520performance%2520compared%2520to%2520equivariant%2520baselines%2520while%2520being%250A%252410%2520%255Ctimes%2524%2520faster%2520at%2520inference%2520and%2520%25242.5%2520%255Ctimes%2524%2520at%2520training.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2410.17878v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Relaxed%20Equivariance%20via%20Multitask%20Learning&entry.906535625=Ahmed%20A.%20Elhag%20and%20T.%20Konstantin%20Rusch%20and%20Francesco%20Di%20Giovanni%20and%20Michael%20Bronstein&entry.1292438233=%20%20Incorporating%20equivariance%20as%20an%20inductive%20bias%20into%20deep%20learning%0Aarchitectures%20to%20take%20advantage%20of%20the%20data%20symmetry%20has%20been%20successful%20in%0Amultiple%20applications%2C%20such%20as%20chemistry%20and%20dynamical%20systems.%20In%20particular%2C%0Aroto-translations%20are%20crucial%20for%20effectively%20modeling%20geometric%20graphs%20and%0Amolecules%2C%20where%20understanding%20the%203D%20structures%20enhances%20generalization.%0AHowever%2C%20equivariant%20models%20often%20pose%20challenges%20due%20to%20their%20high%0Acomputational%20complexity.%20In%20this%20paper%2C%20we%20introduce%20REMUL%2C%20a%20training%0Aprocedure%20for%20approximating%20equivariance%20with%20multitask%20learning.%20We%20show%20that%0Aunconstrained%20models%20%28which%20do%20not%20build%20equivariance%20into%20the%20architecture%29%0Acan%20learn%20approximate%20symmetries%20by%20minimizing%20an%20additional%20simple%0Aequivariance%20loss.%20By%20formulating%20equivariance%20as%20a%20new%20learning%20objective%2C%20we%0Acan%20control%20the%20level%20of%20approximate%20equivariance%20in%20the%20model.%20Our%20method%0Aachieves%20competitive%20performance%20compared%20to%20equivariant%20baselines%20while%20being%0A%2410%20%5Ctimes%24%20faster%20at%20inference%20and%20%242.5%20%5Ctimes%24%20at%20training.%0A&entry.1838667208=http%3A//arxiv.org/abs/2410.17878v2&entry.124074799=Read"},
{"title": "A Recurrent Spiking Network with Hierarchical Intrinsic Excitability\n  Modulation for Schema Learning", "author": "Yingchao Yu and Yaochu Jin and Yuchen Xiao and Yuping Yan", "abstract": "  Schema, a form of structured knowledge that promotes transfer learning, is\nattracting growing attention in both neuroscience and artificial intelligence\n(AI). Current schema research in neural computation is largely constrained to a\nsingle behavioral paradigm and relies heavily on recurrent neural networks\n(RNNs) which lack the neural plausibility and biological interpretability. To\naddress these limitations, this work first constructs a generalized behavioral\nparadigm framework for schema learning and introduces three novel cognitive\ntasks, thus supporting a comprehensive schema exploration. Second, we propose a\nnew model using recurrent spiking neural networks with hierarchical intrinsic\nexcitability modulation (HM-RSNNs). The top level of the model selects\nexcitability properties for task-specific demands, while the bottom level\nfine-tunes these properties for intra-task problems. Finally, extensive\nvisualization analyses of HM-RSNNs are conducted to showcase their\ncomputational advantages, track the intrinsic excitability evolution during\nschema learning, and examine neural coordination differences across tasks.\nBiologically inspired lesion studies further uncover task-specific\ndistributions of intrinsic excitability within schemas. Experimental results\nshow that HM-RSNNs significantly outperform RSNN baselines across all tasks and\nexceed RNNs in three novel cognitive tasks. Additionally, HM-RSNNs offer deeper\ninsights into neural dynamics underlying schema learning.\n", "link": "http://arxiv.org/abs/2501.14539v1", "date": "2025-01-24", "relevancy": 2.0029, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.513}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4983}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4983}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20A%20Recurrent%20Spiking%20Network%20with%20Hierarchical%20Intrinsic%20Excitability%0A%20%20Modulation%20for%20Schema%20Learning&body=Title%3A%20A%20Recurrent%20Spiking%20Network%20with%20Hierarchical%20Intrinsic%20Excitability%0A%20%20Modulation%20for%20Schema%20Learning%0AAuthor%3A%20Yingchao%20Yu%20and%20Yaochu%20Jin%20and%20Yuchen%20Xiao%20and%20Yuping%20Yan%0AAbstract%3A%20%20%20Schema%2C%20a%20form%20of%20structured%20knowledge%20that%20promotes%20transfer%20learning%2C%20is%0Aattracting%20growing%20attention%20in%20both%20neuroscience%20and%20artificial%20intelligence%0A%28AI%29.%20Current%20schema%20research%20in%20neural%20computation%20is%20largely%20constrained%20to%20a%0Asingle%20behavioral%20paradigm%20and%20relies%20heavily%20on%20recurrent%20neural%20networks%0A%28RNNs%29%20which%20lack%20the%20neural%20plausibility%20and%20biological%20interpretability.%20To%0Aaddress%20these%20limitations%2C%20this%20work%20first%20constructs%20a%20generalized%20behavioral%0Aparadigm%20framework%20for%20schema%20learning%20and%20introduces%20three%20novel%20cognitive%0Atasks%2C%20thus%20supporting%20a%20comprehensive%20schema%20exploration.%20Second%2C%20we%20propose%20a%0Anew%20model%20using%20recurrent%20spiking%20neural%20networks%20with%20hierarchical%20intrinsic%0Aexcitability%20modulation%20%28HM-RSNNs%29.%20The%20top%20level%20of%20the%20model%20selects%0Aexcitability%20properties%20for%20task-specific%20demands%2C%20while%20the%20bottom%20level%0Afine-tunes%20these%20properties%20for%20intra-task%20problems.%20Finally%2C%20extensive%0Avisualization%20analyses%20of%20HM-RSNNs%20are%20conducted%20to%20showcase%20their%0Acomputational%20advantages%2C%20track%20the%20intrinsic%20excitability%20evolution%20during%0Aschema%20learning%2C%20and%20examine%20neural%20coordination%20differences%20across%20tasks.%0ABiologically%20inspired%20lesion%20studies%20further%20uncover%20task-specific%0Adistributions%20of%20intrinsic%20excitability%20within%20schemas.%20Experimental%20results%0Ashow%20that%20HM-RSNNs%20significantly%20outperform%20RSNN%20baselines%20across%20all%20tasks%20and%0Aexceed%20RNNs%20in%20three%20novel%20cognitive%20tasks.%20Additionally%2C%20HM-RSNNs%20offer%20deeper%0Ainsights%20into%20neural%20dynamics%20underlying%20schema%20learning.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14539v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DA%2520Recurrent%2520Spiking%2520Network%2520with%2520Hierarchical%2520Intrinsic%2520Excitability%250A%2520%2520Modulation%2520for%2520Schema%2520Learning%26entry.906535625%3DYingchao%2520Yu%2520and%2520Yaochu%2520Jin%2520and%2520Yuchen%2520Xiao%2520and%2520Yuping%2520Yan%26entry.1292438233%3D%2520%2520Schema%252C%2520a%2520form%2520of%2520structured%2520knowledge%2520that%2520promotes%2520transfer%2520learning%252C%2520is%250Aattracting%2520growing%2520attention%2520in%2520both%2520neuroscience%2520and%2520artificial%2520intelligence%250A%2528AI%2529.%2520Current%2520schema%2520research%2520in%2520neural%2520computation%2520is%2520largely%2520constrained%2520to%2520a%250Asingle%2520behavioral%2520paradigm%2520and%2520relies%2520heavily%2520on%2520recurrent%2520neural%2520networks%250A%2528RNNs%2529%2520which%2520lack%2520the%2520neural%2520plausibility%2520and%2520biological%2520interpretability.%2520To%250Aaddress%2520these%2520limitations%252C%2520this%2520work%2520first%2520constructs%2520a%2520generalized%2520behavioral%250Aparadigm%2520framework%2520for%2520schema%2520learning%2520and%2520introduces%2520three%2520novel%2520cognitive%250Atasks%252C%2520thus%2520supporting%2520a%2520comprehensive%2520schema%2520exploration.%2520Second%252C%2520we%2520propose%2520a%250Anew%2520model%2520using%2520recurrent%2520spiking%2520neural%2520networks%2520with%2520hierarchical%2520intrinsic%250Aexcitability%2520modulation%2520%2528HM-RSNNs%2529.%2520The%2520top%2520level%2520of%2520the%2520model%2520selects%250Aexcitability%2520properties%2520for%2520task-specific%2520demands%252C%2520while%2520the%2520bottom%2520level%250Afine-tunes%2520these%2520properties%2520for%2520intra-task%2520problems.%2520Finally%252C%2520extensive%250Avisualization%2520analyses%2520of%2520HM-RSNNs%2520are%2520conducted%2520to%2520showcase%2520their%250Acomputational%2520advantages%252C%2520track%2520the%2520intrinsic%2520excitability%2520evolution%2520during%250Aschema%2520learning%252C%2520and%2520examine%2520neural%2520coordination%2520differences%2520across%2520tasks.%250ABiologically%2520inspired%2520lesion%2520studies%2520further%2520uncover%2520task-specific%250Adistributions%2520of%2520intrinsic%2520excitability%2520within%2520schemas.%2520Experimental%2520results%250Ashow%2520that%2520HM-RSNNs%2520significantly%2520outperform%2520RSNN%2520baselines%2520across%2520all%2520tasks%2520and%250Aexceed%2520RNNs%2520in%2520three%2520novel%2520cognitive%2520tasks.%2520Additionally%252C%2520HM-RSNNs%2520offer%2520deeper%250Ainsights%2520into%2520neural%2520dynamics%2520underlying%2520schema%2520learning.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14539v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=A%20Recurrent%20Spiking%20Network%20with%20Hierarchical%20Intrinsic%20Excitability%0A%20%20Modulation%20for%20Schema%20Learning&entry.906535625=Yingchao%20Yu%20and%20Yaochu%20Jin%20and%20Yuchen%20Xiao%20and%20Yuping%20Yan&entry.1292438233=%20%20Schema%2C%20a%20form%20of%20structured%20knowledge%20that%20promotes%20transfer%20learning%2C%20is%0Aattracting%20growing%20attention%20in%20both%20neuroscience%20and%20artificial%20intelligence%0A%28AI%29.%20Current%20schema%20research%20in%20neural%20computation%20is%20largely%20constrained%20to%20a%0Asingle%20behavioral%20paradigm%20and%20relies%20heavily%20on%20recurrent%20neural%20networks%0A%28RNNs%29%20which%20lack%20the%20neural%20plausibility%20and%20biological%20interpretability.%20To%0Aaddress%20these%20limitations%2C%20this%20work%20first%20constructs%20a%20generalized%20behavioral%0Aparadigm%20framework%20for%20schema%20learning%20and%20introduces%20three%20novel%20cognitive%0Atasks%2C%20thus%20supporting%20a%20comprehensive%20schema%20exploration.%20Second%2C%20we%20propose%20a%0Anew%20model%20using%20recurrent%20spiking%20neural%20networks%20with%20hierarchical%20intrinsic%0Aexcitability%20modulation%20%28HM-RSNNs%29.%20The%20top%20level%20of%20the%20model%20selects%0Aexcitability%20properties%20for%20task-specific%20demands%2C%20while%20the%20bottom%20level%0Afine-tunes%20these%20properties%20for%20intra-task%20problems.%20Finally%2C%20extensive%0Avisualization%20analyses%20of%20HM-RSNNs%20are%20conducted%20to%20showcase%20their%0Acomputational%20advantages%2C%20track%20the%20intrinsic%20excitability%20evolution%20during%0Aschema%20learning%2C%20and%20examine%20neural%20coordination%20differences%20across%20tasks.%0ABiologically%20inspired%20lesion%20studies%20further%20uncover%20task-specific%0Adistributions%20of%20intrinsic%20excitability%20within%20schemas.%20Experimental%20results%0Ashow%20that%20HM-RSNNs%20significantly%20outperform%20RSNN%20baselines%20across%20all%20tasks%20and%0Aexceed%20RNNs%20in%20three%20novel%20cognitive%20tasks.%20Additionally%2C%20HM-RSNNs%20offer%20deeper%0Ainsights%20into%20neural%20dynamics%20underlying%20schema%20learning.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14539v1&entry.124074799=Read"},
{"title": "Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to\n  Sensitivity in Large Language Models", "author": "Somnath Banerjee and Sayan Layek and Hari Shrawgi and Rajarshi Mandal and Avik Halder and Shanu Kumar and Sagnik Basu and Parag Agrawal and Rima Hazra and Animesh Mukherjee", "abstract": "  As LLMs are increasingly deployed in global applications, the importance of\ncultural sensitivity becomes paramount, ensuring that users from diverse\nbackgrounds feel respected and understood. Cultural harm can arise when these\nmodels fail to align with specific cultural norms, resulting in\nmisrepresentations or violations of cultural values. This work addresses the\nchallenges of ensuring cultural sensitivity in LLMs, especially in\nsmall-parameter models that often lack the extensive training data needed to\ncapture global cultural nuances. We present two key contributions: (1) A\ncultural harm test dataset, created to assess model outputs across different\ncultural contexts through scenarios that expose potential cultural\ninsensitivities, and (2) A culturally aligned preference dataset, aimed at\nrestoring cultural sensitivity through fine-tuning based on feedback from\ndiverse annotators. These datasets facilitate the evaluation and enhancement of\nLLMs, ensuring their ethical and safe deployment across different cultural\nlandscapes. Our results show that integrating culturally aligned feedback leads\nto a marked improvement in model behavior, significantly reducing the\nlikelihood of generating culturally insensitive or harmful content. Ultimately,\nthis work paves the way for more inclusive and respectful AI systems, fostering\na future where LLMs can safely and ethically navigate the complexities of\ndiverse cultural landscapes.\n", "link": "http://arxiv.org/abs/2410.12880v3", "date": "2025-01-24", "relevancy": 1.9844, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.499}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.4981}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4924}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Navigating%20the%20Cultural%20Kaleidoscope%3A%20A%20Hitchhiker%27s%20Guide%20to%0A%20%20Sensitivity%20in%20Large%20Language%20Models&body=Title%3A%20Navigating%20the%20Cultural%20Kaleidoscope%3A%20A%20Hitchhiker%27s%20Guide%20to%0A%20%20Sensitivity%20in%20Large%20Language%20Models%0AAuthor%3A%20Somnath%20Banerjee%20and%20Sayan%20Layek%20and%20Hari%20Shrawgi%20and%20Rajarshi%20Mandal%20and%20Avik%20Halder%20and%20Shanu%20Kumar%20and%20Sagnik%20Basu%20and%20Parag%20Agrawal%20and%20Rima%20Hazra%20and%20Animesh%20Mukherjee%0AAbstract%3A%20%20%20As%20LLMs%20are%20increasingly%20deployed%20in%20global%20applications%2C%20the%20importance%20of%0Acultural%20sensitivity%20becomes%20paramount%2C%20ensuring%20that%20users%20from%20diverse%0Abackgrounds%20feel%20respected%20and%20understood.%20Cultural%20harm%20can%20arise%20when%20these%0Amodels%20fail%20to%20align%20with%20specific%20cultural%20norms%2C%20resulting%20in%0Amisrepresentations%20or%20violations%20of%20cultural%20values.%20This%20work%20addresses%20the%0Achallenges%20of%20ensuring%20cultural%20sensitivity%20in%20LLMs%2C%20especially%20in%0Asmall-parameter%20models%20that%20often%20lack%20the%20extensive%20training%20data%20needed%20to%0Acapture%20global%20cultural%20nuances.%20We%20present%20two%20key%20contributions%3A%20%281%29%20A%0Acultural%20harm%20test%20dataset%2C%20created%20to%20assess%20model%20outputs%20across%20different%0Acultural%20contexts%20through%20scenarios%20that%20expose%20potential%20cultural%0Ainsensitivities%2C%20and%20%282%29%20A%20culturally%20aligned%20preference%20dataset%2C%20aimed%20at%0Arestoring%20cultural%20sensitivity%20through%20fine-tuning%20based%20on%20feedback%20from%0Adiverse%20annotators.%20These%20datasets%20facilitate%20the%20evaluation%20and%20enhancement%20of%0ALLMs%2C%20ensuring%20their%20ethical%20and%20safe%20deployment%20across%20different%20cultural%0Alandscapes.%20Our%20results%20show%20that%20integrating%20culturally%20aligned%20feedback%20leads%0Ato%20a%20marked%20improvement%20in%20model%20behavior%2C%20significantly%20reducing%20the%0Alikelihood%20of%20generating%20culturally%20insensitive%20or%20harmful%20content.%20Ultimately%2C%0Athis%20work%20paves%20the%20way%20for%20more%20inclusive%20and%20respectful%20AI%20systems%2C%20fostering%0Aa%20future%20where%20LLMs%20can%20safely%20and%20ethically%20navigate%20the%20complexities%20of%0Adiverse%20cultural%20landscapes.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2410.12880v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DNavigating%2520the%2520Cultural%2520Kaleidoscope%253A%2520A%2520Hitchhiker%2527s%2520Guide%2520to%250A%2520%2520Sensitivity%2520in%2520Large%2520Language%2520Models%26entry.906535625%3DSomnath%2520Banerjee%2520and%2520Sayan%2520Layek%2520and%2520Hari%2520Shrawgi%2520and%2520Rajarshi%2520Mandal%2520and%2520Avik%2520Halder%2520and%2520Shanu%2520Kumar%2520and%2520Sagnik%2520Basu%2520and%2520Parag%2520Agrawal%2520and%2520Rima%2520Hazra%2520and%2520Animesh%2520Mukherjee%26entry.1292438233%3D%2520%2520As%2520LLMs%2520are%2520increasingly%2520deployed%2520in%2520global%2520applications%252C%2520the%2520importance%2520of%250Acultural%2520sensitivity%2520becomes%2520paramount%252C%2520ensuring%2520that%2520users%2520from%2520diverse%250Abackgrounds%2520feel%2520respected%2520and%2520understood.%2520Cultural%2520harm%2520can%2520arise%2520when%2520these%250Amodels%2520fail%2520to%2520align%2520with%2520specific%2520cultural%2520norms%252C%2520resulting%2520in%250Amisrepresentations%2520or%2520violations%2520of%2520cultural%2520values.%2520This%2520work%2520addresses%2520the%250Achallenges%2520of%2520ensuring%2520cultural%2520sensitivity%2520in%2520LLMs%252C%2520especially%2520in%250Asmall-parameter%2520models%2520that%2520often%2520lack%2520the%2520extensive%2520training%2520data%2520needed%2520to%250Acapture%2520global%2520cultural%2520nuances.%2520We%2520present%2520two%2520key%2520contributions%253A%2520%25281%2529%2520A%250Acultural%2520harm%2520test%2520dataset%252C%2520created%2520to%2520assess%2520model%2520outputs%2520across%2520different%250Acultural%2520contexts%2520through%2520scenarios%2520that%2520expose%2520potential%2520cultural%250Ainsensitivities%252C%2520and%2520%25282%2529%2520A%2520culturally%2520aligned%2520preference%2520dataset%252C%2520aimed%2520at%250Arestoring%2520cultural%2520sensitivity%2520through%2520fine-tuning%2520based%2520on%2520feedback%2520from%250Adiverse%2520annotators.%2520These%2520datasets%2520facilitate%2520the%2520evaluation%2520and%2520enhancement%2520of%250ALLMs%252C%2520ensuring%2520their%2520ethical%2520and%2520safe%2520deployment%2520across%2520different%2520cultural%250Alandscapes.%2520Our%2520results%2520show%2520that%2520integrating%2520culturally%2520aligned%2520feedback%2520leads%250Ato%2520a%2520marked%2520improvement%2520in%2520model%2520behavior%252C%2520significantly%2520reducing%2520the%250Alikelihood%2520of%2520generating%2520culturally%2520insensitive%2520or%2520harmful%2520content.%2520Ultimately%252C%250Athis%2520work%2520paves%2520the%2520way%2520for%2520more%2520inclusive%2520and%2520respectful%2520AI%2520systems%252C%2520fostering%250Aa%2520future%2520where%2520LLMs%2520can%2520safely%2520and%2520ethically%2520navigate%2520the%2520complexities%2520of%250Adiverse%2520cultural%2520landscapes.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2410.12880v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Navigating%20the%20Cultural%20Kaleidoscope%3A%20A%20Hitchhiker%27s%20Guide%20to%0A%20%20Sensitivity%20in%20Large%20Language%20Models&entry.906535625=Somnath%20Banerjee%20and%20Sayan%20Layek%20and%20Hari%20Shrawgi%20and%20Rajarshi%20Mandal%20and%20Avik%20Halder%20and%20Shanu%20Kumar%20and%20Sagnik%20Basu%20and%20Parag%20Agrawal%20and%20Rima%20Hazra%20and%20Animesh%20Mukherjee&entry.1292438233=%20%20As%20LLMs%20are%20increasingly%20deployed%20in%20global%20applications%2C%20the%20importance%20of%0Acultural%20sensitivity%20becomes%20paramount%2C%20ensuring%20that%20users%20from%20diverse%0Abackgrounds%20feel%20respected%20and%20understood.%20Cultural%20harm%20can%20arise%20when%20these%0Amodels%20fail%20to%20align%20with%20specific%20cultural%20norms%2C%20resulting%20in%0Amisrepresentations%20or%20violations%20of%20cultural%20values.%20This%20work%20addresses%20the%0Achallenges%20of%20ensuring%20cultural%20sensitivity%20in%20LLMs%2C%20especially%20in%0Asmall-parameter%20models%20that%20often%20lack%20the%20extensive%20training%20data%20needed%20to%0Acapture%20global%20cultural%20nuances.%20We%20present%20two%20key%20contributions%3A%20%281%29%20A%0Acultural%20harm%20test%20dataset%2C%20created%20to%20assess%20model%20outputs%20across%20different%0Acultural%20contexts%20through%20scenarios%20that%20expose%20potential%20cultural%0Ainsensitivities%2C%20and%20%282%29%20A%20culturally%20aligned%20preference%20dataset%2C%20aimed%20at%0Arestoring%20cultural%20sensitivity%20through%20fine-tuning%20based%20on%20feedback%20from%0Adiverse%20annotators.%20These%20datasets%20facilitate%20the%20evaluation%20and%20enhancement%20of%0ALLMs%2C%20ensuring%20their%20ethical%20and%20safe%20deployment%20across%20different%20cultural%0Alandscapes.%20Our%20results%20show%20that%20integrating%20culturally%20aligned%20feedback%20leads%0Ato%20a%20marked%20improvement%20in%20model%20behavior%2C%20significantly%20reducing%20the%0Alikelihood%20of%20generating%20culturally%20insensitive%20or%20harmful%20content.%20Ultimately%2C%0Athis%20work%20paves%20the%20way%20for%20more%20inclusive%20and%20respectful%20AI%20systems%2C%20fostering%0Aa%20future%20where%20LLMs%20can%20safely%20and%20ethically%20navigate%20the%20complexities%20of%0Adiverse%20cultural%20landscapes.%0A&entry.1838667208=http%3A//arxiv.org/abs/2410.12880v3&entry.124074799=Read"},
{"title": "ABPT: Amended Backpropagation through Time with Partially Differentiable\n  Rewards", "author": "Fanxing Li and Fangyu Sun and Tianbao Zhang and Danping Zou", "abstract": "  Using the exact gradients of the rewards to directly optimize policy\nparameters via backpropagation-through-time (BPTT) enables high training\nperformance for quadrotor tasks. However, designing a fully differentiable\nreward architecture is often challenging. Partially differentiable rewards will\nresult in biased gradient propagation that degrades training performance. To\novercome this limitation, we propose Amended Backpropagation-through-Time\n(ABPT), a novel approach that mitigates gradient bias while preserving the\ntraining efficiency of BPTT. ABPT combines 0-step and N-step returns,\neffectively reducing the bias by leveraging value gradients from the learned\nQ-value function. Additionally, it adopts entropy regularization and state\ninitialization mechanisms to encourage exploration during training. We evaluate\nABPT on four representative quadrotor flight tasks. Experimental results\ndemonstrate that ABPT converges significantly faster and achieves higher\nultimate rewards than existing learning algorithms, particularly in tasks\ninvolving partially differentiable rewards.\n", "link": "http://arxiv.org/abs/2501.14513v1", "date": "2025-01-24", "relevancy": 1.9834, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5222}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.4918}, {"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.4894}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ABPT%3A%20Amended%20Backpropagation%20through%20Time%20with%20Partially%20Differentiable%0A%20%20Rewards&body=Title%3A%20ABPT%3A%20Amended%20Backpropagation%20through%20Time%20with%20Partially%20Differentiable%0A%20%20Rewards%0AAuthor%3A%20Fanxing%20Li%20and%20Fangyu%20Sun%20and%20Tianbao%20Zhang%20and%20Danping%20Zou%0AAbstract%3A%20%20%20Using%20the%20exact%20gradients%20of%20the%20rewards%20to%20directly%20optimize%20policy%0Aparameters%20via%20backpropagation-through-time%20%28BPTT%29%20enables%20high%20training%0Aperformance%20for%20quadrotor%20tasks.%20However%2C%20designing%20a%20fully%20differentiable%0Areward%20architecture%20is%20often%20challenging.%20Partially%20differentiable%20rewards%20will%0Aresult%20in%20biased%20gradient%20propagation%20that%20degrades%20training%20performance.%20To%0Aovercome%20this%20limitation%2C%20we%20propose%20Amended%20Backpropagation-through-Time%0A%28ABPT%29%2C%20a%20novel%20approach%20that%20mitigates%20gradient%20bias%20while%20preserving%20the%0Atraining%20efficiency%20of%20BPTT.%20ABPT%20combines%200-step%20and%20N-step%20returns%2C%0Aeffectively%20reducing%20the%20bias%20by%20leveraging%20value%20gradients%20from%20the%20learned%0AQ-value%20function.%20Additionally%2C%20it%20adopts%20entropy%20regularization%20and%20state%0Ainitialization%20mechanisms%20to%20encourage%20exploration%20during%20training.%20We%20evaluate%0AABPT%20on%20four%20representative%20quadrotor%20flight%20tasks.%20Experimental%20results%0Ademonstrate%20that%20ABPT%20converges%20significantly%20faster%20and%20achieves%20higher%0Aultimate%20rewards%20than%20existing%20learning%20algorithms%2C%20particularly%20in%20tasks%0Ainvolving%20partially%20differentiable%20rewards.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14513v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DABPT%253A%2520Amended%2520Backpropagation%2520through%2520Time%2520with%2520Partially%2520Differentiable%250A%2520%2520Rewards%26entry.906535625%3DFanxing%2520Li%2520and%2520Fangyu%2520Sun%2520and%2520Tianbao%2520Zhang%2520and%2520Danping%2520Zou%26entry.1292438233%3D%2520%2520Using%2520the%2520exact%2520gradients%2520of%2520the%2520rewards%2520to%2520directly%2520optimize%2520policy%250Aparameters%2520via%2520backpropagation-through-time%2520%2528BPTT%2529%2520enables%2520high%2520training%250Aperformance%2520for%2520quadrotor%2520tasks.%2520However%252C%2520designing%2520a%2520fully%2520differentiable%250Areward%2520architecture%2520is%2520often%2520challenging.%2520Partially%2520differentiable%2520rewards%2520will%250Aresult%2520in%2520biased%2520gradient%2520propagation%2520that%2520degrades%2520training%2520performance.%2520To%250Aovercome%2520this%2520limitation%252C%2520we%2520propose%2520Amended%2520Backpropagation-through-Time%250A%2528ABPT%2529%252C%2520a%2520novel%2520approach%2520that%2520mitigates%2520gradient%2520bias%2520while%2520preserving%2520the%250Atraining%2520efficiency%2520of%2520BPTT.%2520ABPT%2520combines%25200-step%2520and%2520N-step%2520returns%252C%250Aeffectively%2520reducing%2520the%2520bias%2520by%2520leveraging%2520value%2520gradients%2520from%2520the%2520learned%250AQ-value%2520function.%2520Additionally%252C%2520it%2520adopts%2520entropy%2520regularization%2520and%2520state%250Ainitialization%2520mechanisms%2520to%2520encourage%2520exploration%2520during%2520training.%2520We%2520evaluate%250AABPT%2520on%2520four%2520representative%2520quadrotor%2520flight%2520tasks.%2520Experimental%2520results%250Ademonstrate%2520that%2520ABPT%2520converges%2520significantly%2520faster%2520and%2520achieves%2520higher%250Aultimate%2520rewards%2520than%2520existing%2520learning%2520algorithms%252C%2520particularly%2520in%2520tasks%250Ainvolving%2520partially%2520differentiable%2520rewards.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14513v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ABPT%3A%20Amended%20Backpropagation%20through%20Time%20with%20Partially%20Differentiable%0A%20%20Rewards&entry.906535625=Fanxing%20Li%20and%20Fangyu%20Sun%20and%20Tianbao%20Zhang%20and%20Danping%20Zou&entry.1292438233=%20%20Using%20the%20exact%20gradients%20of%20the%20rewards%20to%20directly%20optimize%20policy%0Aparameters%20via%20backpropagation-through-time%20%28BPTT%29%20enables%20high%20training%0Aperformance%20for%20quadrotor%20tasks.%20However%2C%20designing%20a%20fully%20differentiable%0Areward%20architecture%20is%20often%20challenging.%20Partially%20differentiable%20rewards%20will%0Aresult%20in%20biased%20gradient%20propagation%20that%20degrades%20training%20performance.%20To%0Aovercome%20this%20limitation%2C%20we%20propose%20Amended%20Backpropagation-through-Time%0A%28ABPT%29%2C%20a%20novel%20approach%20that%20mitigates%20gradient%20bias%20while%20preserving%20the%0Atraining%20efficiency%20of%20BPTT.%20ABPT%20combines%200-step%20and%20N-step%20returns%2C%0Aeffectively%20reducing%20the%20bias%20by%20leveraging%20value%20gradients%20from%20the%20learned%0AQ-value%20function.%20Additionally%2C%20it%20adopts%20entropy%20regularization%20and%20state%0Ainitialization%20mechanisms%20to%20encourage%20exploration%20during%20training.%20We%20evaluate%0AABPT%20on%20four%20representative%20quadrotor%20flight%20tasks.%20Experimental%20results%0Ademonstrate%20that%20ABPT%20converges%20significantly%20faster%20and%20achieves%20higher%0Aultimate%20rewards%20than%20existing%20learning%20algorithms%2C%20particularly%20in%20tasks%0Ainvolving%20partially%20differentiable%20rewards.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14513v1&entry.124074799=Read"},
{"title": "ZETA: Leveraging Z-order Curves for Efficient Top-k Attention", "author": "Qiuhao Zeng and Jerry Huang and Peng Lu and Gezheng Xu and Boxing Chen and Charles Ling and Boyu Wang", "abstract": "  Over recent years, the Transformer has become a fundamental building block\nfor sequence modeling architectures. Yet at its core is the use of\nself-attention, whose memory and computational cost grow quadratically with the\nsequence length $N$, rendering it prohibitively expensive for long sequences. A\npromising approach is top-$k$ attention, which selects only the $k$ most\nrelevant tokens and achieves performance comparable to vanilla self-attention\nwhile significantly reducing space and computational demands. However, causal\nmasks require the current query token to only attend to past tokens, preventing\nthe existing top-$k$ attention method from efficiently searching for the most\nrelevant tokens in parallel, thereby limiting training efficiency. In this\nwork, we propose ZETA, leveraging \\textbf{Z}-Order Curves for\n\\textbf{E}fficient \\textbf{T}op-$k$ \\textbf{A}ttention, to enable parallel\nquerying of past tokens for entire sequences. % in both space and time\ncomplexity of $\\mathcal{O}(N \\log N)$. We first theoretically show that the\nchoice of key and query dimensions involves a trade-off between the curse of\ndimensionality and the preservation of relative distances after projection. In\nlight of this insight, we propose reducing the dimensionality of keys and\nqueries in contrast to values and further leverage $Z$-order curves to map\nlow-dimensional keys and queries into \\emph{one}-dimensional space, which\npermits parallel sorting, thereby largely improving the efficiency for top-$k$\ntoken selection. Experimental results demonstrate that ZETA matches the\nperformance of standard attention on the synthetic \\textsc{Multi-Query\nAssociative Recall} task and outperforms attention and its variants on\n\\textsc{Long Range Arena} and \\textsc{WikiText-103} language modeling.\n", "link": "http://arxiv.org/abs/2501.14577v1", "date": "2025-01-24", "relevancy": 1.9469, "topK": [{"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.5078}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4731}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4679}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ZETA%3A%20Leveraging%20Z-order%20Curves%20for%20Efficient%20Top-k%20Attention&body=Title%3A%20ZETA%3A%20Leveraging%20Z-order%20Curves%20for%20Efficient%20Top-k%20Attention%0AAuthor%3A%20Qiuhao%20Zeng%20and%20Jerry%20Huang%20and%20Peng%20Lu%20and%20Gezheng%20Xu%20and%20Boxing%20Chen%20and%20Charles%20Ling%20and%20Boyu%20Wang%0AAbstract%3A%20%20%20Over%20recent%20years%2C%20the%20Transformer%20has%20become%20a%20fundamental%20building%20block%0Afor%20sequence%20modeling%20architectures.%20Yet%20at%20its%20core%20is%20the%20use%20of%0Aself-attention%2C%20whose%20memory%20and%20computational%20cost%20grow%20quadratically%20with%20the%0Asequence%20length%20%24N%24%2C%20rendering%20it%20prohibitively%20expensive%20for%20long%20sequences.%20A%0Apromising%20approach%20is%20top-%24k%24%20attention%2C%20which%20selects%20only%20the%20%24k%24%20most%0Arelevant%20tokens%20and%20achieves%20performance%20comparable%20to%20vanilla%20self-attention%0Awhile%20significantly%20reducing%20space%20and%20computational%20demands.%20However%2C%20causal%0Amasks%20require%20the%20current%20query%20token%20to%20only%20attend%20to%20past%20tokens%2C%20preventing%0Athe%20existing%20top-%24k%24%20attention%20method%20from%20efficiently%20searching%20for%20the%20most%0Arelevant%20tokens%20in%20parallel%2C%20thereby%20limiting%20training%20efficiency.%20In%20this%0Awork%2C%20we%20propose%20ZETA%2C%20leveraging%20%5Ctextbf%7BZ%7D-Order%20Curves%20for%0A%5Ctextbf%7BE%7Dfficient%20%5Ctextbf%7BT%7Dop-%24k%24%20%5Ctextbf%7BA%7Dttention%2C%20to%20enable%20parallel%0Aquerying%20of%20past%20tokens%20for%20entire%20sequences.%20%25%20in%20both%20space%20and%20time%0Acomplexity%20of%20%24%5Cmathcal%7BO%7D%28N%20%5Clog%20N%29%24.%20We%20first%20theoretically%20show%20that%20the%0Achoice%20of%20key%20and%20query%20dimensions%20involves%20a%20trade-off%20between%20the%20curse%20of%0Adimensionality%20and%20the%20preservation%20of%20relative%20distances%20after%20projection.%20In%0Alight%20of%20this%20insight%2C%20we%20propose%20reducing%20the%20dimensionality%20of%20keys%20and%0Aqueries%20in%20contrast%20to%20values%20and%20further%20leverage%20%24Z%24-order%20curves%20to%20map%0Alow-dimensional%20keys%20and%20queries%20into%20%5Cemph%7Bone%7D-dimensional%20space%2C%20which%0Apermits%20parallel%20sorting%2C%20thereby%20largely%20improving%20the%20efficiency%20for%20top-%24k%24%0Atoken%20selection.%20Experimental%20results%20demonstrate%20that%20ZETA%20matches%20the%0Aperformance%20of%20standard%20attention%20on%20the%20synthetic%20%5Ctextsc%7BMulti-Query%0AAssociative%20Recall%7D%20task%20and%20outperforms%20attention%20and%20its%20variants%20on%0A%5Ctextsc%7BLong%20Range%20Arena%7D%20and%20%5Ctextsc%7BWikiText-103%7D%20language%20modeling.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14577v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DZETA%253A%2520Leveraging%2520Z-order%2520Curves%2520for%2520Efficient%2520Top-k%2520Attention%26entry.906535625%3DQiuhao%2520Zeng%2520and%2520Jerry%2520Huang%2520and%2520Peng%2520Lu%2520and%2520Gezheng%2520Xu%2520and%2520Boxing%2520Chen%2520and%2520Charles%2520Ling%2520and%2520Boyu%2520Wang%26entry.1292438233%3D%2520%2520Over%2520recent%2520years%252C%2520the%2520Transformer%2520has%2520become%2520a%2520fundamental%2520building%2520block%250Afor%2520sequence%2520modeling%2520architectures.%2520Yet%2520at%2520its%2520core%2520is%2520the%2520use%2520of%250Aself-attention%252C%2520whose%2520memory%2520and%2520computational%2520cost%2520grow%2520quadratically%2520with%2520the%250Asequence%2520length%2520%2524N%2524%252C%2520rendering%2520it%2520prohibitively%2520expensive%2520for%2520long%2520sequences.%2520A%250Apromising%2520approach%2520is%2520top-%2524k%2524%2520attention%252C%2520which%2520selects%2520only%2520the%2520%2524k%2524%2520most%250Arelevant%2520tokens%2520and%2520achieves%2520performance%2520comparable%2520to%2520vanilla%2520self-attention%250Awhile%2520significantly%2520reducing%2520space%2520and%2520computational%2520demands.%2520However%252C%2520causal%250Amasks%2520require%2520the%2520current%2520query%2520token%2520to%2520only%2520attend%2520to%2520past%2520tokens%252C%2520preventing%250Athe%2520existing%2520top-%2524k%2524%2520attention%2520method%2520from%2520efficiently%2520searching%2520for%2520the%2520most%250Arelevant%2520tokens%2520in%2520parallel%252C%2520thereby%2520limiting%2520training%2520efficiency.%2520In%2520this%250Awork%252C%2520we%2520propose%2520ZETA%252C%2520leveraging%2520%255Ctextbf%257BZ%257D-Order%2520Curves%2520for%250A%255Ctextbf%257BE%257Dfficient%2520%255Ctextbf%257BT%257Dop-%2524k%2524%2520%255Ctextbf%257BA%257Dttention%252C%2520to%2520enable%2520parallel%250Aquerying%2520of%2520past%2520tokens%2520for%2520entire%2520sequences.%2520%2525%2520in%2520both%2520space%2520and%2520time%250Acomplexity%2520of%2520%2524%255Cmathcal%257BO%257D%2528N%2520%255Clog%2520N%2529%2524.%2520We%2520first%2520theoretically%2520show%2520that%2520the%250Achoice%2520of%2520key%2520and%2520query%2520dimensions%2520involves%2520a%2520trade-off%2520between%2520the%2520curse%2520of%250Adimensionality%2520and%2520the%2520preservation%2520of%2520relative%2520distances%2520after%2520projection.%2520In%250Alight%2520of%2520this%2520insight%252C%2520we%2520propose%2520reducing%2520the%2520dimensionality%2520of%2520keys%2520and%250Aqueries%2520in%2520contrast%2520to%2520values%2520and%2520further%2520leverage%2520%2524Z%2524-order%2520curves%2520to%2520map%250Alow-dimensional%2520keys%2520and%2520queries%2520into%2520%255Cemph%257Bone%257D-dimensional%2520space%252C%2520which%250Apermits%2520parallel%2520sorting%252C%2520thereby%2520largely%2520improving%2520the%2520efficiency%2520for%2520top-%2524k%2524%250Atoken%2520selection.%2520Experimental%2520results%2520demonstrate%2520that%2520ZETA%2520matches%2520the%250Aperformance%2520of%2520standard%2520attention%2520on%2520the%2520synthetic%2520%255Ctextsc%257BMulti-Query%250AAssociative%2520Recall%257D%2520task%2520and%2520outperforms%2520attention%2520and%2520its%2520variants%2520on%250A%255Ctextsc%257BLong%2520Range%2520Arena%257D%2520and%2520%255Ctextsc%257BWikiText-103%257D%2520language%2520modeling.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14577v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ZETA%3A%20Leveraging%20Z-order%20Curves%20for%20Efficient%20Top-k%20Attention&entry.906535625=Qiuhao%20Zeng%20and%20Jerry%20Huang%20and%20Peng%20Lu%20and%20Gezheng%20Xu%20and%20Boxing%20Chen%20and%20Charles%20Ling%20and%20Boyu%20Wang&entry.1292438233=%20%20Over%20recent%20years%2C%20the%20Transformer%20has%20become%20a%20fundamental%20building%20block%0Afor%20sequence%20modeling%20architectures.%20Yet%20at%20its%20core%20is%20the%20use%20of%0Aself-attention%2C%20whose%20memory%20and%20computational%20cost%20grow%20quadratically%20with%20the%0Asequence%20length%20%24N%24%2C%20rendering%20it%20prohibitively%20expensive%20for%20long%20sequences.%20A%0Apromising%20approach%20is%20top-%24k%24%20attention%2C%20which%20selects%20only%20the%20%24k%24%20most%0Arelevant%20tokens%20and%20achieves%20performance%20comparable%20to%20vanilla%20self-attention%0Awhile%20significantly%20reducing%20space%20and%20computational%20demands.%20However%2C%20causal%0Amasks%20require%20the%20current%20query%20token%20to%20only%20attend%20to%20past%20tokens%2C%20preventing%0Athe%20existing%20top-%24k%24%20attention%20method%20from%20efficiently%20searching%20for%20the%20most%0Arelevant%20tokens%20in%20parallel%2C%20thereby%20limiting%20training%20efficiency.%20In%20this%0Awork%2C%20we%20propose%20ZETA%2C%20leveraging%20%5Ctextbf%7BZ%7D-Order%20Curves%20for%0A%5Ctextbf%7BE%7Dfficient%20%5Ctextbf%7BT%7Dop-%24k%24%20%5Ctextbf%7BA%7Dttention%2C%20to%20enable%20parallel%0Aquerying%20of%20past%20tokens%20for%20entire%20sequences.%20%25%20in%20both%20space%20and%20time%0Acomplexity%20of%20%24%5Cmathcal%7BO%7D%28N%20%5Clog%20N%29%24.%20We%20first%20theoretically%20show%20that%20the%0Achoice%20of%20key%20and%20query%20dimensions%20involves%20a%20trade-off%20between%20the%20curse%20of%0Adimensionality%20and%20the%20preservation%20of%20relative%20distances%20after%20projection.%20In%0Alight%20of%20this%20insight%2C%20we%20propose%20reducing%20the%20dimensionality%20of%20keys%20and%0Aqueries%20in%20contrast%20to%20values%20and%20further%20leverage%20%24Z%24-order%20curves%20to%20map%0Alow-dimensional%20keys%20and%20queries%20into%20%5Cemph%7Bone%7D-dimensional%20space%2C%20which%0Apermits%20parallel%20sorting%2C%20thereby%20largely%20improving%20the%20efficiency%20for%20top-%24k%24%0Atoken%20selection.%20Experimental%20results%20demonstrate%20that%20ZETA%20matches%20the%0Aperformance%20of%20standard%20attention%20on%20the%20synthetic%20%5Ctextsc%7BMulti-Query%0AAssociative%20Recall%7D%20task%20and%20outperforms%20attention%20and%20its%20variants%20on%0A%5Ctextsc%7BLong%20Range%20Arena%7D%20and%20%5Ctextsc%7BWikiText-103%7D%20language%20modeling.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14577v1&entry.124074799=Read"},
{"title": "An Attentive Graph Agent for Topology-Adaptive Cyber Defence", "author": "Ilya Orson Sandoval and Isaac Symes Thompson and Vasilios Mavroudis and Chris Hicks", "abstract": "  As cyber threats grow increasingly sophisticated, reinforcement learning is\nemerging as a promising technique to create intelligent, self-improving\ndefensive systems. However, most existing autonomous defensive agents have\noverlooked the inherent graph structure of computer networks subject to cyber\nattacks, potentially missing critical information. To address this gap, we\ndeveloped a custom version of the Cyber Operations Research Gym (CybORG)\nenvironment that encodes the observable network state as a directed graph,\nutilizing realistic and interpretable low-level features. %, like number of\nopen ports and unexpected detected connections. We leverage a Graph Attention\nNetwork (GAT) architecture to process node, edge, and global features, and\nmodify its output to be compatible with policy gradient methods in\nreinforcement learning. GAT policies offer several advantages over standard\napproaches based on simplistic flattened state observations. They can handle\nthe changes in network topology that occur at runtime when dynamic connections\nbetween hosts appear. Policies can be deployed to networks that differ in size\nto the ones seen during training, enabling a degree of generalisation\ninaccessible with alternative approaches. Furthermore, the graph neural network\npolicies outputs are explainable in terms of tangible network properties,\nproviding enhanced interpretability of defensive actions. We verify that our\nlow-level graph observations are meaningful enough to train GAT defensive\npolicies that are able to adapt to changing topologies. We evaluate how our\ntrained policies perform when deployed on networks of varying sizes with the\nsame subnetwork structure, comparing them against policies specifically trained\nfor each network configuration. Our study contributes to the development of\nrobust cyber defence systems that can better adapt to real-world network\nsecurity challenges.\n", "link": "http://arxiv.org/abs/2501.14700v1", "date": "2025-01-24", "relevancy": 1.9214, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5274}, {"title": "Genie: Generative Interactive Environments", "link": "http://arxiv.org/abs/2402.15391v1", "similarity": 0.4718}, {"title": "Safe and efficient training of a control agent", "link": "https://patents.google.com/patent/US11709462B2/en", "similarity": 0.47}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20An%20Attentive%20Graph%20Agent%20for%20Topology-Adaptive%20Cyber%20Defence&body=Title%3A%20An%20Attentive%20Graph%20Agent%20for%20Topology-Adaptive%20Cyber%20Defence%0AAuthor%3A%20Ilya%20Orson%20Sandoval%20and%20Isaac%20Symes%20Thompson%20and%20Vasilios%20Mavroudis%20and%20Chris%20Hicks%0AAbstract%3A%20%20%20As%20cyber%20threats%20grow%20increasingly%20sophisticated%2C%20reinforcement%20learning%20is%0Aemerging%20as%20a%20promising%20technique%20to%20create%20intelligent%2C%20self-improving%0Adefensive%20systems.%20However%2C%20most%20existing%20autonomous%20defensive%20agents%20have%0Aoverlooked%20the%20inherent%20graph%20structure%20of%20computer%20networks%20subject%20to%20cyber%0Aattacks%2C%20potentially%20missing%20critical%20information.%20To%20address%20this%20gap%2C%20we%0Adeveloped%20a%20custom%20version%20of%20the%20Cyber%20Operations%20Research%20Gym%20%28CybORG%29%0Aenvironment%20that%20encodes%20the%20observable%20network%20state%20as%20a%20directed%20graph%2C%0Autilizing%20realistic%20and%20interpretable%20low-level%20features.%20%25%2C%20like%20number%20of%0Aopen%20ports%20and%20unexpected%20detected%20connections.%20We%20leverage%20a%20Graph%20Attention%0ANetwork%20%28GAT%29%20architecture%20to%20process%20node%2C%20edge%2C%20and%20global%20features%2C%20and%0Amodify%20its%20output%20to%20be%20compatible%20with%20policy%20gradient%20methods%20in%0Areinforcement%20learning.%20GAT%20policies%20offer%20several%20advantages%20over%20standard%0Aapproaches%20based%20on%20simplistic%20flattened%20state%20observations.%20They%20can%20handle%0Athe%20changes%20in%20network%20topology%20that%20occur%20at%20runtime%20when%20dynamic%20connections%0Abetween%20hosts%20appear.%20Policies%20can%20be%20deployed%20to%20networks%20that%20differ%20in%20size%0Ato%20the%20ones%20seen%20during%20training%2C%20enabling%20a%20degree%20of%20generalisation%0Ainaccessible%20with%20alternative%20approaches.%20Furthermore%2C%20the%20graph%20neural%20network%0Apolicies%20outputs%20are%20explainable%20in%20terms%20of%20tangible%20network%20properties%2C%0Aproviding%20enhanced%20interpretability%20of%20defensive%20actions.%20We%20verify%20that%20our%0Alow-level%20graph%20observations%20are%20meaningful%20enough%20to%20train%20GAT%20defensive%0Apolicies%20that%20are%20able%20to%20adapt%20to%20changing%20topologies.%20We%20evaluate%20how%20our%0Atrained%20policies%20perform%20when%20deployed%20on%20networks%20of%20varying%20sizes%20with%20the%0Asame%20subnetwork%20structure%2C%20comparing%20them%20against%20policies%20specifically%20trained%0Afor%20each%20network%20configuration.%20Our%20study%20contributes%20to%20the%20development%20of%0Arobust%20cyber%20defence%20systems%20that%20can%20better%20adapt%20to%20real-world%20network%0Asecurity%20challenges.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14700v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DAn%2520Attentive%2520Graph%2520Agent%2520for%2520Topology-Adaptive%2520Cyber%2520Defence%26entry.906535625%3DIlya%2520Orson%2520Sandoval%2520and%2520Isaac%2520Symes%2520Thompson%2520and%2520Vasilios%2520Mavroudis%2520and%2520Chris%2520Hicks%26entry.1292438233%3D%2520%2520As%2520cyber%2520threats%2520grow%2520increasingly%2520sophisticated%252C%2520reinforcement%2520learning%2520is%250Aemerging%2520as%2520a%2520promising%2520technique%2520to%2520create%2520intelligent%252C%2520self-improving%250Adefensive%2520systems.%2520However%252C%2520most%2520existing%2520autonomous%2520defensive%2520agents%2520have%250Aoverlooked%2520the%2520inherent%2520graph%2520structure%2520of%2520computer%2520networks%2520subject%2520to%2520cyber%250Aattacks%252C%2520potentially%2520missing%2520critical%2520information.%2520To%2520address%2520this%2520gap%252C%2520we%250Adeveloped%2520a%2520custom%2520version%2520of%2520the%2520Cyber%2520Operations%2520Research%2520Gym%2520%2528CybORG%2529%250Aenvironment%2520that%2520encodes%2520the%2520observable%2520network%2520state%2520as%2520a%2520directed%2520graph%252C%250Autilizing%2520realistic%2520and%2520interpretable%2520low-level%2520features.%2520%2525%252C%2520like%2520number%2520of%250Aopen%2520ports%2520and%2520unexpected%2520detected%2520connections.%2520We%2520leverage%2520a%2520Graph%2520Attention%250ANetwork%2520%2528GAT%2529%2520architecture%2520to%2520process%2520node%252C%2520edge%252C%2520and%2520global%2520features%252C%2520and%250Amodify%2520its%2520output%2520to%2520be%2520compatible%2520with%2520policy%2520gradient%2520methods%2520in%250Areinforcement%2520learning.%2520GAT%2520policies%2520offer%2520several%2520advantages%2520over%2520standard%250Aapproaches%2520based%2520on%2520simplistic%2520flattened%2520state%2520observations.%2520They%2520can%2520handle%250Athe%2520changes%2520in%2520network%2520topology%2520that%2520occur%2520at%2520runtime%2520when%2520dynamic%2520connections%250Abetween%2520hosts%2520appear.%2520Policies%2520can%2520be%2520deployed%2520to%2520networks%2520that%2520differ%2520in%2520size%250Ato%2520the%2520ones%2520seen%2520during%2520training%252C%2520enabling%2520a%2520degree%2520of%2520generalisation%250Ainaccessible%2520with%2520alternative%2520approaches.%2520Furthermore%252C%2520the%2520graph%2520neural%2520network%250Apolicies%2520outputs%2520are%2520explainable%2520in%2520terms%2520of%2520tangible%2520network%2520properties%252C%250Aproviding%2520enhanced%2520interpretability%2520of%2520defensive%2520actions.%2520We%2520verify%2520that%2520our%250Alow-level%2520graph%2520observations%2520are%2520meaningful%2520enough%2520to%2520train%2520GAT%2520defensive%250Apolicies%2520that%2520are%2520able%2520to%2520adapt%2520to%2520changing%2520topologies.%2520We%2520evaluate%2520how%2520our%250Atrained%2520policies%2520perform%2520when%2520deployed%2520on%2520networks%2520of%2520varying%2520sizes%2520with%2520the%250Asame%2520subnetwork%2520structure%252C%2520comparing%2520them%2520against%2520policies%2520specifically%2520trained%250Afor%2520each%2520network%2520configuration.%2520Our%2520study%2520contributes%2520to%2520the%2520development%2520of%250Arobust%2520cyber%2520defence%2520systems%2520that%2520can%2520better%2520adapt%2520to%2520real-world%2520network%250Asecurity%2520challenges.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14700v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=An%20Attentive%20Graph%20Agent%20for%20Topology-Adaptive%20Cyber%20Defence&entry.906535625=Ilya%20Orson%20Sandoval%20and%20Isaac%20Symes%20Thompson%20and%20Vasilios%20Mavroudis%20and%20Chris%20Hicks&entry.1292438233=%20%20As%20cyber%20threats%20grow%20increasingly%20sophisticated%2C%20reinforcement%20learning%20is%0Aemerging%20as%20a%20promising%20technique%20to%20create%20intelligent%2C%20self-improving%0Adefensive%20systems.%20However%2C%20most%20existing%20autonomous%20defensive%20agents%20have%0Aoverlooked%20the%20inherent%20graph%20structure%20of%20computer%20networks%20subject%20to%20cyber%0Aattacks%2C%20potentially%20missing%20critical%20information.%20To%20address%20this%20gap%2C%20we%0Adeveloped%20a%20custom%20version%20of%20the%20Cyber%20Operations%20Research%20Gym%20%28CybORG%29%0Aenvironment%20that%20encodes%20the%20observable%20network%20state%20as%20a%20directed%20graph%2C%0Autilizing%20realistic%20and%20interpretable%20low-level%20features.%20%25%2C%20like%20number%20of%0Aopen%20ports%20and%20unexpected%20detected%20connections.%20We%20leverage%20a%20Graph%20Attention%0ANetwork%20%28GAT%29%20architecture%20to%20process%20node%2C%20edge%2C%20and%20global%20features%2C%20and%0Amodify%20its%20output%20to%20be%20compatible%20with%20policy%20gradient%20methods%20in%0Areinforcement%20learning.%20GAT%20policies%20offer%20several%20advantages%20over%20standard%0Aapproaches%20based%20on%20simplistic%20flattened%20state%20observations.%20They%20can%20handle%0Athe%20changes%20in%20network%20topology%20that%20occur%20at%20runtime%20when%20dynamic%20connections%0Abetween%20hosts%20appear.%20Policies%20can%20be%20deployed%20to%20networks%20that%20differ%20in%20size%0Ato%20the%20ones%20seen%20during%20training%2C%20enabling%20a%20degree%20of%20generalisation%0Ainaccessible%20with%20alternative%20approaches.%20Furthermore%2C%20the%20graph%20neural%20network%0Apolicies%20outputs%20are%20explainable%20in%20terms%20of%20tangible%20network%20properties%2C%0Aproviding%20enhanced%20interpretability%20of%20defensive%20actions.%20We%20verify%20that%20our%0Alow-level%20graph%20observations%20are%20meaningful%20enough%20to%20train%20GAT%20defensive%0Apolicies%20that%20are%20able%20to%20adapt%20to%20changing%20topologies.%20We%20evaluate%20how%20our%0Atrained%20policies%20perform%20when%20deployed%20on%20networks%20of%20varying%20sizes%20with%20the%0Asame%20subnetwork%20structure%2C%20comparing%20them%20against%20policies%20specifically%20trained%0Afor%20each%20network%20configuration.%20Our%20study%20contributes%20to%20the%20development%20of%0Arobust%20cyber%20defence%20systems%20that%20can%20better%20adapt%20to%20real-world%20network%0Asecurity%20challenges.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14700v1&entry.124074799=Read"},
{"title": "State Space Models for Extractive Summarization in Low Resource\n  Scenarios", "author": "Nisrine Ait Khayi", "abstract": "  Extractive summarization involves selecting the most relevant sentences from\na text. Recently, researchers have focused on advancing methods to improve\nstate-of-the-art results in low-resource settings. Motivated by these\nadvancements, we propose the MPoincareSum method. This method applies the Mamba\nstate space model to generate the semantics of reviews and sentences, which are\nthen concatenated. A Poincare compression is used to select the most meaningful\nfeatures, followed by the application of a linear layer to predict sentence\nrelevance based on the corresponding review. Finally, we paraphrase the\nrelevant sentences to create the final summary. To evaluate the effectiveness\nof MPoincareSum, we conducted extensive experiments using the Amazon review\ndataset. The performance of the method was assessed using ROUGE scores. The\nexperimental results demonstrate that MPoincareSum outperforms several existing\napproaches in the literature\n", "link": "http://arxiv.org/abs/2501.14673v1", "date": "2025-01-24", "relevancy": 1.9176, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4817}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4789}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4789}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20State%20Space%20Models%20for%20Extractive%20Summarization%20in%20Low%20Resource%0A%20%20Scenarios&body=Title%3A%20State%20Space%20Models%20for%20Extractive%20Summarization%20in%20Low%20Resource%0A%20%20Scenarios%0AAuthor%3A%20Nisrine%20Ait%20Khayi%0AAbstract%3A%20%20%20Extractive%20summarization%20involves%20selecting%20the%20most%20relevant%20sentences%20from%0Aa%20text.%20Recently%2C%20researchers%20have%20focused%20on%20advancing%20methods%20to%20improve%0Astate-of-the-art%20results%20in%20low-resource%20settings.%20Motivated%20by%20these%0Aadvancements%2C%20we%20propose%20the%20MPoincareSum%20method.%20This%20method%20applies%20the%20Mamba%0Astate%20space%20model%20to%20generate%20the%20semantics%20of%20reviews%20and%20sentences%2C%20which%20are%0Athen%20concatenated.%20A%20Poincare%20compression%20is%20used%20to%20select%20the%20most%20meaningful%0Afeatures%2C%20followed%20by%20the%20application%20of%20a%20linear%20layer%20to%20predict%20sentence%0Arelevance%20based%20on%20the%20corresponding%20review.%20Finally%2C%20we%20paraphrase%20the%0Arelevant%20sentences%20to%20create%20the%20final%20summary.%20To%20evaluate%20the%20effectiveness%0Aof%20MPoincareSum%2C%20we%20conducted%20extensive%20experiments%20using%20the%20Amazon%20review%0Adataset.%20The%20performance%20of%20the%20method%20was%20assessed%20using%20ROUGE%20scores.%20The%0Aexperimental%20results%20demonstrate%20that%20MPoincareSum%20outperforms%20several%20existing%0Aapproaches%20in%20the%20literature%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14673v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DState%2520Space%2520Models%2520for%2520Extractive%2520Summarization%2520in%2520Low%2520Resource%250A%2520%2520Scenarios%26entry.906535625%3DNisrine%2520Ait%2520Khayi%26entry.1292438233%3D%2520%2520Extractive%2520summarization%2520involves%2520selecting%2520the%2520most%2520relevant%2520sentences%2520from%250Aa%2520text.%2520Recently%252C%2520researchers%2520have%2520focused%2520on%2520advancing%2520methods%2520to%2520improve%250Astate-of-the-art%2520results%2520in%2520low-resource%2520settings.%2520Motivated%2520by%2520these%250Aadvancements%252C%2520we%2520propose%2520the%2520MPoincareSum%2520method.%2520This%2520method%2520applies%2520the%2520Mamba%250Astate%2520space%2520model%2520to%2520generate%2520the%2520semantics%2520of%2520reviews%2520and%2520sentences%252C%2520which%2520are%250Athen%2520concatenated.%2520A%2520Poincare%2520compression%2520is%2520used%2520to%2520select%2520the%2520most%2520meaningful%250Afeatures%252C%2520followed%2520by%2520the%2520application%2520of%2520a%2520linear%2520layer%2520to%2520predict%2520sentence%250Arelevance%2520based%2520on%2520the%2520corresponding%2520review.%2520Finally%252C%2520we%2520paraphrase%2520the%250Arelevant%2520sentences%2520to%2520create%2520the%2520final%2520summary.%2520To%2520evaluate%2520the%2520effectiveness%250Aof%2520MPoincareSum%252C%2520we%2520conducted%2520extensive%2520experiments%2520using%2520the%2520Amazon%2520review%250Adataset.%2520The%2520performance%2520of%2520the%2520method%2520was%2520assessed%2520using%2520ROUGE%2520scores.%2520The%250Aexperimental%2520results%2520demonstrate%2520that%2520MPoincareSum%2520outperforms%2520several%2520existing%250Aapproaches%2520in%2520the%2520literature%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14673v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=State%20Space%20Models%20for%20Extractive%20Summarization%20in%20Low%20Resource%0A%20%20Scenarios&entry.906535625=Nisrine%20Ait%20Khayi&entry.1292438233=%20%20Extractive%20summarization%20involves%20selecting%20the%20most%20relevant%20sentences%20from%0Aa%20text.%20Recently%2C%20researchers%20have%20focused%20on%20advancing%20methods%20to%20improve%0Astate-of-the-art%20results%20in%20low-resource%20settings.%20Motivated%20by%20these%0Aadvancements%2C%20we%20propose%20the%20MPoincareSum%20method.%20This%20method%20applies%20the%20Mamba%0Astate%20space%20model%20to%20generate%20the%20semantics%20of%20reviews%20and%20sentences%2C%20which%20are%0Athen%20concatenated.%20A%20Poincare%20compression%20is%20used%20to%20select%20the%20most%20meaningful%0Afeatures%2C%20followed%20by%20the%20application%20of%20a%20linear%20layer%20to%20predict%20sentence%0Arelevance%20based%20on%20the%20corresponding%20review.%20Finally%2C%20we%20paraphrase%20the%0Arelevant%20sentences%20to%20create%20the%20final%20summary.%20To%20evaluate%20the%20effectiveness%0Aof%20MPoincareSum%2C%20we%20conducted%20extensive%20experiments%20using%20the%20Amazon%20review%0Adataset.%20The%20performance%20of%20the%20method%20was%20assessed%20using%20ROUGE%20scores.%20The%0Aexperimental%20results%20demonstrate%20that%20MPoincareSum%20outperforms%20several%20existing%0Aapproaches%20in%20the%20literature%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14673v1&entry.124074799=Read"},
{"title": "Distributed Conformal Prediction via Message Passing", "author": "Haifeng Wen and Hong Xing and Osvaldo Simeone", "abstract": "  Post-hoc calibration of pre-trained models is critical for ensuring reliable\ninference, especially in safety-critical domains such as healthcare. Conformal\nPrediction (CP) offers a robust post-hoc calibration framework, providing\ndistribution-free statistical coverage guarantees for prediction sets by\nleveraging held-out datasets. In this work, we address a decentralized setting\nwhere each device has limited calibration data and can communicate only with\nits neighbors over an arbitrary graph topology. We propose two\nmessage-passing-based approaches for achieving reliable inference via CP:\nquantile-based distributed conformal prediction (Q-DCP) and histogram-based\ndistributed conformal prediction (H-DCP). Q-DCP employs distributed quantile\nregression enhanced with tailored smoothing and regularization terms to\naccelerate convergence, while H-DCP uses a consensus-based histogram estimation\napproach. Through extensive experiments, we investigate the trade-offs between\nhyperparameter tuning requirements, communication overhead, coverage\nguarantees, and prediction set sizes across different network topologies.\n", "link": "http://arxiv.org/abs/2501.14544v1", "date": "2025-01-24", "relevancy": 1.8963, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4786}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.475}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4714}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Distributed%20Conformal%20Prediction%20via%20Message%20Passing&body=Title%3A%20Distributed%20Conformal%20Prediction%20via%20Message%20Passing%0AAuthor%3A%20Haifeng%20Wen%20and%20Hong%20Xing%20and%20Osvaldo%20Simeone%0AAbstract%3A%20%20%20Post-hoc%20calibration%20of%20pre-trained%20models%20is%20critical%20for%20ensuring%20reliable%0Ainference%2C%20especially%20in%20safety-critical%20domains%20such%20as%20healthcare.%20Conformal%0APrediction%20%28CP%29%20offers%20a%20robust%20post-hoc%20calibration%20framework%2C%20providing%0Adistribution-free%20statistical%20coverage%20guarantees%20for%20prediction%20sets%20by%0Aleveraging%20held-out%20datasets.%20In%20this%20work%2C%20we%20address%20a%20decentralized%20setting%0Awhere%20each%20device%20has%20limited%20calibration%20data%20and%20can%20communicate%20only%20with%0Aits%20neighbors%20over%20an%20arbitrary%20graph%20topology.%20We%20propose%20two%0Amessage-passing-based%20approaches%20for%20achieving%20reliable%20inference%20via%20CP%3A%0Aquantile-based%20distributed%20conformal%20prediction%20%28Q-DCP%29%20and%20histogram-based%0Adistributed%20conformal%20prediction%20%28H-DCP%29.%20Q-DCP%20employs%20distributed%20quantile%0Aregression%20enhanced%20with%20tailored%20smoothing%20and%20regularization%20terms%20to%0Aaccelerate%20convergence%2C%20while%20H-DCP%20uses%20a%20consensus-based%20histogram%20estimation%0Aapproach.%20Through%20extensive%20experiments%2C%20we%20investigate%20the%20trade-offs%20between%0Ahyperparameter%20tuning%20requirements%2C%20communication%20overhead%2C%20coverage%0Aguarantees%2C%20and%20prediction%20set%20sizes%20across%20different%20network%20topologies.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14544v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDistributed%2520Conformal%2520Prediction%2520via%2520Message%2520Passing%26entry.906535625%3DHaifeng%2520Wen%2520and%2520Hong%2520Xing%2520and%2520Osvaldo%2520Simeone%26entry.1292438233%3D%2520%2520Post-hoc%2520calibration%2520of%2520pre-trained%2520models%2520is%2520critical%2520for%2520ensuring%2520reliable%250Ainference%252C%2520especially%2520in%2520safety-critical%2520domains%2520such%2520as%2520healthcare.%2520Conformal%250APrediction%2520%2528CP%2529%2520offers%2520a%2520robust%2520post-hoc%2520calibration%2520framework%252C%2520providing%250Adistribution-free%2520statistical%2520coverage%2520guarantees%2520for%2520prediction%2520sets%2520by%250Aleveraging%2520held-out%2520datasets.%2520In%2520this%2520work%252C%2520we%2520address%2520a%2520decentralized%2520setting%250Awhere%2520each%2520device%2520has%2520limited%2520calibration%2520data%2520and%2520can%2520communicate%2520only%2520with%250Aits%2520neighbors%2520over%2520an%2520arbitrary%2520graph%2520topology.%2520We%2520propose%2520two%250Amessage-passing-based%2520approaches%2520for%2520achieving%2520reliable%2520inference%2520via%2520CP%253A%250Aquantile-based%2520distributed%2520conformal%2520prediction%2520%2528Q-DCP%2529%2520and%2520histogram-based%250Adistributed%2520conformal%2520prediction%2520%2528H-DCP%2529.%2520Q-DCP%2520employs%2520distributed%2520quantile%250Aregression%2520enhanced%2520with%2520tailored%2520smoothing%2520and%2520regularization%2520terms%2520to%250Aaccelerate%2520convergence%252C%2520while%2520H-DCP%2520uses%2520a%2520consensus-based%2520histogram%2520estimation%250Aapproach.%2520Through%2520extensive%2520experiments%252C%2520we%2520investigate%2520the%2520trade-offs%2520between%250Ahyperparameter%2520tuning%2520requirements%252C%2520communication%2520overhead%252C%2520coverage%250Aguarantees%252C%2520and%2520prediction%2520set%2520sizes%2520across%2520different%2520network%2520topologies.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14544v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Distributed%20Conformal%20Prediction%20via%20Message%20Passing&entry.906535625=Haifeng%20Wen%20and%20Hong%20Xing%20and%20Osvaldo%20Simeone&entry.1292438233=%20%20Post-hoc%20calibration%20of%20pre-trained%20models%20is%20critical%20for%20ensuring%20reliable%0Ainference%2C%20especially%20in%20safety-critical%20domains%20such%20as%20healthcare.%20Conformal%0APrediction%20%28CP%29%20offers%20a%20robust%20post-hoc%20calibration%20framework%2C%20providing%0Adistribution-free%20statistical%20coverage%20guarantees%20for%20prediction%20sets%20by%0Aleveraging%20held-out%20datasets.%20In%20this%20work%2C%20we%20address%20a%20decentralized%20setting%0Awhere%20each%20device%20has%20limited%20calibration%20data%20and%20can%20communicate%20only%20with%0Aits%20neighbors%20over%20an%20arbitrary%20graph%20topology.%20We%20propose%20two%0Amessage-passing-based%20approaches%20for%20achieving%20reliable%20inference%20via%20CP%3A%0Aquantile-based%20distributed%20conformal%20prediction%20%28Q-DCP%29%20and%20histogram-based%0Adistributed%20conformal%20prediction%20%28H-DCP%29.%20Q-DCP%20employs%20distributed%20quantile%0Aregression%20enhanced%20with%20tailored%20smoothing%20and%20regularization%20terms%20to%0Aaccelerate%20convergence%2C%20while%20H-DCP%20uses%20a%20consensus-based%20histogram%20estimation%0Aapproach.%20Through%20extensive%20experiments%2C%20we%20investigate%20the%20trade-offs%20between%0Ahyperparameter%20tuning%20requirements%2C%20communication%20overhead%2C%20coverage%0Aguarantees%2C%20and%20prediction%20set%20sizes%20across%20different%20network%20topologies.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14544v1&entry.124074799=Read"},
{"title": "Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV\n  Networks", "author": "Sankani Sarathchandra and Eslam Eldeeb and Mohammad Shehab and Hirley Alves and Konstantin Mikhaylov and Mohamed-Slim Alouini", "abstract": "  Age-of-information (AoI) and transmission power are crucial performance\nmetrics in low energy wireless networks, where information freshness is of\nparamount importance. This study examines a power-limited internet of things\n(IoT) network supported by a flying unmanned aerial vehicle(UAV) that collects\ndata. Our aim is to optimize the UAV flight trajectory and scheduling policy to\nminimize a varying AoI and transmission power combination. To tackle this\nvariation, this paper proposes a meta-deep reinforcement learning (RL) approach\nthat integrates deep Q-networks (DQNs) with model-agnostic meta-learning\n(MAML). DQNs determine optimal UAV decisions, while MAML enables scalability\nacross varying objective functions. Numerical results indicate that the\nproposed algorithm converges faster and adapts to new objectives more\neffectively than traditional deep RL methods, achieving minimal AoI and\ntransmission power overall.\n", "link": "http://arxiv.org/abs/2501.14603v1", "date": "2025-01-24", "relevancy": 1.8921, "topK": [{"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.4765}, {"title": "Safe and efficient training of a control agent", "link": "https://patents.google.com/patent/US11709462B2/en", "similarity": 0.4711}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4692}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Age%20and%20Power%20Minimization%20via%20Meta-Deep%20Reinforcement%20Learning%20in%20UAV%0A%20%20Networks&body=Title%3A%20Age%20and%20Power%20Minimization%20via%20Meta-Deep%20Reinforcement%20Learning%20in%20UAV%0A%20%20Networks%0AAuthor%3A%20Sankani%20Sarathchandra%20and%20Eslam%20Eldeeb%20and%20Mohammad%20Shehab%20and%20Hirley%20Alves%20and%20Konstantin%20Mikhaylov%20and%20Mohamed-Slim%20Alouini%0AAbstract%3A%20%20%20Age-of-information%20%28AoI%29%20and%20transmission%20power%20are%20crucial%20performance%0Ametrics%20in%20low%20energy%20wireless%20networks%2C%20where%20information%20freshness%20is%20of%0Aparamount%20importance.%20This%20study%20examines%20a%20power-limited%20internet%20of%20things%0A%28IoT%29%20network%20supported%20by%20a%20flying%20unmanned%20aerial%20vehicle%28UAV%29%20that%20collects%0Adata.%20Our%20aim%20is%20to%20optimize%20the%20UAV%20flight%20trajectory%20and%20scheduling%20policy%20to%0Aminimize%20a%20varying%20AoI%20and%20transmission%20power%20combination.%20To%20tackle%20this%0Avariation%2C%20this%20paper%20proposes%20a%20meta-deep%20reinforcement%20learning%20%28RL%29%20approach%0Athat%20integrates%20deep%20Q-networks%20%28DQNs%29%20with%20model-agnostic%20meta-learning%0A%28MAML%29.%20DQNs%20determine%20optimal%20UAV%20decisions%2C%20while%20MAML%20enables%20scalability%0Aacross%20varying%20objective%20functions.%20Numerical%20results%20indicate%20that%20the%0Aproposed%20algorithm%20converges%20faster%20and%20adapts%20to%20new%20objectives%20more%0Aeffectively%20than%20traditional%20deep%20RL%20methods%2C%20achieving%20minimal%20AoI%20and%0Atransmission%20power%20overall.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14603v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DAge%2520and%2520Power%2520Minimization%2520via%2520Meta-Deep%2520Reinforcement%2520Learning%2520in%2520UAV%250A%2520%2520Networks%26entry.906535625%3DSankani%2520Sarathchandra%2520and%2520Eslam%2520Eldeeb%2520and%2520Mohammad%2520Shehab%2520and%2520Hirley%2520Alves%2520and%2520Konstantin%2520Mikhaylov%2520and%2520Mohamed-Slim%2520Alouini%26entry.1292438233%3D%2520%2520Age-of-information%2520%2528AoI%2529%2520and%2520transmission%2520power%2520are%2520crucial%2520performance%250Ametrics%2520in%2520low%2520energy%2520wireless%2520networks%252C%2520where%2520information%2520freshness%2520is%2520of%250Aparamount%2520importance.%2520This%2520study%2520examines%2520a%2520power-limited%2520internet%2520of%2520things%250A%2528IoT%2529%2520network%2520supported%2520by%2520a%2520flying%2520unmanned%2520aerial%2520vehicle%2528UAV%2529%2520that%2520collects%250Adata.%2520Our%2520aim%2520is%2520to%2520optimize%2520the%2520UAV%2520flight%2520trajectory%2520and%2520scheduling%2520policy%2520to%250Aminimize%2520a%2520varying%2520AoI%2520and%2520transmission%2520power%2520combination.%2520To%2520tackle%2520this%250Avariation%252C%2520this%2520paper%2520proposes%2520a%2520meta-deep%2520reinforcement%2520learning%2520%2528RL%2529%2520approach%250Athat%2520integrates%2520deep%2520Q-networks%2520%2528DQNs%2529%2520with%2520model-agnostic%2520meta-learning%250A%2528MAML%2529.%2520DQNs%2520determine%2520optimal%2520UAV%2520decisions%252C%2520while%2520MAML%2520enables%2520scalability%250Aacross%2520varying%2520objective%2520functions.%2520Numerical%2520results%2520indicate%2520that%2520the%250Aproposed%2520algorithm%2520converges%2520faster%2520and%2520adapts%2520to%2520new%2520objectives%2520more%250Aeffectively%2520than%2520traditional%2520deep%2520RL%2520methods%252C%2520achieving%2520minimal%2520AoI%2520and%250Atransmission%2520power%2520overall.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14603v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Age%20and%20Power%20Minimization%20via%20Meta-Deep%20Reinforcement%20Learning%20in%20UAV%0A%20%20Networks&entry.906535625=Sankani%20Sarathchandra%20and%20Eslam%20Eldeeb%20and%20Mohammad%20Shehab%20and%20Hirley%20Alves%20and%20Konstantin%20Mikhaylov%20and%20Mohamed-Slim%20Alouini&entry.1292438233=%20%20Age-of-information%20%28AoI%29%20and%20transmission%20power%20are%20crucial%20performance%0Ametrics%20in%20low%20energy%20wireless%20networks%2C%20where%20information%20freshness%20is%20of%0Aparamount%20importance.%20This%20study%20examines%20a%20power-limited%20internet%20of%20things%0A%28IoT%29%20network%20supported%20by%20a%20flying%20unmanned%20aerial%20vehicle%28UAV%29%20that%20collects%0Adata.%20Our%20aim%20is%20to%20optimize%20the%20UAV%20flight%20trajectory%20and%20scheduling%20policy%20to%0Aminimize%20a%20varying%20AoI%20and%20transmission%20power%20combination.%20To%20tackle%20this%0Avariation%2C%20this%20paper%20proposes%20a%20meta-deep%20reinforcement%20learning%20%28RL%29%20approach%0Athat%20integrates%20deep%20Q-networks%20%28DQNs%29%20with%20model-agnostic%20meta-learning%0A%28MAML%29.%20DQNs%20determine%20optimal%20UAV%20decisions%2C%20while%20MAML%20enables%20scalability%0Aacross%20varying%20objective%20functions.%20Numerical%20results%20indicate%20that%20the%0Aproposed%20algorithm%20converges%20faster%20and%20adapts%20to%20new%20objectives%20more%0Aeffectively%20than%20traditional%20deep%20RL%20methods%2C%20achieving%20minimal%20AoI%20and%0Atransmission%20power%20overall.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14603v1&entry.124074799=Read"},
{"title": "The Karp Dataset", "author": "Mason DiCicco and Eamon Worden and Conner Olsen and Nikhil Gangaram and Daniel Reichman and Neil Heffernan", "abstract": "  Understanding the mathematical reasoning capabilities of Large Language\nModels (LLMs) is a central topic in the study of artificial intelligence. This\nnew domain necessitates the creation of datasets of reasoning tasks for both\ntraining and benchmarking the performance of LLMs. To this end, we introduce\nthe Karp dataset: The first dataset composed of detailed proofs of\nNP-completeness reductions. The reductions vary in difficulty, ranging from\nsimple exercises of undergraduate courses to more challenging reductions from\nacademic papers. We compare the performance of state-of-the-art models on this\ntask and demonstrate the effect of fine-tuning with the Karp dataset on\nreasoning capacity.\n", "link": "http://arxiv.org/abs/2501.14705v1", "date": "2025-01-24", "relevancy": 1.8676, "topK": [{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4745}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4745}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.429}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20The%20Karp%20Dataset&body=Title%3A%20The%20Karp%20Dataset%0AAuthor%3A%20Mason%20DiCicco%20and%20Eamon%20Worden%20and%20Conner%20Olsen%20and%20Nikhil%20Gangaram%20and%20Daniel%20Reichman%20and%20Neil%20Heffernan%0AAbstract%3A%20%20%20Understanding%20the%20mathematical%20reasoning%20capabilities%20of%20Large%20Language%0AModels%20%28LLMs%29%20is%20a%20central%20topic%20in%20the%20study%20of%20artificial%20intelligence.%20This%0Anew%20domain%20necessitates%20the%20creation%20of%20datasets%20of%20reasoning%20tasks%20for%20both%0Atraining%20and%20benchmarking%20the%20performance%20of%20LLMs.%20To%20this%20end%2C%20we%20introduce%0Athe%20Karp%20dataset%3A%20The%20first%20dataset%20composed%20of%20detailed%20proofs%20of%0ANP-completeness%20reductions.%20The%20reductions%20vary%20in%20difficulty%2C%20ranging%20from%0Asimple%20exercises%20of%20undergraduate%20courses%20to%20more%20challenging%20reductions%20from%0Aacademic%20papers.%20We%20compare%20the%20performance%20of%20state-of-the-art%20models%20on%20this%0Atask%20and%20demonstrate%20the%20effect%20of%20fine-tuning%20with%20the%20Karp%20dataset%20on%0Areasoning%20capacity.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14705v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DThe%2520Karp%2520Dataset%26entry.906535625%3DMason%2520DiCicco%2520and%2520Eamon%2520Worden%2520and%2520Conner%2520Olsen%2520and%2520Nikhil%2520Gangaram%2520and%2520Daniel%2520Reichman%2520and%2520Neil%2520Heffernan%26entry.1292438233%3D%2520%2520Understanding%2520the%2520mathematical%2520reasoning%2520capabilities%2520of%2520Large%2520Language%250AModels%2520%2528LLMs%2529%2520is%2520a%2520central%2520topic%2520in%2520the%2520study%2520of%2520artificial%2520intelligence.%2520This%250Anew%2520domain%2520necessitates%2520the%2520creation%2520of%2520datasets%2520of%2520reasoning%2520tasks%2520for%2520both%250Atraining%2520and%2520benchmarking%2520the%2520performance%2520of%2520LLMs.%2520To%2520this%2520end%252C%2520we%2520introduce%250Athe%2520Karp%2520dataset%253A%2520The%2520first%2520dataset%2520composed%2520of%2520detailed%2520proofs%2520of%250ANP-completeness%2520reductions.%2520The%2520reductions%2520vary%2520in%2520difficulty%252C%2520ranging%2520from%250Asimple%2520exercises%2520of%2520undergraduate%2520courses%2520to%2520more%2520challenging%2520reductions%2520from%250Aacademic%2520papers.%2520We%2520compare%2520the%2520performance%2520of%2520state-of-the-art%2520models%2520on%2520this%250Atask%2520and%2520demonstrate%2520the%2520effect%2520of%2520fine-tuning%2520with%2520the%2520Karp%2520dataset%2520on%250Areasoning%2520capacity.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14705v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=The%20Karp%20Dataset&entry.906535625=Mason%20DiCicco%20and%20Eamon%20Worden%20and%20Conner%20Olsen%20and%20Nikhil%20Gangaram%20and%20Daniel%20Reichman%20and%20Neil%20Heffernan&entry.1292438233=%20%20Understanding%20the%20mathematical%20reasoning%20capabilities%20of%20Large%20Language%0AModels%20%28LLMs%29%20is%20a%20central%20topic%20in%20the%20study%20of%20artificial%20intelligence.%20This%0Anew%20domain%20necessitates%20the%20creation%20of%20datasets%20of%20reasoning%20tasks%20for%20both%0Atraining%20and%20benchmarking%20the%20performance%20of%20LLMs.%20To%20this%20end%2C%20we%20introduce%0Athe%20Karp%20dataset%3A%20The%20first%20dataset%20composed%20of%20detailed%20proofs%20of%0ANP-completeness%20reductions.%20The%20reductions%20vary%20in%20difficulty%2C%20ranging%20from%0Asimple%20exercises%20of%20undergraduate%20courses%20to%20more%20challenging%20reductions%20from%0Aacademic%20papers.%20We%20compare%20the%20performance%20of%20state-of-the-art%20models%20on%20this%0Atask%20and%20demonstrate%20the%20effect%20of%20fine-tuning%20with%20the%20Karp%20dataset%20on%0Areasoning%20capacity.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14705v1&entry.124074799=Read"},
{"title": "Rethinking Table Instruction Tuning", "author": "Naihao Deng and Rada Mihalcea", "abstract": "  Recent advances in table understanding have focused on instruction-tuning\nlarge language models (LLMs) for table-related tasks. However, existing\nresearch has overlooked the impact of hyperparameter choices and lacks a\ncomprehensive evaluation of the out-of-domain table understanding ability and\nthe general capabilities of these table LLMs. In this paper, we evaluate these\nabilities in existing table LLMs, and reveal significant declines in both\nout-of-domain table understanding and general capabilities compared to their\nbase models. Through systematic analysis, we show that hyperparameters, such as\nlearning rate, can significantly influence both table-specific and general\ncapabilities. Contrary to the existing table instruction-tuning works, we\ndemonstrate that smaller learning rates and fewer training instances can\nenhance table understanding while preserving general capabilities. Based on our\nfindings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B\nInstruct, which achieves performance on par with, or surpassing GPT-3.5 and\nGPT-4 on table tasks, while maintaining strong out-of-domain generalization and\ngeneral capabilities. Our findings highlight the potential for reduced data\nannotation costs and more efficient model development through careful\nhyperparameter selection.\n", "link": "http://arxiv.org/abs/2501.14693v1", "date": "2025-01-24", "relevancy": 1.8429, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4931}, {"title": "Breadcrumbs: Adversarial class-balanced sampling for long-tailed recognition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_37", "similarity": 0.4387}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4349}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Rethinking%20Table%20Instruction%20Tuning&body=Title%3A%20Rethinking%20Table%20Instruction%20Tuning%0AAuthor%3A%20Naihao%20Deng%20and%20Rada%20Mihalcea%0AAbstract%3A%20%20%20Recent%20advances%20in%20table%20understanding%20have%20focused%20on%20instruction-tuning%0Alarge%20language%20models%20%28LLMs%29%20for%20table-related%20tasks.%20However%2C%20existing%0Aresearch%20has%20overlooked%20the%20impact%20of%20hyperparameter%20choices%20and%20lacks%20a%0Acomprehensive%20evaluation%20of%20the%20out-of-domain%20table%20understanding%20ability%20and%0Athe%20general%20capabilities%20of%20these%20table%20LLMs.%20In%20this%20paper%2C%20we%20evaluate%20these%0Aabilities%20in%20existing%20table%20LLMs%2C%20and%20reveal%20significant%20declines%20in%20both%0Aout-of-domain%20table%20understanding%20and%20general%20capabilities%20compared%20to%20their%0Abase%20models.%20Through%20systematic%20analysis%2C%20we%20show%20that%20hyperparameters%2C%20such%20as%0Alearning%20rate%2C%20can%20significantly%20influence%20both%20table-specific%20and%20general%0Acapabilities.%20Contrary%20to%20the%20existing%20table%20instruction-tuning%20works%2C%20we%0Ademonstrate%20that%20smaller%20learning%20rates%20and%20fewer%20training%20instances%20can%0Aenhance%20table%20understanding%20while%20preserving%20general%20capabilities.%20Based%20on%20our%0Afindings%2C%20we%20introduce%20TAMA%2C%20a%20TAble%20LLM%20instruction-tuned%20from%20LLaMA%203.1%208B%0AInstruct%2C%20which%20achieves%20performance%20on%20par%20with%2C%20or%20surpassing%20GPT-3.5%20and%0AGPT-4%20on%20table%20tasks%2C%20while%20maintaining%20strong%20out-of-domain%20generalization%20and%0Ageneral%20capabilities.%20Our%20findings%20highlight%20the%20potential%20for%20reduced%20data%0Aannotation%20costs%20and%20more%20efficient%20model%20development%20through%20careful%0Ahyperparameter%20selection.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14693v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRethinking%2520Table%2520Instruction%2520Tuning%26entry.906535625%3DNaihao%2520Deng%2520and%2520Rada%2520Mihalcea%26entry.1292438233%3D%2520%2520Recent%2520advances%2520in%2520table%2520understanding%2520have%2520focused%2520on%2520instruction-tuning%250Alarge%2520language%2520models%2520%2528LLMs%2529%2520for%2520table-related%2520tasks.%2520However%252C%2520existing%250Aresearch%2520has%2520overlooked%2520the%2520impact%2520of%2520hyperparameter%2520choices%2520and%2520lacks%2520a%250Acomprehensive%2520evaluation%2520of%2520the%2520out-of-domain%2520table%2520understanding%2520ability%2520and%250Athe%2520general%2520capabilities%2520of%2520these%2520table%2520LLMs.%2520In%2520this%2520paper%252C%2520we%2520evaluate%2520these%250Aabilities%2520in%2520existing%2520table%2520LLMs%252C%2520and%2520reveal%2520significant%2520declines%2520in%2520both%250Aout-of-domain%2520table%2520understanding%2520and%2520general%2520capabilities%2520compared%2520to%2520their%250Abase%2520models.%2520Through%2520systematic%2520analysis%252C%2520we%2520show%2520that%2520hyperparameters%252C%2520such%2520as%250Alearning%2520rate%252C%2520can%2520significantly%2520influence%2520both%2520table-specific%2520and%2520general%250Acapabilities.%2520Contrary%2520to%2520the%2520existing%2520table%2520instruction-tuning%2520works%252C%2520we%250Ademonstrate%2520that%2520smaller%2520learning%2520rates%2520and%2520fewer%2520training%2520instances%2520can%250Aenhance%2520table%2520understanding%2520while%2520preserving%2520general%2520capabilities.%2520Based%2520on%2520our%250Afindings%252C%2520we%2520introduce%2520TAMA%252C%2520a%2520TAble%2520LLM%2520instruction-tuned%2520from%2520LLaMA%25203.1%25208B%250AInstruct%252C%2520which%2520achieves%2520performance%2520on%2520par%2520with%252C%2520or%2520surpassing%2520GPT-3.5%2520and%250AGPT-4%2520on%2520table%2520tasks%252C%2520while%2520maintaining%2520strong%2520out-of-domain%2520generalization%2520and%250Ageneral%2520capabilities.%2520Our%2520findings%2520highlight%2520the%2520potential%2520for%2520reduced%2520data%250Aannotation%2520costs%2520and%2520more%2520efficient%2520model%2520development%2520through%2520careful%250Ahyperparameter%2520selection.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14693v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Rethinking%20Table%20Instruction%20Tuning&entry.906535625=Naihao%20Deng%20and%20Rada%20Mihalcea&entry.1292438233=%20%20Recent%20advances%20in%20table%20understanding%20have%20focused%20on%20instruction-tuning%0Alarge%20language%20models%20%28LLMs%29%20for%20table-related%20tasks.%20However%2C%20existing%0Aresearch%20has%20overlooked%20the%20impact%20of%20hyperparameter%20choices%20and%20lacks%20a%0Acomprehensive%20evaluation%20of%20the%20out-of-domain%20table%20understanding%20ability%20and%0Athe%20general%20capabilities%20of%20these%20table%20LLMs.%20In%20this%20paper%2C%20we%20evaluate%20these%0Aabilities%20in%20existing%20table%20LLMs%2C%20and%20reveal%20significant%20declines%20in%20both%0Aout-of-domain%20table%20understanding%20and%20general%20capabilities%20compared%20to%20their%0Abase%20models.%20Through%20systematic%20analysis%2C%20we%20show%20that%20hyperparameters%2C%20such%20as%0Alearning%20rate%2C%20can%20significantly%20influence%20both%20table-specific%20and%20general%0Acapabilities.%20Contrary%20to%20the%20existing%20table%20instruction-tuning%20works%2C%20we%0Ademonstrate%20that%20smaller%20learning%20rates%20and%20fewer%20training%20instances%20can%0Aenhance%20table%20understanding%20while%20preserving%20general%20capabilities.%20Based%20on%20our%0Afindings%2C%20we%20introduce%20TAMA%2C%20a%20TAble%20LLM%20instruction-tuned%20from%20LLaMA%203.1%208B%0AInstruct%2C%20which%20achieves%20performance%20on%20par%20with%2C%20or%20surpassing%20GPT-3.5%20and%0AGPT-4%20on%20table%20tasks%2C%20while%20maintaining%20strong%20out-of-domain%20generalization%20and%0Ageneral%20capabilities.%20Our%20findings%20highlight%20the%20potential%20for%20reduced%20data%0Aannotation%20costs%20and%20more%20efficient%20model%20development%20through%20careful%0Ahyperparameter%20selection.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14693v1&entry.124074799=Read"},
{"title": "Decoupled SGDA for Games with Intermittent Strategy Communication", "author": "Ali Zindari and Parham Yazdkhasti and Anton Rodomanov and Tatjana Chavdarova and Sebastian U. Stich", "abstract": "  We focus on reducing communication overhead in multiplayer games, where\nfrequently exchanging strategies between players is not feasible and players\nhave noisy or outdated strategies of the other players. We introduce Decoupled\nSGDA, a novel adaptation of Stochastic Gradient Descent Ascent (SGDA). In this\napproach, players independently update their strategies based on outdated\nopponent strategies, with periodic synchronization to align strategies. For\nStrongly-Convex-Strongly-Concave (SCSC) games, we demonstrate that Decoupled\nSGDA achieves near-optimal communication complexity comparable to the\nbest-known GDA rates. For weakly coupled games where the interaction between\nplayers is lower relative to the non-interactive part of the game, Decoupled\nSGDA significantly reduces communication costs compared to standard SGDA. Our\nfindings extend to multi-player games. To provide insights into the effect of\ncommunication frequency and convergence, we extensively study the convergence\nof Decoupled SGDA for quadratic minimax problems. Lastly, in settings where the\nnoise over the players is imbalanced, Decoupled SGDA significantly outperforms\nfederated minimax methods.\n", "link": "http://arxiv.org/abs/2501.14652v1", "date": "2025-01-24", "relevancy": 1.8259, "topK": [{"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.477}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4457}, {"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.4402}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Decoupled%20SGDA%20for%20Games%20with%20Intermittent%20Strategy%20Communication&body=Title%3A%20Decoupled%20SGDA%20for%20Games%20with%20Intermittent%20Strategy%20Communication%0AAuthor%3A%20Ali%20Zindari%20and%20Parham%20Yazdkhasti%20and%20Anton%20Rodomanov%20and%20Tatjana%20Chavdarova%20and%20Sebastian%20U.%20Stich%0AAbstract%3A%20%20%20We%20focus%20on%20reducing%20communication%20overhead%20in%20multiplayer%20games%2C%20where%0Afrequently%20exchanging%20strategies%20between%20players%20is%20not%20feasible%20and%20players%0Ahave%20noisy%20or%20outdated%20strategies%20of%20the%20other%20players.%20We%20introduce%20Decoupled%0ASGDA%2C%20a%20novel%20adaptation%20of%20Stochastic%20Gradient%20Descent%20Ascent%20%28SGDA%29.%20In%20this%0Aapproach%2C%20players%20independently%20update%20their%20strategies%20based%20on%20outdated%0Aopponent%20strategies%2C%20with%20periodic%20synchronization%20to%20align%20strategies.%20For%0AStrongly-Convex-Strongly-Concave%20%28SCSC%29%20games%2C%20we%20demonstrate%20that%20Decoupled%0ASGDA%20achieves%20near-optimal%20communication%20complexity%20comparable%20to%20the%0Abest-known%20GDA%20rates.%20For%20weakly%20coupled%20games%20where%20the%20interaction%20between%0Aplayers%20is%20lower%20relative%20to%20the%20non-interactive%20part%20of%20the%20game%2C%20Decoupled%0ASGDA%20significantly%20reduces%20communication%20costs%20compared%20to%20standard%20SGDA.%20Our%0Afindings%20extend%20to%20multi-player%20games.%20To%20provide%20insights%20into%20the%20effect%20of%0Acommunication%20frequency%20and%20convergence%2C%20we%20extensively%20study%20the%20convergence%0Aof%20Decoupled%20SGDA%20for%20quadratic%20minimax%20problems.%20Lastly%2C%20in%20settings%20where%20the%0Anoise%20over%20the%20players%20is%20imbalanced%2C%20Decoupled%20SGDA%20significantly%20outperforms%0Afederated%20minimax%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14652v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDecoupled%2520SGDA%2520for%2520Games%2520with%2520Intermittent%2520Strategy%2520Communication%26entry.906535625%3DAli%2520Zindari%2520and%2520Parham%2520Yazdkhasti%2520and%2520Anton%2520Rodomanov%2520and%2520Tatjana%2520Chavdarova%2520and%2520Sebastian%2520U.%2520Stich%26entry.1292438233%3D%2520%2520We%2520focus%2520on%2520reducing%2520communication%2520overhead%2520in%2520multiplayer%2520games%252C%2520where%250Afrequently%2520exchanging%2520strategies%2520between%2520players%2520is%2520not%2520feasible%2520and%2520players%250Ahave%2520noisy%2520or%2520outdated%2520strategies%2520of%2520the%2520other%2520players.%2520We%2520introduce%2520Decoupled%250ASGDA%252C%2520a%2520novel%2520adaptation%2520of%2520Stochastic%2520Gradient%2520Descent%2520Ascent%2520%2528SGDA%2529.%2520In%2520this%250Aapproach%252C%2520players%2520independently%2520update%2520their%2520strategies%2520based%2520on%2520outdated%250Aopponent%2520strategies%252C%2520with%2520periodic%2520synchronization%2520to%2520align%2520strategies.%2520For%250AStrongly-Convex-Strongly-Concave%2520%2528SCSC%2529%2520games%252C%2520we%2520demonstrate%2520that%2520Decoupled%250ASGDA%2520achieves%2520near-optimal%2520communication%2520complexity%2520comparable%2520to%2520the%250Abest-known%2520GDA%2520rates.%2520For%2520weakly%2520coupled%2520games%2520where%2520the%2520interaction%2520between%250Aplayers%2520is%2520lower%2520relative%2520to%2520the%2520non-interactive%2520part%2520of%2520the%2520game%252C%2520Decoupled%250ASGDA%2520significantly%2520reduces%2520communication%2520costs%2520compared%2520to%2520standard%2520SGDA.%2520Our%250Afindings%2520extend%2520to%2520multi-player%2520games.%2520To%2520provide%2520insights%2520into%2520the%2520effect%2520of%250Acommunication%2520frequency%2520and%2520convergence%252C%2520we%2520extensively%2520study%2520the%2520convergence%250Aof%2520Decoupled%2520SGDA%2520for%2520quadratic%2520minimax%2520problems.%2520Lastly%252C%2520in%2520settings%2520where%2520the%250Anoise%2520over%2520the%2520players%2520is%2520imbalanced%252C%2520Decoupled%2520SGDA%2520significantly%2520outperforms%250Afederated%2520minimax%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14652v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Decoupled%20SGDA%20for%20Games%20with%20Intermittent%20Strategy%20Communication&entry.906535625=Ali%20Zindari%20and%20Parham%20Yazdkhasti%20and%20Anton%20Rodomanov%20and%20Tatjana%20Chavdarova%20and%20Sebastian%20U.%20Stich&entry.1292438233=%20%20We%20focus%20on%20reducing%20communication%20overhead%20in%20multiplayer%20games%2C%20where%0Afrequently%20exchanging%20strategies%20between%20players%20is%20not%20feasible%20and%20players%0Ahave%20noisy%20or%20outdated%20strategies%20of%20the%20other%20players.%20We%20introduce%20Decoupled%0ASGDA%2C%20a%20novel%20adaptation%20of%20Stochastic%20Gradient%20Descent%20Ascent%20%28SGDA%29.%20In%20this%0Aapproach%2C%20players%20independently%20update%20their%20strategies%20based%20on%20outdated%0Aopponent%20strategies%2C%20with%20periodic%20synchronization%20to%20align%20strategies.%20For%0AStrongly-Convex-Strongly-Concave%20%28SCSC%29%20games%2C%20we%20demonstrate%20that%20Decoupled%0ASGDA%20achieves%20near-optimal%20communication%20complexity%20comparable%20to%20the%0Abest-known%20GDA%20rates.%20For%20weakly%20coupled%20games%20where%20the%20interaction%20between%0Aplayers%20is%20lower%20relative%20to%20the%20non-interactive%20part%20of%20the%20game%2C%20Decoupled%0ASGDA%20significantly%20reduces%20communication%20costs%20compared%20to%20standard%20SGDA.%20Our%0Afindings%20extend%20to%20multi-player%20games.%20To%20provide%20insights%20into%20the%20effect%20of%0Acommunication%20frequency%20and%20convergence%2C%20we%20extensively%20study%20the%20convergence%0Aof%20Decoupled%20SGDA%20for%20quadratic%20minimax%20problems.%20Lastly%2C%20in%20settings%20where%20the%0Anoise%20over%20the%20players%20is%20imbalanced%2C%20Decoupled%20SGDA%20significantly%20outperforms%0Afederated%20minimax%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14652v1&entry.124074799=Read"},
{"title": "Modyn: Data-Centric Machine Learning Pipeline Orchestration", "author": "Maximilian B\u00f6ther and Ties Robroek and Viktor Gsteiger and Robin Holzinger and Xianzhe Ma and P\u0131nar T\u00f6z\u00fcn and Ana Klimovic", "abstract": "  In real-world machine learning (ML) pipelines, datasets are continuously\ngrowing. Models must incorporate this new training data to improve\ngeneralization and adapt to potential distribution shifts. The cost of model\nretraining is proportional to how frequently the model is retrained and how\nmuch data it is trained on, which makes the naive approach of retraining from\nscratch each time impractical.\n  We present Modyn, a data-centric end-to-end machine learning platform.\nModyn's ML pipeline abstraction enables users to declaratively describe\npolicies for continuously training a model on a growing dataset. Modyn\npipelines allow users to apply data selection policies (to reduce the number of\ndata points) and triggering policies (to reduce the number of trainings). Modyn\nexecutes and orchestrates these continuous ML training pipelines. The system is\nopen-source and comes with an ecosystem of benchmark datasets, models, and\ntooling. We formally discuss how to measure the performance of ML pipelines by\nintroducing the concept of composite models, enabling fair comparison of\npipelines with different data selection and triggering policies. We empirically\nanalyze how various data selection and triggering policies impact model\naccuracy, and also show that Modyn enables high throughput training with\nsample-level data selection.\n", "link": "http://arxiv.org/abs/2312.06254v3", "date": "2025-01-24", "relevancy": 1.8041, "topK": [{"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4592}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.4495}, {"title": "Synthesizing Moving People with 3D Control", "link": "http://arxiv.org/abs/2401.10889v2", "similarity": 0.4493}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Modyn%3A%20Data-Centric%20Machine%20Learning%20Pipeline%20Orchestration&body=Title%3A%20Modyn%3A%20Data-Centric%20Machine%20Learning%20Pipeline%20Orchestration%0AAuthor%3A%20Maximilian%20B%C3%B6ther%20and%20Ties%20Robroek%20and%20Viktor%20Gsteiger%20and%20Robin%20Holzinger%20and%20Xianzhe%20Ma%20and%20P%C4%B1nar%20T%C3%B6z%C3%BCn%20and%20Ana%20Klimovic%0AAbstract%3A%20%20%20In%20real-world%20machine%20learning%20%28ML%29%20pipelines%2C%20datasets%20are%20continuously%0Agrowing.%20Models%20must%20incorporate%20this%20new%20training%20data%20to%20improve%0Ageneralization%20and%20adapt%20to%20potential%20distribution%20shifts.%20The%20cost%20of%20model%0Aretraining%20is%20proportional%20to%20how%20frequently%20the%20model%20is%20retrained%20and%20how%0Amuch%20data%20it%20is%20trained%20on%2C%20which%20makes%20the%20naive%20approach%20of%20retraining%20from%0Ascratch%20each%20time%20impractical.%0A%20%20We%20present%20Modyn%2C%20a%20data-centric%20end-to-end%20machine%20learning%20platform.%0AModyn%27s%20ML%20pipeline%20abstraction%20enables%20users%20to%20declaratively%20describe%0Apolicies%20for%20continuously%20training%20a%20model%20on%20a%20growing%20dataset.%20Modyn%0Apipelines%20allow%20users%20to%20apply%20data%20selection%20policies%20%28to%20reduce%20the%20number%20of%0Adata%20points%29%20and%20triggering%20policies%20%28to%20reduce%20the%20number%20of%20trainings%29.%20Modyn%0Aexecutes%20and%20orchestrates%20these%20continuous%20ML%20training%20pipelines.%20The%20system%20is%0Aopen-source%20and%20comes%20with%20an%20ecosystem%20of%20benchmark%20datasets%2C%20models%2C%20and%0Atooling.%20We%20formally%20discuss%20how%20to%20measure%20the%20performance%20of%20ML%20pipelines%20by%0Aintroducing%20the%20concept%20of%20composite%20models%2C%20enabling%20fair%20comparison%20of%0Apipelines%20with%20different%20data%20selection%20and%20triggering%20policies.%20We%20empirically%0Aanalyze%20how%20various%20data%20selection%20and%20triggering%20policies%20impact%20model%0Aaccuracy%2C%20and%20also%20show%20that%20Modyn%20enables%20high%20throughput%20training%20with%0Asample-level%20data%20selection.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2312.06254v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DModyn%253A%2520Data-Centric%2520Machine%2520Learning%2520Pipeline%2520Orchestration%26entry.906535625%3DMaximilian%2520B%25C3%25B6ther%2520and%2520Ties%2520Robroek%2520and%2520Viktor%2520Gsteiger%2520and%2520Robin%2520Holzinger%2520and%2520Xianzhe%2520Ma%2520and%2520P%25C4%25B1nar%2520T%25C3%25B6z%25C3%25BCn%2520and%2520Ana%2520Klimovic%26entry.1292438233%3D%2520%2520In%2520real-world%2520machine%2520learning%2520%2528ML%2529%2520pipelines%252C%2520datasets%2520are%2520continuously%250Agrowing.%2520Models%2520must%2520incorporate%2520this%2520new%2520training%2520data%2520to%2520improve%250Ageneralization%2520and%2520adapt%2520to%2520potential%2520distribution%2520shifts.%2520The%2520cost%2520of%2520model%250Aretraining%2520is%2520proportional%2520to%2520how%2520frequently%2520the%2520model%2520is%2520retrained%2520and%2520how%250Amuch%2520data%2520it%2520is%2520trained%2520on%252C%2520which%2520makes%2520the%2520naive%2520approach%2520of%2520retraining%2520from%250Ascratch%2520each%2520time%2520impractical.%250A%2520%2520We%2520present%2520Modyn%252C%2520a%2520data-centric%2520end-to-end%2520machine%2520learning%2520platform.%250AModyn%2527s%2520ML%2520pipeline%2520abstraction%2520enables%2520users%2520to%2520declaratively%2520describe%250Apolicies%2520for%2520continuously%2520training%2520a%2520model%2520on%2520a%2520growing%2520dataset.%2520Modyn%250Apipelines%2520allow%2520users%2520to%2520apply%2520data%2520selection%2520policies%2520%2528to%2520reduce%2520the%2520number%2520of%250Adata%2520points%2529%2520and%2520triggering%2520policies%2520%2528to%2520reduce%2520the%2520number%2520of%2520trainings%2529.%2520Modyn%250Aexecutes%2520and%2520orchestrates%2520these%2520continuous%2520ML%2520training%2520pipelines.%2520The%2520system%2520is%250Aopen-source%2520and%2520comes%2520with%2520an%2520ecosystem%2520of%2520benchmark%2520datasets%252C%2520models%252C%2520and%250Atooling.%2520We%2520formally%2520discuss%2520how%2520to%2520measure%2520the%2520performance%2520of%2520ML%2520pipelines%2520by%250Aintroducing%2520the%2520concept%2520of%2520composite%2520models%252C%2520enabling%2520fair%2520comparison%2520of%250Apipelines%2520with%2520different%2520data%2520selection%2520and%2520triggering%2520policies.%2520We%2520empirically%250Aanalyze%2520how%2520various%2520data%2520selection%2520and%2520triggering%2520policies%2520impact%2520model%250Aaccuracy%252C%2520and%2520also%2520show%2520that%2520Modyn%2520enables%2520high%2520throughput%2520training%2520with%250Asample-level%2520data%2520selection.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2312.06254v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Modyn%3A%20Data-Centric%20Machine%20Learning%20Pipeline%20Orchestration&entry.906535625=Maximilian%20B%C3%B6ther%20and%20Ties%20Robroek%20and%20Viktor%20Gsteiger%20and%20Robin%20Holzinger%20and%20Xianzhe%20Ma%20and%20P%C4%B1nar%20T%C3%B6z%C3%BCn%20and%20Ana%20Klimovic&entry.1292438233=%20%20In%20real-world%20machine%20learning%20%28ML%29%20pipelines%2C%20datasets%20are%20continuously%0Agrowing.%20Models%20must%20incorporate%20this%20new%20training%20data%20to%20improve%0Ageneralization%20and%20adapt%20to%20potential%20distribution%20shifts.%20The%20cost%20of%20model%0Aretraining%20is%20proportional%20to%20how%20frequently%20the%20model%20is%20retrained%20and%20how%0Amuch%20data%20it%20is%20trained%20on%2C%20which%20makes%20the%20naive%20approach%20of%20retraining%20from%0Ascratch%20each%20time%20impractical.%0A%20%20We%20present%20Modyn%2C%20a%20data-centric%20end-to-end%20machine%20learning%20platform.%0AModyn%27s%20ML%20pipeline%20abstraction%20enables%20users%20to%20declaratively%20describe%0Apolicies%20for%20continuously%20training%20a%20model%20on%20a%20growing%20dataset.%20Modyn%0Apipelines%20allow%20users%20to%20apply%20data%20selection%20policies%20%28to%20reduce%20the%20number%20of%0Adata%20points%29%20and%20triggering%20policies%20%28to%20reduce%20the%20number%20of%20trainings%29.%20Modyn%0Aexecutes%20and%20orchestrates%20these%20continuous%20ML%20training%20pipelines.%20The%20system%20is%0Aopen-source%20and%20comes%20with%20an%20ecosystem%20of%20benchmark%20datasets%2C%20models%2C%20and%0Atooling.%20We%20formally%20discuss%20how%20to%20measure%20the%20performance%20of%20ML%20pipelines%20by%0Aintroducing%20the%20concept%20of%20composite%20models%2C%20enabling%20fair%20comparison%20of%0Apipelines%20with%20different%20data%20selection%20and%20triggering%20policies.%20We%20empirically%0Aanalyze%20how%20various%20data%20selection%20and%20triggering%20policies%20impact%20model%0Aaccuracy%2C%20and%20also%20show%20that%20Modyn%20enables%20high%20throughput%20training%20with%0Asample-level%20data%20selection.%0A&entry.1838667208=http%3A//arxiv.org/abs/2312.06254v3&entry.124074799=Read"},
{"title": "Fairness of Deep Ensembles: On the interplay between per-group task\n  difficulty and under-representation", "author": "Estanislao Claucich and Sara Hooker and Diego H. Milone and Enzo Ferrante and Rodrigo Echeveste", "abstract": "  Ensembling is commonly regarded as an effective way to improve the general\nperformance of models in machine learning, while also increasing the robustness\nof predictions. When it comes to algorithmic fairness, heterogeneous ensembles,\ncomposed of multiple model types, have been employed to mitigate biases in\nterms of demographic attributes such as sex, age or ethnicity. Moreover, recent\nwork has shown how in multi-class problems even simple homogeneous ensembles\nmay favor performance of the worst-performing target classes. While homogeneous\nensembles are simpler to implement in practice, it is not yet clear whether\ntheir benefits translate to groups defined not in terms of their target class,\nbut in terms of demographic or protected attributes, hence improving fairness.\nIn this work we show how this simple and straightforward method is indeed able\nto mitigate disparities, particularly benefiting under-performing subgroups.\nInterestingly, this can be achieved without sacrificing overall performance,\nwhich is a common trade-off observed in bias mitigation strategies. Moreover,\nwe analyzed the interplay between two factors which may result in biases:\nsub-group under-representation and the inherent difficulty of the task for each\ngroup. These results revealed that, contrary to popular assumptions, having\nbalanced datasets may be suboptimal if the task difficulty varies between\nsubgroups. Indeed, we found that a perfectly balanced dataset may hurt both the\noverall performance and the gap between groups. This highlights the importance\nof considering the interaction between multiple forces at play in fairness.\n", "link": "http://arxiv.org/abs/2501.14551v1", "date": "2025-01-24", "relevancy": 1.8021, "topK": [{"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.4761}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4454}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4454}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Fairness%20of%20Deep%20Ensembles%3A%20On%20the%20interplay%20between%20per-group%20task%0A%20%20difficulty%20and%20under-representation&body=Title%3A%20Fairness%20of%20Deep%20Ensembles%3A%20On%20the%20interplay%20between%20per-group%20task%0A%20%20difficulty%20and%20under-representation%0AAuthor%3A%20Estanislao%20Claucich%20and%20Sara%20Hooker%20and%20Diego%20H.%20Milone%20and%20Enzo%20Ferrante%20and%20Rodrigo%20Echeveste%0AAbstract%3A%20%20%20Ensembling%20is%20commonly%20regarded%20as%20an%20effective%20way%20to%20improve%20the%20general%0Aperformance%20of%20models%20in%20machine%20learning%2C%20while%20also%20increasing%20the%20robustness%0Aof%20predictions.%20When%20it%20comes%20to%20algorithmic%20fairness%2C%20heterogeneous%20ensembles%2C%0Acomposed%20of%20multiple%20model%20types%2C%20have%20been%20employed%20to%20mitigate%20biases%20in%0Aterms%20of%20demographic%20attributes%20such%20as%20sex%2C%20age%20or%20ethnicity.%20Moreover%2C%20recent%0Awork%20has%20shown%20how%20in%20multi-class%20problems%20even%20simple%20homogeneous%20ensembles%0Amay%20favor%20performance%20of%20the%20worst-performing%20target%20classes.%20While%20homogeneous%0Aensembles%20are%20simpler%20to%20implement%20in%20practice%2C%20it%20is%20not%20yet%20clear%20whether%0Atheir%20benefits%20translate%20to%20groups%20defined%20not%20in%20terms%20of%20their%20target%20class%2C%0Abut%20in%20terms%20of%20demographic%20or%20protected%20attributes%2C%20hence%20improving%20fairness.%0AIn%20this%20work%20we%20show%20how%20this%20simple%20and%20straightforward%20method%20is%20indeed%20able%0Ato%20mitigate%20disparities%2C%20particularly%20benefiting%20under-performing%20subgroups.%0AInterestingly%2C%20this%20can%20be%20achieved%20without%20sacrificing%20overall%20performance%2C%0Awhich%20is%20a%20common%20trade-off%20observed%20in%20bias%20mitigation%20strategies.%20Moreover%2C%0Awe%20analyzed%20the%20interplay%20between%20two%20factors%20which%20may%20result%20in%20biases%3A%0Asub-group%20under-representation%20and%20the%20inherent%20difficulty%20of%20the%20task%20for%20each%0Agroup.%20These%20results%20revealed%20that%2C%20contrary%20to%20popular%20assumptions%2C%20having%0Abalanced%20datasets%20may%20be%20suboptimal%20if%20the%20task%20difficulty%20varies%20between%0Asubgroups.%20Indeed%2C%20we%20found%20that%20a%20perfectly%20balanced%20dataset%20may%20hurt%20both%20the%0Aoverall%20performance%20and%20the%20gap%20between%20groups.%20This%20highlights%20the%20importance%0Aof%20considering%20the%20interaction%20between%20multiple%20forces%20at%20play%20in%20fairness.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14551v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DFairness%2520of%2520Deep%2520Ensembles%253A%2520On%2520the%2520interplay%2520between%2520per-group%2520task%250A%2520%2520difficulty%2520and%2520under-representation%26entry.906535625%3DEstanislao%2520Claucich%2520and%2520Sara%2520Hooker%2520and%2520Diego%2520H.%2520Milone%2520and%2520Enzo%2520Ferrante%2520and%2520Rodrigo%2520Echeveste%26entry.1292438233%3D%2520%2520Ensembling%2520is%2520commonly%2520regarded%2520as%2520an%2520effective%2520way%2520to%2520improve%2520the%2520general%250Aperformance%2520of%2520models%2520in%2520machine%2520learning%252C%2520while%2520also%2520increasing%2520the%2520robustness%250Aof%2520predictions.%2520When%2520it%2520comes%2520to%2520algorithmic%2520fairness%252C%2520heterogeneous%2520ensembles%252C%250Acomposed%2520of%2520multiple%2520model%2520types%252C%2520have%2520been%2520employed%2520to%2520mitigate%2520biases%2520in%250Aterms%2520of%2520demographic%2520attributes%2520such%2520as%2520sex%252C%2520age%2520or%2520ethnicity.%2520Moreover%252C%2520recent%250Awork%2520has%2520shown%2520how%2520in%2520multi-class%2520problems%2520even%2520simple%2520homogeneous%2520ensembles%250Amay%2520favor%2520performance%2520of%2520the%2520worst-performing%2520target%2520classes.%2520While%2520homogeneous%250Aensembles%2520are%2520simpler%2520to%2520implement%2520in%2520practice%252C%2520it%2520is%2520not%2520yet%2520clear%2520whether%250Atheir%2520benefits%2520translate%2520to%2520groups%2520defined%2520not%2520in%2520terms%2520of%2520their%2520target%2520class%252C%250Abut%2520in%2520terms%2520of%2520demographic%2520or%2520protected%2520attributes%252C%2520hence%2520improving%2520fairness.%250AIn%2520this%2520work%2520we%2520show%2520how%2520this%2520simple%2520and%2520straightforward%2520method%2520is%2520indeed%2520able%250Ato%2520mitigate%2520disparities%252C%2520particularly%2520benefiting%2520under-performing%2520subgroups.%250AInterestingly%252C%2520this%2520can%2520be%2520achieved%2520without%2520sacrificing%2520overall%2520performance%252C%250Awhich%2520is%2520a%2520common%2520trade-off%2520observed%2520in%2520bias%2520mitigation%2520strategies.%2520Moreover%252C%250Awe%2520analyzed%2520the%2520interplay%2520between%2520two%2520factors%2520which%2520may%2520result%2520in%2520biases%253A%250Asub-group%2520under-representation%2520and%2520the%2520inherent%2520difficulty%2520of%2520the%2520task%2520for%2520each%250Agroup.%2520These%2520results%2520revealed%2520that%252C%2520contrary%2520to%2520popular%2520assumptions%252C%2520having%250Abalanced%2520datasets%2520may%2520be%2520suboptimal%2520if%2520the%2520task%2520difficulty%2520varies%2520between%250Asubgroups.%2520Indeed%252C%2520we%2520found%2520that%2520a%2520perfectly%2520balanced%2520dataset%2520may%2520hurt%2520both%2520the%250Aoverall%2520performance%2520and%2520the%2520gap%2520between%2520groups.%2520This%2520highlights%2520the%2520importance%250Aof%2520considering%2520the%2520interaction%2520between%2520multiple%2520forces%2520at%2520play%2520in%2520fairness.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14551v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Fairness%20of%20Deep%20Ensembles%3A%20On%20the%20interplay%20between%20per-group%20task%0A%20%20difficulty%20and%20under-representation&entry.906535625=Estanislao%20Claucich%20and%20Sara%20Hooker%20and%20Diego%20H.%20Milone%20and%20Enzo%20Ferrante%20and%20Rodrigo%20Echeveste&entry.1292438233=%20%20Ensembling%20is%20commonly%20regarded%20as%20an%20effective%20way%20to%20improve%20the%20general%0Aperformance%20of%20models%20in%20machine%20learning%2C%20while%20also%20increasing%20the%20robustness%0Aof%20predictions.%20When%20it%20comes%20to%20algorithmic%20fairness%2C%20heterogeneous%20ensembles%2C%0Acomposed%20of%20multiple%20model%20types%2C%20have%20been%20employed%20to%20mitigate%20biases%20in%0Aterms%20of%20demographic%20attributes%20such%20as%20sex%2C%20age%20or%20ethnicity.%20Moreover%2C%20recent%0Awork%20has%20shown%20how%20in%20multi-class%20problems%20even%20simple%20homogeneous%20ensembles%0Amay%20favor%20performance%20of%20the%20worst-performing%20target%20classes.%20While%20homogeneous%0Aensembles%20are%20simpler%20to%20implement%20in%20practice%2C%20it%20is%20not%20yet%20clear%20whether%0Atheir%20benefits%20translate%20to%20groups%20defined%20not%20in%20terms%20of%20their%20target%20class%2C%0Abut%20in%20terms%20of%20demographic%20or%20protected%20attributes%2C%20hence%20improving%20fairness.%0AIn%20this%20work%20we%20show%20how%20this%20simple%20and%20straightforward%20method%20is%20indeed%20able%0Ato%20mitigate%20disparities%2C%20particularly%20benefiting%20under-performing%20subgroups.%0AInterestingly%2C%20this%20can%20be%20achieved%20without%20sacrificing%20overall%20performance%2C%0Awhich%20is%20a%20common%20trade-off%20observed%20in%20bias%20mitigation%20strategies.%20Moreover%2C%0Awe%20analyzed%20the%20interplay%20between%20two%20factors%20which%20may%20result%20in%20biases%3A%0Asub-group%20under-representation%20and%20the%20inherent%20difficulty%20of%20the%20task%20for%20each%0Agroup.%20These%20results%20revealed%20that%2C%20contrary%20to%20popular%20assumptions%2C%20having%0Abalanced%20datasets%20may%20be%20suboptimal%20if%20the%20task%20difficulty%20varies%20between%0Asubgroups.%20Indeed%2C%20we%20found%20that%20a%20perfectly%20balanced%20dataset%20may%20hurt%20both%20the%0Aoverall%20performance%20and%20the%20gap%20between%20groups.%20This%20highlights%20the%20importance%0Aof%20considering%20the%20interaction%20between%20multiple%20forces%20at%20play%20in%20fairness.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14551v1&entry.124074799=Read"},
{"title": "A Note on the Prediction-Powered Bootstrap", "author": "Tijana Zrnic", "abstract": "  We introduce PPBoot: a bootstrap-based method for prediction-powered\ninference. PPBoot is applicable to arbitrary estimation problems and is very\nsimple to implement, essentially only requiring one application of the\nbootstrap. Through a series of examples, we demonstrate that PPBoot often\nperforms nearly identically to (and sometimes better than) the earlier PPI(++)\nmethod based on asymptotic normality$\\unicode{x2013}$when the latter is\napplicable$\\unicode{x2013}$without requiring any asymptotic characterizations.\nGiven its versatility, PPBoot could simplify and expand the scope of\napplication of prediction-powered inference to problems where central limit\ntheorems are hard to prove.\n", "link": "http://arxiv.org/abs/2405.18379v3", "date": "2025-01-24", "relevancy": 1.7975, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5033}, {"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4626}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.4145}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20A%20Note%20on%20the%20Prediction-Powered%20Bootstrap&body=Title%3A%20A%20Note%20on%20the%20Prediction-Powered%20Bootstrap%0AAuthor%3A%20Tijana%20Zrnic%0AAbstract%3A%20%20%20We%20introduce%20PPBoot%3A%20a%20bootstrap-based%20method%20for%20prediction-powered%0Ainference.%20PPBoot%20is%20applicable%20to%20arbitrary%20estimation%20problems%20and%20is%20very%0Asimple%20to%20implement%2C%20essentially%20only%20requiring%20one%20application%20of%20the%0Abootstrap.%20Through%20a%20series%20of%20examples%2C%20we%20demonstrate%20that%20PPBoot%20often%0Aperforms%20nearly%20identically%20to%20%28and%20sometimes%20better%20than%29%20the%20earlier%20PPI%28%2B%2B%29%0Amethod%20based%20on%20asymptotic%20normality%24%5Cunicode%7Bx2013%7D%24when%20the%20latter%20is%0Aapplicable%24%5Cunicode%7Bx2013%7D%24without%20requiring%20any%20asymptotic%20characterizations.%0AGiven%20its%20versatility%2C%20PPBoot%20could%20simplify%20and%20expand%20the%20scope%20of%0Aapplication%20of%20prediction-powered%20inference%20to%20problems%20where%20central%20limit%0Atheorems%20are%20hard%20to%20prove.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2405.18379v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DA%2520Note%2520on%2520the%2520Prediction-Powered%2520Bootstrap%26entry.906535625%3DTijana%2520Zrnic%26entry.1292438233%3D%2520%2520We%2520introduce%2520PPBoot%253A%2520a%2520bootstrap-based%2520method%2520for%2520prediction-powered%250Ainference.%2520PPBoot%2520is%2520applicable%2520to%2520arbitrary%2520estimation%2520problems%2520and%2520is%2520very%250Asimple%2520to%2520implement%252C%2520essentially%2520only%2520requiring%2520one%2520application%2520of%2520the%250Abootstrap.%2520Through%2520a%2520series%2520of%2520examples%252C%2520we%2520demonstrate%2520that%2520PPBoot%2520often%250Aperforms%2520nearly%2520identically%2520to%2520%2528and%2520sometimes%2520better%2520than%2529%2520the%2520earlier%2520PPI%2528%252B%252B%2529%250Amethod%2520based%2520on%2520asymptotic%2520normality%2524%255Cunicode%257Bx2013%257D%2524when%2520the%2520latter%2520is%250Aapplicable%2524%255Cunicode%257Bx2013%257D%2524without%2520requiring%2520any%2520asymptotic%2520characterizations.%250AGiven%2520its%2520versatility%252C%2520PPBoot%2520could%2520simplify%2520and%2520expand%2520the%2520scope%2520of%250Aapplication%2520of%2520prediction-powered%2520inference%2520to%2520problems%2520where%2520central%2520limit%250Atheorems%2520are%2520hard%2520to%2520prove.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2405.18379v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=A%20Note%20on%20the%20Prediction-Powered%20Bootstrap&entry.906535625=Tijana%20Zrnic&entry.1292438233=%20%20We%20introduce%20PPBoot%3A%20a%20bootstrap-based%20method%20for%20prediction-powered%0Ainference.%20PPBoot%20is%20applicable%20to%20arbitrary%20estimation%20problems%20and%20is%20very%0Asimple%20to%20implement%2C%20essentially%20only%20requiring%20one%20application%20of%20the%0Abootstrap.%20Through%20a%20series%20of%20examples%2C%20we%20demonstrate%20that%20PPBoot%20often%0Aperforms%20nearly%20identically%20to%20%28and%20sometimes%20better%20than%29%20the%20earlier%20PPI%28%2B%2B%29%0Amethod%20based%20on%20asymptotic%20normality%24%5Cunicode%7Bx2013%7D%24when%20the%20latter%20is%0Aapplicable%24%5Cunicode%7Bx2013%7D%24without%20requiring%20any%20asymptotic%20characterizations.%0AGiven%20its%20versatility%2C%20PPBoot%20could%20simplify%20and%20expand%20the%20scope%20of%0Aapplication%20of%20prediction-powered%20inference%20to%20problems%20where%20central%20limit%0Atheorems%20are%20hard%20to%20prove.%0A&entry.1838667208=http%3A//arxiv.org/abs/2405.18379v3&entry.124074799=Read"},
{"title": "LaMSUM: Amplifying Voices Against Harassment through LLM Guided\n  Extractive Summarization of User Incident Reports", "author": "Garima Chhikara and Anurag Sharma and V. Gurucharan and Kripabandhu Ghosh and Abhijnan Chakraborty", "abstract": "  Citizen reporting platforms like Safe City in India help the public and\nauthorities stay informed about sexual harassment incidents. However, the high\nvolume of data shared on these platforms makes reviewing each individual case\nchallenging. Therefore, a summarization algorithm capable of processing and\nunderstanding various Indian code-mixed languages is essential. In recent\nyears, Large Language Models (LLMs) have shown exceptional performance in NLP\ntasks, including summarization. LLMs inherently produce abstractive summaries\nby paraphrasing the original text, while the generation of extractive summaries\n- selecting specific subsets from the original text - through LLMs remains\nlargely unexplored. Moreover, LLMs have a limited context window size,\nrestricting the amount of data that can be processed at once. We tackle these\nchallenge by introducing LaMSUM, a novel multi-level framework designed to\ngenerate extractive summaries for large collections of Safe City posts using\nLLMs. LaMSUM integrates summarization with different voting methods to achieve\nrobust summaries. Extensive evaluation using three popular LLMs (Llama, Mistral\nand GPT-4o) demonstrates that LaMSUM outperforms state-of-the-art extractive\nsummarization methods for Safe City posts. Overall, this work represents one of\nthe first attempts to achieve extractive summarization through LLMs, and is\nlikely to support stakeholders by offering a comprehensive overview and\nenabling them to develop effective policies to minimize incidents of\nunwarranted harassment.\n", "link": "http://arxiv.org/abs/2406.15809v4", "date": "2025-01-24", "relevancy": 1.796, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4521}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4494}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.4474}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20LaMSUM%3A%20Amplifying%20Voices%20Against%20Harassment%20through%20LLM%20Guided%0A%20%20Extractive%20Summarization%20of%20User%20Incident%20Reports&body=Title%3A%20LaMSUM%3A%20Amplifying%20Voices%20Against%20Harassment%20through%20LLM%20Guided%0A%20%20Extractive%20Summarization%20of%20User%20Incident%20Reports%0AAuthor%3A%20Garima%20Chhikara%20and%20Anurag%20Sharma%20and%20V.%20Gurucharan%20and%20Kripabandhu%20Ghosh%20and%20Abhijnan%20Chakraborty%0AAbstract%3A%20%20%20Citizen%20reporting%20platforms%20like%20Safe%20City%20in%20India%20help%20the%20public%20and%0Aauthorities%20stay%20informed%20about%20sexual%20harassment%20incidents.%20However%2C%20the%20high%0Avolume%20of%20data%20shared%20on%20these%20platforms%20makes%20reviewing%20each%20individual%20case%0Achallenging.%20Therefore%2C%20a%20summarization%20algorithm%20capable%20of%20processing%20and%0Aunderstanding%20various%20Indian%20code-mixed%20languages%20is%20essential.%20In%20recent%0Ayears%2C%20Large%20Language%20Models%20%28LLMs%29%20have%20shown%20exceptional%20performance%20in%20NLP%0Atasks%2C%20including%20summarization.%20LLMs%20inherently%20produce%20abstractive%20summaries%0Aby%20paraphrasing%20the%20original%20text%2C%20while%20the%20generation%20of%20extractive%20summaries%0A-%20selecting%20specific%20subsets%20from%20the%20original%20text%20-%20through%20LLMs%20remains%0Alargely%20unexplored.%20Moreover%2C%20LLMs%20have%20a%20limited%20context%20window%20size%2C%0Arestricting%20the%20amount%20of%20data%20that%20can%20be%20processed%20at%20once.%20We%20tackle%20these%0Achallenge%20by%20introducing%20LaMSUM%2C%20a%20novel%20multi-level%20framework%20designed%20to%0Agenerate%20extractive%20summaries%20for%20large%20collections%20of%20Safe%20City%20posts%20using%0ALLMs.%20LaMSUM%20integrates%20summarization%20with%20different%20voting%20methods%20to%20achieve%0Arobust%20summaries.%20Extensive%20evaluation%20using%20three%20popular%20LLMs%20%28Llama%2C%20Mistral%0Aand%20GPT-4o%29%20demonstrates%20that%20LaMSUM%20outperforms%20state-of-the-art%20extractive%0Asummarization%20methods%20for%20Safe%20City%20posts.%20Overall%2C%20this%20work%20represents%20one%20of%0Athe%20first%20attempts%20to%20achieve%20extractive%20summarization%20through%20LLMs%2C%20and%20is%0Alikely%20to%20support%20stakeholders%20by%20offering%20a%20comprehensive%20overview%20and%0Aenabling%20them%20to%20develop%20effective%20policies%20to%20minimize%20incidents%20of%0Aunwarranted%20harassment.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2406.15809v4%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLaMSUM%253A%2520Amplifying%2520Voices%2520Against%2520Harassment%2520through%2520LLM%2520Guided%250A%2520%2520Extractive%2520Summarization%2520of%2520User%2520Incident%2520Reports%26entry.906535625%3DGarima%2520Chhikara%2520and%2520Anurag%2520Sharma%2520and%2520V.%2520Gurucharan%2520and%2520Kripabandhu%2520Ghosh%2520and%2520Abhijnan%2520Chakraborty%26entry.1292438233%3D%2520%2520Citizen%2520reporting%2520platforms%2520like%2520Safe%2520City%2520in%2520India%2520help%2520the%2520public%2520and%250Aauthorities%2520stay%2520informed%2520about%2520sexual%2520harassment%2520incidents.%2520However%252C%2520the%2520high%250Avolume%2520of%2520data%2520shared%2520on%2520these%2520platforms%2520makes%2520reviewing%2520each%2520individual%2520case%250Achallenging.%2520Therefore%252C%2520a%2520summarization%2520algorithm%2520capable%2520of%2520processing%2520and%250Aunderstanding%2520various%2520Indian%2520code-mixed%2520languages%2520is%2520essential.%2520In%2520recent%250Ayears%252C%2520Large%2520Language%2520Models%2520%2528LLMs%2529%2520have%2520shown%2520exceptional%2520performance%2520in%2520NLP%250Atasks%252C%2520including%2520summarization.%2520LLMs%2520inherently%2520produce%2520abstractive%2520summaries%250Aby%2520paraphrasing%2520the%2520original%2520text%252C%2520while%2520the%2520generation%2520of%2520extractive%2520summaries%250A-%2520selecting%2520specific%2520subsets%2520from%2520the%2520original%2520text%2520-%2520through%2520LLMs%2520remains%250Alargely%2520unexplored.%2520Moreover%252C%2520LLMs%2520have%2520a%2520limited%2520context%2520window%2520size%252C%250Arestricting%2520the%2520amount%2520of%2520data%2520that%2520can%2520be%2520processed%2520at%2520once.%2520We%2520tackle%2520these%250Achallenge%2520by%2520introducing%2520LaMSUM%252C%2520a%2520novel%2520multi-level%2520framework%2520designed%2520to%250Agenerate%2520extractive%2520summaries%2520for%2520large%2520collections%2520of%2520Safe%2520City%2520posts%2520using%250ALLMs.%2520LaMSUM%2520integrates%2520summarization%2520with%2520different%2520voting%2520methods%2520to%2520achieve%250Arobust%2520summaries.%2520Extensive%2520evaluation%2520using%2520three%2520popular%2520LLMs%2520%2528Llama%252C%2520Mistral%250Aand%2520GPT-4o%2529%2520demonstrates%2520that%2520LaMSUM%2520outperforms%2520state-of-the-art%2520extractive%250Asummarization%2520methods%2520for%2520Safe%2520City%2520posts.%2520Overall%252C%2520this%2520work%2520represents%2520one%2520of%250Athe%2520first%2520attempts%2520to%2520achieve%2520extractive%2520summarization%2520through%2520LLMs%252C%2520and%2520is%250Alikely%2520to%2520support%2520stakeholders%2520by%2520offering%2520a%2520comprehensive%2520overview%2520and%250Aenabling%2520them%2520to%2520develop%2520effective%2520policies%2520to%2520minimize%2520incidents%2520of%250Aunwarranted%2520harassment.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2406.15809v4%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=LaMSUM%3A%20Amplifying%20Voices%20Against%20Harassment%20through%20LLM%20Guided%0A%20%20Extractive%20Summarization%20of%20User%20Incident%20Reports&entry.906535625=Garima%20Chhikara%20and%20Anurag%20Sharma%20and%20V.%20Gurucharan%20and%20Kripabandhu%20Ghosh%20and%20Abhijnan%20Chakraborty&entry.1292438233=%20%20Citizen%20reporting%20platforms%20like%20Safe%20City%20in%20India%20help%20the%20public%20and%0Aauthorities%20stay%20informed%20about%20sexual%20harassment%20incidents.%20However%2C%20the%20high%0Avolume%20of%20data%20shared%20on%20these%20platforms%20makes%20reviewing%20each%20individual%20case%0Achallenging.%20Therefore%2C%20a%20summarization%20algorithm%20capable%20of%20processing%20and%0Aunderstanding%20various%20Indian%20code-mixed%20languages%20is%20essential.%20In%20recent%0Ayears%2C%20Large%20Language%20Models%20%28LLMs%29%20have%20shown%20exceptional%20performance%20in%20NLP%0Atasks%2C%20including%20summarization.%20LLMs%20inherently%20produce%20abstractive%20summaries%0Aby%20paraphrasing%20the%20original%20text%2C%20while%20the%20generation%20of%20extractive%20summaries%0A-%20selecting%20specific%20subsets%20from%20the%20original%20text%20-%20through%20LLMs%20remains%0Alargely%20unexplored.%20Moreover%2C%20LLMs%20have%20a%20limited%20context%20window%20size%2C%0Arestricting%20the%20amount%20of%20data%20that%20can%20be%20processed%20at%20once.%20We%20tackle%20these%0Achallenge%20by%20introducing%20LaMSUM%2C%20a%20novel%20multi-level%20framework%20designed%20to%0Agenerate%20extractive%20summaries%20for%20large%20collections%20of%20Safe%20City%20posts%20using%0ALLMs.%20LaMSUM%20integrates%20summarization%20with%20different%20voting%20methods%20to%20achieve%0Arobust%20summaries.%20Extensive%20evaluation%20using%20three%20popular%20LLMs%20%28Llama%2C%20Mistral%0Aand%20GPT-4o%29%20demonstrates%20that%20LaMSUM%20outperforms%20state-of-the-art%20extractive%0Asummarization%20methods%20for%20Safe%20City%20posts.%20Overall%2C%20this%20work%20represents%20one%20of%0Athe%20first%20attempts%20to%20achieve%20extractive%20summarization%20through%20LLMs%2C%20and%20is%0Alikely%20to%20support%20stakeholders%20by%20offering%20a%20comprehensive%20overview%20and%0Aenabling%20them%20to%20develop%20effective%20policies%20to%20minimize%20incidents%20of%0Aunwarranted%20harassment.%0A&entry.1838667208=http%3A//arxiv.org/abs/2406.15809v4&entry.124074799=Read"},
{"title": "Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization", "author": "Kaheon Kim and Rentian Yao and Changbo Zhu and Xiaohui Chen", "abstract": "  The optimal transport barycenter (a.k.a. Wasserstein barycenter) is a\nfundamental notion of averaging that extends from the Euclidean space to the\nWasserstein space of probability distributions. Computation of the\nunregularized barycenter for discretized probability distributions on point\nclouds is a challenging task when the domain dimension $d > 1$. Most practical\nalgorithms for approximating the barycenter problem are based on entropic\nregularization. In this paper, we introduce a nearly linear time $O(m \\log{m})$\nand linear space complexity $O(m)$ primal-dual algorithm, the\nWasserstein-Descent $\\dot{\\mathbb{H}}^1$-Ascent (WDHA) algorithm, for computing\nthe exact barycenter when the input probability density functions are\ndiscretized on an $m$-point grid. The key success of the WDHA algorithm hinges\non alternating between two different yet closely related Wasserstein and\nSobolev optimization geometries for the primal barycenter and dual Kantorovich\npotential subproblems. Under reasonable assumptions, we establish the\nconvergence rate and iteration complexity of WDHA to its stationary point when\nthe step size is appropriately chosen. Superior computational efficacy,\nscalability, and accuracy over the existing Sinkhorn-type algorithms are\ndemonstrated on high-resolution (e.g., $1024 \\times 1024$ images) 2D synthetic\nand real data.\n", "link": "http://arxiv.org/abs/2501.14635v1", "date": "2025-01-24", "relevancy": 1.7857, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4524}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.4501}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4404}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Optimal%20Transport%20Barycenter%20via%20Nonconvex-Concave%20Minimax%20Optimization&body=Title%3A%20Optimal%20Transport%20Barycenter%20via%20Nonconvex-Concave%20Minimax%20Optimization%0AAuthor%3A%20Kaheon%20Kim%20and%20Rentian%20Yao%20and%20Changbo%20Zhu%20and%20Xiaohui%20Chen%0AAbstract%3A%20%20%20The%20optimal%20transport%20barycenter%20%28a.k.a.%20Wasserstein%20barycenter%29%20is%20a%0Afundamental%20notion%20of%20averaging%20that%20extends%20from%20the%20Euclidean%20space%20to%20the%0AWasserstein%20space%20of%20probability%20distributions.%20Computation%20of%20the%0Aunregularized%20barycenter%20for%20discretized%20probability%20distributions%20on%20point%0Aclouds%20is%20a%20challenging%20task%20when%20the%20domain%20dimension%20%24d%20%3E%201%24.%20Most%20practical%0Aalgorithms%20for%20approximating%20the%20barycenter%20problem%20are%20based%20on%20entropic%0Aregularization.%20In%20this%20paper%2C%20we%20introduce%20a%20nearly%20linear%20time%20%24O%28m%20%5Clog%7Bm%7D%29%24%0Aand%20linear%20space%20complexity%20%24O%28m%29%24%20primal-dual%20algorithm%2C%20the%0AWasserstein-Descent%20%24%5Cdot%7B%5Cmathbb%7BH%7D%7D%5E1%24-Ascent%20%28WDHA%29%20algorithm%2C%20for%20computing%0Athe%20exact%20barycenter%20when%20the%20input%20probability%20density%20functions%20are%0Adiscretized%20on%20an%20%24m%24-point%20grid.%20The%20key%20success%20of%20the%20WDHA%20algorithm%20hinges%0Aon%20alternating%20between%20two%20different%20yet%20closely%20related%20Wasserstein%20and%0ASobolev%20optimization%20geometries%20for%20the%20primal%20barycenter%20and%20dual%20Kantorovich%0Apotential%20subproblems.%20Under%20reasonable%20assumptions%2C%20we%20establish%20the%0Aconvergence%20rate%20and%20iteration%20complexity%20of%20WDHA%20to%20its%20stationary%20point%20when%0Athe%20step%20size%20is%20appropriately%20chosen.%20Superior%20computational%20efficacy%2C%0Ascalability%2C%20and%20accuracy%20over%20the%20existing%20Sinkhorn-type%20algorithms%20are%0Ademonstrated%20on%20high-resolution%20%28e.g.%2C%20%241024%20%5Ctimes%201024%24%20images%29%202D%20synthetic%0Aand%20real%20data.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14635v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DOptimal%2520Transport%2520Barycenter%2520via%2520Nonconvex-Concave%2520Minimax%2520Optimization%26entry.906535625%3DKaheon%2520Kim%2520and%2520Rentian%2520Yao%2520and%2520Changbo%2520Zhu%2520and%2520Xiaohui%2520Chen%26entry.1292438233%3D%2520%2520The%2520optimal%2520transport%2520barycenter%2520%2528a.k.a.%2520Wasserstein%2520barycenter%2529%2520is%2520a%250Afundamental%2520notion%2520of%2520averaging%2520that%2520extends%2520from%2520the%2520Euclidean%2520space%2520to%2520the%250AWasserstein%2520space%2520of%2520probability%2520distributions.%2520Computation%2520of%2520the%250Aunregularized%2520barycenter%2520for%2520discretized%2520probability%2520distributions%2520on%2520point%250Aclouds%2520is%2520a%2520challenging%2520task%2520when%2520the%2520domain%2520dimension%2520%2524d%2520%253E%25201%2524.%2520Most%2520practical%250Aalgorithms%2520for%2520approximating%2520the%2520barycenter%2520problem%2520are%2520based%2520on%2520entropic%250Aregularization.%2520In%2520this%2520paper%252C%2520we%2520introduce%2520a%2520nearly%2520linear%2520time%2520%2524O%2528m%2520%255Clog%257Bm%257D%2529%2524%250Aand%2520linear%2520space%2520complexity%2520%2524O%2528m%2529%2524%2520primal-dual%2520algorithm%252C%2520the%250AWasserstein-Descent%2520%2524%255Cdot%257B%255Cmathbb%257BH%257D%257D%255E1%2524-Ascent%2520%2528WDHA%2529%2520algorithm%252C%2520for%2520computing%250Athe%2520exact%2520barycenter%2520when%2520the%2520input%2520probability%2520density%2520functions%2520are%250Adiscretized%2520on%2520an%2520%2524m%2524-point%2520grid.%2520The%2520key%2520success%2520of%2520the%2520WDHA%2520algorithm%2520hinges%250Aon%2520alternating%2520between%2520two%2520different%2520yet%2520closely%2520related%2520Wasserstein%2520and%250ASobolev%2520optimization%2520geometries%2520for%2520the%2520primal%2520barycenter%2520and%2520dual%2520Kantorovich%250Apotential%2520subproblems.%2520Under%2520reasonable%2520assumptions%252C%2520we%2520establish%2520the%250Aconvergence%2520rate%2520and%2520iteration%2520complexity%2520of%2520WDHA%2520to%2520its%2520stationary%2520point%2520when%250Athe%2520step%2520size%2520is%2520appropriately%2520chosen.%2520Superior%2520computational%2520efficacy%252C%250Ascalability%252C%2520and%2520accuracy%2520over%2520the%2520existing%2520Sinkhorn-type%2520algorithms%2520are%250Ademonstrated%2520on%2520high-resolution%2520%2528e.g.%252C%2520%25241024%2520%255Ctimes%25201024%2524%2520images%2529%25202D%2520synthetic%250Aand%2520real%2520data.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14635v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Optimal%20Transport%20Barycenter%20via%20Nonconvex-Concave%20Minimax%20Optimization&entry.906535625=Kaheon%20Kim%20and%20Rentian%20Yao%20and%20Changbo%20Zhu%20and%20Xiaohui%20Chen&entry.1292438233=%20%20The%20optimal%20transport%20barycenter%20%28a.k.a.%20Wasserstein%20barycenter%29%20is%20a%0Afundamental%20notion%20of%20averaging%20that%20extends%20from%20the%20Euclidean%20space%20to%20the%0AWasserstein%20space%20of%20probability%20distributions.%20Computation%20of%20the%0Aunregularized%20barycenter%20for%20discretized%20probability%20distributions%20on%20point%0Aclouds%20is%20a%20challenging%20task%20when%20the%20domain%20dimension%20%24d%20%3E%201%24.%20Most%20practical%0Aalgorithms%20for%20approximating%20the%20barycenter%20problem%20are%20based%20on%20entropic%0Aregularization.%20In%20this%20paper%2C%20we%20introduce%20a%20nearly%20linear%20time%20%24O%28m%20%5Clog%7Bm%7D%29%24%0Aand%20linear%20space%20complexity%20%24O%28m%29%24%20primal-dual%20algorithm%2C%20the%0AWasserstein-Descent%20%24%5Cdot%7B%5Cmathbb%7BH%7D%7D%5E1%24-Ascent%20%28WDHA%29%20algorithm%2C%20for%20computing%0Athe%20exact%20barycenter%20when%20the%20input%20probability%20density%20functions%20are%0Adiscretized%20on%20an%20%24m%24-point%20grid.%20The%20key%20success%20of%20the%20WDHA%20algorithm%20hinges%0Aon%20alternating%20between%20two%20different%20yet%20closely%20related%20Wasserstein%20and%0ASobolev%20optimization%20geometries%20for%20the%20primal%20barycenter%20and%20dual%20Kantorovich%0Apotential%20subproblems.%20Under%20reasonable%20assumptions%2C%20we%20establish%20the%0Aconvergence%20rate%20and%20iteration%20complexity%20of%20WDHA%20to%20its%20stationary%20point%20when%0Athe%20step%20size%20is%20appropriately%20chosen.%20Superior%20computational%20efficacy%2C%0Ascalability%2C%20and%20accuracy%20over%20the%20existing%20Sinkhorn-type%20algorithms%20are%0Ademonstrated%20on%20high-resolution%20%28e.g.%2C%20%241024%20%5Ctimes%201024%24%20images%29%202D%20synthetic%0Aand%20real%20data.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14635v1&entry.124074799=Read"},
{"title": "Mean-field limit from general mixtures of experts to quantum neural\n  networks", "author": "Anderson Melchor Hernandez and Davide Pastorello and Giacomo De Palma", "abstract": "  In this work, we study the asymptotic behavior of Mixture of Experts (MoE)\ntrained via gradient flow on supervised learning problems. Our main result\nestablishes the propagation of chaos for a MoE as the number of experts\ndiverges. We demonstrate that the corresponding empirical measure of their\nparameters is close to a probability measure that solves a nonlinear continuity\nequation, and we provide an explicit convergence rate that depends solely on\nthe number of experts. We apply our results to a MoE generated by a quantum\nneural network.\n", "link": "http://arxiv.org/abs/2501.14660v1", "date": "2025-01-24", "relevancy": 1.7592, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4459}, {"title": "Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance", "link": "http://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html", "similarity": 0.4419}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4194}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Mean-field%20limit%20from%20general%20mixtures%20of%20experts%20to%20quantum%20neural%0A%20%20networks&body=Title%3A%20Mean-field%20limit%20from%20general%20mixtures%20of%20experts%20to%20quantum%20neural%0A%20%20networks%0AAuthor%3A%20Anderson%20Melchor%20Hernandez%20and%20Davide%20Pastorello%20and%20Giacomo%20De%20Palma%0AAbstract%3A%20%20%20In%20this%20work%2C%20we%20study%20the%20asymptotic%20behavior%20of%20Mixture%20of%20Experts%20%28MoE%29%0Atrained%20via%20gradient%20flow%20on%20supervised%20learning%20problems.%20Our%20main%20result%0Aestablishes%20the%20propagation%20of%20chaos%20for%20a%20MoE%20as%20the%20number%20of%20experts%0Adiverges.%20We%20demonstrate%20that%20the%20corresponding%20empirical%20measure%20of%20their%0Aparameters%20is%20close%20to%20a%20probability%20measure%20that%20solves%20a%20nonlinear%20continuity%0Aequation%2C%20and%20we%20provide%20an%20explicit%20convergence%20rate%20that%20depends%20solely%20on%0Athe%20number%20of%20experts.%20We%20apply%20our%20results%20to%20a%20MoE%20generated%20by%20a%20quantum%0Aneural%20network.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14660v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DMean-field%2520limit%2520from%2520general%2520mixtures%2520of%2520experts%2520to%2520quantum%2520neural%250A%2520%2520networks%26entry.906535625%3DAnderson%2520Melchor%2520Hernandez%2520and%2520Davide%2520Pastorello%2520and%2520Giacomo%2520De%2520Palma%26entry.1292438233%3D%2520%2520In%2520this%2520work%252C%2520we%2520study%2520the%2520asymptotic%2520behavior%2520of%2520Mixture%2520of%2520Experts%2520%2528MoE%2529%250Atrained%2520via%2520gradient%2520flow%2520on%2520supervised%2520learning%2520problems.%2520Our%2520main%2520result%250Aestablishes%2520the%2520propagation%2520of%2520chaos%2520for%2520a%2520MoE%2520as%2520the%2520number%2520of%2520experts%250Adiverges.%2520We%2520demonstrate%2520that%2520the%2520corresponding%2520empirical%2520measure%2520of%2520their%250Aparameters%2520is%2520close%2520to%2520a%2520probability%2520measure%2520that%2520solves%2520a%2520nonlinear%2520continuity%250Aequation%252C%2520and%2520we%2520provide%2520an%2520explicit%2520convergence%2520rate%2520that%2520depends%2520solely%2520on%250Athe%2520number%2520of%2520experts.%2520We%2520apply%2520our%2520results%2520to%2520a%2520MoE%2520generated%2520by%2520a%2520quantum%250Aneural%2520network.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14660v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Mean-field%20limit%20from%20general%20mixtures%20of%20experts%20to%20quantum%20neural%0A%20%20networks&entry.906535625=Anderson%20Melchor%20Hernandez%20and%20Davide%20Pastorello%20and%20Giacomo%20De%20Palma&entry.1292438233=%20%20In%20this%20work%2C%20we%20study%20the%20asymptotic%20behavior%20of%20Mixture%20of%20Experts%20%28MoE%29%0Atrained%20via%20gradient%20flow%20on%20supervised%20learning%20problems.%20Our%20main%20result%0Aestablishes%20the%20propagation%20of%20chaos%20for%20a%20MoE%20as%20the%20number%20of%20experts%0Adiverges.%20We%20demonstrate%20that%20the%20corresponding%20empirical%20measure%20of%20their%0Aparameters%20is%20close%20to%20a%20probability%20measure%20that%20solves%20a%20nonlinear%20continuity%0Aequation%2C%20and%20we%20provide%20an%20explicit%20convergence%20rate%20that%20depends%20solely%20on%0Athe%20number%20of%20experts.%20We%20apply%20our%20results%20to%20a%20MoE%20generated%20by%20a%20quantum%0Aneural%20network.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14660v1&entry.124074799=Read"},
{"title": "Accelerated Preference Elicitation with LLM-Based Proxies", "author": "David Huang and Francisco Marmolejo-Coss\u00edo and Edwin Lock and David Parkes", "abstract": "  Bidders in combinatorial auctions face significant challenges when describing\ntheir preferences to an auctioneer. Classical work on preference elicitation\nfocuses on query-based techniques inspired from proper learning--often via\nproxies that interface between bidders and an auction mechanism--to\nincrementally learn bidder preferences as needed to compute efficient\nallocations. Although such elicitation mechanisms enjoy theoretical query\nefficiency, the amount of communication required may still be too cognitively\ntaxing in practice.\n  We propose a family of efficient LLM-based proxy designs for eliciting\npreferences from bidders using natural language. Our proposed mechanism\ncombines LLM pipelines and DNF-proper-learning techniques to quickly\napproximate preferences when communication is limited. To validate our\napproach, we create a testing sandbox for elicitation mechanisms that\ncommunicate in natural language. In our experiments, our most promising LLM\nproxy design reaches approximately efficient outcomes with five times fewer\nqueries than classical proper learning based elicitation mechanisms.\n", "link": "http://arxiv.org/abs/2501.14625v1", "date": "2025-01-24", "relevancy": 1.7578, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4479}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4377}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4377}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Accelerated%20Preference%20Elicitation%20with%20LLM-Based%20Proxies&body=Title%3A%20Accelerated%20Preference%20Elicitation%20with%20LLM-Based%20Proxies%0AAuthor%3A%20David%20Huang%20and%20Francisco%20Marmolejo-Coss%C3%ADo%20and%20Edwin%20Lock%20and%20David%20Parkes%0AAbstract%3A%20%20%20Bidders%20in%20combinatorial%20auctions%20face%20significant%20challenges%20when%20describing%0Atheir%20preferences%20to%20an%20auctioneer.%20Classical%20work%20on%20preference%20elicitation%0Afocuses%20on%20query-based%20techniques%20inspired%20from%20proper%20learning--often%20via%0Aproxies%20that%20interface%20between%20bidders%20and%20an%20auction%20mechanism--to%0Aincrementally%20learn%20bidder%20preferences%20as%20needed%20to%20compute%20efficient%0Aallocations.%20Although%20such%20elicitation%20mechanisms%20enjoy%20theoretical%20query%0Aefficiency%2C%20the%20amount%20of%20communication%20required%20may%20still%20be%20too%20cognitively%0Ataxing%20in%20practice.%0A%20%20We%20propose%20a%20family%20of%20efficient%20LLM-based%20proxy%20designs%20for%20eliciting%0Apreferences%20from%20bidders%20using%20natural%20language.%20Our%20proposed%20mechanism%0Acombines%20LLM%20pipelines%20and%20DNF-proper-learning%20techniques%20to%20quickly%0Aapproximate%20preferences%20when%20communication%20is%20limited.%20To%20validate%20our%0Aapproach%2C%20we%20create%20a%20testing%20sandbox%20for%20elicitation%20mechanisms%20that%0Acommunicate%20in%20natural%20language.%20In%20our%20experiments%2C%20our%20most%20promising%20LLM%0Aproxy%20design%20reaches%20approximately%20efficient%20outcomes%20with%20five%20times%20fewer%0Aqueries%20than%20classical%20proper%20learning%20based%20elicitation%20mechanisms.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14625v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DAccelerated%2520Preference%2520Elicitation%2520with%2520LLM-Based%2520Proxies%26entry.906535625%3DDavid%2520Huang%2520and%2520Francisco%2520Marmolejo-Coss%25C3%25ADo%2520and%2520Edwin%2520Lock%2520and%2520David%2520Parkes%26entry.1292438233%3D%2520%2520Bidders%2520in%2520combinatorial%2520auctions%2520face%2520significant%2520challenges%2520when%2520describing%250Atheir%2520preferences%2520to%2520an%2520auctioneer.%2520Classical%2520work%2520on%2520preference%2520elicitation%250Afocuses%2520on%2520query-based%2520techniques%2520inspired%2520from%2520proper%2520learning--often%2520via%250Aproxies%2520that%2520interface%2520between%2520bidders%2520and%2520an%2520auction%2520mechanism--to%250Aincrementally%2520learn%2520bidder%2520preferences%2520as%2520needed%2520to%2520compute%2520efficient%250Aallocations.%2520Although%2520such%2520elicitation%2520mechanisms%2520enjoy%2520theoretical%2520query%250Aefficiency%252C%2520the%2520amount%2520of%2520communication%2520required%2520may%2520still%2520be%2520too%2520cognitively%250Ataxing%2520in%2520practice.%250A%2520%2520We%2520propose%2520a%2520family%2520of%2520efficient%2520LLM-based%2520proxy%2520designs%2520for%2520eliciting%250Apreferences%2520from%2520bidders%2520using%2520natural%2520language.%2520Our%2520proposed%2520mechanism%250Acombines%2520LLM%2520pipelines%2520and%2520DNF-proper-learning%2520techniques%2520to%2520quickly%250Aapproximate%2520preferences%2520when%2520communication%2520is%2520limited.%2520To%2520validate%2520our%250Aapproach%252C%2520we%2520create%2520a%2520testing%2520sandbox%2520for%2520elicitation%2520mechanisms%2520that%250Acommunicate%2520in%2520natural%2520language.%2520In%2520our%2520experiments%252C%2520our%2520most%2520promising%2520LLM%250Aproxy%2520design%2520reaches%2520approximately%2520efficient%2520outcomes%2520with%2520five%2520times%2520fewer%250Aqueries%2520than%2520classical%2520proper%2520learning%2520based%2520elicitation%2520mechanisms.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14625v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Accelerated%20Preference%20Elicitation%20with%20LLM-Based%20Proxies&entry.906535625=David%20Huang%20and%20Francisco%20Marmolejo-Coss%C3%ADo%20and%20Edwin%20Lock%20and%20David%20Parkes&entry.1292438233=%20%20Bidders%20in%20combinatorial%20auctions%20face%20significant%20challenges%20when%20describing%0Atheir%20preferences%20to%20an%20auctioneer.%20Classical%20work%20on%20preference%20elicitation%0Afocuses%20on%20query-based%20techniques%20inspired%20from%20proper%20learning--often%20via%0Aproxies%20that%20interface%20between%20bidders%20and%20an%20auction%20mechanism--to%0Aincrementally%20learn%20bidder%20preferences%20as%20needed%20to%20compute%20efficient%0Aallocations.%20Although%20such%20elicitation%20mechanisms%20enjoy%20theoretical%20query%0Aefficiency%2C%20the%20amount%20of%20communication%20required%20may%20still%20be%20too%20cognitively%0Ataxing%20in%20practice.%0A%20%20We%20propose%20a%20family%20of%20efficient%20LLM-based%20proxy%20designs%20for%20eliciting%0Apreferences%20from%20bidders%20using%20natural%20language.%20Our%20proposed%20mechanism%0Acombines%20LLM%20pipelines%20and%20DNF-proper-learning%20techniques%20to%20quickly%0Aapproximate%20preferences%20when%20communication%20is%20limited.%20To%20validate%20our%0Aapproach%2C%20we%20create%20a%20testing%20sandbox%20for%20elicitation%20mechanisms%20that%0Acommunicate%20in%20natural%20language.%20In%20our%20experiments%2C%20our%20most%20promising%20LLM%0Aproxy%20design%20reaches%20approximately%20efficient%20outcomes%20with%20five%20times%20fewer%0Aqueries%20than%20classical%20proper%20learning%20based%20elicitation%20mechanisms.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14625v1&entry.124074799=Read"},
{"title": "Do LLMs Provide Consistent Answers to Health-Related Questions across\n  Languages?", "author": "Ipek Baris Schlicht and Zhixue Zhao and Burcu Sayin and Lucie Flek and Paolo Rosso", "abstract": "  Equitable access to reliable health information is vital for public health,\nbut the quality of online health resources varies by language, raising concerns\nabout inconsistencies in Large Language Models (LLMs) for healthcare. In this\nstudy, we examine the consistency of responses provided by LLMs to\nhealth-related questions across English, German, Turkish, and Chinese. We\nlargely expand the HealthFC dataset by categorizing health-related questions by\ndisease type and broadening its multilingual scope with Turkish and Chinese\ntranslations. We reveal significant inconsistencies in responses that could\nspread healthcare misinformation. Our main contributions are 1) a multilingual\nhealth-related inquiry dataset with meta-information on disease categories, and\n2) a novel prompt-based evaluation workflow that enables sub-dimensional\ncomparisons between two languages through parsing. Our findings highlight key\nchallenges in deploying LLM-based tools in multilingual contexts and emphasize\nthe need for improved cross-lingual alignment to ensure accurate and equitable\nhealthcare information.\n", "link": "http://arxiv.org/abs/2501.14719v1", "date": "2025-01-24", "relevancy": 1.7458, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4677}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4302}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4302}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Do%20LLMs%20Provide%20Consistent%20Answers%20to%20Health-Related%20Questions%20across%0A%20%20Languages%3F&body=Title%3A%20Do%20LLMs%20Provide%20Consistent%20Answers%20to%20Health-Related%20Questions%20across%0A%20%20Languages%3F%0AAuthor%3A%20Ipek%20Baris%20Schlicht%20and%20Zhixue%20Zhao%20and%20Burcu%20Sayin%20and%20Lucie%20Flek%20and%20Paolo%20Rosso%0AAbstract%3A%20%20%20Equitable%20access%20to%20reliable%20health%20information%20is%20vital%20for%20public%20health%2C%0Abut%20the%20quality%20of%20online%20health%20resources%20varies%20by%20language%2C%20raising%20concerns%0Aabout%20inconsistencies%20in%20Large%20Language%20Models%20%28LLMs%29%20for%20healthcare.%20In%20this%0Astudy%2C%20we%20examine%20the%20consistency%20of%20responses%20provided%20by%20LLMs%20to%0Ahealth-related%20questions%20across%20English%2C%20German%2C%20Turkish%2C%20and%20Chinese.%20We%0Alargely%20expand%20the%20HealthFC%20dataset%20by%20categorizing%20health-related%20questions%20by%0Adisease%20type%20and%20broadening%20its%20multilingual%20scope%20with%20Turkish%20and%20Chinese%0Atranslations.%20We%20reveal%20significant%20inconsistencies%20in%20responses%20that%20could%0Aspread%20healthcare%20misinformation.%20Our%20main%20contributions%20are%201%29%20a%20multilingual%0Ahealth-related%20inquiry%20dataset%20with%20meta-information%20on%20disease%20categories%2C%20and%0A2%29%20a%20novel%20prompt-based%20evaluation%20workflow%20that%20enables%20sub-dimensional%0Acomparisons%20between%20two%20languages%20through%20parsing.%20Our%20findings%20highlight%20key%0Achallenges%20in%20deploying%20LLM-based%20tools%20in%20multilingual%20contexts%20and%20emphasize%0Athe%20need%20for%20improved%20cross-lingual%20alignment%20to%20ensure%20accurate%20and%20equitable%0Ahealthcare%20information.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14719v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDo%2520LLMs%2520Provide%2520Consistent%2520Answers%2520to%2520Health-Related%2520Questions%2520across%250A%2520%2520Languages%253F%26entry.906535625%3DIpek%2520Baris%2520Schlicht%2520and%2520Zhixue%2520Zhao%2520and%2520Burcu%2520Sayin%2520and%2520Lucie%2520Flek%2520and%2520Paolo%2520Rosso%26entry.1292438233%3D%2520%2520Equitable%2520access%2520to%2520reliable%2520health%2520information%2520is%2520vital%2520for%2520public%2520health%252C%250Abut%2520the%2520quality%2520of%2520online%2520health%2520resources%2520varies%2520by%2520language%252C%2520raising%2520concerns%250Aabout%2520inconsistencies%2520in%2520Large%2520Language%2520Models%2520%2528LLMs%2529%2520for%2520healthcare.%2520In%2520this%250Astudy%252C%2520we%2520examine%2520the%2520consistency%2520of%2520responses%2520provided%2520by%2520LLMs%2520to%250Ahealth-related%2520questions%2520across%2520English%252C%2520German%252C%2520Turkish%252C%2520and%2520Chinese.%2520We%250Alargely%2520expand%2520the%2520HealthFC%2520dataset%2520by%2520categorizing%2520health-related%2520questions%2520by%250Adisease%2520type%2520and%2520broadening%2520its%2520multilingual%2520scope%2520with%2520Turkish%2520and%2520Chinese%250Atranslations.%2520We%2520reveal%2520significant%2520inconsistencies%2520in%2520responses%2520that%2520could%250Aspread%2520healthcare%2520misinformation.%2520Our%2520main%2520contributions%2520are%25201%2529%2520a%2520multilingual%250Ahealth-related%2520inquiry%2520dataset%2520with%2520meta-information%2520on%2520disease%2520categories%252C%2520and%250A2%2529%2520a%2520novel%2520prompt-based%2520evaluation%2520workflow%2520that%2520enables%2520sub-dimensional%250Acomparisons%2520between%2520two%2520languages%2520through%2520parsing.%2520Our%2520findings%2520highlight%2520key%250Achallenges%2520in%2520deploying%2520LLM-based%2520tools%2520in%2520multilingual%2520contexts%2520and%2520emphasize%250Athe%2520need%2520for%2520improved%2520cross-lingual%2520alignment%2520to%2520ensure%2520accurate%2520and%2520equitable%250Ahealthcare%2520information.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14719v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Do%20LLMs%20Provide%20Consistent%20Answers%20to%20Health-Related%20Questions%20across%0A%20%20Languages%3F&entry.906535625=Ipek%20Baris%20Schlicht%20and%20Zhixue%20Zhao%20and%20Burcu%20Sayin%20and%20Lucie%20Flek%20and%20Paolo%20Rosso&entry.1292438233=%20%20Equitable%20access%20to%20reliable%20health%20information%20is%20vital%20for%20public%20health%2C%0Abut%20the%20quality%20of%20online%20health%20resources%20varies%20by%20language%2C%20raising%20concerns%0Aabout%20inconsistencies%20in%20Large%20Language%20Models%20%28LLMs%29%20for%20healthcare.%20In%20this%0Astudy%2C%20we%20examine%20the%20consistency%20of%20responses%20provided%20by%20LLMs%20to%0Ahealth-related%20questions%20across%20English%2C%20German%2C%20Turkish%2C%20and%20Chinese.%20We%0Alargely%20expand%20the%20HealthFC%20dataset%20by%20categorizing%20health-related%20questions%20by%0Adisease%20type%20and%20broadening%20its%20multilingual%20scope%20with%20Turkish%20and%20Chinese%0Atranslations.%20We%20reveal%20significant%20inconsistencies%20in%20responses%20that%20could%0Aspread%20healthcare%20misinformation.%20Our%20main%20contributions%20are%201%29%20a%20multilingual%0Ahealth-related%20inquiry%20dataset%20with%20meta-information%20on%20disease%20categories%2C%20and%0A2%29%20a%20novel%20prompt-based%20evaluation%20workflow%20that%20enables%20sub-dimensional%0Acomparisons%20between%20two%20languages%20through%20parsing.%20Our%20findings%20highlight%20key%0Achallenges%20in%20deploying%20LLM-based%20tools%20in%20multilingual%20contexts%20and%20emphasize%0Athe%20need%20for%20improved%20cross-lingual%20alignment%20to%20ensure%20accurate%20and%20equitable%0Ahealthcare%20information.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14719v1&entry.124074799=Read"},
{"title": "Training-Free Style and Content Transfer by Leveraging U-Net Skip\n  Connections in Stable Diffusion 2.*", "author": "Ludovica Schaerf and Andrea Alfarano and Fabrizio Silvestri and Leonardo Impett", "abstract": "  Despite significant recent advances in image generation with diffusion\nmodels, their internal latent representations remain poorly understood.\nExisting works focus on the bottleneck layer (h-space) of Stable Diffusion's\nU-Net or leverage the cross-attention, self-attention, or decoding layers. Our\nmodel, SkipInject takes advantage of U-Net's skip connections. We conduct\nthorough analyses on the role of the skip connections and find that the\nresidual connections passed by the third encoder block carry most of the\nspatial information of the reconstructed image, splitting the content from the\nstyle. We show that injecting the representations from this block can be used\nfor text-based editing, precise modifications, and style transfer. We compare\nour methods state-of-the-art style transfer and image editing methods and\ndemonstrate that our method obtains the best content alignment and optimal\nstructural preservation tradeoff.\n", "link": "http://arxiv.org/abs/2501.14524v1", "date": "2025-01-24", "relevancy": 1.7364, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.6033}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.5744}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.5654}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Training-Free%20Style%20and%20Content%20Transfer%20by%20Leveraging%20U-Net%20Skip%0A%20%20Connections%20in%20Stable%20Diffusion%202.%2A&body=Title%3A%20Training-Free%20Style%20and%20Content%20Transfer%20by%20Leveraging%20U-Net%20Skip%0A%20%20Connections%20in%20Stable%20Diffusion%202.%2A%0AAuthor%3A%20Ludovica%20Schaerf%20and%20Andrea%20Alfarano%20and%20Fabrizio%20Silvestri%20and%20Leonardo%20Impett%0AAbstract%3A%20%20%20Despite%20significant%20recent%20advances%20in%20image%20generation%20with%20diffusion%0Amodels%2C%20their%20internal%20latent%20representations%20remain%20poorly%20understood.%0AExisting%20works%20focus%20on%20the%20bottleneck%20layer%20%28h-space%29%20of%20Stable%20Diffusion%27s%0AU-Net%20or%20leverage%20the%20cross-attention%2C%20self-attention%2C%20or%20decoding%20layers.%20Our%0Amodel%2C%20SkipInject%20takes%20advantage%20of%20U-Net%27s%20skip%20connections.%20We%20conduct%0Athorough%20analyses%20on%20the%20role%20of%20the%20skip%20connections%20and%20find%20that%20the%0Aresidual%20connections%20passed%20by%20the%20third%20encoder%20block%20carry%20most%20of%20the%0Aspatial%20information%20of%20the%20reconstructed%20image%2C%20splitting%20the%20content%20from%20the%0Astyle.%20We%20show%20that%20injecting%20the%20representations%20from%20this%20block%20can%20be%20used%0Afor%20text-based%20editing%2C%20precise%20modifications%2C%20and%20style%20transfer.%20We%20compare%0Aour%20methods%20state-of-the-art%20style%20transfer%20and%20image%20editing%20methods%20and%0Ademonstrate%20that%20our%20method%20obtains%20the%20best%20content%20alignment%20and%20optimal%0Astructural%20preservation%20tradeoff.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14524v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTraining-Free%2520Style%2520and%2520Content%2520Transfer%2520by%2520Leveraging%2520U-Net%2520Skip%250A%2520%2520Connections%2520in%2520Stable%2520Diffusion%25202.%252A%26entry.906535625%3DLudovica%2520Schaerf%2520and%2520Andrea%2520Alfarano%2520and%2520Fabrizio%2520Silvestri%2520and%2520Leonardo%2520Impett%26entry.1292438233%3D%2520%2520Despite%2520significant%2520recent%2520advances%2520in%2520image%2520generation%2520with%2520diffusion%250Amodels%252C%2520their%2520internal%2520latent%2520representations%2520remain%2520poorly%2520understood.%250AExisting%2520works%2520focus%2520on%2520the%2520bottleneck%2520layer%2520%2528h-space%2529%2520of%2520Stable%2520Diffusion%2527s%250AU-Net%2520or%2520leverage%2520the%2520cross-attention%252C%2520self-attention%252C%2520or%2520decoding%2520layers.%2520Our%250Amodel%252C%2520SkipInject%2520takes%2520advantage%2520of%2520U-Net%2527s%2520skip%2520connections.%2520We%2520conduct%250Athorough%2520analyses%2520on%2520the%2520role%2520of%2520the%2520skip%2520connections%2520and%2520find%2520that%2520the%250Aresidual%2520connections%2520passed%2520by%2520the%2520third%2520encoder%2520block%2520carry%2520most%2520of%2520the%250Aspatial%2520information%2520of%2520the%2520reconstructed%2520image%252C%2520splitting%2520the%2520content%2520from%2520the%250Astyle.%2520We%2520show%2520that%2520injecting%2520the%2520representations%2520from%2520this%2520block%2520can%2520be%2520used%250Afor%2520text-based%2520editing%252C%2520precise%2520modifications%252C%2520and%2520style%2520transfer.%2520We%2520compare%250Aour%2520methods%2520state-of-the-art%2520style%2520transfer%2520and%2520image%2520editing%2520methods%2520and%250Ademonstrate%2520that%2520our%2520method%2520obtains%2520the%2520best%2520content%2520alignment%2520and%2520optimal%250Astructural%2520preservation%2520tradeoff.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14524v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Training-Free%20Style%20and%20Content%20Transfer%20by%20Leveraging%20U-Net%20Skip%0A%20%20Connections%20in%20Stable%20Diffusion%202.%2A&entry.906535625=Ludovica%20Schaerf%20and%20Andrea%20Alfarano%20and%20Fabrizio%20Silvestri%20and%20Leonardo%20Impett&entry.1292438233=%20%20Despite%20significant%20recent%20advances%20in%20image%20generation%20with%20diffusion%0Amodels%2C%20their%20internal%20latent%20representations%20remain%20poorly%20understood.%0AExisting%20works%20focus%20on%20the%20bottleneck%20layer%20%28h-space%29%20of%20Stable%20Diffusion%27s%0AU-Net%20or%20leverage%20the%20cross-attention%2C%20self-attention%2C%20or%20decoding%20layers.%20Our%0Amodel%2C%20SkipInject%20takes%20advantage%20of%20U-Net%27s%20skip%20connections.%20We%20conduct%0Athorough%20analyses%20on%20the%20role%20of%20the%20skip%20connections%20and%20find%20that%20the%0Aresidual%20connections%20passed%20by%20the%20third%20encoder%20block%20carry%20most%20of%20the%0Aspatial%20information%20of%20the%20reconstructed%20image%2C%20splitting%20the%20content%20from%20the%0Astyle.%20We%20show%20that%20injecting%20the%20representations%20from%20this%20block%20can%20be%20used%0Afor%20text-based%20editing%2C%20precise%20modifications%2C%20and%20style%20transfer.%20We%20compare%0Aour%20methods%20state-of-the-art%20style%20transfer%20and%20image%20editing%20methods%20and%0Ademonstrate%20that%20our%20method%20obtains%20the%20best%20content%20alignment%20and%20optimal%0Astructural%20preservation%20tradeoff.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14524v1&entry.124074799=Read"},
{"title": "From One to the Power of Many: Invariance to Multi-LiDAR Perception from\n  Single-Sensor Datasets", "author": "Marc Uecker and J. Marius Z\u00f6llner", "abstract": "  Recently, LiDAR segmentation methods for autonomous vehicles, powered by deep\nneural networks, have experienced steep growth in performance on classic\nbenchmarks, such as nuScenes and SemanticKITTI. However, there are still large\ngaps in performance when deploying models trained on such single-sensor setups\nto modern vehicles with multiple high-resolution LiDAR sensors. In this work,\nwe introduce a new metric for feature-level invariance which can serve as a\nproxy to measure cross-domain generalization without requiring labeled data.\nAdditionally, we propose two application-specific data augmentations, which\nfacilitate better transfer to multi-sensor LiDAR setups, when trained on\nsingle-sensor datasets. We provide experimental evidence on both simulated and\nreal data, that our proposed augmentations improve invariance across LiDAR\nsetups, leading to improved generalization.\n", "link": "http://arxiv.org/abs/2409.18592v2", "date": "2025-01-24", "relevancy": 1.725, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5896}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5792}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5499}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20From%20One%20to%20the%20Power%20of%20Many%3A%20Invariance%20to%20Multi-LiDAR%20Perception%20from%0A%20%20Single-Sensor%20Datasets&body=Title%3A%20From%20One%20to%20the%20Power%20of%20Many%3A%20Invariance%20to%20Multi-LiDAR%20Perception%20from%0A%20%20Single-Sensor%20Datasets%0AAuthor%3A%20Marc%20Uecker%20and%20J.%20Marius%20Z%C3%B6llner%0AAbstract%3A%20%20%20Recently%2C%20LiDAR%20segmentation%20methods%20for%20autonomous%20vehicles%2C%20powered%20by%20deep%0Aneural%20networks%2C%20have%20experienced%20steep%20growth%20in%20performance%20on%20classic%0Abenchmarks%2C%20such%20as%20nuScenes%20and%20SemanticKITTI.%20However%2C%20there%20are%20still%20large%0Agaps%20in%20performance%20when%20deploying%20models%20trained%20on%20such%20single-sensor%20setups%0Ato%20modern%20vehicles%20with%20multiple%20high-resolution%20LiDAR%20sensors.%20In%20this%20work%2C%0Awe%20introduce%20a%20new%20metric%20for%20feature-level%20invariance%20which%20can%20serve%20as%20a%0Aproxy%20to%20measure%20cross-domain%20generalization%20without%20requiring%20labeled%20data.%0AAdditionally%2C%20we%20propose%20two%20application-specific%20data%20augmentations%2C%20which%0Afacilitate%20better%20transfer%20to%20multi-sensor%20LiDAR%20setups%2C%20when%20trained%20on%0Asingle-sensor%20datasets.%20We%20provide%20experimental%20evidence%20on%20both%20simulated%20and%0Areal%20data%2C%20that%20our%20proposed%20augmentations%20improve%20invariance%20across%20LiDAR%0Asetups%2C%20leading%20to%20improved%20generalization.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2409.18592v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DFrom%2520One%2520to%2520the%2520Power%2520of%2520Many%253A%2520Invariance%2520to%2520Multi-LiDAR%2520Perception%2520from%250A%2520%2520Single-Sensor%2520Datasets%26entry.906535625%3DMarc%2520Uecker%2520and%2520J.%2520Marius%2520Z%25C3%25B6llner%26entry.1292438233%3D%2520%2520Recently%252C%2520LiDAR%2520segmentation%2520methods%2520for%2520autonomous%2520vehicles%252C%2520powered%2520by%2520deep%250Aneural%2520networks%252C%2520have%2520experienced%2520steep%2520growth%2520in%2520performance%2520on%2520classic%250Abenchmarks%252C%2520such%2520as%2520nuScenes%2520and%2520SemanticKITTI.%2520However%252C%2520there%2520are%2520still%2520large%250Agaps%2520in%2520performance%2520when%2520deploying%2520models%2520trained%2520on%2520such%2520single-sensor%2520setups%250Ato%2520modern%2520vehicles%2520with%2520multiple%2520high-resolution%2520LiDAR%2520sensors.%2520In%2520this%2520work%252C%250Awe%2520introduce%2520a%2520new%2520metric%2520for%2520feature-level%2520invariance%2520which%2520can%2520serve%2520as%2520a%250Aproxy%2520to%2520measure%2520cross-domain%2520generalization%2520without%2520requiring%2520labeled%2520data.%250AAdditionally%252C%2520we%2520propose%2520two%2520application-specific%2520data%2520augmentations%252C%2520which%250Afacilitate%2520better%2520transfer%2520to%2520multi-sensor%2520LiDAR%2520setups%252C%2520when%2520trained%2520on%250Asingle-sensor%2520datasets.%2520We%2520provide%2520experimental%2520evidence%2520on%2520both%2520simulated%2520and%250Areal%2520data%252C%2520that%2520our%2520proposed%2520augmentations%2520improve%2520invariance%2520across%2520LiDAR%250Asetups%252C%2520leading%2520to%2520improved%2520generalization.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2409.18592v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=From%20One%20to%20the%20Power%20of%20Many%3A%20Invariance%20to%20Multi-LiDAR%20Perception%20from%0A%20%20Single-Sensor%20Datasets&entry.906535625=Marc%20Uecker%20and%20J.%20Marius%20Z%C3%B6llner&entry.1292438233=%20%20Recently%2C%20LiDAR%20segmentation%20methods%20for%20autonomous%20vehicles%2C%20powered%20by%20deep%0Aneural%20networks%2C%20have%20experienced%20steep%20growth%20in%20performance%20on%20classic%0Abenchmarks%2C%20such%20as%20nuScenes%20and%20SemanticKITTI.%20However%2C%20there%20are%20still%20large%0Agaps%20in%20performance%20when%20deploying%20models%20trained%20on%20such%20single-sensor%20setups%0Ato%20modern%20vehicles%20with%20multiple%20high-resolution%20LiDAR%20sensors.%20In%20this%20work%2C%0Awe%20introduce%20a%20new%20metric%20for%20feature-level%20invariance%20which%20can%20serve%20as%20a%0Aproxy%20to%20measure%20cross-domain%20generalization%20without%20requiring%20labeled%20data.%0AAdditionally%2C%20we%20propose%20two%20application-specific%20data%20augmentations%2C%20which%0Afacilitate%20better%20transfer%20to%20multi-sensor%20LiDAR%20setups%2C%20when%20trained%20on%0Asingle-sensor%20datasets.%20We%20provide%20experimental%20evidence%20on%20both%20simulated%20and%0Areal%20data%2C%20that%20our%20proposed%20augmentations%20improve%20invariance%20across%20LiDAR%0Asetups%2C%20leading%20to%20improved%20generalization.%0A&entry.1838667208=http%3A//arxiv.org/abs/2409.18592v2&entry.124074799=Read"},
{"title": "Visual Localization via Semantic Structures in Autonomous Photovoltaic\n  Power Plant Inspection", "author": "Viktor Koz\u00e1k and Karel Ko\u0161nar and Jan Chudoba and Miroslav Kulich and Libor P\u0159eu\u010dil", "abstract": "  Inspection systems utilizing unmanned aerial vehicles (UAVs) equipped with\nthermal cameras are increasingly popular for the maintenance of photovoltaic\n(PV) power plants. However, automation of the inspection task is a challenging\nproblem as it requires precise navigation to capture images from optimal\ndistances and viewing angles.\n  This paper presents a novel localization pipeline that directly integrates PV\nmodule detection with UAV navigation, allowing precise positioning during\ninspection. Detections are used to identify the power plant structures in the\nimage and associate these with the power plant model. We define visually\nrecognizable anchor points for the initial association and use object tracking\nto discern global associations. We present three distinct methods for visual\nsegmentation of PV modules based on traditional computer vision, deep learning,\nand their fusion, and we evaluate their performance in relation to the proposed\nlocalization pipeline.\n  The presented methods were verified and evaluated using custom aerial\ninspection data sets, demonstrating their robustness and applicability for\nreal-time navigation. Additionally, we evaluate the influence of the power\nplant model's precision on the localization methods.\n", "link": "http://arxiv.org/abs/2501.14587v1", "date": "2025-01-24", "relevancy": 1.7244, "topK": [{"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.6129}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5321}, {"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.5223}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Visual%20Localization%20via%20Semantic%20Structures%20in%20Autonomous%20Photovoltaic%0A%20%20Power%20Plant%20Inspection&body=Title%3A%20Visual%20Localization%20via%20Semantic%20Structures%20in%20Autonomous%20Photovoltaic%0A%20%20Power%20Plant%20Inspection%0AAuthor%3A%20Viktor%20Koz%C3%A1k%20and%20Karel%20Ko%C5%A1nar%20and%20Jan%20Chudoba%20and%20Miroslav%20Kulich%20and%20Libor%20P%C5%99eu%C4%8Dil%0AAbstract%3A%20%20%20Inspection%20systems%20utilizing%20unmanned%20aerial%20vehicles%20%28UAVs%29%20equipped%20with%0Athermal%20cameras%20are%20increasingly%20popular%20for%20the%20maintenance%20of%20photovoltaic%0A%28PV%29%20power%20plants.%20However%2C%20automation%20of%20the%20inspection%20task%20is%20a%20challenging%0Aproblem%20as%20it%20requires%20precise%20navigation%20to%20capture%20images%20from%20optimal%0Adistances%20and%20viewing%20angles.%0A%20%20This%20paper%20presents%20a%20novel%20localization%20pipeline%20that%20directly%20integrates%20PV%0Amodule%20detection%20with%20UAV%20navigation%2C%20allowing%20precise%20positioning%20during%0Ainspection.%20Detections%20are%20used%20to%20identify%20the%20power%20plant%20structures%20in%20the%0Aimage%20and%20associate%20these%20with%20the%20power%20plant%20model.%20We%20define%20visually%0Arecognizable%20anchor%20points%20for%20the%20initial%20association%20and%20use%20object%20tracking%0Ato%20discern%20global%20associations.%20We%20present%20three%20distinct%20methods%20for%20visual%0Asegmentation%20of%20PV%20modules%20based%20on%20traditional%20computer%20vision%2C%20deep%20learning%2C%0Aand%20their%20fusion%2C%20and%20we%20evaluate%20their%20performance%20in%20relation%20to%20the%20proposed%0Alocalization%20pipeline.%0A%20%20The%20presented%20methods%20were%20verified%20and%20evaluated%20using%20custom%20aerial%0Ainspection%20data%20sets%2C%20demonstrating%20their%20robustness%20and%20applicability%20for%0Areal-time%20navigation.%20Additionally%2C%20we%20evaluate%20the%20influence%20of%20the%20power%0Aplant%20model%27s%20precision%20on%20the%20localization%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14587v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DVisual%2520Localization%2520via%2520Semantic%2520Structures%2520in%2520Autonomous%2520Photovoltaic%250A%2520%2520Power%2520Plant%2520Inspection%26entry.906535625%3DViktor%2520Koz%25C3%25A1k%2520and%2520Karel%2520Ko%25C5%25A1nar%2520and%2520Jan%2520Chudoba%2520and%2520Miroslav%2520Kulich%2520and%2520Libor%2520P%25C5%2599eu%25C4%258Dil%26entry.1292438233%3D%2520%2520Inspection%2520systems%2520utilizing%2520unmanned%2520aerial%2520vehicles%2520%2528UAVs%2529%2520equipped%2520with%250Athermal%2520cameras%2520are%2520increasingly%2520popular%2520for%2520the%2520maintenance%2520of%2520photovoltaic%250A%2528PV%2529%2520power%2520plants.%2520However%252C%2520automation%2520of%2520the%2520inspection%2520task%2520is%2520a%2520challenging%250Aproblem%2520as%2520it%2520requires%2520precise%2520navigation%2520to%2520capture%2520images%2520from%2520optimal%250Adistances%2520and%2520viewing%2520angles.%250A%2520%2520This%2520paper%2520presents%2520a%2520novel%2520localization%2520pipeline%2520that%2520directly%2520integrates%2520PV%250Amodule%2520detection%2520with%2520UAV%2520navigation%252C%2520allowing%2520precise%2520positioning%2520during%250Ainspection.%2520Detections%2520are%2520used%2520to%2520identify%2520the%2520power%2520plant%2520structures%2520in%2520the%250Aimage%2520and%2520associate%2520these%2520with%2520the%2520power%2520plant%2520model.%2520We%2520define%2520visually%250Arecognizable%2520anchor%2520points%2520for%2520the%2520initial%2520association%2520and%2520use%2520object%2520tracking%250Ato%2520discern%2520global%2520associations.%2520We%2520present%2520three%2520distinct%2520methods%2520for%2520visual%250Asegmentation%2520of%2520PV%2520modules%2520based%2520on%2520traditional%2520computer%2520vision%252C%2520deep%2520learning%252C%250Aand%2520their%2520fusion%252C%2520and%2520we%2520evaluate%2520their%2520performance%2520in%2520relation%2520to%2520the%2520proposed%250Alocalization%2520pipeline.%250A%2520%2520The%2520presented%2520methods%2520were%2520verified%2520and%2520evaluated%2520using%2520custom%2520aerial%250Ainspection%2520data%2520sets%252C%2520demonstrating%2520their%2520robustness%2520and%2520applicability%2520for%250Areal-time%2520navigation.%2520Additionally%252C%2520we%2520evaluate%2520the%2520influence%2520of%2520the%2520power%250Aplant%2520model%2527s%2520precision%2520on%2520the%2520localization%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14587v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Visual%20Localization%20via%20Semantic%20Structures%20in%20Autonomous%20Photovoltaic%0A%20%20Power%20Plant%20Inspection&entry.906535625=Viktor%20Koz%C3%A1k%20and%20Karel%20Ko%C5%A1nar%20and%20Jan%20Chudoba%20and%20Miroslav%20Kulich%20and%20Libor%20P%C5%99eu%C4%8Dil&entry.1292438233=%20%20Inspection%20systems%20utilizing%20unmanned%20aerial%20vehicles%20%28UAVs%29%20equipped%20with%0Athermal%20cameras%20are%20increasingly%20popular%20for%20the%20maintenance%20of%20photovoltaic%0A%28PV%29%20power%20plants.%20However%2C%20automation%20of%20the%20inspection%20task%20is%20a%20challenging%0Aproblem%20as%20it%20requires%20precise%20navigation%20to%20capture%20images%20from%20optimal%0Adistances%20and%20viewing%20angles.%0A%20%20This%20paper%20presents%20a%20novel%20localization%20pipeline%20that%20directly%20integrates%20PV%0Amodule%20detection%20with%20UAV%20navigation%2C%20allowing%20precise%20positioning%20during%0Ainspection.%20Detections%20are%20used%20to%20identify%20the%20power%20plant%20structures%20in%20the%0Aimage%20and%20associate%20these%20with%20the%20power%20plant%20model.%20We%20define%20visually%0Arecognizable%20anchor%20points%20for%20the%20initial%20association%20and%20use%20object%20tracking%0Ato%20discern%20global%20associations.%20We%20present%20three%20distinct%20methods%20for%20visual%0Asegmentation%20of%20PV%20modules%20based%20on%20traditional%20computer%20vision%2C%20deep%20learning%2C%0Aand%20their%20fusion%2C%20and%20we%20evaluate%20their%20performance%20in%20relation%20to%20the%20proposed%0Alocalization%20pipeline.%0A%20%20The%20presented%20methods%20were%20verified%20and%20evaluated%20using%20custom%20aerial%0Ainspection%20data%20sets%2C%20demonstrating%20their%20robustness%20and%20applicability%20for%0Areal-time%20navigation.%20Additionally%2C%20we%20evaluate%20the%20influence%20of%20the%20power%0Aplant%20model%27s%20precision%20on%20the%20localization%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14587v1&entry.124074799=Read"},
{"title": "End-to-end workflow for machine learning-based qubit readout with QICK\n  and hls4ml", "author": "Giuseppe Di Guglielmo and Botao Du and Javier Campos and Alexandra Boltasseva and Akash V. Dixit and Farah Fahim and Zhaxylyk Kudyshev and Santiago Lopez and Ruichao Ma and Gabriel N. Perdue and Nhan Tran and Omer Yesilyurt and Daniel Bowring", "abstract": "  We present an end-to-end workflow for superconducting qubit readout that\nembeds co-designed Neural Networks (NNs) into the Quantum Instrumentation\nControl Kit (QICK). Capitalizing on the custom firmware and software of the\nQICK platform, which is built on Xilinx RFSoC FPGAs, we aim to leverage machine\nlearning (ML) to address critical challenges in qubit readout accuracy and\nscalability. The workflow utilizes the hls4ml package and employs\nquantization-aware training to translate ML models into hardware-efficient FPGA\nimplementations via user-friendly Python APIs. We experimentally demonstrate\nthe design, optimization, and integration of an ML algorithm for single\ntransmon qubit readout, achieving 96% single-shot fidelity with a latency of\n32ns and less than 16% FPGA look-up table resource utilization. Our results\noffer the community an accessible workflow to advance ML-driven readout and\nadaptive control in quantum information processing applications.\n", "link": "http://arxiv.org/abs/2501.14663v1", "date": "2025-01-24", "relevancy": 1.7242, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4501}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.4306}, {"title": "Tuning-Free Noise Rectification for High Fidelity Image-to-Video\n  Generation", "link": "http://arxiv.org/abs/2403.02827v1", "similarity": 0.4238}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20End-to-end%20workflow%20for%20machine%20learning-based%20qubit%20readout%20with%20QICK%0A%20%20and%20hls4ml&body=Title%3A%20End-to-end%20workflow%20for%20machine%20learning-based%20qubit%20readout%20with%20QICK%0A%20%20and%20hls4ml%0AAuthor%3A%20Giuseppe%20Di%20Guglielmo%20and%20Botao%20Du%20and%20Javier%20Campos%20and%20Alexandra%20Boltasseva%20and%20Akash%20V.%20Dixit%20and%20Farah%20Fahim%20and%20Zhaxylyk%20Kudyshev%20and%20Santiago%20Lopez%20and%20Ruichao%20Ma%20and%20Gabriel%20N.%20Perdue%20and%20Nhan%20Tran%20and%20Omer%20Yesilyurt%20and%20Daniel%20Bowring%0AAbstract%3A%20%20%20We%20present%20an%20end-to-end%20workflow%20for%20superconducting%20qubit%20readout%20that%0Aembeds%20co-designed%20Neural%20Networks%20%28NNs%29%20into%20the%20Quantum%20Instrumentation%0AControl%20Kit%20%28QICK%29.%20Capitalizing%20on%20the%20custom%20firmware%20and%20software%20of%20the%0AQICK%20platform%2C%20which%20is%20built%20on%20Xilinx%20RFSoC%20FPGAs%2C%20we%20aim%20to%20leverage%20machine%0Alearning%20%28ML%29%20to%20address%20critical%20challenges%20in%20qubit%20readout%20accuracy%20and%0Ascalability.%20The%20workflow%20utilizes%20the%20hls4ml%20package%20and%20employs%0Aquantization-aware%20training%20to%20translate%20ML%20models%20into%20hardware-efficient%20FPGA%0Aimplementations%20via%20user-friendly%20Python%20APIs.%20We%20experimentally%20demonstrate%0Athe%20design%2C%20optimization%2C%20and%20integration%20of%20an%20ML%20algorithm%20for%20single%0Atransmon%20qubit%20readout%2C%20achieving%2096%25%20single-shot%20fidelity%20with%20a%20latency%20of%0A32ns%20and%20less%20than%2016%25%20FPGA%20look-up%20table%20resource%20utilization.%20Our%20results%0Aoffer%20the%20community%20an%20accessible%20workflow%20to%20advance%20ML-driven%20readout%20and%0Aadaptive%20control%20in%20quantum%20information%20processing%20applications.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14663v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DEnd-to-end%2520workflow%2520for%2520machine%2520learning-based%2520qubit%2520readout%2520with%2520QICK%250A%2520%2520and%2520hls4ml%26entry.906535625%3DGiuseppe%2520Di%2520Guglielmo%2520and%2520Botao%2520Du%2520and%2520Javier%2520Campos%2520and%2520Alexandra%2520Boltasseva%2520and%2520Akash%2520V.%2520Dixit%2520and%2520Farah%2520Fahim%2520and%2520Zhaxylyk%2520Kudyshev%2520and%2520Santiago%2520Lopez%2520and%2520Ruichao%2520Ma%2520and%2520Gabriel%2520N.%2520Perdue%2520and%2520Nhan%2520Tran%2520and%2520Omer%2520Yesilyurt%2520and%2520Daniel%2520Bowring%26entry.1292438233%3D%2520%2520We%2520present%2520an%2520end-to-end%2520workflow%2520for%2520superconducting%2520qubit%2520readout%2520that%250Aembeds%2520co-designed%2520Neural%2520Networks%2520%2528NNs%2529%2520into%2520the%2520Quantum%2520Instrumentation%250AControl%2520Kit%2520%2528QICK%2529.%2520Capitalizing%2520on%2520the%2520custom%2520firmware%2520and%2520software%2520of%2520the%250AQICK%2520platform%252C%2520which%2520is%2520built%2520on%2520Xilinx%2520RFSoC%2520FPGAs%252C%2520we%2520aim%2520to%2520leverage%2520machine%250Alearning%2520%2528ML%2529%2520to%2520address%2520critical%2520challenges%2520in%2520qubit%2520readout%2520accuracy%2520and%250Ascalability.%2520The%2520workflow%2520utilizes%2520the%2520hls4ml%2520package%2520and%2520employs%250Aquantization-aware%2520training%2520to%2520translate%2520ML%2520models%2520into%2520hardware-efficient%2520FPGA%250Aimplementations%2520via%2520user-friendly%2520Python%2520APIs.%2520We%2520experimentally%2520demonstrate%250Athe%2520design%252C%2520optimization%252C%2520and%2520integration%2520of%2520an%2520ML%2520algorithm%2520for%2520single%250Atransmon%2520qubit%2520readout%252C%2520achieving%252096%2525%2520single-shot%2520fidelity%2520with%2520a%2520latency%2520of%250A32ns%2520and%2520less%2520than%252016%2525%2520FPGA%2520look-up%2520table%2520resource%2520utilization.%2520Our%2520results%250Aoffer%2520the%2520community%2520an%2520accessible%2520workflow%2520to%2520advance%2520ML-driven%2520readout%2520and%250Aadaptive%2520control%2520in%2520quantum%2520information%2520processing%2520applications.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14663v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=End-to-end%20workflow%20for%20machine%20learning-based%20qubit%20readout%20with%20QICK%0A%20%20and%20hls4ml&entry.906535625=Giuseppe%20Di%20Guglielmo%20and%20Botao%20Du%20and%20Javier%20Campos%20and%20Alexandra%20Boltasseva%20and%20Akash%20V.%20Dixit%20and%20Farah%20Fahim%20and%20Zhaxylyk%20Kudyshev%20and%20Santiago%20Lopez%20and%20Ruichao%20Ma%20and%20Gabriel%20N.%20Perdue%20and%20Nhan%20Tran%20and%20Omer%20Yesilyurt%20and%20Daniel%20Bowring&entry.1292438233=%20%20We%20present%20an%20end-to-end%20workflow%20for%20superconducting%20qubit%20readout%20that%0Aembeds%20co-designed%20Neural%20Networks%20%28NNs%29%20into%20the%20Quantum%20Instrumentation%0AControl%20Kit%20%28QICK%29.%20Capitalizing%20on%20the%20custom%20firmware%20and%20software%20of%20the%0AQICK%20platform%2C%20which%20is%20built%20on%20Xilinx%20RFSoC%20FPGAs%2C%20we%20aim%20to%20leverage%20machine%0Alearning%20%28ML%29%20to%20address%20critical%20challenges%20in%20qubit%20readout%20accuracy%20and%0Ascalability.%20The%20workflow%20utilizes%20the%20hls4ml%20package%20and%20employs%0Aquantization-aware%20training%20to%20translate%20ML%20models%20into%20hardware-efficient%20FPGA%0Aimplementations%20via%20user-friendly%20Python%20APIs.%20We%20experimentally%20demonstrate%0Athe%20design%2C%20optimization%2C%20and%20integration%20of%20an%20ML%20algorithm%20for%20single%0Atransmon%20qubit%20readout%2C%20achieving%2096%25%20single-shot%20fidelity%20with%20a%20latency%20of%0A32ns%20and%20less%20than%2016%25%20FPGA%20look-up%20table%20resource%20utilization.%20Our%20results%0Aoffer%20the%20community%20an%20accessible%20workflow%20to%20advance%20ML-driven%20readout%20and%0Aadaptive%20control%20in%20quantum%20information%20processing%20applications.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14663v1&entry.124074799=Read"},
{"title": "MLPs at the EOC: Concentration of the NTK", "author": "D\u00e1vid Terj\u00e9k and Diego Gonz\u00e1lez-S\u00e1nchez", "abstract": "  We study the concentration of the Neural Tangent Kernel (NTK) $K_\\theta :\n\\mathbb{R}^{m_0} \\times \\mathbb{R}^{m_0} \\to \\mathbb{R}^{m_l \\times m_l}$ of\n$l$-layer Multilayer Perceptrons (MLPs) $N : \\mathbb{R}^{m_0} \\times \\Theta \\to\n\\mathbb{R}^{m_l}$ equipped with activation functions $\\phi(s) = a s + b \\vert s\n\\vert$ for some $a,b \\in \\mathbb{R}$ with the parameter $\\theta \\in \\Theta$\nbeing initialized at the Edge Of Chaos (EOC). Without relying on the gradient\nindependence assumption that has only been shown to hold asymptotically in the\ninfinitely wide limit, we prove that an approximate version of gradient\nindependence holds at finite width. Showing that the NTK entries\n$K_\\theta(x_{i_1},x_{i_2})$ for $i_1,i_2 \\in [1:n]$ over a dataset\n$\\{x_1,\\cdots,x_n\\} \\subset \\mathbb{R}^{m_0}$ concentrate simultaneously via\nmaximal inequalities, we prove that the NTK matrix $K(\\theta) = [\\frac{1}{n}\nK_\\theta(x_{i_1},x_{i_2}) : i_1,i_2 \\in [1:n]] \\in \\mathbb{R}^{nm_l \\times\nnm_l}$ concentrates around its infinitely wide limit\n$\\overset{\\scriptscriptstyle\\infty}{K} \\in \\mathbb{R}^{nm_l \\times nm_l}$\nwithout the need for linear overparameterization. Our results imply that in\norder to accurately approximate the limit, hidden layer widths have to grow\nquadratically as $m_k = k^2 m$ for some $m \\in \\mathbb{N}+1$ for sufficient\nconcentration. For such MLPs, we obtain the concentration bound $\\mathbb{P}(\n\\Vert K(\\theta) - \\overset{\\scriptscriptstyle\\infty}{K} \\Vert \\leq\nO((\\Delta_\\phi^{-2} + m_l^{\\frac{1}{2}} l) \\kappa_\\phi^2 m^{-\\frac{1}{2}}))\n\\geq 1-O(m^{-1})$ modulo logarithmic terms, where we denoted $\\Delta_\\phi =\n\\frac{b^2}{a^2+b^2}$ and $\\kappa_\\phi = \\frac{\\vert a \\vert + \\vert b\n\\vert}{\\sqrt{a^2 + b^2}}$. This reveals in particular that the absolute value\n($\\Delta_\\phi=1$, $\\kappa_\\phi=1$) beats the ReLU ($\\Delta_\\phi=\\frac{1}{2}$,\n$\\kappa_\\phi=\\sqrt{2}$) in terms of the concentration of the NTK.\n", "link": "http://arxiv.org/abs/2501.14724v1", "date": "2025-01-24", "relevancy": 1.7048, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4372}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.4228}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4072}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20MLPs%20at%20the%20EOC%3A%20Concentration%20of%20the%20NTK&body=Title%3A%20MLPs%20at%20the%20EOC%3A%20Concentration%20of%20the%20NTK%0AAuthor%3A%20D%C3%A1vid%20Terj%C3%A9k%20and%20Diego%20Gonz%C3%A1lez-S%C3%A1nchez%0AAbstract%3A%20%20%20We%20study%20the%20concentration%20of%20the%20Neural%20Tangent%20Kernel%20%28NTK%29%20%24K_%5Ctheta%20%3A%0A%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Ctimes%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Cto%20%5Cmathbb%7BR%7D%5E%7Bm_l%20%5Ctimes%20m_l%7D%24%20of%0A%24l%24-layer%20Multilayer%20Perceptrons%20%28MLPs%29%20%24N%20%3A%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Ctimes%20%5CTheta%20%5Cto%0A%5Cmathbb%7BR%7D%5E%7Bm_l%7D%24%20equipped%20with%20activation%20functions%20%24%5Cphi%28s%29%20%3D%20a%20s%20%2B%20b%20%5Cvert%20s%0A%5Cvert%24%20for%20some%20%24a%2Cb%20%5Cin%20%5Cmathbb%7BR%7D%24%20with%20the%20parameter%20%24%5Ctheta%20%5Cin%20%5CTheta%24%0Abeing%20initialized%20at%20the%20Edge%20Of%20Chaos%20%28EOC%29.%20Without%20relying%20on%20the%20gradient%0Aindependence%20assumption%20that%20has%20only%20been%20shown%20to%20hold%20asymptotically%20in%20the%0Ainfinitely%20wide%20limit%2C%20we%20prove%20that%20an%20approximate%20version%20of%20gradient%0Aindependence%20holds%20at%20finite%20width.%20Showing%20that%20the%20NTK%20entries%0A%24K_%5Ctheta%28x_%7Bi_1%7D%2Cx_%7Bi_2%7D%29%24%20for%20%24i_1%2Ci_2%20%5Cin%20%5B1%3An%5D%24%20over%20a%20dataset%0A%24%5C%7Bx_1%2C%5Ccdots%2Cx_n%5C%7D%20%5Csubset%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%24%20concentrate%20simultaneously%20via%0Amaximal%20inequalities%2C%20we%20prove%20that%20the%20NTK%20matrix%20%24K%28%5Ctheta%29%20%3D%20%5B%5Cfrac%7B1%7D%7Bn%7D%0AK_%5Ctheta%28x_%7Bi_1%7D%2Cx_%7Bi_2%7D%29%20%3A%20i_1%2Ci_2%20%5Cin%20%5B1%3An%5D%5D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bnm_l%20%5Ctimes%0Anm_l%7D%24%20concentrates%20around%20its%20infinitely%20wide%20limit%0A%24%5Coverset%7B%5Cscriptscriptstyle%5Cinfty%7D%7BK%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bnm_l%20%5Ctimes%20nm_l%7D%24%0Awithout%20the%20need%20for%20linear%20overparameterization.%20Our%20results%20imply%20that%20in%0Aorder%20to%20accurately%20approximate%20the%20limit%2C%20hidden%20layer%20widths%20have%20to%20grow%0Aquadratically%20as%20%24m_k%20%3D%20k%5E2%20m%24%20for%20some%20%24m%20%5Cin%20%5Cmathbb%7BN%7D%2B1%24%20for%20sufficient%0Aconcentration.%20For%20such%20MLPs%2C%20we%20obtain%20the%20concentration%20bound%20%24%5Cmathbb%7BP%7D%28%0A%5CVert%20K%28%5Ctheta%29%20-%20%5Coverset%7B%5Cscriptscriptstyle%5Cinfty%7D%7BK%7D%20%5CVert%20%5Cleq%0AO%28%28%5CDelta_%5Cphi%5E%7B-2%7D%20%2B%20m_l%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20l%29%20%5Ckappa_%5Cphi%5E2%20m%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D%29%29%0A%5Cgeq%201-O%28m%5E%7B-1%7D%29%24%20modulo%20logarithmic%20terms%2C%20where%20we%20denoted%20%24%5CDelta_%5Cphi%20%3D%0A%5Cfrac%7Bb%5E2%7D%7Ba%5E2%2Bb%5E2%7D%24%20and%20%24%5Ckappa_%5Cphi%20%3D%20%5Cfrac%7B%5Cvert%20a%20%5Cvert%20%2B%20%5Cvert%20b%0A%5Cvert%7D%7B%5Csqrt%7Ba%5E2%20%2B%20b%5E2%7D%7D%24.%20This%20reveals%20in%20particular%20that%20the%20absolute%20value%0A%28%24%5CDelta_%5Cphi%3D1%24%2C%20%24%5Ckappa_%5Cphi%3D1%24%29%20beats%20the%20ReLU%20%28%24%5CDelta_%5Cphi%3D%5Cfrac%7B1%7D%7B2%7D%24%2C%0A%24%5Ckappa_%5Cphi%3D%5Csqrt%7B2%7D%24%29%20in%20terms%20of%20the%20concentration%20of%20the%20NTK.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14724v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DMLPs%2520at%2520the%2520EOC%253A%2520Concentration%2520of%2520the%2520NTK%26entry.906535625%3DD%25C3%25A1vid%2520Terj%25C3%25A9k%2520and%2520Diego%2520Gonz%25C3%25A1lez-S%25C3%25A1nchez%26entry.1292438233%3D%2520%2520We%2520study%2520the%2520concentration%2520of%2520the%2520Neural%2520Tangent%2520Kernel%2520%2528NTK%2529%2520%2524K_%255Ctheta%2520%253A%250A%255Cmathbb%257BR%257D%255E%257Bm_0%257D%2520%255Ctimes%2520%255Cmathbb%257BR%257D%255E%257Bm_0%257D%2520%255Cto%2520%255Cmathbb%257BR%257D%255E%257Bm_l%2520%255Ctimes%2520m_l%257D%2524%2520of%250A%2524l%2524-layer%2520Multilayer%2520Perceptrons%2520%2528MLPs%2529%2520%2524N%2520%253A%2520%255Cmathbb%257BR%257D%255E%257Bm_0%257D%2520%255Ctimes%2520%255CTheta%2520%255Cto%250A%255Cmathbb%257BR%257D%255E%257Bm_l%257D%2524%2520equipped%2520with%2520activation%2520functions%2520%2524%255Cphi%2528s%2529%2520%253D%2520a%2520s%2520%252B%2520b%2520%255Cvert%2520s%250A%255Cvert%2524%2520for%2520some%2520%2524a%252Cb%2520%255Cin%2520%255Cmathbb%257BR%257D%2524%2520with%2520the%2520parameter%2520%2524%255Ctheta%2520%255Cin%2520%255CTheta%2524%250Abeing%2520initialized%2520at%2520the%2520Edge%2520Of%2520Chaos%2520%2528EOC%2529.%2520Without%2520relying%2520on%2520the%2520gradient%250Aindependence%2520assumption%2520that%2520has%2520only%2520been%2520shown%2520to%2520hold%2520asymptotically%2520in%2520the%250Ainfinitely%2520wide%2520limit%252C%2520we%2520prove%2520that%2520an%2520approximate%2520version%2520of%2520gradient%250Aindependence%2520holds%2520at%2520finite%2520width.%2520Showing%2520that%2520the%2520NTK%2520entries%250A%2524K_%255Ctheta%2528x_%257Bi_1%257D%252Cx_%257Bi_2%257D%2529%2524%2520for%2520%2524i_1%252Ci_2%2520%255Cin%2520%255B1%253An%255D%2524%2520over%2520a%2520dataset%250A%2524%255C%257Bx_1%252C%255Ccdots%252Cx_n%255C%257D%2520%255Csubset%2520%255Cmathbb%257BR%257D%255E%257Bm_0%257D%2524%2520concentrate%2520simultaneously%2520via%250Amaximal%2520inequalities%252C%2520we%2520prove%2520that%2520the%2520NTK%2520matrix%2520%2524K%2528%255Ctheta%2529%2520%253D%2520%255B%255Cfrac%257B1%257D%257Bn%257D%250AK_%255Ctheta%2528x_%257Bi_1%257D%252Cx_%257Bi_2%257D%2529%2520%253A%2520i_1%252Ci_2%2520%255Cin%2520%255B1%253An%255D%255D%2520%255Cin%2520%255Cmathbb%257BR%257D%255E%257Bnm_l%2520%255Ctimes%250Anm_l%257D%2524%2520concentrates%2520around%2520its%2520infinitely%2520wide%2520limit%250A%2524%255Coverset%257B%255Cscriptscriptstyle%255Cinfty%257D%257BK%257D%2520%255Cin%2520%255Cmathbb%257BR%257D%255E%257Bnm_l%2520%255Ctimes%2520nm_l%257D%2524%250Awithout%2520the%2520need%2520for%2520linear%2520overparameterization.%2520Our%2520results%2520imply%2520that%2520in%250Aorder%2520to%2520accurately%2520approximate%2520the%2520limit%252C%2520hidden%2520layer%2520widths%2520have%2520to%2520grow%250Aquadratically%2520as%2520%2524m_k%2520%253D%2520k%255E2%2520m%2524%2520for%2520some%2520%2524m%2520%255Cin%2520%255Cmathbb%257BN%257D%252B1%2524%2520for%2520sufficient%250Aconcentration.%2520For%2520such%2520MLPs%252C%2520we%2520obtain%2520the%2520concentration%2520bound%2520%2524%255Cmathbb%257BP%257D%2528%250A%255CVert%2520K%2528%255Ctheta%2529%2520-%2520%255Coverset%257B%255Cscriptscriptstyle%255Cinfty%257D%257BK%257D%2520%255CVert%2520%255Cleq%250AO%2528%2528%255CDelta_%255Cphi%255E%257B-2%257D%2520%252B%2520m_l%255E%257B%255Cfrac%257B1%257D%257B2%257D%257D%2520l%2529%2520%255Ckappa_%255Cphi%255E2%2520m%255E%257B-%255Cfrac%257B1%257D%257B2%257D%257D%2529%2529%250A%255Cgeq%25201-O%2528m%255E%257B-1%257D%2529%2524%2520modulo%2520logarithmic%2520terms%252C%2520where%2520we%2520denoted%2520%2524%255CDelta_%255Cphi%2520%253D%250A%255Cfrac%257Bb%255E2%257D%257Ba%255E2%252Bb%255E2%257D%2524%2520and%2520%2524%255Ckappa_%255Cphi%2520%253D%2520%255Cfrac%257B%255Cvert%2520a%2520%255Cvert%2520%252B%2520%255Cvert%2520b%250A%255Cvert%257D%257B%255Csqrt%257Ba%255E2%2520%252B%2520b%255E2%257D%257D%2524.%2520This%2520reveals%2520in%2520particular%2520that%2520the%2520absolute%2520value%250A%2528%2524%255CDelta_%255Cphi%253D1%2524%252C%2520%2524%255Ckappa_%255Cphi%253D1%2524%2529%2520beats%2520the%2520ReLU%2520%2528%2524%255CDelta_%255Cphi%253D%255Cfrac%257B1%257D%257B2%257D%2524%252C%250A%2524%255Ckappa_%255Cphi%253D%255Csqrt%257B2%257D%2524%2529%2520in%2520terms%2520of%2520the%2520concentration%2520of%2520the%2520NTK.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14724v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=MLPs%20at%20the%20EOC%3A%20Concentration%20of%20the%20NTK&entry.906535625=D%C3%A1vid%20Terj%C3%A9k%20and%20Diego%20Gonz%C3%A1lez-S%C3%A1nchez&entry.1292438233=%20%20We%20study%20the%20concentration%20of%20the%20Neural%20Tangent%20Kernel%20%28NTK%29%20%24K_%5Ctheta%20%3A%0A%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Ctimes%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Cto%20%5Cmathbb%7BR%7D%5E%7Bm_l%20%5Ctimes%20m_l%7D%24%20of%0A%24l%24-layer%20Multilayer%20Perceptrons%20%28MLPs%29%20%24N%20%3A%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%20%5Ctimes%20%5CTheta%20%5Cto%0A%5Cmathbb%7BR%7D%5E%7Bm_l%7D%24%20equipped%20with%20activation%20functions%20%24%5Cphi%28s%29%20%3D%20a%20s%20%2B%20b%20%5Cvert%20s%0A%5Cvert%24%20for%20some%20%24a%2Cb%20%5Cin%20%5Cmathbb%7BR%7D%24%20with%20the%20parameter%20%24%5Ctheta%20%5Cin%20%5CTheta%24%0Abeing%20initialized%20at%20the%20Edge%20Of%20Chaos%20%28EOC%29.%20Without%20relying%20on%20the%20gradient%0Aindependence%20assumption%20that%20has%20only%20been%20shown%20to%20hold%20asymptotically%20in%20the%0Ainfinitely%20wide%20limit%2C%20we%20prove%20that%20an%20approximate%20version%20of%20gradient%0Aindependence%20holds%20at%20finite%20width.%20Showing%20that%20the%20NTK%20entries%0A%24K_%5Ctheta%28x_%7Bi_1%7D%2Cx_%7Bi_2%7D%29%24%20for%20%24i_1%2Ci_2%20%5Cin%20%5B1%3An%5D%24%20over%20a%20dataset%0A%24%5C%7Bx_1%2C%5Ccdots%2Cx_n%5C%7D%20%5Csubset%20%5Cmathbb%7BR%7D%5E%7Bm_0%7D%24%20concentrate%20simultaneously%20via%0Amaximal%20inequalities%2C%20we%20prove%20that%20the%20NTK%20matrix%20%24K%28%5Ctheta%29%20%3D%20%5B%5Cfrac%7B1%7D%7Bn%7D%0AK_%5Ctheta%28x_%7Bi_1%7D%2Cx_%7Bi_2%7D%29%20%3A%20i_1%2Ci_2%20%5Cin%20%5B1%3An%5D%5D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bnm_l%20%5Ctimes%0Anm_l%7D%24%20concentrates%20around%20its%20infinitely%20wide%20limit%0A%24%5Coverset%7B%5Cscriptscriptstyle%5Cinfty%7D%7BK%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bnm_l%20%5Ctimes%20nm_l%7D%24%0Awithout%20the%20need%20for%20linear%20overparameterization.%20Our%20results%20imply%20that%20in%0Aorder%20to%20accurately%20approximate%20the%20limit%2C%20hidden%20layer%20widths%20have%20to%20grow%0Aquadratically%20as%20%24m_k%20%3D%20k%5E2%20m%24%20for%20some%20%24m%20%5Cin%20%5Cmathbb%7BN%7D%2B1%24%20for%20sufficient%0Aconcentration.%20For%20such%20MLPs%2C%20we%20obtain%20the%20concentration%20bound%20%24%5Cmathbb%7BP%7D%28%0A%5CVert%20K%28%5Ctheta%29%20-%20%5Coverset%7B%5Cscriptscriptstyle%5Cinfty%7D%7BK%7D%20%5CVert%20%5Cleq%0AO%28%28%5CDelta_%5Cphi%5E%7B-2%7D%20%2B%20m_l%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20l%29%20%5Ckappa_%5Cphi%5E2%20m%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D%29%29%0A%5Cgeq%201-O%28m%5E%7B-1%7D%29%24%20modulo%20logarithmic%20terms%2C%20where%20we%20denoted%20%24%5CDelta_%5Cphi%20%3D%0A%5Cfrac%7Bb%5E2%7D%7Ba%5E2%2Bb%5E2%7D%24%20and%20%24%5Ckappa_%5Cphi%20%3D%20%5Cfrac%7B%5Cvert%20a%20%5Cvert%20%2B%20%5Cvert%20b%0A%5Cvert%7D%7B%5Csqrt%7Ba%5E2%20%2B%20b%5E2%7D%7D%24.%20This%20reveals%20in%20particular%20that%20the%20absolute%20value%0A%28%24%5CDelta_%5Cphi%3D1%24%2C%20%24%5Ckappa_%5Cphi%3D1%24%29%20beats%20the%20ReLU%20%28%24%5CDelta_%5Cphi%3D%5Cfrac%7B1%7D%7B2%7D%24%2C%0A%24%5Ckappa_%5Cphi%3D%5Csqrt%7B2%7D%24%29%20in%20terms%20of%20the%20concentration%20of%20the%20NTK.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14724v1&entry.124074799=Read"},
{"title": "Whisper D-SGD: Correlated Noise Across Agents for Differentially Private\n  Decentralized Learning", "author": "Angelo Rodio and Zheng Chen and Erik G. Larsson", "abstract": "  Decentralized learning enables distributed agents to train a shared machine\nlearning model through local computation and peer-to-peer communication.\nAlthough each agent retains its dataset locally, the communication of local\nmodels can still expose private information to adversaries. To mitigate these\nthreats, local differential privacy (LDP) injects independent noise per agent,\nbut it suffers a larger utility gap than central differential privacy (CDP). We\nintroduce Whisper D-SGD, a novel covariance-based approach that generates\ncorrelated privacy noise across agents, unifying several state-of-the-art\nmethods as special cases. By leveraging network topology and mixing weights,\nWhisper D-SGD optimizes the noise covariance to achieve network-wide noise\ncancellation. Experimental results show that Whisper D-SGD cancels more noise\nthan existing pairwise-correlation schemes, substantially narrowing the CDP-LDP\ngap and improving model performance under the same privacy guarantees.\n", "link": "http://arxiv.org/abs/2501.14644v1", "date": "2025-01-24", "relevancy": 1.6971, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4424}, {"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4222}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.4192}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Whisper%20D-SGD%3A%20Correlated%20Noise%20Across%20Agents%20for%20Differentially%20Private%0A%20%20Decentralized%20Learning&body=Title%3A%20Whisper%20D-SGD%3A%20Correlated%20Noise%20Across%20Agents%20for%20Differentially%20Private%0A%20%20Decentralized%20Learning%0AAuthor%3A%20Angelo%20Rodio%20and%20Zheng%20Chen%20and%20Erik%20G.%20Larsson%0AAbstract%3A%20%20%20Decentralized%20learning%20enables%20distributed%20agents%20to%20train%20a%20shared%20machine%0Alearning%20model%20through%20local%20computation%20and%20peer-to-peer%20communication.%0AAlthough%20each%20agent%20retains%20its%20dataset%20locally%2C%20the%20communication%20of%20local%0Amodels%20can%20still%20expose%20private%20information%20to%20adversaries.%20To%20mitigate%20these%0Athreats%2C%20local%20differential%20privacy%20%28LDP%29%20injects%20independent%20noise%20per%20agent%2C%0Abut%20it%20suffers%20a%20larger%20utility%20gap%20than%20central%20differential%20privacy%20%28CDP%29.%20We%0Aintroduce%20Whisper%20D-SGD%2C%20a%20novel%20covariance-based%20approach%20that%20generates%0Acorrelated%20privacy%20noise%20across%20agents%2C%20unifying%20several%20state-of-the-art%0Amethods%20as%20special%20cases.%20By%20leveraging%20network%20topology%20and%20mixing%20weights%2C%0AWhisper%20D-SGD%20optimizes%20the%20noise%20covariance%20to%20achieve%20network-wide%20noise%0Acancellation.%20Experimental%20results%20show%20that%20Whisper%20D-SGD%20cancels%20more%20noise%0Athan%20existing%20pairwise-correlation%20schemes%2C%20substantially%20narrowing%20the%20CDP-LDP%0Agap%20and%20improving%20model%20performance%20under%20the%20same%20privacy%20guarantees.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14644v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DWhisper%2520D-SGD%253A%2520Correlated%2520Noise%2520Across%2520Agents%2520for%2520Differentially%2520Private%250A%2520%2520Decentralized%2520Learning%26entry.906535625%3DAngelo%2520Rodio%2520and%2520Zheng%2520Chen%2520and%2520Erik%2520G.%2520Larsson%26entry.1292438233%3D%2520%2520Decentralized%2520learning%2520enables%2520distributed%2520agents%2520to%2520train%2520a%2520shared%2520machine%250Alearning%2520model%2520through%2520local%2520computation%2520and%2520peer-to-peer%2520communication.%250AAlthough%2520each%2520agent%2520retains%2520its%2520dataset%2520locally%252C%2520the%2520communication%2520of%2520local%250Amodels%2520can%2520still%2520expose%2520private%2520information%2520to%2520adversaries.%2520To%2520mitigate%2520these%250Athreats%252C%2520local%2520differential%2520privacy%2520%2528LDP%2529%2520injects%2520independent%2520noise%2520per%2520agent%252C%250Abut%2520it%2520suffers%2520a%2520larger%2520utility%2520gap%2520than%2520central%2520differential%2520privacy%2520%2528CDP%2529.%2520We%250Aintroduce%2520Whisper%2520D-SGD%252C%2520a%2520novel%2520covariance-based%2520approach%2520that%2520generates%250Acorrelated%2520privacy%2520noise%2520across%2520agents%252C%2520unifying%2520several%2520state-of-the-art%250Amethods%2520as%2520special%2520cases.%2520By%2520leveraging%2520network%2520topology%2520and%2520mixing%2520weights%252C%250AWhisper%2520D-SGD%2520optimizes%2520the%2520noise%2520covariance%2520to%2520achieve%2520network-wide%2520noise%250Acancellation.%2520Experimental%2520results%2520show%2520that%2520Whisper%2520D-SGD%2520cancels%2520more%2520noise%250Athan%2520existing%2520pairwise-correlation%2520schemes%252C%2520substantially%2520narrowing%2520the%2520CDP-LDP%250Agap%2520and%2520improving%2520model%2520performance%2520under%2520the%2520same%2520privacy%2520guarantees.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14644v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Whisper%20D-SGD%3A%20Correlated%20Noise%20Across%20Agents%20for%20Differentially%20Private%0A%20%20Decentralized%20Learning&entry.906535625=Angelo%20Rodio%20and%20Zheng%20Chen%20and%20Erik%20G.%20Larsson&entry.1292438233=%20%20Decentralized%20learning%20enables%20distributed%20agents%20to%20train%20a%20shared%20machine%0Alearning%20model%20through%20local%20computation%20and%20peer-to-peer%20communication.%0AAlthough%20each%20agent%20retains%20its%20dataset%20locally%2C%20the%20communication%20of%20local%0Amodels%20can%20still%20expose%20private%20information%20to%20adversaries.%20To%20mitigate%20these%0Athreats%2C%20local%20differential%20privacy%20%28LDP%29%20injects%20independent%20noise%20per%20agent%2C%0Abut%20it%20suffers%20a%20larger%20utility%20gap%20than%20central%20differential%20privacy%20%28CDP%29.%20We%0Aintroduce%20Whisper%20D-SGD%2C%20a%20novel%20covariance-based%20approach%20that%20generates%0Acorrelated%20privacy%20noise%20across%20agents%2C%20unifying%20several%20state-of-the-art%0Amethods%20as%20special%20cases.%20By%20leveraging%20network%20topology%20and%20mixing%20weights%2C%0AWhisper%20D-SGD%20optimizes%20the%20noise%20covariance%20to%20achieve%20network-wide%20noise%0Acancellation.%20Experimental%20results%20show%20that%20Whisper%20D-SGD%20cancels%20more%20noise%0Athan%20existing%20pairwise-correlation%20schemes%2C%20substantially%20narrowing%20the%20CDP-LDP%0Agap%20and%20improving%20model%20performance%20under%20the%20same%20privacy%20guarantees.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14644v1&entry.124074799=Read"},
{"title": "Token Turing Machines are Efficient Vision Models", "author": "Purvish Jajal and Nick John Eliopoulos and Benjamin Shiue-Hal Chou and George K. Thiruvathukal and James C. Davis and Yung-Hsiang Lu", "abstract": "  We propose Vision Token Turing Machines (ViTTM), an efficient, low-latency,\nmemory-augmented Vision Transformer (ViT). Our approach builds on Neural Turing\nMachines and Token Turing Machines, which were applied to NLP and sequential\nvisual understanding tasks. ViTTMs are designed for non-sequential computer\nvision tasks such as image classification and segmentation. Our model creates\ntwo sets of tokens: process tokens and memory tokens; process tokens pass\nthrough encoder blocks and read-write from memory tokens at each encoder block\nin the network, allowing them to store and retrieve information from memory. By\nensuring that there are fewer process tokens than memory tokens, we are able to\nreduce the inference time of the network while maintaining its accuracy. On\nImageNet-1K, the state-of-the-art ViT-B has median latency of 529.5ms and 81.0%\naccuracy, while our ViTTM-B is 56% faster (234.1ms), with 2.4 times fewer\nFLOPs, with an accuracy of 82.9%. On ADE20K semantic segmentation, ViT-B\nachieves 45.65mIoU at 13.8 frame-per-second (FPS) whereas our ViTTM-B model\nacheives a 45.17 mIoU with 26.8 FPS (+94%).\n", "link": "http://arxiv.org/abs/2409.07613v3", "date": "2025-01-24", "relevancy": 1.6918, "topK": [{"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.5884}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.5436}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.5231}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Token%20Turing%20Machines%20are%20Efficient%20Vision%20Models&body=Title%3A%20Token%20Turing%20Machines%20are%20Efficient%20Vision%20Models%0AAuthor%3A%20Purvish%20Jajal%20and%20Nick%20John%20Eliopoulos%20and%20Benjamin%20Shiue-Hal%20Chou%20and%20George%20K.%20Thiruvathukal%20and%20James%20C.%20Davis%20and%20Yung-Hsiang%20Lu%0AAbstract%3A%20%20%20We%20propose%20Vision%20Token%20Turing%20Machines%20%28ViTTM%29%2C%20an%20efficient%2C%20low-latency%2C%0Amemory-augmented%20Vision%20Transformer%20%28ViT%29.%20Our%20approach%20builds%20on%20Neural%20Turing%0AMachines%20and%20Token%20Turing%20Machines%2C%20which%20were%20applied%20to%20NLP%20and%20sequential%0Avisual%20understanding%20tasks.%20ViTTMs%20are%20designed%20for%20non-sequential%20computer%0Avision%20tasks%20such%20as%20image%20classification%20and%20segmentation.%20Our%20model%20creates%0Atwo%20sets%20of%20tokens%3A%20process%20tokens%20and%20memory%20tokens%3B%20process%20tokens%20pass%0Athrough%20encoder%20blocks%20and%20read-write%20from%20memory%20tokens%20at%20each%20encoder%20block%0Ain%20the%20network%2C%20allowing%20them%20to%20store%20and%20retrieve%20information%20from%20memory.%20By%0Aensuring%20that%20there%20are%20fewer%20process%20tokens%20than%20memory%20tokens%2C%20we%20are%20able%20to%0Areduce%20the%20inference%20time%20of%20the%20network%20while%20maintaining%20its%20accuracy.%20On%0AImageNet-1K%2C%20the%20state-of-the-art%20ViT-B%20has%20median%20latency%20of%20529.5ms%20and%2081.0%25%0Aaccuracy%2C%20while%20our%20ViTTM-B%20is%2056%25%20faster%20%28234.1ms%29%2C%20with%202.4%20times%20fewer%0AFLOPs%2C%20with%20an%20accuracy%20of%2082.9%25.%20On%20ADE20K%20semantic%20segmentation%2C%20ViT-B%0Aachieves%2045.65mIoU%20at%2013.8%20frame-per-second%20%28FPS%29%20whereas%20our%20ViTTM-B%20model%0Aacheives%20a%2045.17%20mIoU%20with%2026.8%20FPS%20%28%2B94%25%29.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2409.07613v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DToken%2520Turing%2520Machines%2520are%2520Efficient%2520Vision%2520Models%26entry.906535625%3DPurvish%2520Jajal%2520and%2520Nick%2520John%2520Eliopoulos%2520and%2520Benjamin%2520Shiue-Hal%2520Chou%2520and%2520George%2520K.%2520Thiruvathukal%2520and%2520James%2520C.%2520Davis%2520and%2520Yung-Hsiang%2520Lu%26entry.1292438233%3D%2520%2520We%2520propose%2520Vision%2520Token%2520Turing%2520Machines%2520%2528ViTTM%2529%252C%2520an%2520efficient%252C%2520low-latency%252C%250Amemory-augmented%2520Vision%2520Transformer%2520%2528ViT%2529.%2520Our%2520approach%2520builds%2520on%2520Neural%2520Turing%250AMachines%2520and%2520Token%2520Turing%2520Machines%252C%2520which%2520were%2520applied%2520to%2520NLP%2520and%2520sequential%250Avisual%2520understanding%2520tasks.%2520ViTTMs%2520are%2520designed%2520for%2520non-sequential%2520computer%250Avision%2520tasks%2520such%2520as%2520image%2520classification%2520and%2520segmentation.%2520Our%2520model%2520creates%250Atwo%2520sets%2520of%2520tokens%253A%2520process%2520tokens%2520and%2520memory%2520tokens%253B%2520process%2520tokens%2520pass%250Athrough%2520encoder%2520blocks%2520and%2520read-write%2520from%2520memory%2520tokens%2520at%2520each%2520encoder%2520block%250Ain%2520the%2520network%252C%2520allowing%2520them%2520to%2520store%2520and%2520retrieve%2520information%2520from%2520memory.%2520By%250Aensuring%2520that%2520there%2520are%2520fewer%2520process%2520tokens%2520than%2520memory%2520tokens%252C%2520we%2520are%2520able%2520to%250Areduce%2520the%2520inference%2520time%2520of%2520the%2520network%2520while%2520maintaining%2520its%2520accuracy.%2520On%250AImageNet-1K%252C%2520the%2520state-of-the-art%2520ViT-B%2520has%2520median%2520latency%2520of%2520529.5ms%2520and%252081.0%2525%250Aaccuracy%252C%2520while%2520our%2520ViTTM-B%2520is%252056%2525%2520faster%2520%2528234.1ms%2529%252C%2520with%25202.4%2520times%2520fewer%250AFLOPs%252C%2520with%2520an%2520accuracy%2520of%252082.9%2525.%2520On%2520ADE20K%2520semantic%2520segmentation%252C%2520ViT-B%250Aachieves%252045.65mIoU%2520at%252013.8%2520frame-per-second%2520%2528FPS%2529%2520whereas%2520our%2520ViTTM-B%2520model%250Aacheives%2520a%252045.17%2520mIoU%2520with%252026.8%2520FPS%2520%2528%252B94%2525%2529.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2409.07613v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Token%20Turing%20Machines%20are%20Efficient%20Vision%20Models&entry.906535625=Purvish%20Jajal%20and%20Nick%20John%20Eliopoulos%20and%20Benjamin%20Shiue-Hal%20Chou%20and%20George%20K.%20Thiruvathukal%20and%20James%20C.%20Davis%20and%20Yung-Hsiang%20Lu&entry.1292438233=%20%20We%20propose%20Vision%20Token%20Turing%20Machines%20%28ViTTM%29%2C%20an%20efficient%2C%20low-latency%2C%0Amemory-augmented%20Vision%20Transformer%20%28ViT%29.%20Our%20approach%20builds%20on%20Neural%20Turing%0AMachines%20and%20Token%20Turing%20Machines%2C%20which%20were%20applied%20to%20NLP%20and%20sequential%0Avisual%20understanding%20tasks.%20ViTTMs%20are%20designed%20for%20non-sequential%20computer%0Avision%20tasks%20such%20as%20image%20classification%20and%20segmentation.%20Our%20model%20creates%0Atwo%20sets%20of%20tokens%3A%20process%20tokens%20and%20memory%20tokens%3B%20process%20tokens%20pass%0Athrough%20encoder%20blocks%20and%20read-write%20from%20memory%20tokens%20at%20each%20encoder%20block%0Ain%20the%20network%2C%20allowing%20them%20to%20store%20and%20retrieve%20information%20from%20memory.%20By%0Aensuring%20that%20there%20are%20fewer%20process%20tokens%20than%20memory%20tokens%2C%20we%20are%20able%20to%0Areduce%20the%20inference%20time%20of%20the%20network%20while%20maintaining%20its%20accuracy.%20On%0AImageNet-1K%2C%20the%20state-of-the-art%20ViT-B%20has%20median%20latency%20of%20529.5ms%20and%2081.0%25%0Aaccuracy%2C%20while%20our%20ViTTM-B%20is%2056%25%20faster%20%28234.1ms%29%2C%20with%202.4%20times%20fewer%0AFLOPs%2C%20with%20an%20accuracy%20of%2082.9%25.%20On%20ADE20K%20semantic%20segmentation%2C%20ViT-B%0Aachieves%2045.65mIoU%20at%2013.8%20frame-per-second%20%28FPS%29%20whereas%20our%20ViTTM-B%20model%0Aacheives%20a%2045.17%20mIoU%20with%2026.8%20FPS%20%28%2B94%25%29.%0A&entry.1838667208=http%3A//arxiv.org/abs/2409.07613v3&entry.124074799=Read"},
{"title": "Random-Key Algorithms for Optimizing Integrated Operating Room\n  Scheduling", "author": "Bruno Salezze Vieira and Eduardo Machado Silva and Antonio Augusto Chaves", "abstract": "  Efficient surgery room scheduling is essential for hospital efficiency,\npatient satisfaction, and resource utilization. This study addresses this\nchallenge by introducing a novel concept of Random-Key Optimizer (RKO),\nrigorously tested on literature and new, real-world inspired instances. Our\ncombinatorial optimization problem incorporates multi-room scheduling,\nequipment scheduling, and complex availability constraints for rooms, patients,\nand surgeons, facilitating rescheduling and enhancing operational flexibility.\nThe RKO approach represents solutions as points in a continuous space, which\nare then mapped in the problem solution space via a deterministic function\nknown as a decoder. The core idea is to operate metaheuristics and heuristics\nin the random-key space, unaware of the original solution space. We design the\nBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and\nIterated Local Search for use within an RKO framework, employing a single\ndecoder function. The proposed metaheuristics are complemented by lower-bound\nformulations, providing optimal gaps for evaluating the effectiveness of the\nheuristic results. Our results demonstrate significant lower and upper bounds\nimprovements for the literature instances, notably proving one optimal result.\nFurthermore, the best-proposed metaheuristic efficiently generates schedules\nfor the newly introduced instances, even in highly constrained scenarios. This\nresearch offers valuable insights and practical solutions for improving surgery\nscheduling processes, offering tangible benefits to hospitals by optimising\nresource allocation, reducing patient wait times, and enhancing overall\noperational efficiency.\n", "link": "http://arxiv.org/abs/2501.10243v2", "date": "2025-01-24", "relevancy": 1.6914, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4673}, {"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.4179}, {"title": "Self-supervised Photographic Image Layout Representation Learning", "link": "http://arxiv.org/abs/2403.03740v1", "similarity": 0.41}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Random-Key%20Algorithms%20for%20Optimizing%20Integrated%20Operating%20Room%0A%20%20Scheduling&body=Title%3A%20Random-Key%20Algorithms%20for%20Optimizing%20Integrated%20Operating%20Room%0A%20%20Scheduling%0AAuthor%3A%20Bruno%20Salezze%20Vieira%20and%20Eduardo%20Machado%20Silva%20and%20Antonio%20Augusto%20Chaves%0AAbstract%3A%20%20%20Efficient%20surgery%20room%20scheduling%20is%20essential%20for%20hospital%20efficiency%2C%0Apatient%20satisfaction%2C%20and%20resource%20utilization.%20This%20study%20addresses%20this%0Achallenge%20by%20introducing%20a%20novel%20concept%20of%20Random-Key%20Optimizer%20%28RKO%29%2C%0Arigorously%20tested%20on%20literature%20and%20new%2C%20real-world%20inspired%20instances.%20Our%0Acombinatorial%20optimization%20problem%20incorporates%20multi-room%20scheduling%2C%0Aequipment%20scheduling%2C%20and%20complex%20availability%20constraints%20for%20rooms%2C%20patients%2C%0Aand%20surgeons%2C%20facilitating%20rescheduling%20and%20enhancing%20operational%20flexibility.%0AThe%20RKO%20approach%20represents%20solutions%20as%20points%20in%20a%20continuous%20space%2C%20which%0Aare%20then%20mapped%20in%20the%20problem%20solution%20space%20via%20a%20deterministic%20function%0Aknown%20as%20a%20decoder.%20The%20core%20idea%20is%20to%20operate%20metaheuristics%20and%20heuristics%0Ain%20the%20random-key%20space%2C%20unaware%20of%20the%20original%20solution%20space.%20We%20design%20the%0ABiased%20Random-Key%20Genetic%20Algorithm%20with%20%24Q%24-Learning%2C%20Simulated%20Annealing%2C%20and%0AIterated%20Local%20Search%20for%20use%20within%20an%20RKO%20framework%2C%20employing%20a%20single%0Adecoder%20function.%20The%20proposed%20metaheuristics%20are%20complemented%20by%20lower-bound%0Aformulations%2C%20providing%20optimal%20gaps%20for%20evaluating%20the%20effectiveness%20of%20the%0Aheuristic%20results.%20Our%20results%20demonstrate%20significant%20lower%20and%20upper%20bounds%0Aimprovements%20for%20the%20literature%20instances%2C%20notably%20proving%20one%20optimal%20result.%0AFurthermore%2C%20the%20best-proposed%20metaheuristic%20efficiently%20generates%20schedules%0Afor%20the%20newly%20introduced%20instances%2C%20even%20in%20highly%20constrained%20scenarios.%20This%0Aresearch%20offers%20valuable%20insights%20and%20practical%20solutions%20for%20improving%20surgery%0Ascheduling%20processes%2C%20offering%20tangible%20benefits%20to%20hospitals%20by%20optimising%0Aresource%20allocation%2C%20reducing%20patient%20wait%20times%2C%20and%20enhancing%20overall%0Aoperational%20efficiency.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.10243v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRandom-Key%2520Algorithms%2520for%2520Optimizing%2520Integrated%2520Operating%2520Room%250A%2520%2520Scheduling%26entry.906535625%3DBruno%2520Salezze%2520Vieira%2520and%2520Eduardo%2520Machado%2520Silva%2520and%2520Antonio%2520Augusto%2520Chaves%26entry.1292438233%3D%2520%2520Efficient%2520surgery%2520room%2520scheduling%2520is%2520essential%2520for%2520hospital%2520efficiency%252C%250Apatient%2520satisfaction%252C%2520and%2520resource%2520utilization.%2520This%2520study%2520addresses%2520this%250Achallenge%2520by%2520introducing%2520a%2520novel%2520concept%2520of%2520Random-Key%2520Optimizer%2520%2528RKO%2529%252C%250Arigorously%2520tested%2520on%2520literature%2520and%2520new%252C%2520real-world%2520inspired%2520instances.%2520Our%250Acombinatorial%2520optimization%2520problem%2520incorporates%2520multi-room%2520scheduling%252C%250Aequipment%2520scheduling%252C%2520and%2520complex%2520availability%2520constraints%2520for%2520rooms%252C%2520patients%252C%250Aand%2520surgeons%252C%2520facilitating%2520rescheduling%2520and%2520enhancing%2520operational%2520flexibility.%250AThe%2520RKO%2520approach%2520represents%2520solutions%2520as%2520points%2520in%2520a%2520continuous%2520space%252C%2520which%250Aare%2520then%2520mapped%2520in%2520the%2520problem%2520solution%2520space%2520via%2520a%2520deterministic%2520function%250Aknown%2520as%2520a%2520decoder.%2520The%2520core%2520idea%2520is%2520to%2520operate%2520metaheuristics%2520and%2520heuristics%250Ain%2520the%2520random-key%2520space%252C%2520unaware%2520of%2520the%2520original%2520solution%2520space.%2520We%2520design%2520the%250ABiased%2520Random-Key%2520Genetic%2520Algorithm%2520with%2520%2524Q%2524-Learning%252C%2520Simulated%2520Annealing%252C%2520and%250AIterated%2520Local%2520Search%2520for%2520use%2520within%2520an%2520RKO%2520framework%252C%2520employing%2520a%2520single%250Adecoder%2520function.%2520The%2520proposed%2520metaheuristics%2520are%2520complemented%2520by%2520lower-bound%250Aformulations%252C%2520providing%2520optimal%2520gaps%2520for%2520evaluating%2520the%2520effectiveness%2520of%2520the%250Aheuristic%2520results.%2520Our%2520results%2520demonstrate%2520significant%2520lower%2520and%2520upper%2520bounds%250Aimprovements%2520for%2520the%2520literature%2520instances%252C%2520notably%2520proving%2520one%2520optimal%2520result.%250AFurthermore%252C%2520the%2520best-proposed%2520metaheuristic%2520efficiently%2520generates%2520schedules%250Afor%2520the%2520newly%2520introduced%2520instances%252C%2520even%2520in%2520highly%2520constrained%2520scenarios.%2520This%250Aresearch%2520offers%2520valuable%2520insights%2520and%2520practical%2520solutions%2520for%2520improving%2520surgery%250Ascheduling%2520processes%252C%2520offering%2520tangible%2520benefits%2520to%2520hospitals%2520by%2520optimising%250Aresource%2520allocation%252C%2520reducing%2520patient%2520wait%2520times%252C%2520and%2520enhancing%2520overall%250Aoperational%2520efficiency.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.10243v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Random-Key%20Algorithms%20for%20Optimizing%20Integrated%20Operating%20Room%0A%20%20Scheduling&entry.906535625=Bruno%20Salezze%20Vieira%20and%20Eduardo%20Machado%20Silva%20and%20Antonio%20Augusto%20Chaves&entry.1292438233=%20%20Efficient%20surgery%20room%20scheduling%20is%20essential%20for%20hospital%20efficiency%2C%0Apatient%20satisfaction%2C%20and%20resource%20utilization.%20This%20study%20addresses%20this%0Achallenge%20by%20introducing%20a%20novel%20concept%20of%20Random-Key%20Optimizer%20%28RKO%29%2C%0Arigorously%20tested%20on%20literature%20and%20new%2C%20real-world%20inspired%20instances.%20Our%0Acombinatorial%20optimization%20problem%20incorporates%20multi-room%20scheduling%2C%0Aequipment%20scheduling%2C%20and%20complex%20availability%20constraints%20for%20rooms%2C%20patients%2C%0Aand%20surgeons%2C%20facilitating%20rescheduling%20and%20enhancing%20operational%20flexibility.%0AThe%20RKO%20approach%20represents%20solutions%20as%20points%20in%20a%20continuous%20space%2C%20which%0Aare%20then%20mapped%20in%20the%20problem%20solution%20space%20via%20a%20deterministic%20function%0Aknown%20as%20a%20decoder.%20The%20core%20idea%20is%20to%20operate%20metaheuristics%20and%20heuristics%0Ain%20the%20random-key%20space%2C%20unaware%20of%20the%20original%20solution%20space.%20We%20design%20the%0ABiased%20Random-Key%20Genetic%20Algorithm%20with%20%24Q%24-Learning%2C%20Simulated%20Annealing%2C%20and%0AIterated%20Local%20Search%20for%20use%20within%20an%20RKO%20framework%2C%20employing%20a%20single%0Adecoder%20function.%20The%20proposed%20metaheuristics%20are%20complemented%20by%20lower-bound%0Aformulations%2C%20providing%20optimal%20gaps%20for%20evaluating%20the%20effectiveness%20of%20the%0Aheuristic%20results.%20Our%20results%20demonstrate%20significant%20lower%20and%20upper%20bounds%0Aimprovements%20for%20the%20literature%20instances%2C%20notably%20proving%20one%20optimal%20result.%0AFurthermore%2C%20the%20best-proposed%20metaheuristic%20efficiently%20generates%20schedules%0Afor%20the%20newly%20introduced%20instances%2C%20even%20in%20highly%20constrained%20scenarios.%20This%0Aresearch%20offers%20valuable%20insights%20and%20practical%20solutions%20for%20improving%20surgery%0Ascheduling%20processes%2C%20offering%20tangible%20benefits%20to%20hospitals%20by%20optimising%0Aresource%20allocation%2C%20reducing%20patient%20wait%20times%2C%20and%20enhancing%20overall%0Aoperational%20efficiency.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.10243v2&entry.124074799=Read"},
{"title": "CheapNVS: Real-Time On-Device Narrow-Baseline Novel View Synthesis", "author": "Konstantinos Georgiadis and Mehmet Kerim Yucel and Albert Saa-Garriga", "abstract": "  Single-view novel view synthesis (NVS) is a notorious problem due to its\nill-posed nature, and often requires large, computationally expensive\napproaches to produce tangible results. In this paper, we propose CheapNVS: a\nfully end-to-end approach for narrow baseline single-view NVS based on a novel,\nefficient multiple encoder/decoder design trained in a multi-stage fashion.\nCheapNVS first approximates the laborious 3D image warping with lightweight\nlearnable modules that are conditioned on the camera pose embeddings of the\ntarget view, and then performs inpainting on the occluded regions in parallel\nto achieve significant performance gains. Once trained on a subset of Open\nImages dataset, CheapNVS outperforms the state-of-the-art despite being 10\ntimes faster and consuming 6% less memory. Furthermore, CheapNVS runs\ncomfortably in real-time on mobile devices, reaching over 30 FPS on a Samsung\nTab 9+.\n", "link": "http://arxiv.org/abs/2501.14533v1", "date": "2025-01-24", "relevancy": 1.6713, "topK": [{"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.573}, {"title": "RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting", "link": "http://arxiv.org/abs/2404.19706v1", "similarity": 0.5528}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.5521}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20CheapNVS%3A%20Real-Time%20On-Device%20Narrow-Baseline%20Novel%20View%20Synthesis&body=Title%3A%20CheapNVS%3A%20Real-Time%20On-Device%20Narrow-Baseline%20Novel%20View%20Synthesis%0AAuthor%3A%20Konstantinos%20Georgiadis%20and%20Mehmet%20Kerim%20Yucel%20and%20Albert%20Saa-Garriga%0AAbstract%3A%20%20%20Single-view%20novel%20view%20synthesis%20%28NVS%29%20is%20a%20notorious%20problem%20due%20to%20its%0Aill-posed%20nature%2C%20and%20often%20requires%20large%2C%20computationally%20expensive%0Aapproaches%20to%20produce%20tangible%20results.%20In%20this%20paper%2C%20we%20propose%20CheapNVS%3A%20a%0Afully%20end-to-end%20approach%20for%20narrow%20baseline%20single-view%20NVS%20based%20on%20a%20novel%2C%0Aefficient%20multiple%20encoder/decoder%20design%20trained%20in%20a%20multi-stage%20fashion.%0ACheapNVS%20first%20approximates%20the%20laborious%203D%20image%20warping%20with%20lightweight%0Alearnable%20modules%20that%20are%20conditioned%20on%20the%20camera%20pose%20embeddings%20of%20the%0Atarget%20view%2C%20and%20then%20performs%20inpainting%20on%20the%20occluded%20regions%20in%20parallel%0Ato%20achieve%20significant%20performance%20gains.%20Once%20trained%20on%20a%20subset%20of%20Open%0AImages%20dataset%2C%20CheapNVS%20outperforms%20the%20state-of-the-art%20despite%20being%2010%0Atimes%20faster%20and%20consuming%206%25%20less%20memory.%20Furthermore%2C%20CheapNVS%20runs%0Acomfortably%20in%20real-time%20on%20mobile%20devices%2C%20reaching%20over%2030%20FPS%20on%20a%20Samsung%0ATab%209%2B.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14533v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DCheapNVS%253A%2520Real-Time%2520On-Device%2520Narrow-Baseline%2520Novel%2520View%2520Synthesis%26entry.906535625%3DKonstantinos%2520Georgiadis%2520and%2520Mehmet%2520Kerim%2520Yucel%2520and%2520Albert%2520Saa-Garriga%26entry.1292438233%3D%2520%2520Single-view%2520novel%2520view%2520synthesis%2520%2528NVS%2529%2520is%2520a%2520notorious%2520problem%2520due%2520to%2520its%250Aill-posed%2520nature%252C%2520and%2520often%2520requires%2520large%252C%2520computationally%2520expensive%250Aapproaches%2520to%2520produce%2520tangible%2520results.%2520In%2520this%2520paper%252C%2520we%2520propose%2520CheapNVS%253A%2520a%250Afully%2520end-to-end%2520approach%2520for%2520narrow%2520baseline%2520single-view%2520NVS%2520based%2520on%2520a%2520novel%252C%250Aefficient%2520multiple%2520encoder/decoder%2520design%2520trained%2520in%2520a%2520multi-stage%2520fashion.%250ACheapNVS%2520first%2520approximates%2520the%2520laborious%25203D%2520image%2520warping%2520with%2520lightweight%250Alearnable%2520modules%2520that%2520are%2520conditioned%2520on%2520the%2520camera%2520pose%2520embeddings%2520of%2520the%250Atarget%2520view%252C%2520and%2520then%2520performs%2520inpainting%2520on%2520the%2520occluded%2520regions%2520in%2520parallel%250Ato%2520achieve%2520significant%2520performance%2520gains.%2520Once%2520trained%2520on%2520a%2520subset%2520of%2520Open%250AImages%2520dataset%252C%2520CheapNVS%2520outperforms%2520the%2520state-of-the-art%2520despite%2520being%252010%250Atimes%2520faster%2520and%2520consuming%25206%2525%2520less%2520memory.%2520Furthermore%252C%2520CheapNVS%2520runs%250Acomfortably%2520in%2520real-time%2520on%2520mobile%2520devices%252C%2520reaching%2520over%252030%2520FPS%2520on%2520a%2520Samsung%250ATab%25209%252B.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14533v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=CheapNVS%3A%20Real-Time%20On-Device%20Narrow-Baseline%20Novel%20View%20Synthesis&entry.906535625=Konstantinos%20Georgiadis%20and%20Mehmet%20Kerim%20Yucel%20and%20Albert%20Saa-Garriga&entry.1292438233=%20%20Single-view%20novel%20view%20synthesis%20%28NVS%29%20is%20a%20notorious%20problem%20due%20to%20its%0Aill-posed%20nature%2C%20and%20often%20requires%20large%2C%20computationally%20expensive%0Aapproaches%20to%20produce%20tangible%20results.%20In%20this%20paper%2C%20we%20propose%20CheapNVS%3A%20a%0Afully%20end-to-end%20approach%20for%20narrow%20baseline%20single-view%20NVS%20based%20on%20a%20novel%2C%0Aefficient%20multiple%20encoder/decoder%20design%20trained%20in%20a%20multi-stage%20fashion.%0ACheapNVS%20first%20approximates%20the%20laborious%203D%20image%20warping%20with%20lightweight%0Alearnable%20modules%20that%20are%20conditioned%20on%20the%20camera%20pose%20embeddings%20of%20the%0Atarget%20view%2C%20and%20then%20performs%20inpainting%20on%20the%20occluded%20regions%20in%20parallel%0Ato%20achieve%20significant%20performance%20gains.%20Once%20trained%20on%20a%20subset%20of%20Open%0AImages%20dataset%2C%20CheapNVS%20outperforms%20the%20state-of-the-art%20despite%20being%2010%0Atimes%20faster%20and%20consuming%206%25%20less%20memory.%20Furthermore%2C%20CheapNVS%20runs%0Acomfortably%20in%20real-time%20on%20mobile%20devices%2C%20reaching%20over%2030%20FPS%20on%20a%20Samsung%0ATab%209%2B.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14533v1&entry.124074799=Read"},
{"title": "Enhanced Confocal Laser Scanning Microscopy with Adaptive Physics\n  Informed Deep Autoencoders", "author": "Zaheer Ahmad and Junaid Shabeer and Usman Saleem and Tahir Qadeer and Abdul Sami and Zahira El Khalidi and Saad Mehmood", "abstract": "  We present a physics-informed deep learning framework to address common\nlimitations in Confocal Laser Scanning Microscopy (CLSM), such as diffraction\nlimited resolution, noise, and undersampling due to low laser power conditions.\nThe optical system's point spread function (PSF) and common CLSM image\ndegradation mechanisms namely photon shot noise, dark current noise, motion\nblur, speckle noise, and undersampling were modeled and were directly included\ninto model architecture. The model reconstructs high fidelity images from\nheavily noisy inputs by using convolutional and transposed convolutional\nlayers. Following the advances in compressed sensing, our approach\nsignificantly reduces data acquisition requirements without compromising image\nresolution. The proposed method was extensively evaluated on simulated CLSM\nimages of diverse structures, including lipid droplets, neuronal networks, and\nfibrillar systems. Comparisons with traditional deconvolution algorithms such\nas Richardson-Lucy (RL), non-negative least squares (NNLS), and other methods\nlike Total Variation (TV) regularization, Wiener filtering, and Wavelet\ndenoising demonstrate the superiority of the network in restoring fine\nstructural details with high fidelity. Assessment metrics like Structural\nSimilarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR), underlines that\nthe AdaptivePhysicsAutoencoder achieved robust image enhancement across diverse\nCLSM conditions, helping faster acquisition, reduced photodamage, and reliable\nperformance in low light and sparse sampling scenarios holding promise for\napplications in live cell imaging, dynamic biological studies, and high\nthroughput material characterization.\n", "link": "http://arxiv.org/abs/2501.14709v1", "date": "2025-01-24", "relevancy": 1.6412, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.5594}, {"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.5522}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5401}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Enhanced%20Confocal%20Laser%20Scanning%20Microscopy%20with%20Adaptive%20Physics%0A%20%20Informed%20Deep%20Autoencoders&body=Title%3A%20Enhanced%20Confocal%20Laser%20Scanning%20Microscopy%20with%20Adaptive%20Physics%0A%20%20Informed%20Deep%20Autoencoders%0AAuthor%3A%20Zaheer%20Ahmad%20and%20Junaid%20Shabeer%20and%20Usman%20Saleem%20and%20Tahir%20Qadeer%20and%20Abdul%20Sami%20and%20Zahira%20El%20Khalidi%20and%20Saad%20Mehmood%0AAbstract%3A%20%20%20We%20present%20a%20physics-informed%20deep%20learning%20framework%20to%20address%20common%0Alimitations%20in%20Confocal%20Laser%20Scanning%20Microscopy%20%28CLSM%29%2C%20such%20as%20diffraction%0Alimited%20resolution%2C%20noise%2C%20and%20undersampling%20due%20to%20low%20laser%20power%20conditions.%0AThe%20optical%20system%27s%20point%20spread%20function%20%28PSF%29%20and%20common%20CLSM%20image%0Adegradation%20mechanisms%20namely%20photon%20shot%20noise%2C%20dark%20current%20noise%2C%20motion%0Ablur%2C%20speckle%20noise%2C%20and%20undersampling%20were%20modeled%20and%20were%20directly%20included%0Ainto%20model%20architecture.%20The%20model%20reconstructs%20high%20fidelity%20images%20from%0Aheavily%20noisy%20inputs%20by%20using%20convolutional%20and%20transposed%20convolutional%0Alayers.%20Following%20the%20advances%20in%20compressed%20sensing%2C%20our%20approach%0Asignificantly%20reduces%20data%20acquisition%20requirements%20without%20compromising%20image%0Aresolution.%20The%20proposed%20method%20was%20extensively%20evaluated%20on%20simulated%20CLSM%0Aimages%20of%20diverse%20structures%2C%20including%20lipid%20droplets%2C%20neuronal%20networks%2C%20and%0Afibrillar%20systems.%20Comparisons%20with%20traditional%20deconvolution%20algorithms%20such%0Aas%20Richardson-Lucy%20%28RL%29%2C%20non-negative%20least%20squares%20%28NNLS%29%2C%20and%20other%20methods%0Alike%20Total%20Variation%20%28TV%29%20regularization%2C%20Wiener%20filtering%2C%20and%20Wavelet%0Adenoising%20demonstrate%20the%20superiority%20of%20the%20network%20in%20restoring%20fine%0Astructural%20details%20with%20high%20fidelity.%20Assessment%20metrics%20like%20Structural%0ASimilarity%20Index%20%28SSIM%29%20and%20Peak%20Signal%20to%20Noise%20Ratio%20%28PSNR%29%2C%20underlines%20that%0Athe%20AdaptivePhysicsAutoencoder%20achieved%20robust%20image%20enhancement%20across%20diverse%0ACLSM%20conditions%2C%20helping%20faster%20acquisition%2C%20reduced%20photodamage%2C%20and%20reliable%0Aperformance%20in%20low%20light%20and%20sparse%20sampling%20scenarios%20holding%20promise%20for%0Aapplications%20in%20live%20cell%20imaging%2C%20dynamic%20biological%20studies%2C%20and%20high%0Athroughput%20material%20characterization.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14709v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DEnhanced%2520Confocal%2520Laser%2520Scanning%2520Microscopy%2520with%2520Adaptive%2520Physics%250A%2520%2520Informed%2520Deep%2520Autoencoders%26entry.906535625%3DZaheer%2520Ahmad%2520and%2520Junaid%2520Shabeer%2520and%2520Usman%2520Saleem%2520and%2520Tahir%2520Qadeer%2520and%2520Abdul%2520Sami%2520and%2520Zahira%2520El%2520Khalidi%2520and%2520Saad%2520Mehmood%26entry.1292438233%3D%2520%2520We%2520present%2520a%2520physics-informed%2520deep%2520learning%2520framework%2520to%2520address%2520common%250Alimitations%2520in%2520Confocal%2520Laser%2520Scanning%2520Microscopy%2520%2528CLSM%2529%252C%2520such%2520as%2520diffraction%250Alimited%2520resolution%252C%2520noise%252C%2520and%2520undersampling%2520due%2520to%2520low%2520laser%2520power%2520conditions.%250AThe%2520optical%2520system%2527s%2520point%2520spread%2520function%2520%2528PSF%2529%2520and%2520common%2520CLSM%2520image%250Adegradation%2520mechanisms%2520namely%2520photon%2520shot%2520noise%252C%2520dark%2520current%2520noise%252C%2520motion%250Ablur%252C%2520speckle%2520noise%252C%2520and%2520undersampling%2520were%2520modeled%2520and%2520were%2520directly%2520included%250Ainto%2520model%2520architecture.%2520The%2520model%2520reconstructs%2520high%2520fidelity%2520images%2520from%250Aheavily%2520noisy%2520inputs%2520by%2520using%2520convolutional%2520and%2520transposed%2520convolutional%250Alayers.%2520Following%2520the%2520advances%2520in%2520compressed%2520sensing%252C%2520our%2520approach%250Asignificantly%2520reduces%2520data%2520acquisition%2520requirements%2520without%2520compromising%2520image%250Aresolution.%2520The%2520proposed%2520method%2520was%2520extensively%2520evaluated%2520on%2520simulated%2520CLSM%250Aimages%2520of%2520diverse%2520structures%252C%2520including%2520lipid%2520droplets%252C%2520neuronal%2520networks%252C%2520and%250Afibrillar%2520systems.%2520Comparisons%2520with%2520traditional%2520deconvolution%2520algorithms%2520such%250Aas%2520Richardson-Lucy%2520%2528RL%2529%252C%2520non-negative%2520least%2520squares%2520%2528NNLS%2529%252C%2520and%2520other%2520methods%250Alike%2520Total%2520Variation%2520%2528TV%2529%2520regularization%252C%2520Wiener%2520filtering%252C%2520and%2520Wavelet%250Adenoising%2520demonstrate%2520the%2520superiority%2520of%2520the%2520network%2520in%2520restoring%2520fine%250Astructural%2520details%2520with%2520high%2520fidelity.%2520Assessment%2520metrics%2520like%2520Structural%250ASimilarity%2520Index%2520%2528SSIM%2529%2520and%2520Peak%2520Signal%2520to%2520Noise%2520Ratio%2520%2528PSNR%2529%252C%2520underlines%2520that%250Athe%2520AdaptivePhysicsAutoencoder%2520achieved%2520robust%2520image%2520enhancement%2520across%2520diverse%250ACLSM%2520conditions%252C%2520helping%2520faster%2520acquisition%252C%2520reduced%2520photodamage%252C%2520and%2520reliable%250Aperformance%2520in%2520low%2520light%2520and%2520sparse%2520sampling%2520scenarios%2520holding%2520promise%2520for%250Aapplications%2520in%2520live%2520cell%2520imaging%252C%2520dynamic%2520biological%2520studies%252C%2520and%2520high%250Athroughput%2520material%2520characterization.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14709v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Enhanced%20Confocal%20Laser%20Scanning%20Microscopy%20with%20Adaptive%20Physics%0A%20%20Informed%20Deep%20Autoencoders&entry.906535625=Zaheer%20Ahmad%20and%20Junaid%20Shabeer%20and%20Usman%20Saleem%20and%20Tahir%20Qadeer%20and%20Abdul%20Sami%20and%20Zahira%20El%20Khalidi%20and%20Saad%20Mehmood&entry.1292438233=%20%20We%20present%20a%20physics-informed%20deep%20learning%20framework%20to%20address%20common%0Alimitations%20in%20Confocal%20Laser%20Scanning%20Microscopy%20%28CLSM%29%2C%20such%20as%20diffraction%0Alimited%20resolution%2C%20noise%2C%20and%20undersampling%20due%20to%20low%20laser%20power%20conditions.%0AThe%20optical%20system%27s%20point%20spread%20function%20%28PSF%29%20and%20common%20CLSM%20image%0Adegradation%20mechanisms%20namely%20photon%20shot%20noise%2C%20dark%20current%20noise%2C%20motion%0Ablur%2C%20speckle%20noise%2C%20and%20undersampling%20were%20modeled%20and%20were%20directly%20included%0Ainto%20model%20architecture.%20The%20model%20reconstructs%20high%20fidelity%20images%20from%0Aheavily%20noisy%20inputs%20by%20using%20convolutional%20and%20transposed%20convolutional%0Alayers.%20Following%20the%20advances%20in%20compressed%20sensing%2C%20our%20approach%0Asignificantly%20reduces%20data%20acquisition%20requirements%20without%20compromising%20image%0Aresolution.%20The%20proposed%20method%20was%20extensively%20evaluated%20on%20simulated%20CLSM%0Aimages%20of%20diverse%20structures%2C%20including%20lipid%20droplets%2C%20neuronal%20networks%2C%20and%0Afibrillar%20systems.%20Comparisons%20with%20traditional%20deconvolution%20algorithms%20such%0Aas%20Richardson-Lucy%20%28RL%29%2C%20non-negative%20least%20squares%20%28NNLS%29%2C%20and%20other%20methods%0Alike%20Total%20Variation%20%28TV%29%20regularization%2C%20Wiener%20filtering%2C%20and%20Wavelet%0Adenoising%20demonstrate%20the%20superiority%20of%20the%20network%20in%20restoring%20fine%0Astructural%20details%20with%20high%20fidelity.%20Assessment%20metrics%20like%20Structural%0ASimilarity%20Index%20%28SSIM%29%20and%20Peak%20Signal%20to%20Noise%20Ratio%20%28PSNR%29%2C%20underlines%20that%0Athe%20AdaptivePhysicsAutoencoder%20achieved%20robust%20image%20enhancement%20across%20diverse%0ACLSM%20conditions%2C%20helping%20faster%20acquisition%2C%20reduced%20photodamage%2C%20and%20reliable%0Aperformance%20in%20low%20light%20and%20sparse%20sampling%20scenarios%20holding%20promise%20for%0Aapplications%20in%20live%20cell%20imaging%2C%20dynamic%20biological%20studies%2C%20and%20high%0Athroughput%20material%20characterization.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14709v1&entry.124074799=Read"},
{"title": "NLP Verification: Towards a General Methodology for Certifying\n  Robustness", "author": "Marco Casadio and Tanvi Dinkar and Ekaterina Komendantskaya and Luca Arnaboldi and Matthew L. Daggitt and Omri Isac and Guy Katz and Verena Rieser and Oliver Lemon", "abstract": "  Machine Learning (ML) has exhibited substantial success in the field of\nNatural Language Processing (NLP). For example large language models have\nempirically proven to be capable of producing text of high complexity and\ncohesion. However, they are prone to inaccuracies and hallucinations. As these\nsystems are increasingly integrated into real-world applications, ensuring\ntheir safety and reliability becomes a primary concern. There are safety\ncritical contexts where such models must be robust to variability or attack,\nand give guarantees over their output. Computer Vision had pioneered the use of\nformal verification of neural networks for such scenarios and developed common\nverification standards and pipelines, leveraging precise formal reasoning about\ngeometric properties of data manifolds. In contrast, NLP verification methods\nhave only recently appeared in the literature. While presenting sophisticated\nalgorithms, these papers have not yet crystallised into a common methodology.\nThey are often light on the pragmatical issues of NLP verification and the area\nremains fragmented. In this paper, we attempt to distil and evaluate general\ncomponents of an NLP verification pipeline, that emerges from the progress in\nthe field to date. Our contributions are two-fold. Firstly, we propose a\ngeneral methodology to analyse the effect of the embedding gap, a problem that\nrefers to the discrepancy between verification of geometric subspaces and the\nsemantic meaning of sentences, which the geometric subspaces are supposed to\nrepresent. We propose a number of practical NLP methods that can help to\nquantify the effects of the embedding gap. Secondly, we give a general method\nfor training and verification of neural networks that leverages a more precise\ngeometric estimation of semantic similarity of sentences in the embedding space\nand helps to overcome the effects of the embedding gap in practice.\n", "link": "http://arxiv.org/abs/2403.10144v3", "date": "2025-01-24", "relevancy": 1.6141, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5473}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5398}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5242}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20NLP%20Verification%3A%20Towards%20a%20General%20Methodology%20for%20Certifying%0A%20%20Robustness&body=Title%3A%20NLP%20Verification%3A%20Towards%20a%20General%20Methodology%20for%20Certifying%0A%20%20Robustness%0AAuthor%3A%20Marco%20Casadio%20and%20Tanvi%20Dinkar%20and%20Ekaterina%20Komendantskaya%20and%20Luca%20Arnaboldi%20and%20Matthew%20L.%20Daggitt%20and%20Omri%20Isac%20and%20Guy%20Katz%20and%20Verena%20Rieser%20and%20Oliver%20Lemon%0AAbstract%3A%20%20%20Machine%20Learning%20%28ML%29%20has%20exhibited%20substantial%20success%20in%20the%20field%20of%0ANatural%20Language%20Processing%20%28NLP%29.%20For%20example%20large%20language%20models%20have%0Aempirically%20proven%20to%20be%20capable%20of%20producing%20text%20of%20high%20complexity%20and%0Acohesion.%20However%2C%20they%20are%20prone%20to%20inaccuracies%20and%20hallucinations.%20As%20these%0Asystems%20are%20increasingly%20integrated%20into%20real-world%20applications%2C%20ensuring%0Atheir%20safety%20and%20reliability%20becomes%20a%20primary%20concern.%20There%20are%20safety%0Acritical%20contexts%20where%20such%20models%20must%20be%20robust%20to%20variability%20or%20attack%2C%0Aand%20give%20guarantees%20over%20their%20output.%20Computer%20Vision%20had%20pioneered%20the%20use%20of%0Aformal%20verification%20of%20neural%20networks%20for%20such%20scenarios%20and%20developed%20common%0Averification%20standards%20and%20pipelines%2C%20leveraging%20precise%20formal%20reasoning%20about%0Ageometric%20properties%20of%20data%20manifolds.%20In%20contrast%2C%20NLP%20verification%20methods%0Ahave%20only%20recently%20appeared%20in%20the%20literature.%20While%20presenting%20sophisticated%0Aalgorithms%2C%20these%20papers%20have%20not%20yet%20crystallised%20into%20a%20common%20methodology.%0AThey%20are%20often%20light%20on%20the%20pragmatical%20issues%20of%20NLP%20verification%20and%20the%20area%0Aremains%20fragmented.%20In%20this%20paper%2C%20we%20attempt%20to%20distil%20and%20evaluate%20general%0Acomponents%20of%20an%20NLP%20verification%20pipeline%2C%20that%20emerges%20from%20the%20progress%20in%0Athe%20field%20to%20date.%20Our%20contributions%20are%20two-fold.%20Firstly%2C%20we%20propose%20a%0Ageneral%20methodology%20to%20analyse%20the%20effect%20of%20the%20embedding%20gap%2C%20a%20problem%20that%0Arefers%20to%20the%20discrepancy%20between%20verification%20of%20geometric%20subspaces%20and%20the%0Asemantic%20meaning%20of%20sentences%2C%20which%20the%20geometric%20subspaces%20are%20supposed%20to%0Arepresent.%20We%20propose%20a%20number%20of%20practical%20NLP%20methods%20that%20can%20help%20to%0Aquantify%20the%20effects%20of%20the%20embedding%20gap.%20Secondly%2C%20we%20give%20a%20general%20method%0Afor%20training%20and%20verification%20of%20neural%20networks%20that%20leverages%20a%20more%20precise%0Ageometric%20estimation%20of%20semantic%20similarity%20of%20sentences%20in%20the%20embedding%20space%0Aand%20helps%20to%20overcome%20the%20effects%20of%20the%20embedding%20gap%20in%20practice.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2403.10144v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DNLP%2520Verification%253A%2520Towards%2520a%2520General%2520Methodology%2520for%2520Certifying%250A%2520%2520Robustness%26entry.906535625%3DMarco%2520Casadio%2520and%2520Tanvi%2520Dinkar%2520and%2520Ekaterina%2520Komendantskaya%2520and%2520Luca%2520Arnaboldi%2520and%2520Matthew%2520L.%2520Daggitt%2520and%2520Omri%2520Isac%2520and%2520Guy%2520Katz%2520and%2520Verena%2520Rieser%2520and%2520Oliver%2520Lemon%26entry.1292438233%3D%2520%2520Machine%2520Learning%2520%2528ML%2529%2520has%2520exhibited%2520substantial%2520success%2520in%2520the%2520field%2520of%250ANatural%2520Language%2520Processing%2520%2528NLP%2529.%2520For%2520example%2520large%2520language%2520models%2520have%250Aempirically%2520proven%2520to%2520be%2520capable%2520of%2520producing%2520text%2520of%2520high%2520complexity%2520and%250Acohesion.%2520However%252C%2520they%2520are%2520prone%2520to%2520inaccuracies%2520and%2520hallucinations.%2520As%2520these%250Asystems%2520are%2520increasingly%2520integrated%2520into%2520real-world%2520applications%252C%2520ensuring%250Atheir%2520safety%2520and%2520reliability%2520becomes%2520a%2520primary%2520concern.%2520There%2520are%2520safety%250Acritical%2520contexts%2520where%2520such%2520models%2520must%2520be%2520robust%2520to%2520variability%2520or%2520attack%252C%250Aand%2520give%2520guarantees%2520over%2520their%2520output.%2520Computer%2520Vision%2520had%2520pioneered%2520the%2520use%2520of%250Aformal%2520verification%2520of%2520neural%2520networks%2520for%2520such%2520scenarios%2520and%2520developed%2520common%250Averification%2520standards%2520and%2520pipelines%252C%2520leveraging%2520precise%2520formal%2520reasoning%2520about%250Ageometric%2520properties%2520of%2520data%2520manifolds.%2520In%2520contrast%252C%2520NLP%2520verification%2520methods%250Ahave%2520only%2520recently%2520appeared%2520in%2520the%2520literature.%2520While%2520presenting%2520sophisticated%250Aalgorithms%252C%2520these%2520papers%2520have%2520not%2520yet%2520crystallised%2520into%2520a%2520common%2520methodology.%250AThey%2520are%2520often%2520light%2520on%2520the%2520pragmatical%2520issues%2520of%2520NLP%2520verification%2520and%2520the%2520area%250Aremains%2520fragmented.%2520In%2520this%2520paper%252C%2520we%2520attempt%2520to%2520distil%2520and%2520evaluate%2520general%250Acomponents%2520of%2520an%2520NLP%2520verification%2520pipeline%252C%2520that%2520emerges%2520from%2520the%2520progress%2520in%250Athe%2520field%2520to%2520date.%2520Our%2520contributions%2520are%2520two-fold.%2520Firstly%252C%2520we%2520propose%2520a%250Ageneral%2520methodology%2520to%2520analyse%2520the%2520effect%2520of%2520the%2520embedding%2520gap%252C%2520a%2520problem%2520that%250Arefers%2520to%2520the%2520discrepancy%2520between%2520verification%2520of%2520geometric%2520subspaces%2520and%2520the%250Asemantic%2520meaning%2520of%2520sentences%252C%2520which%2520the%2520geometric%2520subspaces%2520are%2520supposed%2520to%250Arepresent.%2520We%2520propose%2520a%2520number%2520of%2520practical%2520NLP%2520methods%2520that%2520can%2520help%2520to%250Aquantify%2520the%2520effects%2520of%2520the%2520embedding%2520gap.%2520Secondly%252C%2520we%2520give%2520a%2520general%2520method%250Afor%2520training%2520and%2520verification%2520of%2520neural%2520networks%2520that%2520leverages%2520a%2520more%2520precise%250Ageometric%2520estimation%2520of%2520semantic%2520similarity%2520of%2520sentences%2520in%2520the%2520embedding%2520space%250Aand%2520helps%2520to%2520overcome%2520the%2520effects%2520of%2520the%2520embedding%2520gap%2520in%2520practice.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2403.10144v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=NLP%20Verification%3A%20Towards%20a%20General%20Methodology%20for%20Certifying%0A%20%20Robustness&entry.906535625=Marco%20Casadio%20and%20Tanvi%20Dinkar%20and%20Ekaterina%20Komendantskaya%20and%20Luca%20Arnaboldi%20and%20Matthew%20L.%20Daggitt%20and%20Omri%20Isac%20and%20Guy%20Katz%20and%20Verena%20Rieser%20and%20Oliver%20Lemon&entry.1292438233=%20%20Machine%20Learning%20%28ML%29%20has%20exhibited%20substantial%20success%20in%20the%20field%20of%0ANatural%20Language%20Processing%20%28NLP%29.%20For%20example%20large%20language%20models%20have%0Aempirically%20proven%20to%20be%20capable%20of%20producing%20text%20of%20high%20complexity%20and%0Acohesion.%20However%2C%20they%20are%20prone%20to%20inaccuracies%20and%20hallucinations.%20As%20these%0Asystems%20are%20increasingly%20integrated%20into%20real-world%20applications%2C%20ensuring%0Atheir%20safety%20and%20reliability%20becomes%20a%20primary%20concern.%20There%20are%20safety%0Acritical%20contexts%20where%20such%20models%20must%20be%20robust%20to%20variability%20or%20attack%2C%0Aand%20give%20guarantees%20over%20their%20output.%20Computer%20Vision%20had%20pioneered%20the%20use%20of%0Aformal%20verification%20of%20neural%20networks%20for%20such%20scenarios%20and%20developed%20common%0Averification%20standards%20and%20pipelines%2C%20leveraging%20precise%20formal%20reasoning%20about%0Ageometric%20properties%20of%20data%20manifolds.%20In%20contrast%2C%20NLP%20verification%20methods%0Ahave%20only%20recently%20appeared%20in%20the%20literature.%20While%20presenting%20sophisticated%0Aalgorithms%2C%20these%20papers%20have%20not%20yet%20crystallised%20into%20a%20common%20methodology.%0AThey%20are%20often%20light%20on%20the%20pragmatical%20issues%20of%20NLP%20verification%20and%20the%20area%0Aremains%20fragmented.%20In%20this%20paper%2C%20we%20attempt%20to%20distil%20and%20evaluate%20general%0Acomponents%20of%20an%20NLP%20verification%20pipeline%2C%20that%20emerges%20from%20the%20progress%20in%0Athe%20field%20to%20date.%20Our%20contributions%20are%20two-fold.%20Firstly%2C%20we%20propose%20a%0Ageneral%20methodology%20to%20analyse%20the%20effect%20of%20the%20embedding%20gap%2C%20a%20problem%20that%0Arefers%20to%20the%20discrepancy%20between%20verification%20of%20geometric%20subspaces%20and%20the%0Asemantic%20meaning%20of%20sentences%2C%20which%20the%20geometric%20subspaces%20are%20supposed%20to%0Arepresent.%20We%20propose%20a%20number%20of%20practical%20NLP%20methods%20that%20can%20help%20to%0Aquantify%20the%20effects%20of%20the%20embedding%20gap.%20Secondly%2C%20we%20give%20a%20general%20method%0Afor%20training%20and%20verification%20of%20neural%20networks%20that%20leverages%20a%20more%20precise%0Ageometric%20estimation%20of%20semantic%20similarity%20of%20sentences%20in%20the%20embedding%20space%0Aand%20helps%20to%20overcome%20the%20effects%20of%20the%20embedding%20gap%20in%20practice.%0A&entry.1838667208=http%3A//arxiv.org/abs/2403.10144v3&entry.124074799=Read"},
{"title": "On the Causal Sufficiency and Necessity of Multi-Modal Representation\n  Learning", "author": "Jingyao Wang and Siyu Zhao and Wenwen Qiang and Jiangmeng Li and Fuchun Sun and Hui Xiong", "abstract": "  Multi-Modal Learning (MML) aims to learn effective representations across\nmodalities for accurate predictions. Existing methods typically focus on\nmodality consistency and specificity to learn effective representations.\nHowever, from a causal perspective, they may lead to representations that\ncontain insufficient and unnecessary information. To address this, we propose\nthat effective MML representations should be causally sufficient and necessary.\nConsidering practical issues like spurious correlations and modality conflicts,\nwe relax the exogeneity and monotonicity assumptions prevalent in prior works\nand explore the concepts specific to MML, i.e., Causal Complete Cause\n(\\(C^3\\)). We begin by defining \\(C^3\\), which quantifies the probability of\nrepresentations being causally sufficient and necessary. We then discuss the\nidentifiability of \\(C^3\\) and introduce an instrumental variable to support\nidentifying \\(C^3\\) with non-exogeneity and non-monotonicity. Building on this,\nwe conduct the $C^3$ measurement, i.e., \\(C^3\\) risk. We propose a twin network\nto estimate it through (i) the real-world branch: utilizing the instrumental\nvariable for sufficiency, and (ii) the hypothetical-world branch: applying\ngradient-based counterfactual modeling for necessity. Theoretical analyses\nconfirm its reliability. Based on these results, we propose $C^3$\nRegularization, a plug-and-play method that enforces the causal completeness of\nthe learned representations by minimizing \\(C^3\\) risk. Extensive experiments\ndemonstrate its effectiveness.\n", "link": "http://arxiv.org/abs/2407.14058v3", "date": "2025-01-24", "relevancy": 1.605, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5559}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5352}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.5135}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20On%20the%20Causal%20Sufficiency%20and%20Necessity%20of%20Multi-Modal%20Representation%0A%20%20Learning&body=Title%3A%20On%20the%20Causal%20Sufficiency%20and%20Necessity%20of%20Multi-Modal%20Representation%0A%20%20Learning%0AAuthor%3A%20Jingyao%20Wang%20and%20Siyu%20Zhao%20and%20Wenwen%20Qiang%20and%20Jiangmeng%20Li%20and%20Fuchun%20Sun%20and%20Hui%20Xiong%0AAbstract%3A%20%20%20Multi-Modal%20Learning%20%28MML%29%20aims%20to%20learn%20effective%20representations%20across%0Amodalities%20for%20accurate%20predictions.%20Existing%20methods%20typically%20focus%20on%0Amodality%20consistency%20and%20specificity%20to%20learn%20effective%20representations.%0AHowever%2C%20from%20a%20causal%20perspective%2C%20they%20may%20lead%20to%20representations%20that%0Acontain%20insufficient%20and%20unnecessary%20information.%20To%20address%20this%2C%20we%20propose%0Athat%20effective%20MML%20representations%20should%20be%20causally%20sufficient%20and%20necessary.%0AConsidering%20practical%20issues%20like%20spurious%20correlations%20and%20modality%20conflicts%2C%0Awe%20relax%20the%20exogeneity%20and%20monotonicity%20assumptions%20prevalent%20in%20prior%20works%0Aand%20explore%20the%20concepts%20specific%20to%20MML%2C%20i.e.%2C%20Causal%20Complete%20Cause%0A%28%5C%28C%5E3%5C%29%29.%20We%20begin%20by%20defining%20%5C%28C%5E3%5C%29%2C%20which%20quantifies%20the%20probability%20of%0Arepresentations%20being%20causally%20sufficient%20and%20necessary.%20We%20then%20discuss%20the%0Aidentifiability%20of%20%5C%28C%5E3%5C%29%20and%20introduce%20an%20instrumental%20variable%20to%20support%0Aidentifying%20%5C%28C%5E3%5C%29%20with%20non-exogeneity%20and%20non-monotonicity.%20Building%20on%20this%2C%0Awe%20conduct%20the%20%24C%5E3%24%20measurement%2C%20i.e.%2C%20%5C%28C%5E3%5C%29%20risk.%20We%20propose%20a%20twin%20network%0Ato%20estimate%20it%20through%20%28i%29%20the%20real-world%20branch%3A%20utilizing%20the%20instrumental%0Avariable%20for%20sufficiency%2C%20and%20%28ii%29%20the%20hypothetical-world%20branch%3A%20applying%0Agradient-based%20counterfactual%20modeling%20for%20necessity.%20Theoretical%20analyses%0Aconfirm%20its%20reliability.%20Based%20on%20these%20results%2C%20we%20propose%20%24C%5E3%24%0ARegularization%2C%20a%20plug-and-play%20method%20that%20enforces%20the%20causal%20completeness%20of%0Athe%20learned%20representations%20by%20minimizing%20%5C%28C%5E3%5C%29%20risk.%20Extensive%20experiments%0Ademonstrate%20its%20effectiveness.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2407.14058v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DOn%2520the%2520Causal%2520Sufficiency%2520and%2520Necessity%2520of%2520Multi-Modal%2520Representation%250A%2520%2520Learning%26entry.906535625%3DJingyao%2520Wang%2520and%2520Siyu%2520Zhao%2520and%2520Wenwen%2520Qiang%2520and%2520Jiangmeng%2520Li%2520and%2520Fuchun%2520Sun%2520and%2520Hui%2520Xiong%26entry.1292438233%3D%2520%2520Multi-Modal%2520Learning%2520%2528MML%2529%2520aims%2520to%2520learn%2520effective%2520representations%2520across%250Amodalities%2520for%2520accurate%2520predictions.%2520Existing%2520methods%2520typically%2520focus%2520on%250Amodality%2520consistency%2520and%2520specificity%2520to%2520learn%2520effective%2520representations.%250AHowever%252C%2520from%2520a%2520causal%2520perspective%252C%2520they%2520may%2520lead%2520to%2520representations%2520that%250Acontain%2520insufficient%2520and%2520unnecessary%2520information.%2520To%2520address%2520this%252C%2520we%2520propose%250Athat%2520effective%2520MML%2520representations%2520should%2520be%2520causally%2520sufficient%2520and%2520necessary.%250AConsidering%2520practical%2520issues%2520like%2520spurious%2520correlations%2520and%2520modality%2520conflicts%252C%250Awe%2520relax%2520the%2520exogeneity%2520and%2520monotonicity%2520assumptions%2520prevalent%2520in%2520prior%2520works%250Aand%2520explore%2520the%2520concepts%2520specific%2520to%2520MML%252C%2520i.e.%252C%2520Causal%2520Complete%2520Cause%250A%2528%255C%2528C%255E3%255C%2529%2529.%2520We%2520begin%2520by%2520defining%2520%255C%2528C%255E3%255C%2529%252C%2520which%2520quantifies%2520the%2520probability%2520of%250Arepresentations%2520being%2520causally%2520sufficient%2520and%2520necessary.%2520We%2520then%2520discuss%2520the%250Aidentifiability%2520of%2520%255C%2528C%255E3%255C%2529%2520and%2520introduce%2520an%2520instrumental%2520variable%2520to%2520support%250Aidentifying%2520%255C%2528C%255E3%255C%2529%2520with%2520non-exogeneity%2520and%2520non-monotonicity.%2520Building%2520on%2520this%252C%250Awe%2520conduct%2520the%2520%2524C%255E3%2524%2520measurement%252C%2520i.e.%252C%2520%255C%2528C%255E3%255C%2529%2520risk.%2520We%2520propose%2520a%2520twin%2520network%250Ato%2520estimate%2520it%2520through%2520%2528i%2529%2520the%2520real-world%2520branch%253A%2520utilizing%2520the%2520instrumental%250Avariable%2520for%2520sufficiency%252C%2520and%2520%2528ii%2529%2520the%2520hypothetical-world%2520branch%253A%2520applying%250Agradient-based%2520counterfactual%2520modeling%2520for%2520necessity.%2520Theoretical%2520analyses%250Aconfirm%2520its%2520reliability.%2520Based%2520on%2520these%2520results%252C%2520we%2520propose%2520%2524C%255E3%2524%250ARegularization%252C%2520a%2520plug-and-play%2520method%2520that%2520enforces%2520the%2520causal%2520completeness%2520of%250Athe%2520learned%2520representations%2520by%2520minimizing%2520%255C%2528C%255E3%255C%2529%2520risk.%2520Extensive%2520experiments%250Ademonstrate%2520its%2520effectiveness.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2407.14058v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=On%20the%20Causal%20Sufficiency%20and%20Necessity%20of%20Multi-Modal%20Representation%0A%20%20Learning&entry.906535625=Jingyao%20Wang%20and%20Siyu%20Zhao%20and%20Wenwen%20Qiang%20and%20Jiangmeng%20Li%20and%20Fuchun%20Sun%20and%20Hui%20Xiong&entry.1292438233=%20%20Multi-Modal%20Learning%20%28MML%29%20aims%20to%20learn%20effective%20representations%20across%0Amodalities%20for%20accurate%20predictions.%20Existing%20methods%20typically%20focus%20on%0Amodality%20consistency%20and%20specificity%20to%20learn%20effective%20representations.%0AHowever%2C%20from%20a%20causal%20perspective%2C%20they%20may%20lead%20to%20representations%20that%0Acontain%20insufficient%20and%20unnecessary%20information.%20To%20address%20this%2C%20we%20propose%0Athat%20effective%20MML%20representations%20should%20be%20causally%20sufficient%20and%20necessary.%0AConsidering%20practical%20issues%20like%20spurious%20correlations%20and%20modality%20conflicts%2C%0Awe%20relax%20the%20exogeneity%20and%20monotonicity%20assumptions%20prevalent%20in%20prior%20works%0Aand%20explore%20the%20concepts%20specific%20to%20MML%2C%20i.e.%2C%20Causal%20Complete%20Cause%0A%28%5C%28C%5E3%5C%29%29.%20We%20begin%20by%20defining%20%5C%28C%5E3%5C%29%2C%20which%20quantifies%20the%20probability%20of%0Arepresentations%20being%20causally%20sufficient%20and%20necessary.%20We%20then%20discuss%20the%0Aidentifiability%20of%20%5C%28C%5E3%5C%29%20and%20introduce%20an%20instrumental%20variable%20to%20support%0Aidentifying%20%5C%28C%5E3%5C%29%20with%20non-exogeneity%20and%20non-monotonicity.%20Building%20on%20this%2C%0Awe%20conduct%20the%20%24C%5E3%24%20measurement%2C%20i.e.%2C%20%5C%28C%5E3%5C%29%20risk.%20We%20propose%20a%20twin%20network%0Ato%20estimate%20it%20through%20%28i%29%20the%20real-world%20branch%3A%20utilizing%20the%20instrumental%0Avariable%20for%20sufficiency%2C%20and%20%28ii%29%20the%20hypothetical-world%20branch%3A%20applying%0Agradient-based%20counterfactual%20modeling%20for%20necessity.%20Theoretical%20analyses%0Aconfirm%20its%20reliability.%20Based%20on%20these%20results%2C%20we%20propose%20%24C%5E3%24%0ARegularization%2C%20a%20plug-and-play%20method%20that%20enforces%20the%20causal%20completeness%20of%0Athe%20learned%20representations%20by%20minimizing%20%5C%28C%5E3%5C%29%20risk.%20Extensive%20experiments%0Ademonstrate%20its%20effectiveness.%0A&entry.1838667208=http%3A//arxiv.org/abs/2407.14058v3&entry.124074799=Read"},
{"title": "ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy\n  Representation Learning", "author": "Aleksandar Vujinovic and Aleksandar Kovacevic", "abstract": "  Learning efficient representations for decision-making policies is a\nchallenge in imitation learning (IL). Current IL methods require expert\ndemonstrations, which are expensive to collect. Consequently, they often have\nunderdeveloped world models. Self-supervised learning (SSL) offers an\nalternative by allowing models to learn from diverse, unlabeled data, including\nfailures. However, SSL methods often operate in raw input space, making them\ninefficient. In this work, we propose ACT-JEPA, a novel architecture that\nintegrates IL and SSL to enhance policy representations. We train a policy to\npredict (1) action sequences and (2) abstract observation sequences. The first\nobjective uses action chunking to improve action prediction and reduce\ncompounding errors. The second objective extends this idea of chunking by\npredicting abstract observation sequences. We utilize Joint-Embedding\nPredictive Architecture to predict in abstract representation space, allowing\nthe model to filter out irrelevant details, improve efficiency, and develop a\nrobust world model. Our experiments show that ACT-JEPA improves the quality of\nrepresentations by learning temporal environment dynamics. Additionally, the\nmodel's ability to predict abstract observation sequences results in\nrepresentations that effectively generalize to action sequence prediction.\nACT-JEPA performs on par with established baselines across a range of\ndecision-making tasks.\n", "link": "http://arxiv.org/abs/2501.14622v1", "date": "2025-01-24", "relevancy": 1.6002, "topK": [{"title": "IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation Learning", "link": "https://arxiv.org/abs/2201.00785", "similarity": 0.5366}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5339}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5249}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20ACT-JEPA%3A%20Joint-Embedding%20Predictive%20Architecture%20Improves%20Policy%0A%20%20Representation%20Learning&body=Title%3A%20ACT-JEPA%3A%20Joint-Embedding%20Predictive%20Architecture%20Improves%20Policy%0A%20%20Representation%20Learning%0AAuthor%3A%20Aleksandar%20Vujinovic%20and%20Aleksandar%20Kovacevic%0AAbstract%3A%20%20%20Learning%20efficient%20representations%20for%20decision-making%20policies%20is%20a%0Achallenge%20in%20imitation%20learning%20%28IL%29.%20Current%20IL%20methods%20require%20expert%0Ademonstrations%2C%20which%20are%20expensive%20to%20collect.%20Consequently%2C%20they%20often%20have%0Aunderdeveloped%20world%20models.%20Self-supervised%20learning%20%28SSL%29%20offers%20an%0Aalternative%20by%20allowing%20models%20to%20learn%20from%20diverse%2C%20unlabeled%20data%2C%20including%0Afailures.%20However%2C%20SSL%20methods%20often%20operate%20in%20raw%20input%20space%2C%20making%20them%0Ainefficient.%20In%20this%20work%2C%20we%20propose%20ACT-JEPA%2C%20a%20novel%20architecture%20that%0Aintegrates%20IL%20and%20SSL%20to%20enhance%20policy%20representations.%20We%20train%20a%20policy%20to%0Apredict%20%281%29%20action%20sequences%20and%20%282%29%20abstract%20observation%20sequences.%20The%20first%0Aobjective%20uses%20action%20chunking%20to%20improve%20action%20prediction%20and%20reduce%0Acompounding%20errors.%20The%20second%20objective%20extends%20this%20idea%20of%20chunking%20by%0Apredicting%20abstract%20observation%20sequences.%20We%20utilize%20Joint-Embedding%0APredictive%20Architecture%20to%20predict%20in%20abstract%20representation%20space%2C%20allowing%0Athe%20model%20to%20filter%20out%20irrelevant%20details%2C%20improve%20efficiency%2C%20and%20develop%20a%0Arobust%20world%20model.%20Our%20experiments%20show%20that%20ACT-JEPA%20improves%20the%20quality%20of%0Arepresentations%20by%20learning%20temporal%20environment%20dynamics.%20Additionally%2C%20the%0Amodel%27s%20ability%20to%20predict%20abstract%20observation%20sequences%20results%20in%0Arepresentations%20that%20effectively%20generalize%20to%20action%20sequence%20prediction.%0AACT-JEPA%20performs%20on%20par%20with%20established%20baselines%20across%20a%20range%20of%0Adecision-making%20tasks.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14622v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DACT-JEPA%253A%2520Joint-Embedding%2520Predictive%2520Architecture%2520Improves%2520Policy%250A%2520%2520Representation%2520Learning%26entry.906535625%3DAleksandar%2520Vujinovic%2520and%2520Aleksandar%2520Kovacevic%26entry.1292438233%3D%2520%2520Learning%2520efficient%2520representations%2520for%2520decision-making%2520policies%2520is%2520a%250Achallenge%2520in%2520imitation%2520learning%2520%2528IL%2529.%2520Current%2520IL%2520methods%2520require%2520expert%250Ademonstrations%252C%2520which%2520are%2520expensive%2520to%2520collect.%2520Consequently%252C%2520they%2520often%2520have%250Aunderdeveloped%2520world%2520models.%2520Self-supervised%2520learning%2520%2528SSL%2529%2520offers%2520an%250Aalternative%2520by%2520allowing%2520models%2520to%2520learn%2520from%2520diverse%252C%2520unlabeled%2520data%252C%2520including%250Afailures.%2520However%252C%2520SSL%2520methods%2520often%2520operate%2520in%2520raw%2520input%2520space%252C%2520making%2520them%250Ainefficient.%2520In%2520this%2520work%252C%2520we%2520propose%2520ACT-JEPA%252C%2520a%2520novel%2520architecture%2520that%250Aintegrates%2520IL%2520and%2520SSL%2520to%2520enhance%2520policy%2520representations.%2520We%2520train%2520a%2520policy%2520to%250Apredict%2520%25281%2529%2520action%2520sequences%2520and%2520%25282%2529%2520abstract%2520observation%2520sequences.%2520The%2520first%250Aobjective%2520uses%2520action%2520chunking%2520to%2520improve%2520action%2520prediction%2520and%2520reduce%250Acompounding%2520errors.%2520The%2520second%2520objective%2520extends%2520this%2520idea%2520of%2520chunking%2520by%250Apredicting%2520abstract%2520observation%2520sequences.%2520We%2520utilize%2520Joint-Embedding%250APredictive%2520Architecture%2520to%2520predict%2520in%2520abstract%2520representation%2520space%252C%2520allowing%250Athe%2520model%2520to%2520filter%2520out%2520irrelevant%2520details%252C%2520improve%2520efficiency%252C%2520and%2520develop%2520a%250Arobust%2520world%2520model.%2520Our%2520experiments%2520show%2520that%2520ACT-JEPA%2520improves%2520the%2520quality%2520of%250Arepresentations%2520by%2520learning%2520temporal%2520environment%2520dynamics.%2520Additionally%252C%2520the%250Amodel%2527s%2520ability%2520to%2520predict%2520abstract%2520observation%2520sequences%2520results%2520in%250Arepresentations%2520that%2520effectively%2520generalize%2520to%2520action%2520sequence%2520prediction.%250AACT-JEPA%2520performs%2520on%2520par%2520with%2520established%2520baselines%2520across%2520a%2520range%2520of%250Adecision-making%2520tasks.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14622v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=ACT-JEPA%3A%20Joint-Embedding%20Predictive%20Architecture%20Improves%20Policy%0A%20%20Representation%20Learning&entry.906535625=Aleksandar%20Vujinovic%20and%20Aleksandar%20Kovacevic&entry.1292438233=%20%20Learning%20efficient%20representations%20for%20decision-making%20policies%20is%20a%0Achallenge%20in%20imitation%20learning%20%28IL%29.%20Current%20IL%20methods%20require%20expert%0Ademonstrations%2C%20which%20are%20expensive%20to%20collect.%20Consequently%2C%20they%20often%20have%0Aunderdeveloped%20world%20models.%20Self-supervised%20learning%20%28SSL%29%20offers%20an%0Aalternative%20by%20allowing%20models%20to%20learn%20from%20diverse%2C%20unlabeled%20data%2C%20including%0Afailures.%20However%2C%20SSL%20methods%20often%20operate%20in%20raw%20input%20space%2C%20making%20them%0Ainefficient.%20In%20this%20work%2C%20we%20propose%20ACT-JEPA%2C%20a%20novel%20architecture%20that%0Aintegrates%20IL%20and%20SSL%20to%20enhance%20policy%20representations.%20We%20train%20a%20policy%20to%0Apredict%20%281%29%20action%20sequences%20and%20%282%29%20abstract%20observation%20sequences.%20The%20first%0Aobjective%20uses%20action%20chunking%20to%20improve%20action%20prediction%20and%20reduce%0Acompounding%20errors.%20The%20second%20objective%20extends%20this%20idea%20of%20chunking%20by%0Apredicting%20abstract%20observation%20sequences.%20We%20utilize%20Joint-Embedding%0APredictive%20Architecture%20to%20predict%20in%20abstract%20representation%20space%2C%20allowing%0Athe%20model%20to%20filter%20out%20irrelevant%20details%2C%20improve%20efficiency%2C%20and%20develop%20a%0Arobust%20world%20model.%20Our%20experiments%20show%20that%20ACT-JEPA%20improves%20the%20quality%20of%0Arepresentations%20by%20learning%20temporal%20environment%20dynamics.%20Additionally%2C%20the%0Amodel%27s%20ability%20to%20predict%20abstract%20observation%20sequences%20results%20in%0Arepresentations%20that%20effectively%20generalize%20to%20action%20sequence%20prediction.%0AACT-JEPA%20performs%20on%20par%20with%20established%20baselines%20across%20a%20range%20of%0Adecision-making%20tasks.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14622v1&entry.124074799=Read"},
{"title": "Towards Human-Guided, Data-Centric LLM Co-Pilots", "author": "Evgeny Saveliev and Jiashuo Liu and Nabeel Seedat and Anders Boyd and Mihaela van der Schaar", "abstract": "  Machine learning (ML) has the potential to revolutionize various domains, but\nits adoption is often hindered by the disconnect between the needs of domain\nexperts and translating these needs into robust and valid ML tools. Despite\nrecent advances in LLM-based co-pilots to democratize ML for non-technical\ndomain experts, these systems remain predominantly focused on model-centric\naspects while overlooking critical data-centric challenges. This limitation is\nproblematic in complex real-world settings where raw data often contains\ncomplex issues, such as missing values, label noise, and domain-specific\nnuances requiring tailored handling. To address this we introduce CliMB-DC, a\nhuman-guided, data-centric framework for LLM co-pilots that combines advanced\ndata-centric tools with LLM-driven reasoning to enable robust, context-aware\ndata processing. At its core, CliMB-DC introduces a novel, multi-agent\nreasoning system that combines a strategic coordinator for dynamic planning and\nadaptation with a specialized worker agent for precise execution. Domain\nexpertise is then systematically incorporated to guide the reasoning process\nusing a human-in-the-loop approach. To guide development, we formalize a\ntaxonomy of key data-centric challenges that co-pilots must address.\nThereafter, to address the dimensions of the taxonomy, we integrate\nstate-of-the-art data-centric tools into an extensible, open-source\narchitecture, facilitating the addition of new tools from the research\ncommunity. Empirically, using real-world healthcare datasets we demonstrate\nCliMB-DC's ability to transform uncurated datasets into ML-ready formats,\nsignificantly outperforming existing co-pilot baselines for handling\ndata-centric challenges. CliMB-DC promises to empower domain experts from\ndiverse domains -- healthcare, finance, social sciences and more -- to actively\nparticipate in driving real-world impact using ML.\n", "link": "http://arxiv.org/abs/2501.10321v2", "date": "2025-01-24", "relevancy": 1.5898, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.5332}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5322}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5195}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Towards%20Human-Guided%2C%20Data-Centric%20LLM%20Co-Pilots&body=Title%3A%20Towards%20Human-Guided%2C%20Data-Centric%20LLM%20Co-Pilots%0AAuthor%3A%20Evgeny%20Saveliev%20and%20Jiashuo%20Liu%20and%20Nabeel%20Seedat%20and%20Anders%20Boyd%20and%20Mihaela%20van%20der%20Schaar%0AAbstract%3A%20%20%20Machine%20learning%20%28ML%29%20has%20the%20potential%20to%20revolutionize%20various%20domains%2C%20but%0Aits%20adoption%20is%20often%20hindered%20by%20the%20disconnect%20between%20the%20needs%20of%20domain%0Aexperts%20and%20translating%20these%20needs%20into%20robust%20and%20valid%20ML%20tools.%20Despite%0Arecent%20advances%20in%20LLM-based%20co-pilots%20to%20democratize%20ML%20for%20non-technical%0Adomain%20experts%2C%20these%20systems%20remain%20predominantly%20focused%20on%20model-centric%0Aaspects%20while%20overlooking%20critical%20data-centric%20challenges.%20This%20limitation%20is%0Aproblematic%20in%20complex%20real-world%20settings%20where%20raw%20data%20often%20contains%0Acomplex%20issues%2C%20such%20as%20missing%20values%2C%20label%20noise%2C%20and%20domain-specific%0Anuances%20requiring%20tailored%20handling.%20To%20address%20this%20we%20introduce%20CliMB-DC%2C%20a%0Ahuman-guided%2C%20data-centric%20framework%20for%20LLM%20co-pilots%20that%20combines%20advanced%0Adata-centric%20tools%20with%20LLM-driven%20reasoning%20to%20enable%20robust%2C%20context-aware%0Adata%20processing.%20At%20its%20core%2C%20CliMB-DC%20introduces%20a%20novel%2C%20multi-agent%0Areasoning%20system%20that%20combines%20a%20strategic%20coordinator%20for%20dynamic%20planning%20and%0Aadaptation%20with%20a%20specialized%20worker%20agent%20for%20precise%20execution.%20Domain%0Aexpertise%20is%20then%20systematically%20incorporated%20to%20guide%20the%20reasoning%20process%0Ausing%20a%20human-in-the-loop%20approach.%20To%20guide%20development%2C%20we%20formalize%20a%0Ataxonomy%20of%20key%20data-centric%20challenges%20that%20co-pilots%20must%20address.%0AThereafter%2C%20to%20address%20the%20dimensions%20of%20the%20taxonomy%2C%20we%20integrate%0Astate-of-the-art%20data-centric%20tools%20into%20an%20extensible%2C%20open-source%0Aarchitecture%2C%20facilitating%20the%20addition%20of%20new%20tools%20from%20the%20research%0Acommunity.%20Empirically%2C%20using%20real-world%20healthcare%20datasets%20we%20demonstrate%0ACliMB-DC%27s%20ability%20to%20transform%20uncurated%20datasets%20into%20ML-ready%20formats%2C%0Asignificantly%20outperforming%20existing%20co-pilot%20baselines%20for%20handling%0Adata-centric%20challenges.%20CliMB-DC%20promises%20to%20empower%20domain%20experts%20from%0Adiverse%20domains%20--%20healthcare%2C%20finance%2C%20social%20sciences%20and%20more%20--%20to%20actively%0Aparticipate%20in%20driving%20real-world%20impact%20using%20ML.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.10321v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTowards%2520Human-Guided%252C%2520Data-Centric%2520LLM%2520Co-Pilots%26entry.906535625%3DEvgeny%2520Saveliev%2520and%2520Jiashuo%2520Liu%2520and%2520Nabeel%2520Seedat%2520and%2520Anders%2520Boyd%2520and%2520Mihaela%2520van%2520der%2520Schaar%26entry.1292438233%3D%2520%2520Machine%2520learning%2520%2528ML%2529%2520has%2520the%2520potential%2520to%2520revolutionize%2520various%2520domains%252C%2520but%250Aits%2520adoption%2520is%2520often%2520hindered%2520by%2520the%2520disconnect%2520between%2520the%2520needs%2520of%2520domain%250Aexperts%2520and%2520translating%2520these%2520needs%2520into%2520robust%2520and%2520valid%2520ML%2520tools.%2520Despite%250Arecent%2520advances%2520in%2520LLM-based%2520co-pilots%2520to%2520democratize%2520ML%2520for%2520non-technical%250Adomain%2520experts%252C%2520these%2520systems%2520remain%2520predominantly%2520focused%2520on%2520model-centric%250Aaspects%2520while%2520overlooking%2520critical%2520data-centric%2520challenges.%2520This%2520limitation%2520is%250Aproblematic%2520in%2520complex%2520real-world%2520settings%2520where%2520raw%2520data%2520often%2520contains%250Acomplex%2520issues%252C%2520such%2520as%2520missing%2520values%252C%2520label%2520noise%252C%2520and%2520domain-specific%250Anuances%2520requiring%2520tailored%2520handling.%2520To%2520address%2520this%2520we%2520introduce%2520CliMB-DC%252C%2520a%250Ahuman-guided%252C%2520data-centric%2520framework%2520for%2520LLM%2520co-pilots%2520that%2520combines%2520advanced%250Adata-centric%2520tools%2520with%2520LLM-driven%2520reasoning%2520to%2520enable%2520robust%252C%2520context-aware%250Adata%2520processing.%2520At%2520its%2520core%252C%2520CliMB-DC%2520introduces%2520a%2520novel%252C%2520multi-agent%250Areasoning%2520system%2520that%2520combines%2520a%2520strategic%2520coordinator%2520for%2520dynamic%2520planning%2520and%250Aadaptation%2520with%2520a%2520specialized%2520worker%2520agent%2520for%2520precise%2520execution.%2520Domain%250Aexpertise%2520is%2520then%2520systematically%2520incorporated%2520to%2520guide%2520the%2520reasoning%2520process%250Ausing%2520a%2520human-in-the-loop%2520approach.%2520To%2520guide%2520development%252C%2520we%2520formalize%2520a%250Ataxonomy%2520of%2520key%2520data-centric%2520challenges%2520that%2520co-pilots%2520must%2520address.%250AThereafter%252C%2520to%2520address%2520the%2520dimensions%2520of%2520the%2520taxonomy%252C%2520we%2520integrate%250Astate-of-the-art%2520data-centric%2520tools%2520into%2520an%2520extensible%252C%2520open-source%250Aarchitecture%252C%2520facilitating%2520the%2520addition%2520of%2520new%2520tools%2520from%2520the%2520research%250Acommunity.%2520Empirically%252C%2520using%2520real-world%2520healthcare%2520datasets%2520we%2520demonstrate%250ACliMB-DC%2527s%2520ability%2520to%2520transform%2520uncurated%2520datasets%2520into%2520ML-ready%2520formats%252C%250Asignificantly%2520outperforming%2520existing%2520co-pilot%2520baselines%2520for%2520handling%250Adata-centric%2520challenges.%2520CliMB-DC%2520promises%2520to%2520empower%2520domain%2520experts%2520from%250Adiverse%2520domains%2520--%2520healthcare%252C%2520finance%252C%2520social%2520sciences%2520and%2520more%2520--%2520to%2520actively%250Aparticipate%2520in%2520driving%2520real-world%2520impact%2520using%2520ML.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.10321v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Towards%20Human-Guided%2C%20Data-Centric%20LLM%20Co-Pilots&entry.906535625=Evgeny%20Saveliev%20and%20Jiashuo%20Liu%20and%20Nabeel%20Seedat%20and%20Anders%20Boyd%20and%20Mihaela%20van%20der%20Schaar&entry.1292438233=%20%20Machine%20learning%20%28ML%29%20has%20the%20potential%20to%20revolutionize%20various%20domains%2C%20but%0Aits%20adoption%20is%20often%20hindered%20by%20the%20disconnect%20between%20the%20needs%20of%20domain%0Aexperts%20and%20translating%20these%20needs%20into%20robust%20and%20valid%20ML%20tools.%20Despite%0Arecent%20advances%20in%20LLM-based%20co-pilots%20to%20democratize%20ML%20for%20non-technical%0Adomain%20experts%2C%20these%20systems%20remain%20predominantly%20focused%20on%20model-centric%0Aaspects%20while%20overlooking%20critical%20data-centric%20challenges.%20This%20limitation%20is%0Aproblematic%20in%20complex%20real-world%20settings%20where%20raw%20data%20often%20contains%0Acomplex%20issues%2C%20such%20as%20missing%20values%2C%20label%20noise%2C%20and%20domain-specific%0Anuances%20requiring%20tailored%20handling.%20To%20address%20this%20we%20introduce%20CliMB-DC%2C%20a%0Ahuman-guided%2C%20data-centric%20framework%20for%20LLM%20co-pilots%20that%20combines%20advanced%0Adata-centric%20tools%20with%20LLM-driven%20reasoning%20to%20enable%20robust%2C%20context-aware%0Adata%20processing.%20At%20its%20core%2C%20CliMB-DC%20introduces%20a%20novel%2C%20multi-agent%0Areasoning%20system%20that%20combines%20a%20strategic%20coordinator%20for%20dynamic%20planning%20and%0Aadaptation%20with%20a%20specialized%20worker%20agent%20for%20precise%20execution.%20Domain%0Aexpertise%20is%20then%20systematically%20incorporated%20to%20guide%20the%20reasoning%20process%0Ausing%20a%20human-in-the-loop%20approach.%20To%20guide%20development%2C%20we%20formalize%20a%0Ataxonomy%20of%20key%20data-centric%20challenges%20that%20co-pilots%20must%20address.%0AThereafter%2C%20to%20address%20the%20dimensions%20of%20the%20taxonomy%2C%20we%20integrate%0Astate-of-the-art%20data-centric%20tools%20into%20an%20extensible%2C%20open-source%0Aarchitecture%2C%20facilitating%20the%20addition%20of%20new%20tools%20from%20the%20research%0Acommunity.%20Empirically%2C%20using%20real-world%20healthcare%20datasets%20we%20demonstrate%0ACliMB-DC%27s%20ability%20to%20transform%20uncurated%20datasets%20into%20ML-ready%20formats%2C%0Asignificantly%20outperforming%20existing%20co-pilot%20baselines%20for%20handling%0Adata-centric%20challenges.%20CliMB-DC%20promises%20to%20empower%20domain%20experts%20from%0Adiverse%20domains%20--%20healthcare%2C%20finance%2C%20social%20sciences%20and%20more%20--%20to%20actively%0Aparticipate%20in%20driving%20real-world%20impact%20using%20ML.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.10321v2&entry.124074799=Read"},
{"title": "A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery\n  Using Informer Model", "author": "Muhammad Hanif Lashari and Shakil Ahmed and Wafa Batayneh and Ashfaq Khokhar", "abstract": "  Precise and real-time estimation of the robotic arm's position on the\npatient's side is essential for the success of remote robotic surgery in\nTactile Internet (TI) environments. This paper presents a prediction model\nbased on the Transformer-based Informer framework for accurate and efficient\nposition estimation. Additionally, it combines a Four-State Hidden Markov Model\n(4-State HMM) to simulate realistic packet loss scenarios. The proposed\napproach addresses challenges such as network delays, jitter, and packet loss\nto ensure reliable and precise operation in remote surgical applications. The\nmethod integrates the optimization problem into the Informer model by embedding\nconstraints such as energy efficiency, smoothness, and robustness into its\ntraining process using a differentiable optimization layer. The Informer\nframework uses features such as ProbSparse attention, attention distilling, and\na generative-style decoder to focus on position-critical features while\nmaintaining a low computational complexity of O(L log L). The method is\nevaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90\npercent under various network scenarios. A comparison with models such as TCN,\nRNN, and LSTM demonstrates the Informer framework's superior performance in\nhandling position prediction and meeting real-time requirements, making it\nsuitable for Tactile Internet-enabled robotic surgery.\n", "link": "http://arxiv.org/abs/2501.14678v1", "date": "2025-01-24", "relevancy": 1.5597, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5867}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5024}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4967}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20A%20Predictive%20Approach%20for%20Enhancing%20Accuracy%20in%20Remote%20Robotic%20Surgery%0A%20%20Using%20Informer%20Model&body=Title%3A%20A%20Predictive%20Approach%20for%20Enhancing%20Accuracy%20in%20Remote%20Robotic%20Surgery%0A%20%20Using%20Informer%20Model%0AAuthor%3A%20Muhammad%20Hanif%20Lashari%20and%20Shakil%20Ahmed%20and%20Wafa%20Batayneh%20and%20Ashfaq%20Khokhar%0AAbstract%3A%20%20%20Precise%20and%20real-time%20estimation%20of%20the%20robotic%20arm%27s%20position%20on%20the%0Apatient%27s%20side%20is%20essential%20for%20the%20success%20of%20remote%20robotic%20surgery%20in%0ATactile%20Internet%20%28TI%29%20environments.%20This%20paper%20presents%20a%20prediction%20model%0Abased%20on%20the%20Transformer-based%20Informer%20framework%20for%20accurate%20and%20efficient%0Aposition%20estimation.%20Additionally%2C%20it%20combines%20a%20Four-State%20Hidden%20Markov%20Model%0A%284-State%20HMM%29%20to%20simulate%20realistic%20packet%20loss%20scenarios.%20The%20proposed%0Aapproach%20addresses%20challenges%20such%20as%20network%20delays%2C%20jitter%2C%20and%20packet%20loss%0Ato%20ensure%20reliable%20and%20precise%20operation%20in%20remote%20surgical%20applications.%20The%0Amethod%20integrates%20the%20optimization%20problem%20into%20the%20Informer%20model%20by%20embedding%0Aconstraints%20such%20as%20energy%20efficiency%2C%20smoothness%2C%20and%20robustness%20into%20its%0Atraining%20process%20using%20a%20differentiable%20optimization%20layer.%20The%20Informer%0Aframework%20uses%20features%20such%20as%20ProbSparse%20attention%2C%20attention%20distilling%2C%20and%0Aa%20generative-style%20decoder%20to%20focus%20on%20position-critical%20features%20while%0Amaintaining%20a%20low%20computational%20complexity%20of%20O%28L%20log%20L%29.%20The%20method%20is%0Aevaluated%20using%20the%20JIGSAWS%20dataset%2C%20achieving%20a%20prediction%20accuracy%20of%20over%2090%0Apercent%20under%20various%20network%20scenarios.%20A%20comparison%20with%20models%20such%20as%20TCN%2C%0ARNN%2C%20and%20LSTM%20demonstrates%20the%20Informer%20framework%27s%20superior%20performance%20in%0Ahandling%20position%20prediction%20and%20meeting%20real-time%20requirements%2C%20making%20it%0Asuitable%20for%20Tactile%20Internet-enabled%20robotic%20surgery.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14678v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DA%2520Predictive%2520Approach%2520for%2520Enhancing%2520Accuracy%2520in%2520Remote%2520Robotic%2520Surgery%250A%2520%2520Using%2520Informer%2520Model%26entry.906535625%3DMuhammad%2520Hanif%2520Lashari%2520and%2520Shakil%2520Ahmed%2520and%2520Wafa%2520Batayneh%2520and%2520Ashfaq%2520Khokhar%26entry.1292438233%3D%2520%2520Precise%2520and%2520real-time%2520estimation%2520of%2520the%2520robotic%2520arm%2527s%2520position%2520on%2520the%250Apatient%2527s%2520side%2520is%2520essential%2520for%2520the%2520success%2520of%2520remote%2520robotic%2520surgery%2520in%250ATactile%2520Internet%2520%2528TI%2529%2520environments.%2520This%2520paper%2520presents%2520a%2520prediction%2520model%250Abased%2520on%2520the%2520Transformer-based%2520Informer%2520framework%2520for%2520accurate%2520and%2520efficient%250Aposition%2520estimation.%2520Additionally%252C%2520it%2520combines%2520a%2520Four-State%2520Hidden%2520Markov%2520Model%250A%25284-State%2520HMM%2529%2520to%2520simulate%2520realistic%2520packet%2520loss%2520scenarios.%2520The%2520proposed%250Aapproach%2520addresses%2520challenges%2520such%2520as%2520network%2520delays%252C%2520jitter%252C%2520and%2520packet%2520loss%250Ato%2520ensure%2520reliable%2520and%2520precise%2520operation%2520in%2520remote%2520surgical%2520applications.%2520The%250Amethod%2520integrates%2520the%2520optimization%2520problem%2520into%2520the%2520Informer%2520model%2520by%2520embedding%250Aconstraints%2520such%2520as%2520energy%2520efficiency%252C%2520smoothness%252C%2520and%2520robustness%2520into%2520its%250Atraining%2520process%2520using%2520a%2520differentiable%2520optimization%2520layer.%2520The%2520Informer%250Aframework%2520uses%2520features%2520such%2520as%2520ProbSparse%2520attention%252C%2520attention%2520distilling%252C%2520and%250Aa%2520generative-style%2520decoder%2520to%2520focus%2520on%2520position-critical%2520features%2520while%250Amaintaining%2520a%2520low%2520computational%2520complexity%2520of%2520O%2528L%2520log%2520L%2529.%2520The%2520method%2520is%250Aevaluated%2520using%2520the%2520JIGSAWS%2520dataset%252C%2520achieving%2520a%2520prediction%2520accuracy%2520of%2520over%252090%250Apercent%2520under%2520various%2520network%2520scenarios.%2520A%2520comparison%2520with%2520models%2520such%2520as%2520TCN%252C%250ARNN%252C%2520and%2520LSTM%2520demonstrates%2520the%2520Informer%2520framework%2527s%2520superior%2520performance%2520in%250Ahandling%2520position%2520prediction%2520and%2520meeting%2520real-time%2520requirements%252C%2520making%2520it%250Asuitable%2520for%2520Tactile%2520Internet-enabled%2520robotic%2520surgery.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14678v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=A%20Predictive%20Approach%20for%20Enhancing%20Accuracy%20in%20Remote%20Robotic%20Surgery%0A%20%20Using%20Informer%20Model&entry.906535625=Muhammad%20Hanif%20Lashari%20and%20Shakil%20Ahmed%20and%20Wafa%20Batayneh%20and%20Ashfaq%20Khokhar&entry.1292438233=%20%20Precise%20and%20real-time%20estimation%20of%20the%20robotic%20arm%27s%20position%20on%20the%0Apatient%27s%20side%20is%20essential%20for%20the%20success%20of%20remote%20robotic%20surgery%20in%0ATactile%20Internet%20%28TI%29%20environments.%20This%20paper%20presents%20a%20prediction%20model%0Abased%20on%20the%20Transformer-based%20Informer%20framework%20for%20accurate%20and%20efficient%0Aposition%20estimation.%20Additionally%2C%20it%20combines%20a%20Four-State%20Hidden%20Markov%20Model%0A%284-State%20HMM%29%20to%20simulate%20realistic%20packet%20loss%20scenarios.%20The%20proposed%0Aapproach%20addresses%20challenges%20such%20as%20network%20delays%2C%20jitter%2C%20and%20packet%20loss%0Ato%20ensure%20reliable%20and%20precise%20operation%20in%20remote%20surgical%20applications.%20The%0Amethod%20integrates%20the%20optimization%20problem%20into%20the%20Informer%20model%20by%20embedding%0Aconstraints%20such%20as%20energy%20efficiency%2C%20smoothness%2C%20and%20robustness%20into%20its%0Atraining%20process%20using%20a%20differentiable%20optimization%20layer.%20The%20Informer%0Aframework%20uses%20features%20such%20as%20ProbSparse%20attention%2C%20attention%20distilling%2C%20and%0Aa%20generative-style%20decoder%20to%20focus%20on%20position-critical%20features%20while%0Amaintaining%20a%20low%20computational%20complexity%20of%20O%28L%20log%20L%29.%20The%20method%20is%0Aevaluated%20using%20the%20JIGSAWS%20dataset%2C%20achieving%20a%20prediction%20accuracy%20of%20over%2090%0Apercent%20under%20various%20network%20scenarios.%20A%20comparison%20with%20models%20such%20as%20TCN%2C%0ARNN%2C%20and%20LSTM%20demonstrates%20the%20Informer%20framework%27s%20superior%20performance%20in%0Ahandling%20position%20prediction%20and%20meeting%20real-time%20requirements%2C%20making%20it%0Asuitable%20for%20Tactile%20Internet-enabled%20robotic%20surgery.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14678v1&entry.124074799=Read"},
{"title": "Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis", "author": "Haoxin Liu and Shangqing Xu and Zhiyuan Zhao and Lingkai Kong and Harshavardhan Kamarthi and Aditya B. Sasanur and Megha Sharma and Jiaming Cui and Qingsong Wen and Chao Zhang and B. Aditya Prakash", "abstract": "  Time series data are ubiquitous across a wide range of real-world domains.\nWhile real-world time series analysis (TSA) requires human experts to integrate\nnumerical series data with multimodal domain-specific knowledge, most existing\nTSA models rely solely on numerical data, overlooking the significance of\ninformation beyond numerical series. This oversight is due to the untapped\npotential of textual series data and the absence of a comprehensive,\nhigh-quality multimodal dataset. To overcome this obstacle, we introduce\nTime-MMD, the first multi-domain, multimodal time series dataset covering 9\nprimary data domains. Time-MMD ensures fine-grained modality alignment,\neliminates data contamination, and provides high usability. Additionally, we\ndevelop MM-TSFlib, the first-cut multimodal time-series forecasting (TSF)\nlibrary, seamlessly pipelining multimodal TSF evaluations based on Time-MMD for\nin-depth analyses. Extensive experiments conducted on Time-MMD through\nMM-TSFlib demonstrate significant performance enhancements by extending\nunimodal TSF to multimodality, evidenced by over 15% mean squared error\nreduction in general, and up to 40% in domains with rich textual data. More\nimportantly, our datasets and library revolutionize broader applications,\nimpacts, research topics to advance TSA. The dataset is available at\nhttps://github.com/AdityaLab/Time-MMD.\n", "link": "http://arxiv.org/abs/2406.08627v4", "date": "2025-01-24", "relevancy": 1.5549, "topK": [{"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.549}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.4952}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4647}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Time-MMD%3A%20Multi-Domain%20Multimodal%20Dataset%20for%20Time%20Series%20Analysis&body=Title%3A%20Time-MMD%3A%20Multi-Domain%20Multimodal%20Dataset%20for%20Time%20Series%20Analysis%0AAuthor%3A%20Haoxin%20Liu%20and%20Shangqing%20Xu%20and%20Zhiyuan%20Zhao%20and%20Lingkai%20Kong%20and%20Harshavardhan%20Kamarthi%20and%20Aditya%20B.%20Sasanur%20and%20Megha%20Sharma%20and%20Jiaming%20Cui%20and%20Qingsong%20Wen%20and%20Chao%20Zhang%20and%20B.%20Aditya%20Prakash%0AAbstract%3A%20%20%20Time%20series%20data%20are%20ubiquitous%20across%20a%20wide%20range%20of%20real-world%20domains.%0AWhile%20real-world%20time%20series%20analysis%20%28TSA%29%20requires%20human%20experts%20to%20integrate%0Anumerical%20series%20data%20with%20multimodal%20domain-specific%20knowledge%2C%20most%20existing%0ATSA%20models%20rely%20solely%20on%20numerical%20data%2C%20overlooking%20the%20significance%20of%0Ainformation%20beyond%20numerical%20series.%20This%20oversight%20is%20due%20to%20the%20untapped%0Apotential%20of%20textual%20series%20data%20and%20the%20absence%20of%20a%20comprehensive%2C%0Ahigh-quality%20multimodal%20dataset.%20To%20overcome%20this%20obstacle%2C%20we%20introduce%0ATime-MMD%2C%20the%20first%20multi-domain%2C%20multimodal%20time%20series%20dataset%20covering%209%0Aprimary%20data%20domains.%20Time-MMD%20ensures%20fine-grained%20modality%20alignment%2C%0Aeliminates%20data%20contamination%2C%20and%20provides%20high%20usability.%20Additionally%2C%20we%0Adevelop%20MM-TSFlib%2C%20the%20first-cut%20multimodal%20time-series%20forecasting%20%28TSF%29%0Alibrary%2C%20seamlessly%20pipelining%20multimodal%20TSF%20evaluations%20based%20on%20Time-MMD%20for%0Ain-depth%20analyses.%20Extensive%20experiments%20conducted%20on%20Time-MMD%20through%0AMM-TSFlib%20demonstrate%20significant%20performance%20enhancements%20by%20extending%0Aunimodal%20TSF%20to%20multimodality%2C%20evidenced%20by%20over%2015%25%20mean%20squared%20error%0Areduction%20in%20general%2C%20and%20up%20to%2040%25%20in%20domains%20with%20rich%20textual%20data.%20More%0Aimportantly%2C%20our%20datasets%20and%20library%20revolutionize%20broader%20applications%2C%0Aimpacts%2C%20research%20topics%20to%20advance%20TSA.%20The%20dataset%20is%20available%20at%0Ahttps%3A//github.com/AdityaLab/Time-MMD.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2406.08627v4%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DTime-MMD%253A%2520Multi-Domain%2520Multimodal%2520Dataset%2520for%2520Time%2520Series%2520Analysis%26entry.906535625%3DHaoxin%2520Liu%2520and%2520Shangqing%2520Xu%2520and%2520Zhiyuan%2520Zhao%2520and%2520Lingkai%2520Kong%2520and%2520Harshavardhan%2520Kamarthi%2520and%2520Aditya%2520B.%2520Sasanur%2520and%2520Megha%2520Sharma%2520and%2520Jiaming%2520Cui%2520and%2520Qingsong%2520Wen%2520and%2520Chao%2520Zhang%2520and%2520B.%2520Aditya%2520Prakash%26entry.1292438233%3D%2520%2520Time%2520series%2520data%2520are%2520ubiquitous%2520across%2520a%2520wide%2520range%2520of%2520real-world%2520domains.%250AWhile%2520real-world%2520time%2520series%2520analysis%2520%2528TSA%2529%2520requires%2520human%2520experts%2520to%2520integrate%250Anumerical%2520series%2520data%2520with%2520multimodal%2520domain-specific%2520knowledge%252C%2520most%2520existing%250ATSA%2520models%2520rely%2520solely%2520on%2520numerical%2520data%252C%2520overlooking%2520the%2520significance%2520of%250Ainformation%2520beyond%2520numerical%2520series.%2520This%2520oversight%2520is%2520due%2520to%2520the%2520untapped%250Apotential%2520of%2520textual%2520series%2520data%2520and%2520the%2520absence%2520of%2520a%2520comprehensive%252C%250Ahigh-quality%2520multimodal%2520dataset.%2520To%2520overcome%2520this%2520obstacle%252C%2520we%2520introduce%250ATime-MMD%252C%2520the%2520first%2520multi-domain%252C%2520multimodal%2520time%2520series%2520dataset%2520covering%25209%250Aprimary%2520data%2520domains.%2520Time-MMD%2520ensures%2520fine-grained%2520modality%2520alignment%252C%250Aeliminates%2520data%2520contamination%252C%2520and%2520provides%2520high%2520usability.%2520Additionally%252C%2520we%250Adevelop%2520MM-TSFlib%252C%2520the%2520first-cut%2520multimodal%2520time-series%2520forecasting%2520%2528TSF%2529%250Alibrary%252C%2520seamlessly%2520pipelining%2520multimodal%2520TSF%2520evaluations%2520based%2520on%2520Time-MMD%2520for%250Ain-depth%2520analyses.%2520Extensive%2520experiments%2520conducted%2520on%2520Time-MMD%2520through%250AMM-TSFlib%2520demonstrate%2520significant%2520performance%2520enhancements%2520by%2520extending%250Aunimodal%2520TSF%2520to%2520multimodality%252C%2520evidenced%2520by%2520over%252015%2525%2520mean%2520squared%2520error%250Areduction%2520in%2520general%252C%2520and%2520up%2520to%252040%2525%2520in%2520domains%2520with%2520rich%2520textual%2520data.%2520More%250Aimportantly%252C%2520our%2520datasets%2520and%2520library%2520revolutionize%2520broader%2520applications%252C%250Aimpacts%252C%2520research%2520topics%2520to%2520advance%2520TSA.%2520The%2520dataset%2520is%2520available%2520at%250Ahttps%253A//github.com/AdityaLab/Time-MMD.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2406.08627v4%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Time-MMD%3A%20Multi-Domain%20Multimodal%20Dataset%20for%20Time%20Series%20Analysis&entry.906535625=Haoxin%20Liu%20and%20Shangqing%20Xu%20and%20Zhiyuan%20Zhao%20and%20Lingkai%20Kong%20and%20Harshavardhan%20Kamarthi%20and%20Aditya%20B.%20Sasanur%20and%20Megha%20Sharma%20and%20Jiaming%20Cui%20and%20Qingsong%20Wen%20and%20Chao%20Zhang%20and%20B.%20Aditya%20Prakash&entry.1292438233=%20%20Time%20series%20data%20are%20ubiquitous%20across%20a%20wide%20range%20of%20real-world%20domains.%0AWhile%20real-world%20time%20series%20analysis%20%28TSA%29%20requires%20human%20experts%20to%20integrate%0Anumerical%20series%20data%20with%20multimodal%20domain-specific%20knowledge%2C%20most%20existing%0ATSA%20models%20rely%20solely%20on%20numerical%20data%2C%20overlooking%20the%20significance%20of%0Ainformation%20beyond%20numerical%20series.%20This%20oversight%20is%20due%20to%20the%20untapped%0Apotential%20of%20textual%20series%20data%20and%20the%20absence%20of%20a%20comprehensive%2C%0Ahigh-quality%20multimodal%20dataset.%20To%20overcome%20this%20obstacle%2C%20we%20introduce%0ATime-MMD%2C%20the%20first%20multi-domain%2C%20multimodal%20time%20series%20dataset%20covering%209%0Aprimary%20data%20domains.%20Time-MMD%20ensures%20fine-grained%20modality%20alignment%2C%0Aeliminates%20data%20contamination%2C%20and%20provides%20high%20usability.%20Additionally%2C%20we%0Adevelop%20MM-TSFlib%2C%20the%20first-cut%20multimodal%20time-series%20forecasting%20%28TSF%29%0Alibrary%2C%20seamlessly%20pipelining%20multimodal%20TSF%20evaluations%20based%20on%20Time-MMD%20for%0Ain-depth%20analyses.%20Extensive%20experiments%20conducted%20on%20Time-MMD%20through%0AMM-TSFlib%20demonstrate%20significant%20performance%20enhancements%20by%20extending%0Aunimodal%20TSF%20to%20multimodality%2C%20evidenced%20by%20over%2015%25%20mean%20squared%20error%0Areduction%20in%20general%2C%20and%20up%20to%2040%25%20in%20domains%20with%20rich%20textual%20data.%20More%0Aimportantly%2C%20our%20datasets%20and%20library%20revolutionize%20broader%20applications%2C%0Aimpacts%2C%20research%20topics%20to%20advance%20TSA.%20The%20dataset%20is%20available%20at%0Ahttps%3A//github.com/AdityaLab/Time-MMD.%0A&entry.1838667208=http%3A//arxiv.org/abs/2406.08627v4&entry.124074799=Read"},
{"title": "Reducing Action Space for Deep Reinforcement Learning via Causal Effect\n  Estimation", "author": "Wenzhang Liu and Lianjun Jin and Lu Ren and Chaoxu Mu and Changyin Sun", "abstract": "  Intelligent decision-making within large and redundant action spaces remains\nchallenging in deep reinforcement learning. Considering similar but ineffective\nactions at each step can lead to repetitive and unproductive trials. Existing\nmethods attempt to improve agent exploration by reducing or penalizing\nredundant actions, yet they fail to provide quantitative and reliable evidence\nto determine redundancy. In this paper, we propose a method to improve\nexploration efficiency by estimating the causal effects of actions. Unlike\nprior methods, our approach offers quantitative results regarding the causality\nof actions for one-step transitions. We first pre-train an inverse dynamics\nmodel to serve as prior knowledge of the environment. Subsequently, we classify\nactions across the entire action space at each time step and estimate the\ncausal effect of each action to suppress redundant actions during exploration.\nWe provide a theoretical analysis to demonstrate the effectiveness of our\nmethod and present empirical results from simulations in environments with\nredundant actions to evaluate its performance. Our implementation is available\nat https://github.com/agi-brain/cee.git.\n", "link": "http://arxiv.org/abs/2501.14543v1", "date": "2025-01-24", "relevancy": 1.5397, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.5719}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5302}, {"title": "Genie: Generative Interactive Environments", "link": "http://arxiv.org/abs/2402.15391v1", "similarity": 0.483}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Reducing%20Action%20Space%20for%20Deep%20Reinforcement%20Learning%20via%20Causal%20Effect%0A%20%20Estimation&body=Title%3A%20Reducing%20Action%20Space%20for%20Deep%20Reinforcement%20Learning%20via%20Causal%20Effect%0A%20%20Estimation%0AAuthor%3A%20Wenzhang%20Liu%20and%20Lianjun%20Jin%20and%20Lu%20Ren%20and%20Chaoxu%20Mu%20and%20Changyin%20Sun%0AAbstract%3A%20%20%20Intelligent%20decision-making%20within%20large%20and%20redundant%20action%20spaces%20remains%0Achallenging%20in%20deep%20reinforcement%20learning.%20Considering%20similar%20but%20ineffective%0Aactions%20at%20each%20step%20can%20lead%20to%20repetitive%20and%20unproductive%20trials.%20Existing%0Amethods%20attempt%20to%20improve%20agent%20exploration%20by%20reducing%20or%20penalizing%0Aredundant%20actions%2C%20yet%20they%20fail%20to%20provide%20quantitative%20and%20reliable%20evidence%0Ato%20determine%20redundancy.%20In%20this%20paper%2C%20we%20propose%20a%20method%20to%20improve%0Aexploration%20efficiency%20by%20estimating%20the%20causal%20effects%20of%20actions.%20Unlike%0Aprior%20methods%2C%20our%20approach%20offers%20quantitative%20results%20regarding%20the%20causality%0Aof%20actions%20for%20one-step%20transitions.%20We%20first%20pre-train%20an%20inverse%20dynamics%0Amodel%20to%20serve%20as%20prior%20knowledge%20of%20the%20environment.%20Subsequently%2C%20we%20classify%0Aactions%20across%20the%20entire%20action%20space%20at%20each%20time%20step%20and%20estimate%20the%0Acausal%20effect%20of%20each%20action%20to%20suppress%20redundant%20actions%20during%20exploration.%0AWe%20provide%20a%20theoretical%20analysis%20to%20demonstrate%20the%20effectiveness%20of%20our%0Amethod%20and%20present%20empirical%20results%20from%20simulations%20in%20environments%20with%0Aredundant%20actions%20to%20evaluate%20its%20performance.%20Our%20implementation%20is%20available%0Aat%20https%3A//github.com/agi-brain/cee.git.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14543v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DReducing%2520Action%2520Space%2520for%2520Deep%2520Reinforcement%2520Learning%2520via%2520Causal%2520Effect%250A%2520%2520Estimation%26entry.906535625%3DWenzhang%2520Liu%2520and%2520Lianjun%2520Jin%2520and%2520Lu%2520Ren%2520and%2520Chaoxu%2520Mu%2520and%2520Changyin%2520Sun%26entry.1292438233%3D%2520%2520Intelligent%2520decision-making%2520within%2520large%2520and%2520redundant%2520action%2520spaces%2520remains%250Achallenging%2520in%2520deep%2520reinforcement%2520learning.%2520Considering%2520similar%2520but%2520ineffective%250Aactions%2520at%2520each%2520step%2520can%2520lead%2520to%2520repetitive%2520and%2520unproductive%2520trials.%2520Existing%250Amethods%2520attempt%2520to%2520improve%2520agent%2520exploration%2520by%2520reducing%2520or%2520penalizing%250Aredundant%2520actions%252C%2520yet%2520they%2520fail%2520to%2520provide%2520quantitative%2520and%2520reliable%2520evidence%250Ato%2520determine%2520redundancy.%2520In%2520this%2520paper%252C%2520we%2520propose%2520a%2520method%2520to%2520improve%250Aexploration%2520efficiency%2520by%2520estimating%2520the%2520causal%2520effects%2520of%2520actions.%2520Unlike%250Aprior%2520methods%252C%2520our%2520approach%2520offers%2520quantitative%2520results%2520regarding%2520the%2520causality%250Aof%2520actions%2520for%2520one-step%2520transitions.%2520We%2520first%2520pre-train%2520an%2520inverse%2520dynamics%250Amodel%2520to%2520serve%2520as%2520prior%2520knowledge%2520of%2520the%2520environment.%2520Subsequently%252C%2520we%2520classify%250Aactions%2520across%2520the%2520entire%2520action%2520space%2520at%2520each%2520time%2520step%2520and%2520estimate%2520the%250Acausal%2520effect%2520of%2520each%2520action%2520to%2520suppress%2520redundant%2520actions%2520during%2520exploration.%250AWe%2520provide%2520a%2520theoretical%2520analysis%2520to%2520demonstrate%2520the%2520effectiveness%2520of%2520our%250Amethod%2520and%2520present%2520empirical%2520results%2520from%2520simulations%2520in%2520environments%2520with%250Aredundant%2520actions%2520to%2520evaluate%2520its%2520performance.%2520Our%2520implementation%2520is%2520available%250Aat%2520https%253A//github.com/agi-brain/cee.git.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14543v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Reducing%20Action%20Space%20for%20Deep%20Reinforcement%20Learning%20via%20Causal%20Effect%0A%20%20Estimation&entry.906535625=Wenzhang%20Liu%20and%20Lianjun%20Jin%20and%20Lu%20Ren%20and%20Chaoxu%20Mu%20and%20Changyin%20Sun&entry.1292438233=%20%20Intelligent%20decision-making%20within%20large%20and%20redundant%20action%20spaces%20remains%0Achallenging%20in%20deep%20reinforcement%20learning.%20Considering%20similar%20but%20ineffective%0Aactions%20at%20each%20step%20can%20lead%20to%20repetitive%20and%20unproductive%20trials.%20Existing%0Amethods%20attempt%20to%20improve%20agent%20exploration%20by%20reducing%20or%20penalizing%0Aredundant%20actions%2C%20yet%20they%20fail%20to%20provide%20quantitative%20and%20reliable%20evidence%0Ato%20determine%20redundancy.%20In%20this%20paper%2C%20we%20propose%20a%20method%20to%20improve%0Aexploration%20efficiency%20by%20estimating%20the%20causal%20effects%20of%20actions.%20Unlike%0Aprior%20methods%2C%20our%20approach%20offers%20quantitative%20results%20regarding%20the%20causality%0Aof%20actions%20for%20one-step%20transitions.%20We%20first%20pre-train%20an%20inverse%20dynamics%0Amodel%20to%20serve%20as%20prior%20knowledge%20of%20the%20environment.%20Subsequently%2C%20we%20classify%0Aactions%20across%20the%20entire%20action%20space%20at%20each%20time%20step%20and%20estimate%20the%0Acausal%20effect%20of%20each%20action%20to%20suppress%20redundant%20actions%20during%20exploration.%0AWe%20provide%20a%20theoretical%20analysis%20to%20demonstrate%20the%20effectiveness%20of%20our%0Amethod%20and%20present%20empirical%20results%20from%20simulations%20in%20environments%20with%0Aredundant%20actions%20to%20evaluate%20its%20performance.%20Our%20implementation%20is%20available%0Aat%20https%3A//github.com/agi-brain/cee.git.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14543v1&entry.124074799=Read"},
{"title": "FlexiGPT: Pruning and Extending Large Language Models with Low-Rank\n  Weight Sharing", "author": "James Seale Smith and Chi-Heng Lin and Shikhar Tuli and Haris Jeelani and Shangqian Gao and Yilin Shen and Hongxia Jin and Yen-Chang Hsu", "abstract": "  The rapid proliferation of large language models (LLMs) in natural language\nprocessing (NLP) has created a critical need for techniques that enable\nefficient deployment on memory-constrained devices without compromising\nperformance. We present a method to prune LLMs that selectively prunes model\nblocks based on an importance score and replaces them with a low-parameter\nreplacement strategy. Specifically, we propose a principled metric to replace\neach pruned block using a weight-sharing mechanism that leverages unpruned\ncounterparts from the model and block-specific low-rank adapters. Furthermore,\nwe facilitate the learning of these replacement blocks with output feature\nnormalization and an adapter initialization scheme built on low-rank SVD\nreconstructions. Empirical evaluations demonstrate substantial performance\ngains over existing methods, achieving state-of-the-art performance on 5/6\nbenchmarks for a compression rate of 30% and 6/6 benchmarks for a compression\nrate of 40%. We also demonstrate that our approach can extend smaller models,\nboosting performance on 6/6 benchmarks using only ~0.3% tokens of extended\ntraining with minimal additional parameter costs.\n", "link": "http://arxiv.org/abs/2501.14713v1", "date": "2025-01-24", "relevancy": 1.5302, "topK": [{"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.5142}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.513}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4986}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20FlexiGPT%3A%20Pruning%20and%20Extending%20Large%20Language%20Models%20with%20Low-Rank%0A%20%20Weight%20Sharing&body=Title%3A%20FlexiGPT%3A%20Pruning%20and%20Extending%20Large%20Language%20Models%20with%20Low-Rank%0A%20%20Weight%20Sharing%0AAuthor%3A%20James%20Seale%20Smith%20and%20Chi-Heng%20Lin%20and%20Shikhar%20Tuli%20and%20Haris%20Jeelani%20and%20Shangqian%20Gao%20and%20Yilin%20Shen%20and%20Hongxia%20Jin%20and%20Yen-Chang%20Hsu%0AAbstract%3A%20%20%20The%20rapid%20proliferation%20of%20large%20language%20models%20%28LLMs%29%20in%20natural%20language%0Aprocessing%20%28NLP%29%20has%20created%20a%20critical%20need%20for%20techniques%20that%20enable%0Aefficient%20deployment%20on%20memory-constrained%20devices%20without%20compromising%0Aperformance.%20We%20present%20a%20method%20to%20prune%20LLMs%20that%20selectively%20prunes%20model%0Ablocks%20based%20on%20an%20importance%20score%20and%20replaces%20them%20with%20a%20low-parameter%0Areplacement%20strategy.%20Specifically%2C%20we%20propose%20a%20principled%20metric%20to%20replace%0Aeach%20pruned%20block%20using%20a%20weight-sharing%20mechanism%20that%20leverages%20unpruned%0Acounterparts%20from%20the%20model%20and%20block-specific%20low-rank%20adapters.%20Furthermore%2C%0Awe%20facilitate%20the%20learning%20of%20these%20replacement%20blocks%20with%20output%20feature%0Anormalization%20and%20an%20adapter%20initialization%20scheme%20built%20on%20low-rank%20SVD%0Areconstructions.%20Empirical%20evaluations%20demonstrate%20substantial%20performance%0Agains%20over%20existing%20methods%2C%20achieving%20state-of-the-art%20performance%20on%205/6%0Abenchmarks%20for%20a%20compression%20rate%20of%2030%25%20and%206/6%20benchmarks%20for%20a%20compression%0Arate%20of%2040%25.%20We%20also%20demonstrate%20that%20our%20approach%20can%20extend%20smaller%20models%2C%0Aboosting%20performance%20on%206/6%20benchmarks%20using%20only%20~0.3%25%20tokens%20of%20extended%0Atraining%20with%20minimal%20additional%20parameter%20costs.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14713v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DFlexiGPT%253A%2520Pruning%2520and%2520Extending%2520Large%2520Language%2520Models%2520with%2520Low-Rank%250A%2520%2520Weight%2520Sharing%26entry.906535625%3DJames%2520Seale%2520Smith%2520and%2520Chi-Heng%2520Lin%2520and%2520Shikhar%2520Tuli%2520and%2520Haris%2520Jeelani%2520and%2520Shangqian%2520Gao%2520and%2520Yilin%2520Shen%2520and%2520Hongxia%2520Jin%2520and%2520Yen-Chang%2520Hsu%26entry.1292438233%3D%2520%2520The%2520rapid%2520proliferation%2520of%2520large%2520language%2520models%2520%2528LLMs%2529%2520in%2520natural%2520language%250Aprocessing%2520%2528NLP%2529%2520has%2520created%2520a%2520critical%2520need%2520for%2520techniques%2520that%2520enable%250Aefficient%2520deployment%2520on%2520memory-constrained%2520devices%2520without%2520compromising%250Aperformance.%2520We%2520present%2520a%2520method%2520to%2520prune%2520LLMs%2520that%2520selectively%2520prunes%2520model%250Ablocks%2520based%2520on%2520an%2520importance%2520score%2520and%2520replaces%2520them%2520with%2520a%2520low-parameter%250Areplacement%2520strategy.%2520Specifically%252C%2520we%2520propose%2520a%2520principled%2520metric%2520to%2520replace%250Aeach%2520pruned%2520block%2520using%2520a%2520weight-sharing%2520mechanism%2520that%2520leverages%2520unpruned%250Acounterparts%2520from%2520the%2520model%2520and%2520block-specific%2520low-rank%2520adapters.%2520Furthermore%252C%250Awe%2520facilitate%2520the%2520learning%2520of%2520these%2520replacement%2520blocks%2520with%2520output%2520feature%250Anormalization%2520and%2520an%2520adapter%2520initialization%2520scheme%2520built%2520on%2520low-rank%2520SVD%250Areconstructions.%2520Empirical%2520evaluations%2520demonstrate%2520substantial%2520performance%250Agains%2520over%2520existing%2520methods%252C%2520achieving%2520state-of-the-art%2520performance%2520on%25205/6%250Abenchmarks%2520for%2520a%2520compression%2520rate%2520of%252030%2525%2520and%25206/6%2520benchmarks%2520for%2520a%2520compression%250Arate%2520of%252040%2525.%2520We%2520also%2520demonstrate%2520that%2520our%2520approach%2520can%2520extend%2520smaller%2520models%252C%250Aboosting%2520performance%2520on%25206/6%2520benchmarks%2520using%2520only%2520~0.3%2525%2520tokens%2520of%2520extended%250Atraining%2520with%2520minimal%2520additional%2520parameter%2520costs.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14713v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=FlexiGPT%3A%20Pruning%20and%20Extending%20Large%20Language%20Models%20with%20Low-Rank%0A%20%20Weight%20Sharing&entry.906535625=James%20Seale%20Smith%20and%20Chi-Heng%20Lin%20and%20Shikhar%20Tuli%20and%20Haris%20Jeelani%20and%20Shangqian%20Gao%20and%20Yilin%20Shen%20and%20Hongxia%20Jin%20and%20Yen-Chang%20Hsu&entry.1292438233=%20%20The%20rapid%20proliferation%20of%20large%20language%20models%20%28LLMs%29%20in%20natural%20language%0Aprocessing%20%28NLP%29%20has%20created%20a%20critical%20need%20for%20techniques%20that%20enable%0Aefficient%20deployment%20on%20memory-constrained%20devices%20without%20compromising%0Aperformance.%20We%20present%20a%20method%20to%20prune%20LLMs%20that%20selectively%20prunes%20model%0Ablocks%20based%20on%20an%20importance%20score%20and%20replaces%20them%20with%20a%20low-parameter%0Areplacement%20strategy.%20Specifically%2C%20we%20propose%20a%20principled%20metric%20to%20replace%0Aeach%20pruned%20block%20using%20a%20weight-sharing%20mechanism%20that%20leverages%20unpruned%0Acounterparts%20from%20the%20model%20and%20block-specific%20low-rank%20adapters.%20Furthermore%2C%0Awe%20facilitate%20the%20learning%20of%20these%20replacement%20blocks%20with%20output%20feature%0Anormalization%20and%20an%20adapter%20initialization%20scheme%20built%20on%20low-rank%20SVD%0Areconstructions.%20Empirical%20evaluations%20demonstrate%20substantial%20performance%0Agains%20over%20existing%20methods%2C%20achieving%20state-of-the-art%20performance%20on%205/6%0Abenchmarks%20for%20a%20compression%20rate%20of%2030%25%20and%206/6%20benchmarks%20for%20a%20compression%0Arate%20of%2040%25.%20We%20also%20demonstrate%20that%20our%20approach%20can%20extend%20smaller%20models%2C%0Aboosting%20performance%20on%206/6%20benchmarks%20using%20only%20~0.3%25%20tokens%20of%20extended%0Atraining%20with%20minimal%20additional%20parameter%20costs.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14713v1&entry.124074799=Read"},
{"title": "Recommending Actionable Strategies: A Semantic Approach to Integrating\n  Analytical Frameworks with Decision Heuristics", "author": "Renato Ghisellini and Remo Pareschi and Marco Pedroni and Giovanni Battista Raggi", "abstract": "  We present a novel approach for recommending actionable strategies by\nintegrating strategic frameworks with decision heuristics through semantic\nanalysis. While strategy frameworks provide systematic models for assessment\nand planning, and decision heuristics encode experiential knowledge,these\ntraditions have historically remained separate. Our methodology bridges this\ngap using advanced natural language processing (NLP), demonstrated through\nintegrating frameworks like the 6C model with the Thirty-Six Stratagems. The\napproach employs vector space representations and semantic similarity\ncalculations to map framework parameters to heuristic patterns, supported by a\ncomputational architecture that combines deep semantic processing with\nconstrained use of Large Language Models. By processing both primary content\nand secondary elements (diagrams, matrices) as complementary linguistic\nrepresentations, we demonstrate effectiveness through corporate strategy case\nstudies. The methodology generalizes to various analytical frameworks and\nheuristic sets, culminating in a plug-and-play architecture for generating\nrecommender systems that enable cohesive integration of strategic frameworks\nand decision heuristics into actionable guidance.\n", "link": "http://arxiv.org/abs/2501.14634v1", "date": "2025-01-24", "relevancy": 1.4924, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5195}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4949}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4897}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Recommending%20Actionable%20Strategies%3A%20A%20Semantic%20Approach%20to%20Integrating%0A%20%20Analytical%20Frameworks%20with%20Decision%20Heuristics&body=Title%3A%20Recommending%20Actionable%20Strategies%3A%20A%20Semantic%20Approach%20to%20Integrating%0A%20%20Analytical%20Frameworks%20with%20Decision%20Heuristics%0AAuthor%3A%20Renato%20Ghisellini%20and%20Remo%20Pareschi%20and%20Marco%20Pedroni%20and%20Giovanni%20Battista%20Raggi%0AAbstract%3A%20%20%20We%20present%20a%20novel%20approach%20for%20recommending%20actionable%20strategies%20by%0Aintegrating%20strategic%20frameworks%20with%20decision%20heuristics%20through%20semantic%0Aanalysis.%20While%20strategy%20frameworks%20provide%20systematic%20models%20for%20assessment%0Aand%20planning%2C%20and%20decision%20heuristics%20encode%20experiential%20knowledge%2Cthese%0Atraditions%20have%20historically%20remained%20separate.%20Our%20methodology%20bridges%20this%0Agap%20using%20advanced%20natural%20language%20processing%20%28NLP%29%2C%20demonstrated%20through%0Aintegrating%20frameworks%20like%20the%206C%20model%20with%20the%20Thirty-Six%20Stratagems.%20The%0Aapproach%20employs%20vector%20space%20representations%20and%20semantic%20similarity%0Acalculations%20to%20map%20framework%20parameters%20to%20heuristic%20patterns%2C%20supported%20by%20a%0Acomputational%20architecture%20that%20combines%20deep%20semantic%20processing%20with%0Aconstrained%20use%20of%20Large%20Language%20Models.%20By%20processing%20both%20primary%20content%0Aand%20secondary%20elements%20%28diagrams%2C%20matrices%29%20as%20complementary%20linguistic%0Arepresentations%2C%20we%20demonstrate%20effectiveness%20through%20corporate%20strategy%20case%0Astudies.%20The%20methodology%20generalizes%20to%20various%20analytical%20frameworks%20and%0Aheuristic%20sets%2C%20culminating%20in%20a%20plug-and-play%20architecture%20for%20generating%0Arecommender%20systems%20that%20enable%20cohesive%20integration%20of%20strategic%20frameworks%0Aand%20decision%20heuristics%20into%20actionable%20guidance.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14634v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DRecommending%2520Actionable%2520Strategies%253A%2520A%2520Semantic%2520Approach%2520to%2520Integrating%250A%2520%2520Analytical%2520Frameworks%2520with%2520Decision%2520Heuristics%26entry.906535625%3DRenato%2520Ghisellini%2520and%2520Remo%2520Pareschi%2520and%2520Marco%2520Pedroni%2520and%2520Giovanni%2520Battista%2520Raggi%26entry.1292438233%3D%2520%2520We%2520present%2520a%2520novel%2520approach%2520for%2520recommending%2520actionable%2520strategies%2520by%250Aintegrating%2520strategic%2520frameworks%2520with%2520decision%2520heuristics%2520through%2520semantic%250Aanalysis.%2520While%2520strategy%2520frameworks%2520provide%2520systematic%2520models%2520for%2520assessment%250Aand%2520planning%252C%2520and%2520decision%2520heuristics%2520encode%2520experiential%2520knowledge%252Cthese%250Atraditions%2520have%2520historically%2520remained%2520separate.%2520Our%2520methodology%2520bridges%2520this%250Agap%2520using%2520advanced%2520natural%2520language%2520processing%2520%2528NLP%2529%252C%2520demonstrated%2520through%250Aintegrating%2520frameworks%2520like%2520the%25206C%2520model%2520with%2520the%2520Thirty-Six%2520Stratagems.%2520The%250Aapproach%2520employs%2520vector%2520space%2520representations%2520and%2520semantic%2520similarity%250Acalculations%2520to%2520map%2520framework%2520parameters%2520to%2520heuristic%2520patterns%252C%2520supported%2520by%2520a%250Acomputational%2520architecture%2520that%2520combines%2520deep%2520semantic%2520processing%2520with%250Aconstrained%2520use%2520of%2520Large%2520Language%2520Models.%2520By%2520processing%2520both%2520primary%2520content%250Aand%2520secondary%2520elements%2520%2528diagrams%252C%2520matrices%2529%2520as%2520complementary%2520linguistic%250Arepresentations%252C%2520we%2520demonstrate%2520effectiveness%2520through%2520corporate%2520strategy%2520case%250Astudies.%2520The%2520methodology%2520generalizes%2520to%2520various%2520analytical%2520frameworks%2520and%250Aheuristic%2520sets%252C%2520culminating%2520in%2520a%2520plug-and-play%2520architecture%2520for%2520generating%250Arecommender%2520systems%2520that%2520enable%2520cohesive%2520integration%2520of%2520strategic%2520frameworks%250Aand%2520decision%2520heuristics%2520into%2520actionable%2520guidance.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14634v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Recommending%20Actionable%20Strategies%3A%20A%20Semantic%20Approach%20to%20Integrating%0A%20%20Analytical%20Frameworks%20with%20Decision%20Heuristics&entry.906535625=Renato%20Ghisellini%20and%20Remo%20Pareschi%20and%20Marco%20Pedroni%20and%20Giovanni%20Battista%20Raggi&entry.1292438233=%20%20We%20present%20a%20novel%20approach%20for%20recommending%20actionable%20strategies%20by%0Aintegrating%20strategic%20frameworks%20with%20decision%20heuristics%20through%20semantic%0Aanalysis.%20While%20strategy%20frameworks%20provide%20systematic%20models%20for%20assessment%0Aand%20planning%2C%20and%20decision%20heuristics%20encode%20experiential%20knowledge%2Cthese%0Atraditions%20have%20historically%20remained%20separate.%20Our%20methodology%20bridges%20this%0Agap%20using%20advanced%20natural%20language%20processing%20%28NLP%29%2C%20demonstrated%20through%0Aintegrating%20frameworks%20like%20the%206C%20model%20with%20the%20Thirty-Six%20Stratagems.%20The%0Aapproach%20employs%20vector%20space%20representations%20and%20semantic%20similarity%0Acalculations%20to%20map%20framework%20parameters%20to%20heuristic%20patterns%2C%20supported%20by%20a%0Acomputational%20architecture%20that%20combines%20deep%20semantic%20processing%20with%0Aconstrained%20use%20of%20Large%20Language%20Models.%20By%20processing%20both%20primary%20content%0Aand%20secondary%20elements%20%28diagrams%2C%20matrices%29%20as%20complementary%20linguistic%0Arepresentations%2C%20we%20demonstrate%20effectiveness%20through%20corporate%20strategy%20case%0Astudies.%20The%20methodology%20generalizes%20to%20various%20analytical%20frameworks%20and%0Aheuristic%20sets%2C%20culminating%20in%20a%20plug-and-play%20architecture%20for%20generating%0Arecommender%20systems%20that%20enable%20cohesive%20integration%20of%20strategic%20frameworks%0Aand%20decision%20heuristics%20into%20actionable%20guidance.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14634v1&entry.124074799=Read"},
{"title": "Inverse Evolution Data Augmentation for Neural PDE Solvers", "author": "Chaoyu Liu and Chris Budd and Carola-Bibiane Sch\u00f6nlieb", "abstract": "  Neural networks have emerged as promising tools for solving partial\ndifferential equations (PDEs), particularly through the application of neural\noperators. Training neural operators typically requires a large amount of\ntraining data to ensure accuracy and generalization. In this paper, we propose\na novel data augmentation method specifically designed for training neural\noperators on evolution equations. Our approach utilizes insights from inverse\nprocesses of these equations to efficiently generate data from random\ninitialization that are combined with original data. To further enhance the\naccuracy of the augmented data, we introduce high-order inverse evolution\nschemes. These schemes consist of only a few explicit computation steps, yet\nthe resulting data pairs can be proven to satisfy the corresponding implicit\nnumerical schemes. In contrast to traditional PDE solvers that require small\ntime steps or implicit schemes to guarantee accuracy, our data augmentation\nmethod employs explicit schemes with relatively large time steps, thereby\nsignificantly reducing computational costs. Accuracy and efficacy experiments\nconfirm the effectiveness of our approach. Additionally, we validate our\napproach through experiments with the Fourier Neural Operator and UNet on three\ncommon evolution equations that are Burgers' equation, the Allen-Cahn equation\nand the Navier-Stokes equation. The results demonstrate a significant\nimprovement in the performance and robustness of the Fourier Neural Operator\nwhen coupled with our inverse evolution data augmentation method.\n", "link": "http://arxiv.org/abs/2501.14604v1", "date": "2025-01-24", "relevancy": 1.4903, "topK": [{"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.5027}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4955}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4834}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Inverse%20Evolution%20Data%20Augmentation%20for%20Neural%20PDE%20Solvers&body=Title%3A%20Inverse%20Evolution%20Data%20Augmentation%20for%20Neural%20PDE%20Solvers%0AAuthor%3A%20Chaoyu%20Liu%20and%20Chris%20Budd%20and%20Carola-Bibiane%20Sch%C3%B6nlieb%0AAbstract%3A%20%20%20Neural%20networks%20have%20emerged%20as%20promising%20tools%20for%20solving%20partial%0Adifferential%20equations%20%28PDEs%29%2C%20particularly%20through%20the%20application%20of%20neural%0Aoperators.%20Training%20neural%20operators%20typically%20requires%20a%20large%20amount%20of%0Atraining%20data%20to%20ensure%20accuracy%20and%20generalization.%20In%20this%20paper%2C%20we%20propose%0Aa%20novel%20data%20augmentation%20method%20specifically%20designed%20for%20training%20neural%0Aoperators%20on%20evolution%20equations.%20Our%20approach%20utilizes%20insights%20from%20inverse%0Aprocesses%20of%20these%20equations%20to%20efficiently%20generate%20data%20from%20random%0Ainitialization%20that%20are%20combined%20with%20original%20data.%20To%20further%20enhance%20the%0Aaccuracy%20of%20the%20augmented%20data%2C%20we%20introduce%20high-order%20inverse%20evolution%0Aschemes.%20These%20schemes%20consist%20of%20only%20a%20few%20explicit%20computation%20steps%2C%20yet%0Athe%20resulting%20data%20pairs%20can%20be%20proven%20to%20satisfy%20the%20corresponding%20implicit%0Anumerical%20schemes.%20In%20contrast%20to%20traditional%20PDE%20solvers%20that%20require%20small%0Atime%20steps%20or%20implicit%20schemes%20to%20guarantee%20accuracy%2C%20our%20data%20augmentation%0Amethod%20employs%20explicit%20schemes%20with%20relatively%20large%20time%20steps%2C%20thereby%0Asignificantly%20reducing%20computational%20costs.%20Accuracy%20and%20efficacy%20experiments%0Aconfirm%20the%20effectiveness%20of%20our%20approach.%20Additionally%2C%20we%20validate%20our%0Aapproach%20through%20experiments%20with%20the%20Fourier%20Neural%20Operator%20and%20UNet%20on%20three%0Acommon%20evolution%20equations%20that%20are%20Burgers%27%20equation%2C%20the%20Allen-Cahn%20equation%0Aand%20the%20Navier-Stokes%20equation.%20The%20results%20demonstrate%20a%20significant%0Aimprovement%20in%20the%20performance%20and%20robustness%20of%20the%20Fourier%20Neural%20Operator%0Awhen%20coupled%20with%20our%20inverse%20evolution%20data%20augmentation%20method.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14604v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DInverse%2520Evolution%2520Data%2520Augmentation%2520for%2520Neural%2520PDE%2520Solvers%26entry.906535625%3DChaoyu%2520Liu%2520and%2520Chris%2520Budd%2520and%2520Carola-Bibiane%2520Sch%25C3%25B6nlieb%26entry.1292438233%3D%2520%2520Neural%2520networks%2520have%2520emerged%2520as%2520promising%2520tools%2520for%2520solving%2520partial%250Adifferential%2520equations%2520%2528PDEs%2529%252C%2520particularly%2520through%2520the%2520application%2520of%2520neural%250Aoperators.%2520Training%2520neural%2520operators%2520typically%2520requires%2520a%2520large%2520amount%2520of%250Atraining%2520data%2520to%2520ensure%2520accuracy%2520and%2520generalization.%2520In%2520this%2520paper%252C%2520we%2520propose%250Aa%2520novel%2520data%2520augmentation%2520method%2520specifically%2520designed%2520for%2520training%2520neural%250Aoperators%2520on%2520evolution%2520equations.%2520Our%2520approach%2520utilizes%2520insights%2520from%2520inverse%250Aprocesses%2520of%2520these%2520equations%2520to%2520efficiently%2520generate%2520data%2520from%2520random%250Ainitialization%2520that%2520are%2520combined%2520with%2520original%2520data.%2520To%2520further%2520enhance%2520the%250Aaccuracy%2520of%2520the%2520augmented%2520data%252C%2520we%2520introduce%2520high-order%2520inverse%2520evolution%250Aschemes.%2520These%2520schemes%2520consist%2520of%2520only%2520a%2520few%2520explicit%2520computation%2520steps%252C%2520yet%250Athe%2520resulting%2520data%2520pairs%2520can%2520be%2520proven%2520to%2520satisfy%2520the%2520corresponding%2520implicit%250Anumerical%2520schemes.%2520In%2520contrast%2520to%2520traditional%2520PDE%2520solvers%2520that%2520require%2520small%250Atime%2520steps%2520or%2520implicit%2520schemes%2520to%2520guarantee%2520accuracy%252C%2520our%2520data%2520augmentation%250Amethod%2520employs%2520explicit%2520schemes%2520with%2520relatively%2520large%2520time%2520steps%252C%2520thereby%250Asignificantly%2520reducing%2520computational%2520costs.%2520Accuracy%2520and%2520efficacy%2520experiments%250Aconfirm%2520the%2520effectiveness%2520of%2520our%2520approach.%2520Additionally%252C%2520we%2520validate%2520our%250Aapproach%2520through%2520experiments%2520with%2520the%2520Fourier%2520Neural%2520Operator%2520and%2520UNet%2520on%2520three%250Acommon%2520evolution%2520equations%2520that%2520are%2520Burgers%2527%2520equation%252C%2520the%2520Allen-Cahn%2520equation%250Aand%2520the%2520Navier-Stokes%2520equation.%2520The%2520results%2520demonstrate%2520a%2520significant%250Aimprovement%2520in%2520the%2520performance%2520and%2520robustness%2520of%2520the%2520Fourier%2520Neural%2520Operator%250Awhen%2520coupled%2520with%2520our%2520inverse%2520evolution%2520data%2520augmentation%2520method.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14604v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Inverse%20Evolution%20Data%20Augmentation%20for%20Neural%20PDE%20Solvers&entry.906535625=Chaoyu%20Liu%20and%20Chris%20Budd%20and%20Carola-Bibiane%20Sch%C3%B6nlieb&entry.1292438233=%20%20Neural%20networks%20have%20emerged%20as%20promising%20tools%20for%20solving%20partial%0Adifferential%20equations%20%28PDEs%29%2C%20particularly%20through%20the%20application%20of%20neural%0Aoperators.%20Training%20neural%20operators%20typically%20requires%20a%20large%20amount%20of%0Atraining%20data%20to%20ensure%20accuracy%20and%20generalization.%20In%20this%20paper%2C%20we%20propose%0Aa%20novel%20data%20augmentation%20method%20specifically%20designed%20for%20training%20neural%0Aoperators%20on%20evolution%20equations.%20Our%20approach%20utilizes%20insights%20from%20inverse%0Aprocesses%20of%20these%20equations%20to%20efficiently%20generate%20data%20from%20random%0Ainitialization%20that%20are%20combined%20with%20original%20data.%20To%20further%20enhance%20the%0Aaccuracy%20of%20the%20augmented%20data%2C%20we%20introduce%20high-order%20inverse%20evolution%0Aschemes.%20These%20schemes%20consist%20of%20only%20a%20few%20explicit%20computation%20steps%2C%20yet%0Athe%20resulting%20data%20pairs%20can%20be%20proven%20to%20satisfy%20the%20corresponding%20implicit%0Anumerical%20schemes.%20In%20contrast%20to%20traditional%20PDE%20solvers%20that%20require%20small%0Atime%20steps%20or%20implicit%20schemes%20to%20guarantee%20accuracy%2C%20our%20data%20augmentation%0Amethod%20employs%20explicit%20schemes%20with%20relatively%20large%20time%20steps%2C%20thereby%0Asignificantly%20reducing%20computational%20costs.%20Accuracy%20and%20efficacy%20experiments%0Aconfirm%20the%20effectiveness%20of%20our%20approach.%20Additionally%2C%20we%20validate%20our%0Aapproach%20through%20experiments%20with%20the%20Fourier%20Neural%20Operator%20and%20UNet%20on%20three%0Acommon%20evolution%20equations%20that%20are%20Burgers%27%20equation%2C%20the%20Allen-Cahn%20equation%0Aand%20the%20Navier-Stokes%20equation.%20The%20results%20demonstrate%20a%20significant%0Aimprovement%20in%20the%20performance%20and%20robustness%20of%20the%20Fourier%20Neural%20Operator%0Awhen%20coupled%20with%20our%20inverse%20evolution%20data%20augmentation%20method.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14604v1&entry.124074799=Read"},
{"title": "On Hardening DNNs against Noisy Computations", "author": "Xiao Wang and Hendrik Borras and Bernhard Klein and Holger Fr\u00f6ning", "abstract": "  The success of deep learning has sparked significant interest in designing\ncomputer hardware optimized for the high computational demands of neural\nnetwork inference. As further miniaturization of digital CMOS processors\nbecomes increasingly challenging, alternative computing paradigms, such as\nanalog computing, are gaining consideration. Particularly for compute-intensive\ntasks such as matrix multiplication, analog computing presents a promising\nalternative due to its potential for significantly higher energy efficiency\ncompared to conventional digital technology. However, analog computations are\ninherently noisy, which makes it challenging to maintain high accuracy on deep\nneural networks. This work investigates the effectiveness of training neural\nnetworks with quantization to increase the robustness against noise.\nExperimental results across various network architectures show that\nquantization-aware training with constant scaling factors enhances robustness.\nWe compare these methods with noisy training, which incorporates a noise\ninjection during training that mimics the noise encountered during inference.\nWhile both two methods increase tolerance against noise, noisy training emerges\nas the superior approach for achieving robust neural network performance,\nespecially in complex neural architectures.\n", "link": "http://arxiv.org/abs/2501.14531v1", "date": "2025-01-24", "relevancy": 1.4865, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4994}, {"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4977}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.486}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20On%20Hardening%20DNNs%20against%20Noisy%20Computations&body=Title%3A%20On%20Hardening%20DNNs%20against%20Noisy%20Computations%0AAuthor%3A%20Xiao%20Wang%20and%20Hendrik%20Borras%20and%20Bernhard%20Klein%20and%20Holger%20Fr%C3%B6ning%0AAbstract%3A%20%20%20The%20success%20of%20deep%20learning%20has%20sparked%20significant%20interest%20in%20designing%0Acomputer%20hardware%20optimized%20for%20the%20high%20computational%20demands%20of%20neural%0Anetwork%20inference.%20As%20further%20miniaturization%20of%20digital%20CMOS%20processors%0Abecomes%20increasingly%20challenging%2C%20alternative%20computing%20paradigms%2C%20such%20as%0Aanalog%20computing%2C%20are%20gaining%20consideration.%20Particularly%20for%20compute-intensive%0Atasks%20such%20as%20matrix%20multiplication%2C%20analog%20computing%20presents%20a%20promising%0Aalternative%20due%20to%20its%20potential%20for%20significantly%20higher%20energy%20efficiency%0Acompared%20to%20conventional%20digital%20technology.%20However%2C%20analog%20computations%20are%0Ainherently%20noisy%2C%20which%20makes%20it%20challenging%20to%20maintain%20high%20accuracy%20on%20deep%0Aneural%20networks.%20This%20work%20investigates%20the%20effectiveness%20of%20training%20neural%0Anetworks%20with%20quantization%20to%20increase%20the%20robustness%20against%20noise.%0AExperimental%20results%20across%20various%20network%20architectures%20show%20that%0Aquantization-aware%20training%20with%20constant%20scaling%20factors%20enhances%20robustness.%0AWe%20compare%20these%20methods%20with%20noisy%20training%2C%20which%20incorporates%20a%20noise%0Ainjection%20during%20training%20that%20mimics%20the%20noise%20encountered%20during%20inference.%0AWhile%20both%20two%20methods%20increase%20tolerance%20against%20noise%2C%20noisy%20training%20emerges%0Aas%20the%20superior%20approach%20for%20achieving%20robust%20neural%20network%20performance%2C%0Aespecially%20in%20complex%20neural%20architectures.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14531v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DOn%2520Hardening%2520DNNs%2520against%2520Noisy%2520Computations%26entry.906535625%3DXiao%2520Wang%2520and%2520Hendrik%2520Borras%2520and%2520Bernhard%2520Klein%2520and%2520Holger%2520Fr%25C3%25B6ning%26entry.1292438233%3D%2520%2520The%2520success%2520of%2520deep%2520learning%2520has%2520sparked%2520significant%2520interest%2520in%2520designing%250Acomputer%2520hardware%2520optimized%2520for%2520the%2520high%2520computational%2520demands%2520of%2520neural%250Anetwork%2520inference.%2520As%2520further%2520miniaturization%2520of%2520digital%2520CMOS%2520processors%250Abecomes%2520increasingly%2520challenging%252C%2520alternative%2520computing%2520paradigms%252C%2520such%2520as%250Aanalog%2520computing%252C%2520are%2520gaining%2520consideration.%2520Particularly%2520for%2520compute-intensive%250Atasks%2520such%2520as%2520matrix%2520multiplication%252C%2520analog%2520computing%2520presents%2520a%2520promising%250Aalternative%2520due%2520to%2520its%2520potential%2520for%2520significantly%2520higher%2520energy%2520efficiency%250Acompared%2520to%2520conventional%2520digital%2520technology.%2520However%252C%2520analog%2520computations%2520are%250Ainherently%2520noisy%252C%2520which%2520makes%2520it%2520challenging%2520to%2520maintain%2520high%2520accuracy%2520on%2520deep%250Aneural%2520networks.%2520This%2520work%2520investigates%2520the%2520effectiveness%2520of%2520training%2520neural%250Anetworks%2520with%2520quantization%2520to%2520increase%2520the%2520robustness%2520against%2520noise.%250AExperimental%2520results%2520across%2520various%2520network%2520architectures%2520show%2520that%250Aquantization-aware%2520training%2520with%2520constant%2520scaling%2520factors%2520enhances%2520robustness.%250AWe%2520compare%2520these%2520methods%2520with%2520noisy%2520training%252C%2520which%2520incorporates%2520a%2520noise%250Ainjection%2520during%2520training%2520that%2520mimics%2520the%2520noise%2520encountered%2520during%2520inference.%250AWhile%2520both%2520two%2520methods%2520increase%2520tolerance%2520against%2520noise%252C%2520noisy%2520training%2520emerges%250Aas%2520the%2520superior%2520approach%2520for%2520achieving%2520robust%2520neural%2520network%2520performance%252C%250Aespecially%2520in%2520complex%2520neural%2520architectures.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14531v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=On%20Hardening%20DNNs%20against%20Noisy%20Computations&entry.906535625=Xiao%20Wang%20and%20Hendrik%20Borras%20and%20Bernhard%20Klein%20and%20Holger%20Fr%C3%B6ning&entry.1292438233=%20%20The%20success%20of%20deep%20learning%20has%20sparked%20significant%20interest%20in%20designing%0Acomputer%20hardware%20optimized%20for%20the%20high%20computational%20demands%20of%20neural%0Anetwork%20inference.%20As%20further%20miniaturization%20of%20digital%20CMOS%20processors%0Abecomes%20increasingly%20challenging%2C%20alternative%20computing%20paradigms%2C%20such%20as%0Aanalog%20computing%2C%20are%20gaining%20consideration.%20Particularly%20for%20compute-intensive%0Atasks%20such%20as%20matrix%20multiplication%2C%20analog%20computing%20presents%20a%20promising%0Aalternative%20due%20to%20its%20potential%20for%20significantly%20higher%20energy%20efficiency%0Acompared%20to%20conventional%20digital%20technology.%20However%2C%20analog%20computations%20are%0Ainherently%20noisy%2C%20which%20makes%20it%20challenging%20to%20maintain%20high%20accuracy%20on%20deep%0Aneural%20networks.%20This%20work%20investigates%20the%20effectiveness%20of%20training%20neural%0Anetworks%20with%20quantization%20to%20increase%20the%20robustness%20against%20noise.%0AExperimental%20results%20across%20various%20network%20architectures%20show%20that%0Aquantization-aware%20training%20with%20constant%20scaling%20factors%20enhances%20robustness.%0AWe%20compare%20these%20methods%20with%20noisy%20training%2C%20which%20incorporates%20a%20noise%0Ainjection%20during%20training%20that%20mimics%20the%20noise%20encountered%20during%20inference.%0AWhile%20both%20two%20methods%20increase%20tolerance%20against%20noise%2C%20noisy%20training%20emerges%0Aas%20the%20superior%20approach%20for%20achieving%20robust%20neural%20network%20performance%2C%0Aespecially%20in%20complex%20neural%20architectures.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14531v1&entry.124074799=Read"},
{"title": "Hybrid Quantum-Classical Multi-Agent Pathfinding", "author": "Thore Gerlach and Loong Kuan Lee and Fr\u00e9d\u00e9ric Barbaresco and Nico Piatkowski", "abstract": "  Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths\nfor multiple agents navigating through a shared space to reach specified goal\nlocations. This problem becomes computationally challenging, particularly when\nhandling large numbers of agents, as frequently encountered in practical\napplications like coordinating autonomous vehicles. Quantum computing (QC) is a\npromising candidate in overcoming such limits. However, current quantum\nhardware is still in its infancy and thus limited in terms of computing power\nand error robustness. In this work, we present the first optimal hybrid\nquantum-classical MAPF algorithm which is based on branch-and-cut-and-prize. QC\nis integrated by iteratively solving QUBO problems, based on conflict graphs.\nExperiments on actual quantum hardware and results on benchmark data suggest\nthat our approach dominates previous QUBO formulations and baseline MAPF\nsolvers.\n", "link": "http://arxiv.org/abs/2501.14568v1", "date": "2025-01-24", "relevancy": 1.4664, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5359}, {"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.4828}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4568}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Hybrid%20Quantum-Classical%20Multi-Agent%20Pathfinding&body=Title%3A%20Hybrid%20Quantum-Classical%20Multi-Agent%20Pathfinding%0AAuthor%3A%20Thore%20Gerlach%20and%20Loong%20Kuan%20Lee%20and%20Fr%C3%A9d%C3%A9ric%20Barbaresco%20and%20Nico%20Piatkowski%0AAbstract%3A%20%20%20Multi-Agent%20Path%20Finding%20%28MAPF%29%20focuses%20on%20determining%20conflict-free%20paths%0Afor%20multiple%20agents%20navigating%20through%20a%20shared%20space%20to%20reach%20specified%20goal%0Alocations.%20This%20problem%20becomes%20computationally%20challenging%2C%20particularly%20when%0Ahandling%20large%20numbers%20of%20agents%2C%20as%20frequently%20encountered%20in%20practical%0Aapplications%20like%20coordinating%20autonomous%20vehicles.%20Quantum%20computing%20%28QC%29%20is%20a%0Apromising%20candidate%20in%20overcoming%20such%20limits.%20However%2C%20current%20quantum%0Ahardware%20is%20still%20in%20its%20infancy%20and%20thus%20limited%20in%20terms%20of%20computing%20power%0Aand%20error%20robustness.%20In%20this%20work%2C%20we%20present%20the%20first%20optimal%20hybrid%0Aquantum-classical%20MAPF%20algorithm%20which%20is%20based%20on%20branch-and-cut-and-prize.%20QC%0Ais%20integrated%20by%20iteratively%20solving%20QUBO%20problems%2C%20based%20on%20conflict%20graphs.%0AExperiments%20on%20actual%20quantum%20hardware%20and%20results%20on%20benchmark%20data%20suggest%0Athat%20our%20approach%20dominates%20previous%20QUBO%20formulations%20and%20baseline%20MAPF%0Asolvers.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14568v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DHybrid%2520Quantum-Classical%2520Multi-Agent%2520Pathfinding%26entry.906535625%3DThore%2520Gerlach%2520and%2520Loong%2520Kuan%2520Lee%2520and%2520Fr%25C3%25A9d%25C3%25A9ric%2520Barbaresco%2520and%2520Nico%2520Piatkowski%26entry.1292438233%3D%2520%2520Multi-Agent%2520Path%2520Finding%2520%2528MAPF%2529%2520focuses%2520on%2520determining%2520conflict-free%2520paths%250Afor%2520multiple%2520agents%2520navigating%2520through%2520a%2520shared%2520space%2520to%2520reach%2520specified%2520goal%250Alocations.%2520This%2520problem%2520becomes%2520computationally%2520challenging%252C%2520particularly%2520when%250Ahandling%2520large%2520numbers%2520of%2520agents%252C%2520as%2520frequently%2520encountered%2520in%2520practical%250Aapplications%2520like%2520coordinating%2520autonomous%2520vehicles.%2520Quantum%2520computing%2520%2528QC%2529%2520is%2520a%250Apromising%2520candidate%2520in%2520overcoming%2520such%2520limits.%2520However%252C%2520current%2520quantum%250Ahardware%2520is%2520still%2520in%2520its%2520infancy%2520and%2520thus%2520limited%2520in%2520terms%2520of%2520computing%2520power%250Aand%2520error%2520robustness.%2520In%2520this%2520work%252C%2520we%2520present%2520the%2520first%2520optimal%2520hybrid%250Aquantum-classical%2520MAPF%2520algorithm%2520which%2520is%2520based%2520on%2520branch-and-cut-and-prize.%2520QC%250Ais%2520integrated%2520by%2520iteratively%2520solving%2520QUBO%2520problems%252C%2520based%2520on%2520conflict%2520graphs.%250AExperiments%2520on%2520actual%2520quantum%2520hardware%2520and%2520results%2520on%2520benchmark%2520data%2520suggest%250Athat%2520our%2520approach%2520dominates%2520previous%2520QUBO%2520formulations%2520and%2520baseline%2520MAPF%250Asolvers.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14568v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Hybrid%20Quantum-Classical%20Multi-Agent%20Pathfinding&entry.906535625=Thore%20Gerlach%20and%20Loong%20Kuan%20Lee%20and%20Fr%C3%A9d%C3%A9ric%20Barbaresco%20and%20Nico%20Piatkowski&entry.1292438233=%20%20Multi-Agent%20Path%20Finding%20%28MAPF%29%20focuses%20on%20determining%20conflict-free%20paths%0Afor%20multiple%20agents%20navigating%20through%20a%20shared%20space%20to%20reach%20specified%20goal%0Alocations.%20This%20problem%20becomes%20computationally%20challenging%2C%20particularly%20when%0Ahandling%20large%20numbers%20of%20agents%2C%20as%20frequently%20encountered%20in%20practical%0Aapplications%20like%20coordinating%20autonomous%20vehicles.%20Quantum%20computing%20%28QC%29%20is%20a%0Apromising%20candidate%20in%20overcoming%20such%20limits.%20However%2C%20current%20quantum%0Ahardware%20is%20still%20in%20its%20infancy%20and%20thus%20limited%20in%20terms%20of%20computing%20power%0Aand%20error%20robustness.%20In%20this%20work%2C%20we%20present%20the%20first%20optimal%20hybrid%0Aquantum-classical%20MAPF%20algorithm%20which%20is%20based%20on%20branch-and-cut-and-prize.%20QC%0Ais%20integrated%20by%20iteratively%20solving%20QUBO%20problems%2C%20based%20on%20conflict%20graphs.%0AExperiments%20on%20actual%20quantum%20hardware%20and%20results%20on%20benchmark%20data%20suggest%0Athat%20our%20approach%20dominates%20previous%20QUBO%20formulations%20and%20baseline%20MAPF%0Asolvers.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14568v1&entry.124074799=Read"},
{"title": "MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical\n  Applications", "author": "Yixing Jiang and Kameron C. Black and Gloria Geng and Danny Park and Andrew Y. Ng and Jonathan H. Chen", "abstract": "  Recent large language models (LLMs) have demonstrated significant\nadvancements, particularly in their ability to serve as agents thereby\nsurpassing their traditional role as chatbots. These agents can leverage their\nplanning and tool utilization capabilities to address tasks specified at a high\nlevel. However, a standardized dataset to benchmark the agent capabilities of\nLLMs in medical applications is currently lacking, making the evaluation of\nLLMs on complex tasks in interactive healthcare environments challenging. To\naddress this gap, we introduce MedAgentBench, a broad evaluation suite designed\nto assess the agent capabilities of large language models within medical\nrecords contexts. MedAgentBench encompasses 100 patient-specific\nclinically-derived tasks from 10 categories written by human physicians,\nrealistic profiles of 100 patients with over 700,000 data elements, a\nFHIR-compliant interactive environment, and an accompanying codebase. The\nenvironment uses the standard APIs and communication infrastructure used in\nmodern EMR systems, so it can be easily migrated into live EMR systems.\nMedAgentBench presents an unsaturated agent-oriented benchmark that current\nstate-of-the-art LLMs exhibit some ability to succeed at. The best model\n(GPT-4o) achieves a success rate of 72%. However, there is still substantial\nspace for improvement to give the community a next direction to optimize.\nFurthermore, there is significant variation in performance across task\ncategories. MedAgentBench establishes this and is publicly available at\nhttps://github.com/stanfordmlgroup/MedAgentBench , offering a valuable\nframework for model developers to track progress and drive continuous\nimprovements in the agent capabilities of large language models within the\nmedical domain.\n", "link": "http://arxiv.org/abs/2501.14654v1", "date": "2025-01-24", "relevancy": 1.4658, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5279}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4811}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4759}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20MedAgentBench%3A%20Dataset%20for%20Benchmarking%20LLMs%20as%20Agents%20in%20Medical%0A%20%20Applications&body=Title%3A%20MedAgentBench%3A%20Dataset%20for%20Benchmarking%20LLMs%20as%20Agents%20in%20Medical%0A%20%20Applications%0AAuthor%3A%20Yixing%20Jiang%20and%20Kameron%20C.%20Black%20and%20Gloria%20Geng%20and%20Danny%20Park%20and%20Andrew%20Y.%20Ng%20and%20Jonathan%20H.%20Chen%0AAbstract%3A%20%20%20Recent%20large%20language%20models%20%28LLMs%29%20have%20demonstrated%20significant%0Aadvancements%2C%20particularly%20in%20their%20ability%20to%20serve%20as%20agents%20thereby%0Asurpassing%20their%20traditional%20role%20as%20chatbots.%20These%20agents%20can%20leverage%20their%0Aplanning%20and%20tool%20utilization%20capabilities%20to%20address%20tasks%20specified%20at%20a%20high%0Alevel.%20However%2C%20a%20standardized%20dataset%20to%20benchmark%20the%20agent%20capabilities%20of%0ALLMs%20in%20medical%20applications%20is%20currently%20lacking%2C%20making%20the%20evaluation%20of%0ALLMs%20on%20complex%20tasks%20in%20interactive%20healthcare%20environments%20challenging.%20To%0Aaddress%20this%20gap%2C%20we%20introduce%20MedAgentBench%2C%20a%20broad%20evaluation%20suite%20designed%0Ato%20assess%20the%20agent%20capabilities%20of%20large%20language%20models%20within%20medical%0Arecords%20contexts.%20MedAgentBench%20encompasses%20100%20patient-specific%0Aclinically-derived%20tasks%20from%2010%20categories%20written%20by%20human%20physicians%2C%0Arealistic%20profiles%20of%20100%20patients%20with%20over%20700%2C000%20data%20elements%2C%20a%0AFHIR-compliant%20interactive%20environment%2C%20and%20an%20accompanying%20codebase.%20The%0Aenvironment%20uses%20the%20standard%20APIs%20and%20communication%20infrastructure%20used%20in%0Amodern%20EMR%20systems%2C%20so%20it%20can%20be%20easily%20migrated%20into%20live%20EMR%20systems.%0AMedAgentBench%20presents%20an%20unsaturated%20agent-oriented%20benchmark%20that%20current%0Astate-of-the-art%20LLMs%20exhibit%20some%20ability%20to%20succeed%20at.%20The%20best%20model%0A%28GPT-4o%29%20achieves%20a%20success%20rate%20of%2072%25.%20However%2C%20there%20is%20still%20substantial%0Aspace%20for%20improvement%20to%20give%20the%20community%20a%20next%20direction%20to%20optimize.%0AFurthermore%2C%20there%20is%20significant%20variation%20in%20performance%20across%20task%0Acategories.%20MedAgentBench%20establishes%20this%20and%20is%20publicly%20available%20at%0Ahttps%3A//github.com/stanfordmlgroup/MedAgentBench%20%2C%20offering%20a%20valuable%0Aframework%20for%20model%20developers%20to%20track%20progress%20and%20drive%20continuous%0Aimprovements%20in%20the%20agent%20capabilities%20of%20large%20language%20models%20within%20the%0Amedical%20domain.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14654v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DMedAgentBench%253A%2520Dataset%2520for%2520Benchmarking%2520LLMs%2520as%2520Agents%2520in%2520Medical%250A%2520%2520Applications%26entry.906535625%3DYixing%2520Jiang%2520and%2520Kameron%2520C.%2520Black%2520and%2520Gloria%2520Geng%2520and%2520Danny%2520Park%2520and%2520Andrew%2520Y.%2520Ng%2520and%2520Jonathan%2520H.%2520Chen%26entry.1292438233%3D%2520%2520Recent%2520large%2520language%2520models%2520%2528LLMs%2529%2520have%2520demonstrated%2520significant%250Aadvancements%252C%2520particularly%2520in%2520their%2520ability%2520to%2520serve%2520as%2520agents%2520thereby%250Asurpassing%2520their%2520traditional%2520role%2520as%2520chatbots.%2520These%2520agents%2520can%2520leverage%2520their%250Aplanning%2520and%2520tool%2520utilization%2520capabilities%2520to%2520address%2520tasks%2520specified%2520at%2520a%2520high%250Alevel.%2520However%252C%2520a%2520standardized%2520dataset%2520to%2520benchmark%2520the%2520agent%2520capabilities%2520of%250ALLMs%2520in%2520medical%2520applications%2520is%2520currently%2520lacking%252C%2520making%2520the%2520evaluation%2520of%250ALLMs%2520on%2520complex%2520tasks%2520in%2520interactive%2520healthcare%2520environments%2520challenging.%2520To%250Aaddress%2520this%2520gap%252C%2520we%2520introduce%2520MedAgentBench%252C%2520a%2520broad%2520evaluation%2520suite%2520designed%250Ato%2520assess%2520the%2520agent%2520capabilities%2520of%2520large%2520language%2520models%2520within%2520medical%250Arecords%2520contexts.%2520MedAgentBench%2520encompasses%2520100%2520patient-specific%250Aclinically-derived%2520tasks%2520from%252010%2520categories%2520written%2520by%2520human%2520physicians%252C%250Arealistic%2520profiles%2520of%2520100%2520patients%2520with%2520over%2520700%252C000%2520data%2520elements%252C%2520a%250AFHIR-compliant%2520interactive%2520environment%252C%2520and%2520an%2520accompanying%2520codebase.%2520The%250Aenvironment%2520uses%2520the%2520standard%2520APIs%2520and%2520communication%2520infrastructure%2520used%2520in%250Amodern%2520EMR%2520systems%252C%2520so%2520it%2520can%2520be%2520easily%2520migrated%2520into%2520live%2520EMR%2520systems.%250AMedAgentBench%2520presents%2520an%2520unsaturated%2520agent-oriented%2520benchmark%2520that%2520current%250Astate-of-the-art%2520LLMs%2520exhibit%2520some%2520ability%2520to%2520succeed%2520at.%2520The%2520best%2520model%250A%2528GPT-4o%2529%2520achieves%2520a%2520success%2520rate%2520of%252072%2525.%2520However%252C%2520there%2520is%2520still%2520substantial%250Aspace%2520for%2520improvement%2520to%2520give%2520the%2520community%2520a%2520next%2520direction%2520to%2520optimize.%250AFurthermore%252C%2520there%2520is%2520significant%2520variation%2520in%2520performance%2520across%2520task%250Acategories.%2520MedAgentBench%2520establishes%2520this%2520and%2520is%2520publicly%2520available%2520at%250Ahttps%253A//github.com/stanfordmlgroup/MedAgentBench%2520%252C%2520offering%2520a%2520valuable%250Aframework%2520for%2520model%2520developers%2520to%2520track%2520progress%2520and%2520drive%2520continuous%250Aimprovements%2520in%2520the%2520agent%2520capabilities%2520of%2520large%2520language%2520models%2520within%2520the%250Amedical%2520domain.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14654v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=MedAgentBench%3A%20Dataset%20for%20Benchmarking%20LLMs%20as%20Agents%20in%20Medical%0A%20%20Applications&entry.906535625=Yixing%20Jiang%20and%20Kameron%20C.%20Black%20and%20Gloria%20Geng%20and%20Danny%20Park%20and%20Andrew%20Y.%20Ng%20and%20Jonathan%20H.%20Chen&entry.1292438233=%20%20Recent%20large%20language%20models%20%28LLMs%29%20have%20demonstrated%20significant%0Aadvancements%2C%20particularly%20in%20their%20ability%20to%20serve%20as%20agents%20thereby%0Asurpassing%20their%20traditional%20role%20as%20chatbots.%20These%20agents%20can%20leverage%20their%0Aplanning%20and%20tool%20utilization%20capabilities%20to%20address%20tasks%20specified%20at%20a%20high%0Alevel.%20However%2C%20a%20standardized%20dataset%20to%20benchmark%20the%20agent%20capabilities%20of%0ALLMs%20in%20medical%20applications%20is%20currently%20lacking%2C%20making%20the%20evaluation%20of%0ALLMs%20on%20complex%20tasks%20in%20interactive%20healthcare%20environments%20challenging.%20To%0Aaddress%20this%20gap%2C%20we%20introduce%20MedAgentBench%2C%20a%20broad%20evaluation%20suite%20designed%0Ato%20assess%20the%20agent%20capabilities%20of%20large%20language%20models%20within%20medical%0Arecords%20contexts.%20MedAgentBench%20encompasses%20100%20patient-specific%0Aclinically-derived%20tasks%20from%2010%20categories%20written%20by%20human%20physicians%2C%0Arealistic%20profiles%20of%20100%20patients%20with%20over%20700%2C000%20data%20elements%2C%20a%0AFHIR-compliant%20interactive%20environment%2C%20and%20an%20accompanying%20codebase.%20The%0Aenvironment%20uses%20the%20standard%20APIs%20and%20communication%20infrastructure%20used%20in%0Amodern%20EMR%20systems%2C%20so%20it%20can%20be%20easily%20migrated%20into%20live%20EMR%20systems.%0AMedAgentBench%20presents%20an%20unsaturated%20agent-oriented%20benchmark%20that%20current%0Astate-of-the-art%20LLMs%20exhibit%20some%20ability%20to%20succeed%20at.%20The%20best%20model%0A%28GPT-4o%29%20achieves%20a%20success%20rate%20of%2072%25.%20However%2C%20there%20is%20still%20substantial%0Aspace%20for%20improvement%20to%20give%20the%20community%20a%20next%20direction%20to%20optimize.%0AFurthermore%2C%20there%20is%20significant%20variation%20in%20performance%20across%20task%0Acategories.%20MedAgentBench%20establishes%20this%20and%20is%20publicly%20available%20at%0Ahttps%3A//github.com/stanfordmlgroup/MedAgentBench%20%2C%20offering%20a%20valuable%0Aframework%20for%20model%20developers%20to%20track%20progress%20and%20drive%20continuous%0Aimprovements%20in%20the%20agent%20capabilities%20of%20large%20language%20models%20within%20the%0Amedical%20domain.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14654v1&entry.124074799=Read"},
{"title": "Neural-Symbolic Message Passing with Dynamic Pruning", "author": "Chongzhi Zhang and Junhao Zheng and Zhiping Peng and Qianli Ma", "abstract": "  Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs) is a\nchallenging task. Recently, a line of message-passing-based research has been\nproposed to solve CQA. However, they perform unsatisfactorily on negative\nqueries and fail to address the noisy messages between variable nodes in the\nquery graph. Moreover, they offer little interpretability and require complex\nquery data and resource-intensive training. In this paper, we propose a\nNeural-Symbolic Message Passing (NSMP) framework based on pre-trained neural\nlink predictors. By introducing symbolic reasoning and fuzzy logic, NSMP can\ngeneralize to arbitrary existential first order logic queries without requiring\ntraining while providing interpretable answers. Furthermore, we introduce a\ndynamic pruning strategy to filter out noisy messages between variable nodes.\nExperimental results show that NSMP achieves a strong performance.\nAdditionally, through complexity analysis and empirical verification, we\ndemonstrate the superiority of NSMP in inference time over the current\nstate-of-the-art neural-symbolic method. Compared to this approach, NSMP\ndemonstrates faster inference times across all query types on benchmark\ndatasets, with speedup ranging from 2$\\times$ to over 150$\\times$.\n", "link": "http://arxiv.org/abs/2501.14661v1", "date": "2025-01-24", "relevancy": 1.4105, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4846}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4736}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.463}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Neural-Symbolic%20Message%20Passing%20with%20Dynamic%20Pruning&body=Title%3A%20Neural-Symbolic%20Message%20Passing%20with%20Dynamic%20Pruning%0AAuthor%3A%20Chongzhi%20Zhang%20and%20Junhao%20Zheng%20and%20Zhiping%20Peng%20and%20Qianli%20Ma%0AAbstract%3A%20%20%20Complex%20Query%20Answering%20%28CQA%29%20over%20incomplete%20Knowledge%20Graphs%20%28KGs%29%20is%20a%0Achallenging%20task.%20Recently%2C%20a%20line%20of%20message-passing-based%20research%20has%20been%0Aproposed%20to%20solve%20CQA.%20However%2C%20they%20perform%20unsatisfactorily%20on%20negative%0Aqueries%20and%20fail%20to%20address%20the%20noisy%20messages%20between%20variable%20nodes%20in%20the%0Aquery%20graph.%20Moreover%2C%20they%20offer%20little%20interpretability%20and%20require%20complex%0Aquery%20data%20and%20resource-intensive%20training.%20In%20this%20paper%2C%20we%20propose%20a%0ANeural-Symbolic%20Message%20Passing%20%28NSMP%29%20framework%20based%20on%20pre-trained%20neural%0Alink%20predictors.%20By%20introducing%20symbolic%20reasoning%20and%20fuzzy%20logic%2C%20NSMP%20can%0Ageneralize%20to%20arbitrary%20existential%20first%20order%20logic%20queries%20without%20requiring%0Atraining%20while%20providing%20interpretable%20answers.%20Furthermore%2C%20we%20introduce%20a%0Adynamic%20pruning%20strategy%20to%20filter%20out%20noisy%20messages%20between%20variable%20nodes.%0AExperimental%20results%20show%20that%20NSMP%20achieves%20a%20strong%20performance.%0AAdditionally%2C%20through%20complexity%20analysis%20and%20empirical%20verification%2C%20we%0Ademonstrate%20the%20superiority%20of%20NSMP%20in%20inference%20time%20over%20the%20current%0Astate-of-the-art%20neural-symbolic%20method.%20Compared%20to%20this%20approach%2C%20NSMP%0Ademonstrates%20faster%20inference%20times%20across%20all%20query%20types%20on%20benchmark%0Adatasets%2C%20with%20speedup%20ranging%20from%202%24%5Ctimes%24%20to%20over%20150%24%5Ctimes%24.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14661v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DNeural-Symbolic%2520Message%2520Passing%2520with%2520Dynamic%2520Pruning%26entry.906535625%3DChongzhi%2520Zhang%2520and%2520Junhao%2520Zheng%2520and%2520Zhiping%2520Peng%2520and%2520Qianli%2520Ma%26entry.1292438233%3D%2520%2520Complex%2520Query%2520Answering%2520%2528CQA%2529%2520over%2520incomplete%2520Knowledge%2520Graphs%2520%2528KGs%2529%2520is%2520a%250Achallenging%2520task.%2520Recently%252C%2520a%2520line%2520of%2520message-passing-based%2520research%2520has%2520been%250Aproposed%2520to%2520solve%2520CQA.%2520However%252C%2520they%2520perform%2520unsatisfactorily%2520on%2520negative%250Aqueries%2520and%2520fail%2520to%2520address%2520the%2520noisy%2520messages%2520between%2520variable%2520nodes%2520in%2520the%250Aquery%2520graph.%2520Moreover%252C%2520they%2520offer%2520little%2520interpretability%2520and%2520require%2520complex%250Aquery%2520data%2520and%2520resource-intensive%2520training.%2520In%2520this%2520paper%252C%2520we%2520propose%2520a%250ANeural-Symbolic%2520Message%2520Passing%2520%2528NSMP%2529%2520framework%2520based%2520on%2520pre-trained%2520neural%250Alink%2520predictors.%2520By%2520introducing%2520symbolic%2520reasoning%2520and%2520fuzzy%2520logic%252C%2520NSMP%2520can%250Ageneralize%2520to%2520arbitrary%2520existential%2520first%2520order%2520logic%2520queries%2520without%2520requiring%250Atraining%2520while%2520providing%2520interpretable%2520answers.%2520Furthermore%252C%2520we%2520introduce%2520a%250Adynamic%2520pruning%2520strategy%2520to%2520filter%2520out%2520noisy%2520messages%2520between%2520variable%2520nodes.%250AExperimental%2520results%2520show%2520that%2520NSMP%2520achieves%2520a%2520strong%2520performance.%250AAdditionally%252C%2520through%2520complexity%2520analysis%2520and%2520empirical%2520verification%252C%2520we%250Ademonstrate%2520the%2520superiority%2520of%2520NSMP%2520in%2520inference%2520time%2520over%2520the%2520current%250Astate-of-the-art%2520neural-symbolic%2520method.%2520Compared%2520to%2520this%2520approach%252C%2520NSMP%250Ademonstrates%2520faster%2520inference%2520times%2520across%2520all%2520query%2520types%2520on%2520benchmark%250Adatasets%252C%2520with%2520speedup%2520ranging%2520from%25202%2524%255Ctimes%2524%2520to%2520over%2520150%2524%255Ctimes%2524.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14661v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Neural-Symbolic%20Message%20Passing%20with%20Dynamic%20Pruning&entry.906535625=Chongzhi%20Zhang%20and%20Junhao%20Zheng%20and%20Zhiping%20Peng%20and%20Qianli%20Ma&entry.1292438233=%20%20Complex%20Query%20Answering%20%28CQA%29%20over%20incomplete%20Knowledge%20Graphs%20%28KGs%29%20is%20a%0Achallenging%20task.%20Recently%2C%20a%20line%20of%20message-passing-based%20research%20has%20been%0Aproposed%20to%20solve%20CQA.%20However%2C%20they%20perform%20unsatisfactorily%20on%20negative%0Aqueries%20and%20fail%20to%20address%20the%20noisy%20messages%20between%20variable%20nodes%20in%20the%0Aquery%20graph.%20Moreover%2C%20they%20offer%20little%20interpretability%20and%20require%20complex%0Aquery%20data%20and%20resource-intensive%20training.%20In%20this%20paper%2C%20we%20propose%20a%0ANeural-Symbolic%20Message%20Passing%20%28NSMP%29%20framework%20based%20on%20pre-trained%20neural%0Alink%20predictors.%20By%20introducing%20symbolic%20reasoning%20and%20fuzzy%20logic%2C%20NSMP%20can%0Ageneralize%20to%20arbitrary%20existential%20first%20order%20logic%20queries%20without%20requiring%0Atraining%20while%20providing%20interpretable%20answers.%20Furthermore%2C%20we%20introduce%20a%0Adynamic%20pruning%20strategy%20to%20filter%20out%20noisy%20messages%20between%20variable%20nodes.%0AExperimental%20results%20show%20that%20NSMP%20achieves%20a%20strong%20performance.%0AAdditionally%2C%20through%20complexity%20analysis%20and%20empirical%20verification%2C%20we%0Ademonstrate%20the%20superiority%20of%20NSMP%20in%20inference%20time%20over%20the%20current%0Astate-of-the-art%20neural-symbolic%20method.%20Compared%20to%20this%20approach%2C%20NSMP%0Ademonstrates%20faster%20inference%20times%20across%20all%20query%20types%20on%20benchmark%0Adatasets%2C%20with%20speedup%20ranging%20from%202%24%5Ctimes%24%20to%20over%20150%24%5Ctimes%24.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14661v1&entry.124074799=Read"},
{"title": "Overcoming Fairness Trade-offs via Pre-processing: A Causal Perspective", "author": "Charlotte Leininger and Simon Rittel and Ludwig Bothmann", "abstract": "  Training machine learning models for fair decisions faces two key challenges:\nThe \\emph{fairness-accuracy trade-off} results from enforcing fairness which\nweakens its predictive performance in contrast to an unconstrained model. The\nincompatibility of different fairness metrics poses another trade-off -- also\nknown as the \\emph{impossibility theorem}. Recent work identifies the bias\nwithin the observed data as a possible root cause and shows that fairness and\npredictive performance are in fact in accord when predictive performance is\nmeasured on unbiased data. We offer a causal explanation for these findings\nusing the framework of the FiND (fictitious and normatively desired) world, a\n\"fair\" world, where protected attributes have no causal effects on the target\nvariable. We show theoretically that (i) classical fairness metrics deemed to\nbe incompatible are naturally satisfied in the FiND world, while (ii) fairness\naligns with high predictive performance. We extend our analysis by suggesting\nhow one can benefit from these theoretical insights in practice, using causal\npre-processing methods that approximate the FiND world. Additionally, we\npropose a method for evaluating the approximation of the FiND world via\npre-processing in practical use cases where we do not have access to the FiND\nworld. In simulations and empirical studies, we demonstrate that these\npre-processing methods are successful in approximating the FiND world and\nresolve both trade-offs. Our results provide actionable solutions for\npractitioners to achieve fairness and high predictive performance\nsimultaneously.\n", "link": "http://arxiv.org/abs/2501.14710v1", "date": "2025-01-24", "relevancy": 1.4059, "topK": [{"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.4938}, {"title": "Tuning-Free Noise Rectification for High Fidelity Image-to-Video\n  Generation", "link": "http://arxiv.org/abs/2403.02827v1", "similarity": 0.462}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4601}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Overcoming%20Fairness%20Trade-offs%20via%20Pre-processing%3A%20A%20Causal%20Perspective&body=Title%3A%20Overcoming%20Fairness%20Trade-offs%20via%20Pre-processing%3A%20A%20Causal%20Perspective%0AAuthor%3A%20Charlotte%20Leininger%20and%20Simon%20Rittel%20and%20Ludwig%20Bothmann%0AAbstract%3A%20%20%20Training%20machine%20learning%20models%20for%20fair%20decisions%20faces%20two%20key%20challenges%3A%0AThe%20%5Cemph%7Bfairness-accuracy%20trade-off%7D%20results%20from%20enforcing%20fairness%20which%0Aweakens%20its%20predictive%20performance%20in%20contrast%20to%20an%20unconstrained%20model.%20The%0Aincompatibility%20of%20different%20fairness%20metrics%20poses%20another%20trade-off%20--%20also%0Aknown%20as%20the%20%5Cemph%7Bimpossibility%20theorem%7D.%20Recent%20work%20identifies%20the%20bias%0Awithin%20the%20observed%20data%20as%20a%20possible%20root%20cause%20and%20shows%20that%20fairness%20and%0Apredictive%20performance%20are%20in%20fact%20in%20accord%20when%20predictive%20performance%20is%0Ameasured%20on%20unbiased%20data.%20We%20offer%20a%20causal%20explanation%20for%20these%20findings%0Ausing%20the%20framework%20of%20the%20FiND%20%28fictitious%20and%20normatively%20desired%29%20world%2C%20a%0A%22fair%22%20world%2C%20where%20protected%20attributes%20have%20no%20causal%20effects%20on%20the%20target%0Avariable.%20We%20show%20theoretically%20that%20%28i%29%20classical%20fairness%20metrics%20deemed%20to%0Abe%20incompatible%20are%20naturally%20satisfied%20in%20the%20FiND%20world%2C%20while%20%28ii%29%20fairness%0Aaligns%20with%20high%20predictive%20performance.%20We%20extend%20our%20analysis%20by%20suggesting%0Ahow%20one%20can%20benefit%20from%20these%20theoretical%20insights%20in%20practice%2C%20using%20causal%0Apre-processing%20methods%20that%20approximate%20the%20FiND%20world.%20Additionally%2C%20we%0Apropose%20a%20method%20for%20evaluating%20the%20approximation%20of%20the%20FiND%20world%20via%0Apre-processing%20in%20practical%20use%20cases%20where%20we%20do%20not%20have%20access%20to%20the%20FiND%0Aworld.%20In%20simulations%20and%20empirical%20studies%2C%20we%20demonstrate%20that%20these%0Apre-processing%20methods%20are%20successful%20in%20approximating%20the%20FiND%20world%20and%0Aresolve%20both%20trade-offs.%20Our%20results%20provide%20actionable%20solutions%20for%0Apractitioners%20to%20achieve%20fairness%20and%20high%20predictive%20performance%0Asimultaneously.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14710v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DOvercoming%2520Fairness%2520Trade-offs%2520via%2520Pre-processing%253A%2520A%2520Causal%2520Perspective%26entry.906535625%3DCharlotte%2520Leininger%2520and%2520Simon%2520Rittel%2520and%2520Ludwig%2520Bothmann%26entry.1292438233%3D%2520%2520Training%2520machine%2520learning%2520models%2520for%2520fair%2520decisions%2520faces%2520two%2520key%2520challenges%253A%250AThe%2520%255Cemph%257Bfairness-accuracy%2520trade-off%257D%2520results%2520from%2520enforcing%2520fairness%2520which%250Aweakens%2520its%2520predictive%2520performance%2520in%2520contrast%2520to%2520an%2520unconstrained%2520model.%2520The%250Aincompatibility%2520of%2520different%2520fairness%2520metrics%2520poses%2520another%2520trade-off%2520--%2520also%250Aknown%2520as%2520the%2520%255Cemph%257Bimpossibility%2520theorem%257D.%2520Recent%2520work%2520identifies%2520the%2520bias%250Awithin%2520the%2520observed%2520data%2520as%2520a%2520possible%2520root%2520cause%2520and%2520shows%2520that%2520fairness%2520and%250Apredictive%2520performance%2520are%2520in%2520fact%2520in%2520accord%2520when%2520predictive%2520performance%2520is%250Ameasured%2520on%2520unbiased%2520data.%2520We%2520offer%2520a%2520causal%2520explanation%2520for%2520these%2520findings%250Ausing%2520the%2520framework%2520of%2520the%2520FiND%2520%2528fictitious%2520and%2520normatively%2520desired%2529%2520world%252C%2520a%250A%2522fair%2522%2520world%252C%2520where%2520protected%2520attributes%2520have%2520no%2520causal%2520effects%2520on%2520the%2520target%250Avariable.%2520We%2520show%2520theoretically%2520that%2520%2528i%2529%2520classical%2520fairness%2520metrics%2520deemed%2520to%250Abe%2520incompatible%2520are%2520naturally%2520satisfied%2520in%2520the%2520FiND%2520world%252C%2520while%2520%2528ii%2529%2520fairness%250Aaligns%2520with%2520high%2520predictive%2520performance.%2520We%2520extend%2520our%2520analysis%2520by%2520suggesting%250Ahow%2520one%2520can%2520benefit%2520from%2520these%2520theoretical%2520insights%2520in%2520practice%252C%2520using%2520causal%250Apre-processing%2520methods%2520that%2520approximate%2520the%2520FiND%2520world.%2520Additionally%252C%2520we%250Apropose%2520a%2520method%2520for%2520evaluating%2520the%2520approximation%2520of%2520the%2520FiND%2520world%2520via%250Apre-processing%2520in%2520practical%2520use%2520cases%2520where%2520we%2520do%2520not%2520have%2520access%2520to%2520the%2520FiND%250Aworld.%2520In%2520simulations%2520and%2520empirical%2520studies%252C%2520we%2520demonstrate%2520that%2520these%250Apre-processing%2520methods%2520are%2520successful%2520in%2520approximating%2520the%2520FiND%2520world%2520and%250Aresolve%2520both%2520trade-offs.%2520Our%2520results%2520provide%2520actionable%2520solutions%2520for%250Apractitioners%2520to%2520achieve%2520fairness%2520and%2520high%2520predictive%2520performance%250Asimultaneously.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14710v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Overcoming%20Fairness%20Trade-offs%20via%20Pre-processing%3A%20A%20Causal%20Perspective&entry.906535625=Charlotte%20Leininger%20and%20Simon%20Rittel%20and%20Ludwig%20Bothmann&entry.1292438233=%20%20Training%20machine%20learning%20models%20for%20fair%20decisions%20faces%20two%20key%20challenges%3A%0AThe%20%5Cemph%7Bfairness-accuracy%20trade-off%7D%20results%20from%20enforcing%20fairness%20which%0Aweakens%20its%20predictive%20performance%20in%20contrast%20to%20an%20unconstrained%20model.%20The%0Aincompatibility%20of%20different%20fairness%20metrics%20poses%20another%20trade-off%20--%20also%0Aknown%20as%20the%20%5Cemph%7Bimpossibility%20theorem%7D.%20Recent%20work%20identifies%20the%20bias%0Awithin%20the%20observed%20data%20as%20a%20possible%20root%20cause%20and%20shows%20that%20fairness%20and%0Apredictive%20performance%20are%20in%20fact%20in%20accord%20when%20predictive%20performance%20is%0Ameasured%20on%20unbiased%20data.%20We%20offer%20a%20causal%20explanation%20for%20these%20findings%0Ausing%20the%20framework%20of%20the%20FiND%20%28fictitious%20and%20normatively%20desired%29%20world%2C%20a%0A%22fair%22%20world%2C%20where%20protected%20attributes%20have%20no%20causal%20effects%20on%20the%20target%0Avariable.%20We%20show%20theoretically%20that%20%28i%29%20classical%20fairness%20metrics%20deemed%20to%0Abe%20incompatible%20are%20naturally%20satisfied%20in%20the%20FiND%20world%2C%20while%20%28ii%29%20fairness%0Aaligns%20with%20high%20predictive%20performance.%20We%20extend%20our%20analysis%20by%20suggesting%0Ahow%20one%20can%20benefit%20from%20these%20theoretical%20insights%20in%20practice%2C%20using%20causal%0Apre-processing%20methods%20that%20approximate%20the%20FiND%20world.%20Additionally%2C%20we%0Apropose%20a%20method%20for%20evaluating%20the%20approximation%20of%20the%20FiND%20world%20via%0Apre-processing%20in%20practical%20use%20cases%20where%20we%20do%20not%20have%20access%20to%20the%20FiND%0Aworld.%20In%20simulations%20and%20empirical%20studies%2C%20we%20demonstrate%20that%20these%0Apre-processing%20methods%20are%20successful%20in%20approximating%20the%20FiND%20world%20and%0Aresolve%20both%20trade-offs.%20Our%20results%20provide%20actionable%20solutions%20for%0Apractitioners%20to%20achieve%20fairness%20and%20high%20predictive%20performance%0Asimultaneously.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14710v1&entry.124074799=Read"},
{"title": "Decision-Focused Learning for Complex System Identification: HVAC\n  Management System Application", "author": "Pietro Favaro and Jean-Fran\u00e7ois Toubeau and Fran\u00e7ois Vall\u00e9e and Yury Dvorkin", "abstract": "  As opposed to conventional training methods tailored to minimize a given\nstatistical metric or task-agnostic loss (e.g., mean squared error),\nDecision-Focused Learning (DFL) trains machine learning models for optimal\nperformance in downstream decision-making tools. We argue that DFL can be\nleveraged to learn the parameters of system dynamics, expressed as constraint\nof the convex optimization control policy, while the system control signal is\nbeing optimized, thus creating an end-to-end learning framework. This is\nparticularly relevant for systems in which behavior changes once the control\npolicy is applied, hence rendering historical data less applicable. The\nproposed approach can perform system identification - i.e., determine\nappropriate parameters for the system analytical model - and control\nsimultaneously to ensure that the model's accuracy is focused on areas most\nrelevant to control. Furthermore, because black-box systems are\nnon-differentiable, we design a loss function that requires solely to measure\nthe system response. We propose pre-training on historical data and constraint\nrelaxation to stabilize the DFL and deal with potential infeasibilities in\nlearning. We demonstrate the usefulness of the method on a building Heating,\nVentilation, and Air Conditioning day-ahead management system for a realistic\n15-zone building located in Denver, US. The results show that the conventional\nRC building model, with the parameters obtained from historical data using\nsupervised learning, underestimates HVAC electrical power consumption. For our\ncase study, the ex-post cost is on average six times higher than the expected\none. Meanwhile, the same RC model with parameters obtained via DFL\nunderestimates the ex-post cost only by 3%.\n", "link": "http://arxiv.org/abs/2501.14708v1", "date": "2025-01-24", "relevancy": 1.401, "topK": [{"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.468}, {"title": "Safe and efficient training of a control agent", "link": "https://patents.google.com/patent/US11709462B2/en", "similarity": 0.4672}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4656}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Decision-Focused%20Learning%20for%20Complex%20System%20Identification%3A%20HVAC%0A%20%20Management%20System%20Application&body=Title%3A%20Decision-Focused%20Learning%20for%20Complex%20System%20Identification%3A%20HVAC%0A%20%20Management%20System%20Application%0AAuthor%3A%20Pietro%20Favaro%20and%20Jean-Fran%C3%A7ois%20Toubeau%20and%20Fran%C3%A7ois%20Vall%C3%A9e%20and%20Yury%20Dvorkin%0AAbstract%3A%20%20%20As%20opposed%20to%20conventional%20training%20methods%20tailored%20to%20minimize%20a%20given%0Astatistical%20metric%20or%20task-agnostic%20loss%20%28e.g.%2C%20mean%20squared%20error%29%2C%0ADecision-Focused%20Learning%20%28DFL%29%20trains%20machine%20learning%20models%20for%20optimal%0Aperformance%20in%20downstream%20decision-making%20tools.%20We%20argue%20that%20DFL%20can%20be%0Aleveraged%20to%20learn%20the%20parameters%20of%20system%20dynamics%2C%20expressed%20as%20constraint%0Aof%20the%20convex%20optimization%20control%20policy%2C%20while%20the%20system%20control%20signal%20is%0Abeing%20optimized%2C%20thus%20creating%20an%20end-to-end%20learning%20framework.%20This%20is%0Aparticularly%20relevant%20for%20systems%20in%20which%20behavior%20changes%20once%20the%20control%0Apolicy%20is%20applied%2C%20hence%20rendering%20historical%20data%20less%20applicable.%20The%0Aproposed%20approach%20can%20perform%20system%20identification%20-%20i.e.%2C%20determine%0Aappropriate%20parameters%20for%20the%20system%20analytical%20model%20-%20and%20control%0Asimultaneously%20to%20ensure%20that%20the%20model%27s%20accuracy%20is%20focused%20on%20areas%20most%0Arelevant%20to%20control.%20Furthermore%2C%20because%20black-box%20systems%20are%0Anon-differentiable%2C%20we%20design%20a%20loss%20function%20that%20requires%20solely%20to%20measure%0Athe%20system%20response.%20We%20propose%20pre-training%20on%20historical%20data%20and%20constraint%0Arelaxation%20to%20stabilize%20the%20DFL%20and%20deal%20with%20potential%20infeasibilities%20in%0Alearning.%20We%20demonstrate%20the%20usefulness%20of%20the%20method%20on%20a%20building%20Heating%2C%0AVentilation%2C%20and%20Air%20Conditioning%20day-ahead%20management%20system%20for%20a%20realistic%0A15-zone%20building%20located%20in%20Denver%2C%20US.%20The%20results%20show%20that%20the%20conventional%0ARC%20building%20model%2C%20with%20the%20parameters%20obtained%20from%20historical%20data%20using%0Asupervised%20learning%2C%20underestimates%20HVAC%20electrical%20power%20consumption.%20For%20our%0Acase%20study%2C%20the%20ex-post%20cost%20is%20on%20average%20six%20times%20higher%20than%20the%20expected%0Aone.%20Meanwhile%2C%20the%20same%20RC%20model%20with%20parameters%20obtained%20via%20DFL%0Aunderestimates%20the%20ex-post%20cost%20only%20by%203%25.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14708v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDecision-Focused%2520Learning%2520for%2520Complex%2520System%2520Identification%253A%2520HVAC%250A%2520%2520Management%2520System%2520Application%26entry.906535625%3DPietro%2520Favaro%2520and%2520Jean-Fran%25C3%25A7ois%2520Toubeau%2520and%2520Fran%25C3%25A7ois%2520Vall%25C3%25A9e%2520and%2520Yury%2520Dvorkin%26entry.1292438233%3D%2520%2520As%2520opposed%2520to%2520conventional%2520training%2520methods%2520tailored%2520to%2520minimize%2520a%2520given%250Astatistical%2520metric%2520or%2520task-agnostic%2520loss%2520%2528e.g.%252C%2520mean%2520squared%2520error%2529%252C%250ADecision-Focused%2520Learning%2520%2528DFL%2529%2520trains%2520machine%2520learning%2520models%2520for%2520optimal%250Aperformance%2520in%2520downstream%2520decision-making%2520tools.%2520We%2520argue%2520that%2520DFL%2520can%2520be%250Aleveraged%2520to%2520learn%2520the%2520parameters%2520of%2520system%2520dynamics%252C%2520expressed%2520as%2520constraint%250Aof%2520the%2520convex%2520optimization%2520control%2520policy%252C%2520while%2520the%2520system%2520control%2520signal%2520is%250Abeing%2520optimized%252C%2520thus%2520creating%2520an%2520end-to-end%2520learning%2520framework.%2520This%2520is%250Aparticularly%2520relevant%2520for%2520systems%2520in%2520which%2520behavior%2520changes%2520once%2520the%2520control%250Apolicy%2520is%2520applied%252C%2520hence%2520rendering%2520historical%2520data%2520less%2520applicable.%2520The%250Aproposed%2520approach%2520can%2520perform%2520system%2520identification%2520-%2520i.e.%252C%2520determine%250Aappropriate%2520parameters%2520for%2520the%2520system%2520analytical%2520model%2520-%2520and%2520control%250Asimultaneously%2520to%2520ensure%2520that%2520the%2520model%2527s%2520accuracy%2520is%2520focused%2520on%2520areas%2520most%250Arelevant%2520to%2520control.%2520Furthermore%252C%2520because%2520black-box%2520systems%2520are%250Anon-differentiable%252C%2520we%2520design%2520a%2520loss%2520function%2520that%2520requires%2520solely%2520to%2520measure%250Athe%2520system%2520response.%2520We%2520propose%2520pre-training%2520on%2520historical%2520data%2520and%2520constraint%250Arelaxation%2520to%2520stabilize%2520the%2520DFL%2520and%2520deal%2520with%2520potential%2520infeasibilities%2520in%250Alearning.%2520We%2520demonstrate%2520the%2520usefulness%2520of%2520the%2520method%2520on%2520a%2520building%2520Heating%252C%250AVentilation%252C%2520and%2520Air%2520Conditioning%2520day-ahead%2520management%2520system%2520for%2520a%2520realistic%250A15-zone%2520building%2520located%2520in%2520Denver%252C%2520US.%2520The%2520results%2520show%2520that%2520the%2520conventional%250ARC%2520building%2520model%252C%2520with%2520the%2520parameters%2520obtained%2520from%2520historical%2520data%2520using%250Asupervised%2520learning%252C%2520underestimates%2520HVAC%2520electrical%2520power%2520consumption.%2520For%2520our%250Acase%2520study%252C%2520the%2520ex-post%2520cost%2520is%2520on%2520average%2520six%2520times%2520higher%2520than%2520the%2520expected%250Aone.%2520Meanwhile%252C%2520the%2520same%2520RC%2520model%2520with%2520parameters%2520obtained%2520via%2520DFL%250Aunderestimates%2520the%2520ex-post%2520cost%2520only%2520by%25203%2525.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14708v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Decision-Focused%20Learning%20for%20Complex%20System%20Identification%3A%20HVAC%0A%20%20Management%20System%20Application&entry.906535625=Pietro%20Favaro%20and%20Jean-Fran%C3%A7ois%20Toubeau%20and%20Fran%C3%A7ois%20Vall%C3%A9e%20and%20Yury%20Dvorkin&entry.1292438233=%20%20As%20opposed%20to%20conventional%20training%20methods%20tailored%20to%20minimize%20a%20given%0Astatistical%20metric%20or%20task-agnostic%20loss%20%28e.g.%2C%20mean%20squared%20error%29%2C%0ADecision-Focused%20Learning%20%28DFL%29%20trains%20machine%20learning%20models%20for%20optimal%0Aperformance%20in%20downstream%20decision-making%20tools.%20We%20argue%20that%20DFL%20can%20be%0Aleveraged%20to%20learn%20the%20parameters%20of%20system%20dynamics%2C%20expressed%20as%20constraint%0Aof%20the%20convex%20optimization%20control%20policy%2C%20while%20the%20system%20control%20signal%20is%0Abeing%20optimized%2C%20thus%20creating%20an%20end-to-end%20learning%20framework.%20This%20is%0Aparticularly%20relevant%20for%20systems%20in%20which%20behavior%20changes%20once%20the%20control%0Apolicy%20is%20applied%2C%20hence%20rendering%20historical%20data%20less%20applicable.%20The%0Aproposed%20approach%20can%20perform%20system%20identification%20-%20i.e.%2C%20determine%0Aappropriate%20parameters%20for%20the%20system%20analytical%20model%20-%20and%20control%0Asimultaneously%20to%20ensure%20that%20the%20model%27s%20accuracy%20is%20focused%20on%20areas%20most%0Arelevant%20to%20control.%20Furthermore%2C%20because%20black-box%20systems%20are%0Anon-differentiable%2C%20we%20design%20a%20loss%20function%20that%20requires%20solely%20to%20measure%0Athe%20system%20response.%20We%20propose%20pre-training%20on%20historical%20data%20and%20constraint%0Arelaxation%20to%20stabilize%20the%20DFL%20and%20deal%20with%20potential%20infeasibilities%20in%0Alearning.%20We%20demonstrate%20the%20usefulness%20of%20the%20method%20on%20a%20building%20Heating%2C%0AVentilation%2C%20and%20Air%20Conditioning%20day-ahead%20management%20system%20for%20a%20realistic%0A15-zone%20building%20located%20in%20Denver%2C%20US.%20The%20results%20show%20that%20the%20conventional%0ARC%20building%20model%2C%20with%20the%20parameters%20obtained%20from%20historical%20data%20using%0Asupervised%20learning%2C%20underestimates%20HVAC%20electrical%20power%20consumption.%20For%20our%0Acase%20study%2C%20the%20ex-post%20cost%20is%20on%20average%20six%20times%20higher%20than%20the%20expected%0Aone.%20Meanwhile%2C%20the%20same%20RC%20model%20with%20parameters%20obtained%20via%20DFL%0Aunderestimates%20the%20ex-post%20cost%20only%20by%203%25.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14708v1&entry.124074799=Read"},
{"title": "Disentangled Condensation for Large-scale Graphs", "author": "Zhenbang Xiao and Yu Wang and Shunyu Liu and Bingde Hu and Huiqiong Wang and Mingli Song and Tongya Zheng", "abstract": "  Graph condensation has emerged as an intriguing technique to save the\nexpensive training costs of Graph Neural Networks (GNNs) by substituting a\ncondensed small graph with the original graph. Despite the promising results\nachieved, previous methods usually employ an entangled paradigm of redundant\nparameters (nodes, edges, GNNs), which incurs complex joint optimization during\ncondensation. This paradigm has considerably impeded the scalability of graph\ncondensation, making it challenging to condense extremely large-scale graphs\nand generate high-fidelity condensed graphs. Therefore, we propose to\ndisentangle the condensation process into a two-stage GNN-free paradigm,\nindependently condensing nodes and generating edges while eliminating the need\nto optimize GNNs at the same time. The node condensation module avoids the\ncomplexity of GNNs by focusing on node feature alignment with anchors of the\noriginal graph, while the edge translation module constructs the edges of the\ncondensed nodes by transferring the original structure knowledge with\nneighborhood anchors. This simple yet effective approach achieves at least 10\ntimes faster than state-of-the-art methods with comparable accuracy on\nmedium-scale graphs. Moreover, the proposed DisCo can successfully scale up to\nthe Ogbn-papers100M graph containing over 100 million nodes with flexible\nreduction rates and improves performance on the second-largest Ogbn-products\ndataset by over 5%. Extensive downstream tasks and ablation study on five\ncommon datasets further demonstrate the effectiveness of the proposed DisCo\nframework. Our code is available at https://github.com/BangHonor/DisCo.\n", "link": "http://arxiv.org/abs/2401.12231v3", "date": "2025-01-24", "relevancy": 1.4001, "topK": [{"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.4741}, {"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4698}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.4625}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Disentangled%20Condensation%20for%20Large-scale%20Graphs&body=Title%3A%20Disentangled%20Condensation%20for%20Large-scale%20Graphs%0AAuthor%3A%20Zhenbang%20Xiao%20and%20Yu%20Wang%20and%20Shunyu%20Liu%20and%20Bingde%20Hu%20and%20Huiqiong%20Wang%20and%20Mingli%20Song%20and%20Tongya%20Zheng%0AAbstract%3A%20%20%20Graph%20condensation%20has%20emerged%20as%20an%20intriguing%20technique%20to%20save%20the%0Aexpensive%20training%20costs%20of%20Graph%20Neural%20Networks%20%28GNNs%29%20by%20substituting%20a%0Acondensed%20small%20graph%20with%20the%20original%20graph.%20Despite%20the%20promising%20results%0Aachieved%2C%20previous%20methods%20usually%20employ%20an%20entangled%20paradigm%20of%20redundant%0Aparameters%20%28nodes%2C%20edges%2C%20GNNs%29%2C%20which%20incurs%20complex%20joint%20optimization%20during%0Acondensation.%20This%20paradigm%20has%20considerably%20impeded%20the%20scalability%20of%20graph%0Acondensation%2C%20making%20it%20challenging%20to%20condense%20extremely%20large-scale%20graphs%0Aand%20generate%20high-fidelity%20condensed%20graphs.%20Therefore%2C%20we%20propose%20to%0Adisentangle%20the%20condensation%20process%20into%20a%20two-stage%20GNN-free%20paradigm%2C%0Aindependently%20condensing%20nodes%20and%20generating%20edges%20while%20eliminating%20the%20need%0Ato%20optimize%20GNNs%20at%20the%20same%20time.%20The%20node%20condensation%20module%20avoids%20the%0Acomplexity%20of%20GNNs%20by%20focusing%20on%20node%20feature%20alignment%20with%20anchors%20of%20the%0Aoriginal%20graph%2C%20while%20the%20edge%20translation%20module%20constructs%20the%20edges%20of%20the%0Acondensed%20nodes%20by%20transferring%20the%20original%20structure%20knowledge%20with%0Aneighborhood%20anchors.%20This%20simple%20yet%20effective%20approach%20achieves%20at%20least%2010%0Atimes%20faster%20than%20state-of-the-art%20methods%20with%20comparable%20accuracy%20on%0Amedium-scale%20graphs.%20Moreover%2C%20the%20proposed%20DisCo%20can%20successfully%20scale%20up%20to%0Athe%20Ogbn-papers100M%20graph%20containing%20over%20100%20million%20nodes%20with%20flexible%0Areduction%20rates%20and%20improves%20performance%20on%20the%20second-largest%20Ogbn-products%0Adataset%20by%20over%205%25.%20Extensive%20downstream%20tasks%20and%20ablation%20study%20on%20five%0Acommon%20datasets%20further%20demonstrate%20the%20effectiveness%20of%20the%20proposed%20DisCo%0Aframework.%20Our%20code%20is%20available%20at%20https%3A//github.com/BangHonor/DisCo.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2401.12231v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDisentangled%2520Condensation%2520for%2520Large-scale%2520Graphs%26entry.906535625%3DZhenbang%2520Xiao%2520and%2520Yu%2520Wang%2520and%2520Shunyu%2520Liu%2520and%2520Bingde%2520Hu%2520and%2520Huiqiong%2520Wang%2520and%2520Mingli%2520Song%2520and%2520Tongya%2520Zheng%26entry.1292438233%3D%2520%2520Graph%2520condensation%2520has%2520emerged%2520as%2520an%2520intriguing%2520technique%2520to%2520save%2520the%250Aexpensive%2520training%2520costs%2520of%2520Graph%2520Neural%2520Networks%2520%2528GNNs%2529%2520by%2520substituting%2520a%250Acondensed%2520small%2520graph%2520with%2520the%2520original%2520graph.%2520Despite%2520the%2520promising%2520results%250Aachieved%252C%2520previous%2520methods%2520usually%2520employ%2520an%2520entangled%2520paradigm%2520of%2520redundant%250Aparameters%2520%2528nodes%252C%2520edges%252C%2520GNNs%2529%252C%2520which%2520incurs%2520complex%2520joint%2520optimization%2520during%250Acondensation.%2520This%2520paradigm%2520has%2520considerably%2520impeded%2520the%2520scalability%2520of%2520graph%250Acondensation%252C%2520making%2520it%2520challenging%2520to%2520condense%2520extremely%2520large-scale%2520graphs%250Aand%2520generate%2520high-fidelity%2520condensed%2520graphs.%2520Therefore%252C%2520we%2520propose%2520to%250Adisentangle%2520the%2520condensation%2520process%2520into%2520a%2520two-stage%2520GNN-free%2520paradigm%252C%250Aindependently%2520condensing%2520nodes%2520and%2520generating%2520edges%2520while%2520eliminating%2520the%2520need%250Ato%2520optimize%2520GNNs%2520at%2520the%2520same%2520time.%2520The%2520node%2520condensation%2520module%2520avoids%2520the%250Acomplexity%2520of%2520GNNs%2520by%2520focusing%2520on%2520node%2520feature%2520alignment%2520with%2520anchors%2520of%2520the%250Aoriginal%2520graph%252C%2520while%2520the%2520edge%2520translation%2520module%2520constructs%2520the%2520edges%2520of%2520the%250Acondensed%2520nodes%2520by%2520transferring%2520the%2520original%2520structure%2520knowledge%2520with%250Aneighborhood%2520anchors.%2520This%2520simple%2520yet%2520effective%2520approach%2520achieves%2520at%2520least%252010%250Atimes%2520faster%2520than%2520state-of-the-art%2520methods%2520with%2520comparable%2520accuracy%2520on%250Amedium-scale%2520graphs.%2520Moreover%252C%2520the%2520proposed%2520DisCo%2520can%2520successfully%2520scale%2520up%2520to%250Athe%2520Ogbn-papers100M%2520graph%2520containing%2520over%2520100%2520million%2520nodes%2520with%2520flexible%250Areduction%2520rates%2520and%2520improves%2520performance%2520on%2520the%2520second-largest%2520Ogbn-products%250Adataset%2520by%2520over%25205%2525.%2520Extensive%2520downstream%2520tasks%2520and%2520ablation%2520study%2520on%2520five%250Acommon%2520datasets%2520further%2520demonstrate%2520the%2520effectiveness%2520of%2520the%2520proposed%2520DisCo%250Aframework.%2520Our%2520code%2520is%2520available%2520at%2520https%253A//github.com/BangHonor/DisCo.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2401.12231v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Disentangled%20Condensation%20for%20Large-scale%20Graphs&entry.906535625=Zhenbang%20Xiao%20and%20Yu%20Wang%20and%20Shunyu%20Liu%20and%20Bingde%20Hu%20and%20Huiqiong%20Wang%20and%20Mingli%20Song%20and%20Tongya%20Zheng&entry.1292438233=%20%20Graph%20condensation%20has%20emerged%20as%20an%20intriguing%20technique%20to%20save%20the%0Aexpensive%20training%20costs%20of%20Graph%20Neural%20Networks%20%28GNNs%29%20by%20substituting%20a%0Acondensed%20small%20graph%20with%20the%20original%20graph.%20Despite%20the%20promising%20results%0Aachieved%2C%20previous%20methods%20usually%20employ%20an%20entangled%20paradigm%20of%20redundant%0Aparameters%20%28nodes%2C%20edges%2C%20GNNs%29%2C%20which%20incurs%20complex%20joint%20optimization%20during%0Acondensation.%20This%20paradigm%20has%20considerably%20impeded%20the%20scalability%20of%20graph%0Acondensation%2C%20making%20it%20challenging%20to%20condense%20extremely%20large-scale%20graphs%0Aand%20generate%20high-fidelity%20condensed%20graphs.%20Therefore%2C%20we%20propose%20to%0Adisentangle%20the%20condensation%20process%20into%20a%20two-stage%20GNN-free%20paradigm%2C%0Aindependently%20condensing%20nodes%20and%20generating%20edges%20while%20eliminating%20the%20need%0Ato%20optimize%20GNNs%20at%20the%20same%20time.%20The%20node%20condensation%20module%20avoids%20the%0Acomplexity%20of%20GNNs%20by%20focusing%20on%20node%20feature%20alignment%20with%20anchors%20of%20the%0Aoriginal%20graph%2C%20while%20the%20edge%20translation%20module%20constructs%20the%20edges%20of%20the%0Acondensed%20nodes%20by%20transferring%20the%20original%20structure%20knowledge%20with%0Aneighborhood%20anchors.%20This%20simple%20yet%20effective%20approach%20achieves%20at%20least%2010%0Atimes%20faster%20than%20state-of-the-art%20methods%20with%20comparable%20accuracy%20on%0Amedium-scale%20graphs.%20Moreover%2C%20the%20proposed%20DisCo%20can%20successfully%20scale%20up%20to%0Athe%20Ogbn-papers100M%20graph%20containing%20over%20100%20million%20nodes%20with%20flexible%0Areduction%20rates%20and%20improves%20performance%20on%20the%20second-largest%20Ogbn-products%0Adataset%20by%20over%205%25.%20Extensive%20downstream%20tasks%20and%20ablation%20study%20on%20five%0Acommon%20datasets%20further%20demonstrate%20the%20effectiveness%20of%20the%20proposed%20DisCo%0Aframework.%20Our%20code%20is%20available%20at%20https%3A//github.com/BangHonor/DisCo.%0A&entry.1838667208=http%3A//arxiv.org/abs/2401.12231v3&entry.124074799=Read"},
{"title": "Data Assetization via Resources-decoupled Federated Learning", "author": "Jianzhe Zhao and Feida Zhu and Lingyan He and Zixin Tang and Mingce Gao and Shiyu Yang and Guibing Guo", "abstract": "  With the development of the digital economy, data is increasingly recognized\nas an essential resource for both work and life. However, due to privacy\nconcerns, data owners tend to maximize the value of data through information\nflow rather than direct data transfer. Federated learning (FL) provides an\neffective approach to collaborative training models while preserving privacy.\nHowever, different data owners not only have variations in the quantity and\nquality of their data resources but also face mismatches between data and\ncomputing resources as model parameters and training data grow. These\nchallenges hinder data owners' willingness to participate and reduce the\neffectiveness of data assetization. In this work, we first identify the\nresource-decoupled FL environment, which includes model owners, data owners,\nand computing centers. We design a Tripartite Stackelberg Model and\ntheoretically analyze the Stackelberg-Nash Equilibrium (SNE) for participants\nto optimize global utility. We propose the Quality-aware Dynamic\nResources-decoupled FL algorithm (QD-RDFL), in which we derive and solve the\noptimal strategies of all parties to achieve SHE using backward induction, and\na dynamic optimization mechanism is designed to improve the optimal strategy\nprofile by evaluating the contribution of data quality from data owners to the\nglobal model during real training. Our comprehensive experiments demonstrate\nthat our method effectively encourages the linkage of the three parties\ninvolved, maximizing global utility and data asset value.\n", "link": "http://arxiv.org/abs/2501.14588v1", "date": "2025-01-24", "relevancy": 1.3932, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4731}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4661}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4603}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Data%20Assetization%20via%20Resources-decoupled%20Federated%20Learning&body=Title%3A%20Data%20Assetization%20via%20Resources-decoupled%20Federated%20Learning%0AAuthor%3A%20Jianzhe%20Zhao%20and%20Feida%20Zhu%20and%20Lingyan%20He%20and%20Zixin%20Tang%20and%20Mingce%20Gao%20and%20Shiyu%20Yang%20and%20Guibing%20Guo%0AAbstract%3A%20%20%20With%20the%20development%20of%20the%20digital%20economy%2C%20data%20is%20increasingly%20recognized%0Aas%20an%20essential%20resource%20for%20both%20work%20and%20life.%20However%2C%20due%20to%20privacy%0Aconcerns%2C%20data%20owners%20tend%20to%20maximize%20the%20value%20of%20data%20through%20information%0Aflow%20rather%20than%20direct%20data%20transfer.%20Federated%20learning%20%28FL%29%20provides%20an%0Aeffective%20approach%20to%20collaborative%20training%20models%20while%20preserving%20privacy.%0AHowever%2C%20different%20data%20owners%20not%20only%20have%20variations%20in%20the%20quantity%20and%0Aquality%20of%20their%20data%20resources%20but%20also%20face%20mismatches%20between%20data%20and%0Acomputing%20resources%20as%20model%20parameters%20and%20training%20data%20grow.%20These%0Achallenges%20hinder%20data%20owners%27%20willingness%20to%20participate%20and%20reduce%20the%0Aeffectiveness%20of%20data%20assetization.%20In%20this%20work%2C%20we%20first%20identify%20the%0Aresource-decoupled%20FL%20environment%2C%20which%20includes%20model%20owners%2C%20data%20owners%2C%0Aand%20computing%20centers.%20We%20design%20a%20Tripartite%20Stackelberg%20Model%20and%0Atheoretically%20analyze%20the%20Stackelberg-Nash%20Equilibrium%20%28SNE%29%20for%20participants%0Ato%20optimize%20global%20utility.%20We%20propose%20the%20Quality-aware%20Dynamic%0AResources-decoupled%20FL%20algorithm%20%28QD-RDFL%29%2C%20in%20which%20we%20derive%20and%20solve%20the%0Aoptimal%20strategies%20of%20all%20parties%20to%20achieve%20SHE%20using%20backward%20induction%2C%20and%0Aa%20dynamic%20optimization%20mechanism%20is%20designed%20to%20improve%20the%20optimal%20strategy%0Aprofile%20by%20evaluating%20the%20contribution%20of%20data%20quality%20from%20data%20owners%20to%20the%0Aglobal%20model%20during%20real%20training.%20Our%20comprehensive%20experiments%20demonstrate%0Athat%20our%20method%20effectively%20encourages%20the%20linkage%20of%20the%20three%20parties%0Ainvolved%2C%20maximizing%20global%20utility%20and%20data%20asset%20value.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14588v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DData%2520Assetization%2520via%2520Resources-decoupled%2520Federated%2520Learning%26entry.906535625%3DJianzhe%2520Zhao%2520and%2520Feida%2520Zhu%2520and%2520Lingyan%2520He%2520and%2520Zixin%2520Tang%2520and%2520Mingce%2520Gao%2520and%2520Shiyu%2520Yang%2520and%2520Guibing%2520Guo%26entry.1292438233%3D%2520%2520With%2520the%2520development%2520of%2520the%2520digital%2520economy%252C%2520data%2520is%2520increasingly%2520recognized%250Aas%2520an%2520essential%2520resource%2520for%2520both%2520work%2520and%2520life.%2520However%252C%2520due%2520to%2520privacy%250Aconcerns%252C%2520data%2520owners%2520tend%2520to%2520maximize%2520the%2520value%2520of%2520data%2520through%2520information%250Aflow%2520rather%2520than%2520direct%2520data%2520transfer.%2520Federated%2520learning%2520%2528FL%2529%2520provides%2520an%250Aeffective%2520approach%2520to%2520collaborative%2520training%2520models%2520while%2520preserving%2520privacy.%250AHowever%252C%2520different%2520data%2520owners%2520not%2520only%2520have%2520variations%2520in%2520the%2520quantity%2520and%250Aquality%2520of%2520their%2520data%2520resources%2520but%2520also%2520face%2520mismatches%2520between%2520data%2520and%250Acomputing%2520resources%2520as%2520model%2520parameters%2520and%2520training%2520data%2520grow.%2520These%250Achallenges%2520hinder%2520data%2520owners%2527%2520willingness%2520to%2520participate%2520and%2520reduce%2520the%250Aeffectiveness%2520of%2520data%2520assetization.%2520In%2520this%2520work%252C%2520we%2520first%2520identify%2520the%250Aresource-decoupled%2520FL%2520environment%252C%2520which%2520includes%2520model%2520owners%252C%2520data%2520owners%252C%250Aand%2520computing%2520centers.%2520We%2520design%2520a%2520Tripartite%2520Stackelberg%2520Model%2520and%250Atheoretically%2520analyze%2520the%2520Stackelberg-Nash%2520Equilibrium%2520%2528SNE%2529%2520for%2520participants%250Ato%2520optimize%2520global%2520utility.%2520We%2520propose%2520the%2520Quality-aware%2520Dynamic%250AResources-decoupled%2520FL%2520algorithm%2520%2528QD-RDFL%2529%252C%2520in%2520which%2520we%2520derive%2520and%2520solve%2520the%250Aoptimal%2520strategies%2520of%2520all%2520parties%2520to%2520achieve%2520SHE%2520using%2520backward%2520induction%252C%2520and%250Aa%2520dynamic%2520optimization%2520mechanism%2520is%2520designed%2520to%2520improve%2520the%2520optimal%2520strategy%250Aprofile%2520by%2520evaluating%2520the%2520contribution%2520of%2520data%2520quality%2520from%2520data%2520owners%2520to%2520the%250Aglobal%2520model%2520during%2520real%2520training.%2520Our%2520comprehensive%2520experiments%2520demonstrate%250Athat%2520our%2520method%2520effectively%2520encourages%2520the%2520linkage%2520of%2520the%2520three%2520parties%250Ainvolved%252C%2520maximizing%2520global%2520utility%2520and%2520data%2520asset%2520value.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14588v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Data%20Assetization%20via%20Resources-decoupled%20Federated%20Learning&entry.906535625=Jianzhe%20Zhao%20and%20Feida%20Zhu%20and%20Lingyan%20He%20and%20Zixin%20Tang%20and%20Mingce%20Gao%20and%20Shiyu%20Yang%20and%20Guibing%20Guo&entry.1292438233=%20%20With%20the%20development%20of%20the%20digital%20economy%2C%20data%20is%20increasingly%20recognized%0Aas%20an%20essential%20resource%20for%20both%20work%20and%20life.%20However%2C%20due%20to%20privacy%0Aconcerns%2C%20data%20owners%20tend%20to%20maximize%20the%20value%20of%20data%20through%20information%0Aflow%20rather%20than%20direct%20data%20transfer.%20Federated%20learning%20%28FL%29%20provides%20an%0Aeffective%20approach%20to%20collaborative%20training%20models%20while%20preserving%20privacy.%0AHowever%2C%20different%20data%20owners%20not%20only%20have%20variations%20in%20the%20quantity%20and%0Aquality%20of%20their%20data%20resources%20but%20also%20face%20mismatches%20between%20data%20and%0Acomputing%20resources%20as%20model%20parameters%20and%20training%20data%20grow.%20These%0Achallenges%20hinder%20data%20owners%27%20willingness%20to%20participate%20and%20reduce%20the%0Aeffectiveness%20of%20data%20assetization.%20In%20this%20work%2C%20we%20first%20identify%20the%0Aresource-decoupled%20FL%20environment%2C%20which%20includes%20model%20owners%2C%20data%20owners%2C%0Aand%20computing%20centers.%20We%20design%20a%20Tripartite%20Stackelberg%20Model%20and%0Atheoretically%20analyze%20the%20Stackelberg-Nash%20Equilibrium%20%28SNE%29%20for%20participants%0Ato%20optimize%20global%20utility.%20We%20propose%20the%20Quality-aware%20Dynamic%0AResources-decoupled%20FL%20algorithm%20%28QD-RDFL%29%2C%20in%20which%20we%20derive%20and%20solve%20the%0Aoptimal%20strategies%20of%20all%20parties%20to%20achieve%20SHE%20using%20backward%20induction%2C%20and%0Aa%20dynamic%20optimization%20mechanism%20is%20designed%20to%20improve%20the%20optimal%20strategy%0Aprofile%20by%20evaluating%20the%20contribution%20of%20data%20quality%20from%20data%20owners%20to%20the%0Aglobal%20model%20during%20real%20training.%20Our%20comprehensive%20experiments%20demonstrate%0Athat%20our%20method%20effectively%20encourages%20the%20linkage%20of%20the%20three%20parties%0Ainvolved%2C%20maximizing%20global%20utility%20and%20data%20asset%20value.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14588v1&entry.124074799=Read"},
{"title": "NLP-based assessment of prescription appropriateness from Italian\n  referrals", "author": "Vittorio Torri and Annamaria Bottelli and Michele Ercolanoni and Olivia Leoni and Francesca Ieva", "abstract": "  Objective: This study proposes a Natural Language Processing pipeline to\nevaluate prescription appropriateness in Italian referrals, where reasons for\nprescriptions are recorded only as free text, complicating automated\ncomparisons with guidelines. The pipeline aims to derive, for the first time, a\ncomprehensive summary of the reasons behind these referrals and a\nquantification of their appropriateness. While demonstrated in a specific case\nstudy, the approach is designed to generalize to other types of examinations.\n  Methods: Leveraging embeddings from a transformer-based model, the proposed\napproach clusters referral texts, maps clusters to labels, and aligns these\nlabels with existing guidelines. We present a case study on a dataset of\n496,971 referrals, consisting of all referrals for venous echocolordopplers of\nthe lower limbs between 2019 and 2021 in the Lombardy Region. A sample of 1,000\nreferrals was manually annotated to validate the results.\n  Results: The pipeline exhibited high performance for referrals' reasons\n(Prec=92.43%, Rec=83.28%) and excellent results for referrals' appropriateness\n(Prec=93.58%, Rec=91.52%) on the annotated subset. Analysis of the entire\ndataset identified clusters matching guideline-defined reasons - both\nappropriate and inappropriate - as well as clusters not addressed in the\nguidelines. Overall, 34.32% of referrals were marked as appropriate, 34.07%\ninappropriate, 14.37% likely inappropriate, and 17.24% could not be mapped to\nguidelines.\n  Conclusions: The proposed pipeline effectively assessed prescription\nappropriateness across a large dataset, serving as a valuable tool for health\nauthorities. Findings have informed the Lombardy Region's efforts to strengthen\nrecommendations and reduce the burden of inappropriate referrals.\n", "link": "http://arxiv.org/abs/2501.14701v1", "date": "2025-01-24", "relevancy": 1.3021, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4492}, {"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.4374}, {"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "link": "http://arxiv.org/abs/2409.03757v1", "similarity": 0.4266}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20NLP-based%20assessment%20of%20prescription%20appropriateness%20from%20Italian%0A%20%20referrals&body=Title%3A%20NLP-based%20assessment%20of%20prescription%20appropriateness%20from%20Italian%0A%20%20referrals%0AAuthor%3A%20Vittorio%20Torri%20and%20Annamaria%20Bottelli%20and%20Michele%20Ercolanoni%20and%20Olivia%20Leoni%20and%20Francesca%20Ieva%0AAbstract%3A%20%20%20Objective%3A%20This%20study%20proposes%20a%20Natural%20Language%20Processing%20pipeline%20to%0Aevaluate%20prescription%20appropriateness%20in%20Italian%20referrals%2C%20where%20reasons%20for%0Aprescriptions%20are%20recorded%20only%20as%20free%20text%2C%20complicating%20automated%0Acomparisons%20with%20guidelines.%20The%20pipeline%20aims%20to%20derive%2C%20for%20the%20first%20time%2C%20a%0Acomprehensive%20summary%20of%20the%20reasons%20behind%20these%20referrals%20and%20a%0Aquantification%20of%20their%20appropriateness.%20While%20demonstrated%20in%20a%20specific%20case%0Astudy%2C%20the%20approach%20is%20designed%20to%20generalize%20to%20other%20types%20of%20examinations.%0A%20%20Methods%3A%20Leveraging%20embeddings%20from%20a%20transformer-based%20model%2C%20the%20proposed%0Aapproach%20clusters%20referral%20texts%2C%20maps%20clusters%20to%20labels%2C%20and%20aligns%20these%0Alabels%20with%20existing%20guidelines.%20We%20present%20a%20case%20study%20on%20a%20dataset%20of%0A496%2C971%20referrals%2C%20consisting%20of%20all%20referrals%20for%20venous%20echocolordopplers%20of%0Athe%20lower%20limbs%20between%202019%20and%202021%20in%20the%20Lombardy%20Region.%20A%20sample%20of%201%2C000%0Areferrals%20was%20manually%20annotated%20to%20validate%20the%20results.%0A%20%20Results%3A%20The%20pipeline%20exhibited%20high%20performance%20for%20referrals%27%20reasons%0A%28Prec%3D92.43%25%2C%20Rec%3D83.28%25%29%20and%20excellent%20results%20for%20referrals%27%20appropriateness%0A%28Prec%3D93.58%25%2C%20Rec%3D91.52%25%29%20on%20the%20annotated%20subset.%20Analysis%20of%20the%20entire%0Adataset%20identified%20clusters%20matching%20guideline-defined%20reasons%20-%20both%0Aappropriate%20and%20inappropriate%20-%20as%20well%20as%20clusters%20not%20addressed%20in%20the%0Aguidelines.%20Overall%2C%2034.32%25%20of%20referrals%20were%20marked%20as%20appropriate%2C%2034.07%25%0Ainappropriate%2C%2014.37%25%20likely%20inappropriate%2C%20and%2017.24%25%20could%20not%20be%20mapped%20to%0Aguidelines.%0A%20%20Conclusions%3A%20The%20proposed%20pipeline%20effectively%20assessed%20prescription%0Aappropriateness%20across%20a%20large%20dataset%2C%20serving%20as%20a%20valuable%20tool%20for%20health%0Aauthorities.%20Findings%20have%20informed%20the%20Lombardy%20Region%27s%20efforts%20to%20strengthen%0Arecommendations%20and%20reduce%20the%20burden%20of%20inappropriate%20referrals.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14701v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DNLP-based%2520assessment%2520of%2520prescription%2520appropriateness%2520from%2520Italian%250A%2520%2520referrals%26entry.906535625%3DVittorio%2520Torri%2520and%2520Annamaria%2520Bottelli%2520and%2520Michele%2520Ercolanoni%2520and%2520Olivia%2520Leoni%2520and%2520Francesca%2520Ieva%26entry.1292438233%3D%2520%2520Objective%253A%2520This%2520study%2520proposes%2520a%2520Natural%2520Language%2520Processing%2520pipeline%2520to%250Aevaluate%2520prescription%2520appropriateness%2520in%2520Italian%2520referrals%252C%2520where%2520reasons%2520for%250Aprescriptions%2520are%2520recorded%2520only%2520as%2520free%2520text%252C%2520complicating%2520automated%250Acomparisons%2520with%2520guidelines.%2520The%2520pipeline%2520aims%2520to%2520derive%252C%2520for%2520the%2520first%2520time%252C%2520a%250Acomprehensive%2520summary%2520of%2520the%2520reasons%2520behind%2520these%2520referrals%2520and%2520a%250Aquantification%2520of%2520their%2520appropriateness.%2520While%2520demonstrated%2520in%2520a%2520specific%2520case%250Astudy%252C%2520the%2520approach%2520is%2520designed%2520to%2520generalize%2520to%2520other%2520types%2520of%2520examinations.%250A%2520%2520Methods%253A%2520Leveraging%2520embeddings%2520from%2520a%2520transformer-based%2520model%252C%2520the%2520proposed%250Aapproach%2520clusters%2520referral%2520texts%252C%2520maps%2520clusters%2520to%2520labels%252C%2520and%2520aligns%2520these%250Alabels%2520with%2520existing%2520guidelines.%2520We%2520present%2520a%2520case%2520study%2520on%2520a%2520dataset%2520of%250A496%252C971%2520referrals%252C%2520consisting%2520of%2520all%2520referrals%2520for%2520venous%2520echocolordopplers%2520of%250Athe%2520lower%2520limbs%2520between%25202019%2520and%25202021%2520in%2520the%2520Lombardy%2520Region.%2520A%2520sample%2520of%25201%252C000%250Areferrals%2520was%2520manually%2520annotated%2520to%2520validate%2520the%2520results.%250A%2520%2520Results%253A%2520The%2520pipeline%2520exhibited%2520high%2520performance%2520for%2520referrals%2527%2520reasons%250A%2528Prec%253D92.43%2525%252C%2520Rec%253D83.28%2525%2529%2520and%2520excellent%2520results%2520for%2520referrals%2527%2520appropriateness%250A%2528Prec%253D93.58%2525%252C%2520Rec%253D91.52%2525%2529%2520on%2520the%2520annotated%2520subset.%2520Analysis%2520of%2520the%2520entire%250Adataset%2520identified%2520clusters%2520matching%2520guideline-defined%2520reasons%2520-%2520both%250Aappropriate%2520and%2520inappropriate%2520-%2520as%2520well%2520as%2520clusters%2520not%2520addressed%2520in%2520the%250Aguidelines.%2520Overall%252C%252034.32%2525%2520of%2520referrals%2520were%2520marked%2520as%2520appropriate%252C%252034.07%2525%250Ainappropriate%252C%252014.37%2525%2520likely%2520inappropriate%252C%2520and%252017.24%2525%2520could%2520not%2520be%2520mapped%2520to%250Aguidelines.%250A%2520%2520Conclusions%253A%2520The%2520proposed%2520pipeline%2520effectively%2520assessed%2520prescription%250Aappropriateness%2520across%2520a%2520large%2520dataset%252C%2520serving%2520as%2520a%2520valuable%2520tool%2520for%2520health%250Aauthorities.%2520Findings%2520have%2520informed%2520the%2520Lombardy%2520Region%2527s%2520efforts%2520to%2520strengthen%250Arecommendations%2520and%2520reduce%2520the%2520burden%2520of%2520inappropriate%2520referrals.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14701v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=NLP-based%20assessment%20of%20prescription%20appropriateness%20from%20Italian%0A%20%20referrals&entry.906535625=Vittorio%20Torri%20and%20Annamaria%20Bottelli%20and%20Michele%20Ercolanoni%20and%20Olivia%20Leoni%20and%20Francesca%20Ieva&entry.1292438233=%20%20Objective%3A%20This%20study%20proposes%20a%20Natural%20Language%20Processing%20pipeline%20to%0Aevaluate%20prescription%20appropriateness%20in%20Italian%20referrals%2C%20where%20reasons%20for%0Aprescriptions%20are%20recorded%20only%20as%20free%20text%2C%20complicating%20automated%0Acomparisons%20with%20guidelines.%20The%20pipeline%20aims%20to%20derive%2C%20for%20the%20first%20time%2C%20a%0Acomprehensive%20summary%20of%20the%20reasons%20behind%20these%20referrals%20and%20a%0Aquantification%20of%20their%20appropriateness.%20While%20demonstrated%20in%20a%20specific%20case%0Astudy%2C%20the%20approach%20is%20designed%20to%20generalize%20to%20other%20types%20of%20examinations.%0A%20%20Methods%3A%20Leveraging%20embeddings%20from%20a%20transformer-based%20model%2C%20the%20proposed%0Aapproach%20clusters%20referral%20texts%2C%20maps%20clusters%20to%20labels%2C%20and%20aligns%20these%0Alabels%20with%20existing%20guidelines.%20We%20present%20a%20case%20study%20on%20a%20dataset%20of%0A496%2C971%20referrals%2C%20consisting%20of%20all%20referrals%20for%20venous%20echocolordopplers%20of%0Athe%20lower%20limbs%20between%202019%20and%202021%20in%20the%20Lombardy%20Region.%20A%20sample%20of%201%2C000%0Areferrals%20was%20manually%20annotated%20to%20validate%20the%20results.%0A%20%20Results%3A%20The%20pipeline%20exhibited%20high%20performance%20for%20referrals%27%20reasons%0A%28Prec%3D92.43%25%2C%20Rec%3D83.28%25%29%20and%20excellent%20results%20for%20referrals%27%20appropriateness%0A%28Prec%3D93.58%25%2C%20Rec%3D91.52%25%29%20on%20the%20annotated%20subset.%20Analysis%20of%20the%20entire%0Adataset%20identified%20clusters%20matching%20guideline-defined%20reasons%20-%20both%0Aappropriate%20and%20inappropriate%20-%20as%20well%20as%20clusters%20not%20addressed%20in%20the%0Aguidelines.%20Overall%2C%2034.32%25%20of%20referrals%20were%20marked%20as%20appropriate%2C%2034.07%25%0Ainappropriate%2C%2014.37%25%20likely%20inappropriate%2C%20and%2017.24%25%20could%20not%20be%20mapped%20to%0Aguidelines.%0A%20%20Conclusions%3A%20The%20proposed%20pipeline%20effectively%20assessed%20prescription%0Aappropriateness%20across%20a%20large%20dataset%2C%20serving%20as%20a%20valuable%20tool%20for%20health%0Aauthorities.%20Findings%20have%20informed%20the%20Lombardy%20Region%27s%20efforts%20to%20strengthen%0Arecommendations%20and%20reduce%20the%20burden%20of%20inappropriate%20referrals.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14701v1&entry.124074799=Read"},
{"title": "Mitigating GenAI-powered Evidence Pollution for Out-of-Context\n  Multimodal Misinformation Detection", "author": "Zehong Yan and Peng Qi and Wynne Hsu and Mong Li Lee", "abstract": "  While large generative artificial intelligence (GenAI) models have achieved\nsignificant success, they also raise growing concerns about online information\nsecurity due to their potential misuse for generating deceptive content.\nOut-of-context (OOC) multimodal misinformation detection, which often retrieves\nWeb evidence to identify the repurposing of images in false contexts, faces the\nissue of reasoning over GenAI-polluted evidence to derive accurate predictions.\nExisting works simulate GenAI-powered pollution at the claim level with\nstylistic rewriting to conceal linguistic cues, and ignore evidence-level\npollution for such information-seeking applications. In this work, we\ninvestigate how polluted evidence affects the performance of existing OOC\ndetectors, revealing a performance degradation of more than 9 percentage\npoints. We propose two strategies, cross-modal evidence reranking and\ncross-modal claim-evidence reasoning, to address the challenges posed by\npolluted evidence. Extensive experiments on two benchmark datasets show that\nthese strategies can effectively enhance the robustness of existing\nout-of-context detectors amidst polluted evidence.\n", "link": "http://arxiv.org/abs/2501.14728v1", "date": "2025-01-24", "relevancy": 1.0446, "topK": [{"title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential\n  Deep Learning", "link": "http://arxiv.org/abs/2309.09599v3", "similarity": 0.5533}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.5075}, {"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.5062}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Mitigating%20GenAI-powered%20Evidence%20Pollution%20for%20Out-of-Context%0A%20%20Multimodal%20Misinformation%20Detection&body=Title%3A%20Mitigating%20GenAI-powered%20Evidence%20Pollution%20for%20Out-of-Context%0A%20%20Multimodal%20Misinformation%20Detection%0AAuthor%3A%20Zehong%20Yan%20and%20Peng%20Qi%20and%20Wynne%20Hsu%20and%20Mong%20Li%20Lee%0AAbstract%3A%20%20%20While%20large%20generative%20artificial%20intelligence%20%28GenAI%29%20models%20have%20achieved%0Asignificant%20success%2C%20they%20also%20raise%20growing%20concerns%20about%20online%20information%0Asecurity%20due%20to%20their%20potential%20misuse%20for%20generating%20deceptive%20content.%0AOut-of-context%20%28OOC%29%20multimodal%20misinformation%20detection%2C%20which%20often%20retrieves%0AWeb%20evidence%20to%20identify%20the%20repurposing%20of%20images%20in%20false%20contexts%2C%20faces%20the%0Aissue%20of%20reasoning%20over%20GenAI-polluted%20evidence%20to%20derive%20accurate%20predictions.%0AExisting%20works%20simulate%20GenAI-powered%20pollution%20at%20the%20claim%20level%20with%0Astylistic%20rewriting%20to%20conceal%20linguistic%20cues%2C%20and%20ignore%20evidence-level%0Apollution%20for%20such%20information-seeking%20applications.%20In%20this%20work%2C%20we%0Ainvestigate%20how%20polluted%20evidence%20affects%20the%20performance%20of%20existing%20OOC%0Adetectors%2C%20revealing%20a%20performance%20degradation%20of%20more%20than%209%20percentage%0Apoints.%20We%20propose%20two%20strategies%2C%20cross-modal%20evidence%20reranking%20and%0Across-modal%20claim-evidence%20reasoning%2C%20to%20address%20the%20challenges%20posed%20by%0Apolluted%20evidence.%20Extensive%20experiments%20on%20two%20benchmark%20datasets%20show%20that%0Athese%20strategies%20can%20effectively%20enhance%20the%20robustness%20of%20existing%0Aout-of-context%20detectors%20amidst%20polluted%20evidence.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14728v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DMitigating%2520GenAI-powered%2520Evidence%2520Pollution%2520for%2520Out-of-Context%250A%2520%2520Multimodal%2520Misinformation%2520Detection%26entry.906535625%3DZehong%2520Yan%2520and%2520Peng%2520Qi%2520and%2520Wynne%2520Hsu%2520and%2520Mong%2520Li%2520Lee%26entry.1292438233%3D%2520%2520While%2520large%2520generative%2520artificial%2520intelligence%2520%2528GenAI%2529%2520models%2520have%2520achieved%250Asignificant%2520success%252C%2520they%2520also%2520raise%2520growing%2520concerns%2520about%2520online%2520information%250Asecurity%2520due%2520to%2520their%2520potential%2520misuse%2520for%2520generating%2520deceptive%2520content.%250AOut-of-context%2520%2528OOC%2529%2520multimodal%2520misinformation%2520detection%252C%2520which%2520often%2520retrieves%250AWeb%2520evidence%2520to%2520identify%2520the%2520repurposing%2520of%2520images%2520in%2520false%2520contexts%252C%2520faces%2520the%250Aissue%2520of%2520reasoning%2520over%2520GenAI-polluted%2520evidence%2520to%2520derive%2520accurate%2520predictions.%250AExisting%2520works%2520simulate%2520GenAI-powered%2520pollution%2520at%2520the%2520claim%2520level%2520with%250Astylistic%2520rewriting%2520to%2520conceal%2520linguistic%2520cues%252C%2520and%2520ignore%2520evidence-level%250Apollution%2520for%2520such%2520information-seeking%2520applications.%2520In%2520this%2520work%252C%2520we%250Ainvestigate%2520how%2520polluted%2520evidence%2520affects%2520the%2520performance%2520of%2520existing%2520OOC%250Adetectors%252C%2520revealing%2520a%2520performance%2520degradation%2520of%2520more%2520than%25209%2520percentage%250Apoints.%2520We%2520propose%2520two%2520strategies%252C%2520cross-modal%2520evidence%2520reranking%2520and%250Across-modal%2520claim-evidence%2520reasoning%252C%2520to%2520address%2520the%2520challenges%2520posed%2520by%250Apolluted%2520evidence.%2520Extensive%2520experiments%2520on%2520two%2520benchmark%2520datasets%2520show%2520that%250Athese%2520strategies%2520can%2520effectively%2520enhance%2520the%2520robustness%2520of%2520existing%250Aout-of-context%2520detectors%2520amidst%2520polluted%2520evidence.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14728v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Mitigating%20GenAI-powered%20Evidence%20Pollution%20for%20Out-of-Context%0A%20%20Multimodal%20Misinformation%20Detection&entry.906535625=Zehong%20Yan%20and%20Peng%20Qi%20and%20Wynne%20Hsu%20and%20Mong%20Li%20Lee&entry.1292438233=%20%20While%20large%20generative%20artificial%20intelligence%20%28GenAI%29%20models%20have%20achieved%0Asignificant%20success%2C%20they%20also%20raise%20growing%20concerns%20about%20online%20information%0Asecurity%20due%20to%20their%20potential%20misuse%20for%20generating%20deceptive%20content.%0AOut-of-context%20%28OOC%29%20multimodal%20misinformation%20detection%2C%20which%20often%20retrieves%0AWeb%20evidence%20to%20identify%20the%20repurposing%20of%20images%20in%20false%20contexts%2C%20faces%20the%0Aissue%20of%20reasoning%20over%20GenAI-polluted%20evidence%20to%20derive%20accurate%20predictions.%0AExisting%20works%20simulate%20GenAI-powered%20pollution%20at%20the%20claim%20level%20with%0Astylistic%20rewriting%20to%20conceal%20linguistic%20cues%2C%20and%20ignore%20evidence-level%0Apollution%20for%20such%20information-seeking%20applications.%20In%20this%20work%2C%20we%0Ainvestigate%20how%20polluted%20evidence%20affects%20the%20performance%20of%20existing%20OOC%0Adetectors%2C%20revealing%20a%20performance%20degradation%20of%20more%20than%209%20percentage%0Apoints.%20We%20propose%20two%20strategies%2C%20cross-modal%20evidence%20reranking%20and%0Across-modal%20claim-evidence%20reasoning%2C%20to%20address%20the%20challenges%20posed%20by%0Apolluted%20evidence.%20Extensive%20experiments%20on%20two%20benchmark%20datasets%20show%20that%0Athese%20strategies%20can%20effectively%20enhance%20the%20robustness%20of%20existing%0Aout-of-context%20detectors%20amidst%20polluted%20evidence.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14728v1&entry.124074799=Read"},
{"title": "coverforest: Conformal Predictions with Random Forest in Python", "author": "Panisara Meehinkong and Donlapark Ponnoprat", "abstract": "  Conformal prediction provides a framework for uncertainty quantification,\nspecifically in the forms of prediction intervals and sets with\ndistribution-free guaranteed coverage. While recent cross-conformal techniques\nsuch as CV+ and Jackknife+-after-bootstrap achieve better data efficiency than\ntraditional split conformal methods, they incur substantial computational costs\ndue to required pairwise comparisons between training and test samples'\nout-of-bag scores. Observing that these methods naturally extend from ensemble\nmodels, particularly random forests, we leverage existing optimized random\nforest implementations to enable efficient cross-conformal predictions.\n  We present coverforest, a Python package that implements efficient conformal\nprediction methods specifically optimized for random forests. coverforest\nsupports both regression and classification tasks through various conformal\nprediction methods, including split conformal, CV+, Jackknife+-after-bootstrap,\nand adaptive prediction sets. Our package leverages parallel computing and\nCython optimizations to speed up out-of-bag calculations. Our experiments\ndemonstrate that coverforest's predictions achieve the desired level of\ncoverage. In addition, its training and prediction times can be faster than an\nexisting implementation by 2--9 times. The source code for the coverforest is\nhosted on GitHub at https://github.com/donlapark/coverforest.\n", "link": "http://arxiv.org/abs/2501.14570v1", "date": "2025-01-24", "relevancy": 1.2697, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4519}, {"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.4185}, {"title": "Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance", "link": "http://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html", "similarity": 0.4137}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20coverforest%3A%20Conformal%20Predictions%20with%20Random%20Forest%20in%20Python&body=Title%3A%20coverforest%3A%20Conformal%20Predictions%20with%20Random%20Forest%20in%20Python%0AAuthor%3A%20Panisara%20Meehinkong%20and%20Donlapark%20Ponnoprat%0AAbstract%3A%20%20%20Conformal%20prediction%20provides%20a%20framework%20for%20uncertainty%20quantification%2C%0Aspecifically%20in%20the%20forms%20of%20prediction%20intervals%20and%20sets%20with%0Adistribution-free%20guaranteed%20coverage.%20While%20recent%20cross-conformal%20techniques%0Asuch%20as%20CV%2B%20and%20Jackknife%2B-after-bootstrap%20achieve%20better%20data%20efficiency%20than%0Atraditional%20split%20conformal%20methods%2C%20they%20incur%20substantial%20computational%20costs%0Adue%20to%20required%20pairwise%20comparisons%20between%20training%20and%20test%20samples%27%0Aout-of-bag%20scores.%20Observing%20that%20these%20methods%20naturally%20extend%20from%20ensemble%0Amodels%2C%20particularly%20random%20forests%2C%20we%20leverage%20existing%20optimized%20random%0Aforest%20implementations%20to%20enable%20efficient%20cross-conformal%20predictions.%0A%20%20We%20present%20coverforest%2C%20a%20Python%20package%20that%20implements%20efficient%20conformal%0Aprediction%20methods%20specifically%20optimized%20for%20random%20forests.%20coverforest%0Asupports%20both%20regression%20and%20classification%20tasks%20through%20various%20conformal%0Aprediction%20methods%2C%20including%20split%20conformal%2C%20CV%2B%2C%20Jackknife%2B-after-bootstrap%2C%0Aand%20adaptive%20prediction%20sets.%20Our%20package%20leverages%20parallel%20computing%20and%0ACython%20optimizations%20to%20speed%20up%20out-of-bag%20calculations.%20Our%20experiments%0Ademonstrate%20that%20coverforest%27s%20predictions%20achieve%20the%20desired%20level%20of%0Acoverage.%20In%20addition%2C%20its%20training%20and%20prediction%20times%20can%20be%20faster%20than%20an%0Aexisting%20implementation%20by%202--9%20times.%20The%20source%20code%20for%20the%20coverforest%20is%0Ahosted%20on%20GitHub%20at%20https%3A//github.com/donlapark/coverforest.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14570v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3Dcoverforest%253A%2520Conformal%2520Predictions%2520with%2520Random%2520Forest%2520in%2520Python%26entry.906535625%3DPanisara%2520Meehinkong%2520and%2520Donlapark%2520Ponnoprat%26entry.1292438233%3D%2520%2520Conformal%2520prediction%2520provides%2520a%2520framework%2520for%2520uncertainty%2520quantification%252C%250Aspecifically%2520in%2520the%2520forms%2520of%2520prediction%2520intervals%2520and%2520sets%2520with%250Adistribution-free%2520guaranteed%2520coverage.%2520While%2520recent%2520cross-conformal%2520techniques%250Asuch%2520as%2520CV%252B%2520and%2520Jackknife%252B-after-bootstrap%2520achieve%2520better%2520data%2520efficiency%2520than%250Atraditional%2520split%2520conformal%2520methods%252C%2520they%2520incur%2520substantial%2520computational%2520costs%250Adue%2520to%2520required%2520pairwise%2520comparisons%2520between%2520training%2520and%2520test%2520samples%2527%250Aout-of-bag%2520scores.%2520Observing%2520that%2520these%2520methods%2520naturally%2520extend%2520from%2520ensemble%250Amodels%252C%2520particularly%2520random%2520forests%252C%2520we%2520leverage%2520existing%2520optimized%2520random%250Aforest%2520implementations%2520to%2520enable%2520efficient%2520cross-conformal%2520predictions.%250A%2520%2520We%2520present%2520coverforest%252C%2520a%2520Python%2520package%2520that%2520implements%2520efficient%2520conformal%250Aprediction%2520methods%2520specifically%2520optimized%2520for%2520random%2520forests.%2520coverforest%250Asupports%2520both%2520regression%2520and%2520classification%2520tasks%2520through%2520various%2520conformal%250Aprediction%2520methods%252C%2520including%2520split%2520conformal%252C%2520CV%252B%252C%2520Jackknife%252B-after-bootstrap%252C%250Aand%2520adaptive%2520prediction%2520sets.%2520Our%2520package%2520leverages%2520parallel%2520computing%2520and%250ACython%2520optimizations%2520to%2520speed%2520up%2520out-of-bag%2520calculations.%2520Our%2520experiments%250Ademonstrate%2520that%2520coverforest%2527s%2520predictions%2520achieve%2520the%2520desired%2520level%2520of%250Acoverage.%2520In%2520addition%252C%2520its%2520training%2520and%2520prediction%2520times%2520can%2520be%2520faster%2520than%2520an%250Aexisting%2520implementation%2520by%25202--9%2520times.%2520The%2520source%2520code%2520for%2520the%2520coverforest%2520is%250Ahosted%2520on%2520GitHub%2520at%2520https%253A//github.com/donlapark/coverforest.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14570v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=coverforest%3A%20Conformal%20Predictions%20with%20Random%20Forest%20in%20Python&entry.906535625=Panisara%20Meehinkong%20and%20Donlapark%20Ponnoprat&entry.1292438233=%20%20Conformal%20prediction%20provides%20a%20framework%20for%20uncertainty%20quantification%2C%0Aspecifically%20in%20the%20forms%20of%20prediction%20intervals%20and%20sets%20with%0Adistribution-free%20guaranteed%20coverage.%20While%20recent%20cross-conformal%20techniques%0Asuch%20as%20CV%2B%20and%20Jackknife%2B-after-bootstrap%20achieve%20better%20data%20efficiency%20than%0Atraditional%20split%20conformal%20methods%2C%20they%20incur%20substantial%20computational%20costs%0Adue%20to%20required%20pairwise%20comparisons%20between%20training%20and%20test%20samples%27%0Aout-of-bag%20scores.%20Observing%20that%20these%20methods%20naturally%20extend%20from%20ensemble%0Amodels%2C%20particularly%20random%20forests%2C%20we%20leverage%20existing%20optimized%20random%0Aforest%20implementations%20to%20enable%20efficient%20cross-conformal%20predictions.%0A%20%20We%20present%20coverforest%2C%20a%20Python%20package%20that%20implements%20efficient%20conformal%0Aprediction%20methods%20specifically%20optimized%20for%20random%20forests.%20coverforest%0Asupports%20both%20regression%20and%20classification%20tasks%20through%20various%20conformal%0Aprediction%20methods%2C%20including%20split%20conformal%2C%20CV%2B%2C%20Jackknife%2B-after-bootstrap%2C%0Aand%20adaptive%20prediction%20sets.%20Our%20package%20leverages%20parallel%20computing%20and%0ACython%20optimizations%20to%20speed%20up%20out-of-bag%20calculations.%20Our%20experiments%0Ademonstrate%20that%20coverforest%27s%20predictions%20achieve%20the%20desired%20level%20of%0Acoverage.%20In%20addition%2C%20its%20training%20and%20prediction%20times%20can%20be%20faster%20than%20an%0Aexisting%20implementation%20by%202--9%20times.%20The%20source%20code%20for%20the%20coverforest%20is%0Ahosted%20on%20GitHub%20at%20https%3A//github.com/donlapark/coverforest.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14570v1&entry.124074799=Read"},
{"title": "Controlling Moments with Kernel Stein Discrepancies", "author": "Heishiro Kanagawa and Alessandro Barp and Arthur Gretton and Lester Mackey", "abstract": "  Kernel Stein discrepancies (KSDs) measure the quality of a distributional\napproximation and can be computed even when the target density has an\nintractable normalizing constant. Notable applications include the diagnosis of\napproximate MCMC samplers and goodness-of-fit tests for unnormalized\nstatistical models. The present work analyzes the convergence control\nproperties of KSDs. We first show that standard KSDs used for weak convergence\ncontrol fail to control moment convergence. To address this limitation, we next\nprovide sufficient conditions under which alternative diffusion KSDs control\nboth moment and weak convergence. As an immediate consequence we develop, for\neach $q > 0$, the first KSDs known to exactly characterize $q$-Wasserstein\nconvergence.\n", "link": "http://arxiv.org/abs/2211.05408v6", "date": "2025-01-24", "relevancy": 1.2734, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.4532}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.4253}, {"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.3935}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Controlling%20Moments%20with%20Kernel%20Stein%20Discrepancies&body=Title%3A%20Controlling%20Moments%20with%20Kernel%20Stein%20Discrepancies%0AAuthor%3A%20Heishiro%20Kanagawa%20and%20Alessandro%20Barp%20and%20Arthur%20Gretton%20and%20Lester%20Mackey%0AAbstract%3A%20%20%20Kernel%20Stein%20discrepancies%20%28KSDs%29%20measure%20the%20quality%20of%20a%20distributional%0Aapproximation%20and%20can%20be%20computed%20even%20when%20the%20target%20density%20has%20an%0Aintractable%20normalizing%20constant.%20Notable%20applications%20include%20the%20diagnosis%20of%0Aapproximate%20MCMC%20samplers%20and%20goodness-of-fit%20tests%20for%20unnormalized%0Astatistical%20models.%20The%20present%20work%20analyzes%20the%20convergence%20control%0Aproperties%20of%20KSDs.%20We%20first%20show%20that%20standard%20KSDs%20used%20for%20weak%20convergence%0Acontrol%20fail%20to%20control%20moment%20convergence.%20To%20address%20this%20limitation%2C%20we%20next%0Aprovide%20sufficient%20conditions%20under%20which%20alternative%20diffusion%20KSDs%20control%0Aboth%20moment%20and%20weak%20convergence.%20As%20an%20immediate%20consequence%20we%20develop%2C%20for%0Aeach%20%24q%20%3E%200%24%2C%20the%20first%20KSDs%20known%20to%20exactly%20characterize%20%24q%24-Wasserstein%0Aconvergence.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2211.05408v6%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DControlling%2520Moments%2520with%2520Kernel%2520Stein%2520Discrepancies%26entry.906535625%3DHeishiro%2520Kanagawa%2520and%2520Alessandro%2520Barp%2520and%2520Arthur%2520Gretton%2520and%2520Lester%2520Mackey%26entry.1292438233%3D%2520%2520Kernel%2520Stein%2520discrepancies%2520%2528KSDs%2529%2520measure%2520the%2520quality%2520of%2520a%2520distributional%250Aapproximation%2520and%2520can%2520be%2520computed%2520even%2520when%2520the%2520target%2520density%2520has%2520an%250Aintractable%2520normalizing%2520constant.%2520Notable%2520applications%2520include%2520the%2520diagnosis%2520of%250Aapproximate%2520MCMC%2520samplers%2520and%2520goodness-of-fit%2520tests%2520for%2520unnormalized%250Astatistical%2520models.%2520The%2520present%2520work%2520analyzes%2520the%2520convergence%2520control%250Aproperties%2520of%2520KSDs.%2520We%2520first%2520show%2520that%2520standard%2520KSDs%2520used%2520for%2520weak%2520convergence%250Acontrol%2520fail%2520to%2520control%2520moment%2520convergence.%2520To%2520address%2520this%2520limitation%252C%2520we%2520next%250Aprovide%2520sufficient%2520conditions%2520under%2520which%2520alternative%2520diffusion%2520KSDs%2520control%250Aboth%2520moment%2520and%2520weak%2520convergence.%2520As%2520an%2520immediate%2520consequence%2520we%2520develop%252C%2520for%250Aeach%2520%2524q%2520%253E%25200%2524%252C%2520the%2520first%2520KSDs%2520known%2520to%2520exactly%2520characterize%2520%2524q%2524-Wasserstein%250Aconvergence.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2211.05408v6%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Controlling%20Moments%20with%20Kernel%20Stein%20Discrepancies&entry.906535625=Heishiro%20Kanagawa%20and%20Alessandro%20Barp%20and%20Arthur%20Gretton%20and%20Lester%20Mackey&entry.1292438233=%20%20Kernel%20Stein%20discrepancies%20%28KSDs%29%20measure%20the%20quality%20of%20a%20distributional%0Aapproximation%20and%20can%20be%20computed%20even%20when%20the%20target%20density%20has%20an%0Aintractable%20normalizing%20constant.%20Notable%20applications%20include%20the%20diagnosis%20of%0Aapproximate%20MCMC%20samplers%20and%20goodness-of-fit%20tests%20for%20unnormalized%0Astatistical%20models.%20The%20present%20work%20analyzes%20the%20convergence%20control%0Aproperties%20of%20KSDs.%20We%20first%20show%20that%20standard%20KSDs%20used%20for%20weak%20convergence%0Acontrol%20fail%20to%20control%20moment%20convergence.%20To%20address%20this%20limitation%2C%20we%20next%0Aprovide%20sufficient%20conditions%20under%20which%20alternative%20diffusion%20KSDs%20control%0Aboth%20moment%20and%20weak%20convergence.%20As%20an%20immediate%20consequence%20we%20develop%2C%20for%0Aeach%20%24q%20%3E%200%24%2C%20the%20first%20KSDs%20known%20to%20exactly%20characterize%20%24q%24-Wasserstein%0Aconvergence.%0A&entry.1838667208=http%3A//arxiv.org/abs/2211.05408v6&entry.124074799=Read"},
{"title": "PCM Selector: Penalized Covariate-Mediator Selection Operator for\n  Evaluating Linear Causal Effects", "author": "Hisayoshi Nanmo and Manabu Kuroki", "abstract": "  For a data-generating process for random variables that can be described with\na linear structural equation model, we consider a situation in which (i) a set\nof covariates satisfying the back-door criterion cannot be observed or (ii)\nsuch a set can be observed, but standard statistical estimation methods cannot\nbe applied to estimate causal effects because of\nmulticollinearity/high-dimensional data problems. We propose a novel two-stage\npenalized regression approach, the penalized covariate-mediator selection\noperator (PCM Selector), to estimate the causal effects in such scenarios.\nUnlike existing penalized regression analyses, when a set of intermediate\nvariables is available, PCM Selector provides a consistent or less biased\nestimator of the causal effect. In addition, PCM Selector provides a variable\nselection procedure for intermediate variables to obtain better estimation\naccuracy of the causal effects than does the back-door criterion.\n", "link": "http://arxiv.org/abs/2412.18180v2", "date": "2025-01-24", "relevancy": 0.8092, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4203}, {"title": "Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing", "link": "http://arxiv.org/abs/2403.14828v2", "similarity": 0.419}, {"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.3745}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20PCM%20Selector%3A%20Penalized%20Covariate-Mediator%20Selection%20Operator%20for%0A%20%20Evaluating%20Linear%20Causal%20Effects&body=Title%3A%20PCM%20Selector%3A%20Penalized%20Covariate-Mediator%20Selection%20Operator%20for%0A%20%20Evaluating%20Linear%20Causal%20Effects%0AAuthor%3A%20Hisayoshi%20Nanmo%20and%20Manabu%20Kuroki%0AAbstract%3A%20%20%20For%20a%20data-generating%20process%20for%20random%20variables%20that%20can%20be%20described%20with%0Aa%20linear%20structural%20equation%20model%2C%20we%20consider%20a%20situation%20in%20which%20%28i%29%20a%20set%0Aof%20covariates%20satisfying%20the%20back-door%20criterion%20cannot%20be%20observed%20or%20%28ii%29%0Asuch%20a%20set%20can%20be%20observed%2C%20but%20standard%20statistical%20estimation%20methods%20cannot%0Abe%20applied%20to%20estimate%20causal%20effects%20because%20of%0Amulticollinearity/high-dimensional%20data%20problems.%20We%20propose%20a%20novel%20two-stage%0Apenalized%20regression%20approach%2C%20the%20penalized%20covariate-mediator%20selection%0Aoperator%20%28PCM%20Selector%29%2C%20to%20estimate%20the%20causal%20effects%20in%20such%20scenarios.%0AUnlike%20existing%20penalized%20regression%20analyses%2C%20when%20a%20set%20of%20intermediate%0Avariables%20is%20available%2C%20PCM%20Selector%20provides%20a%20consistent%20or%20less%20biased%0Aestimator%20of%20the%20causal%20effect.%20In%20addition%2C%20PCM%20Selector%20provides%20a%20variable%0Aselection%20procedure%20for%20intermediate%20variables%20to%20obtain%20better%20estimation%0Aaccuracy%20of%20the%20causal%20effects%20than%20does%20the%20back-door%20criterion.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2412.18180v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DPCM%2520Selector%253A%2520Penalized%2520Covariate-Mediator%2520Selection%2520Operator%2520for%250A%2520%2520Evaluating%2520Linear%2520Causal%2520Effects%26entry.906535625%3DHisayoshi%2520Nanmo%2520and%2520Manabu%2520Kuroki%26entry.1292438233%3D%2520%2520For%2520a%2520data-generating%2520process%2520for%2520random%2520variables%2520that%2520can%2520be%2520described%2520with%250Aa%2520linear%2520structural%2520equation%2520model%252C%2520we%2520consider%2520a%2520situation%2520in%2520which%2520%2528i%2529%2520a%2520set%250Aof%2520covariates%2520satisfying%2520the%2520back-door%2520criterion%2520cannot%2520be%2520observed%2520or%2520%2528ii%2529%250Asuch%2520a%2520set%2520can%2520be%2520observed%252C%2520but%2520standard%2520statistical%2520estimation%2520methods%2520cannot%250Abe%2520applied%2520to%2520estimate%2520causal%2520effects%2520because%2520of%250Amulticollinearity/high-dimensional%2520data%2520problems.%2520We%2520propose%2520a%2520novel%2520two-stage%250Apenalized%2520regression%2520approach%252C%2520the%2520penalized%2520covariate-mediator%2520selection%250Aoperator%2520%2528PCM%2520Selector%2529%252C%2520to%2520estimate%2520the%2520causal%2520effects%2520in%2520such%2520scenarios.%250AUnlike%2520existing%2520penalized%2520regression%2520analyses%252C%2520when%2520a%2520set%2520of%2520intermediate%250Avariables%2520is%2520available%252C%2520PCM%2520Selector%2520provides%2520a%2520consistent%2520or%2520less%2520biased%250Aestimator%2520of%2520the%2520causal%2520effect.%2520In%2520addition%252C%2520PCM%2520Selector%2520provides%2520a%2520variable%250Aselection%2520procedure%2520for%2520intermediate%2520variables%2520to%2520obtain%2520better%2520estimation%250Aaccuracy%2520of%2520the%2520causal%2520effects%2520than%2520does%2520the%2520back-door%2520criterion.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2412.18180v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=PCM%20Selector%3A%20Penalized%20Covariate-Mediator%20Selection%20Operator%20for%0A%20%20Evaluating%20Linear%20Causal%20Effects&entry.906535625=Hisayoshi%20Nanmo%20and%20Manabu%20Kuroki&entry.1292438233=%20%20For%20a%20data-generating%20process%20for%20random%20variables%20that%20can%20be%20described%20with%0Aa%20linear%20structural%20equation%20model%2C%20we%20consider%20a%20situation%20in%20which%20%28i%29%20a%20set%0Aof%20covariates%20satisfying%20the%20back-door%20criterion%20cannot%20be%20observed%20or%20%28ii%29%0Asuch%20a%20set%20can%20be%20observed%2C%20but%20standard%20statistical%20estimation%20methods%20cannot%0Abe%20applied%20to%20estimate%20causal%20effects%20because%20of%0Amulticollinearity/high-dimensional%20data%20problems.%20We%20propose%20a%20novel%20two-stage%0Apenalized%20regression%20approach%2C%20the%20penalized%20covariate-mediator%20selection%0Aoperator%20%28PCM%20Selector%29%2C%20to%20estimate%20the%20causal%20effects%20in%20such%20scenarios.%0AUnlike%20existing%20penalized%20regression%20analyses%2C%20when%20a%20set%20of%20intermediate%0Avariables%20is%20available%2C%20PCM%20Selector%20provides%20a%20consistent%20or%20less%20biased%0Aestimator%20of%20the%20causal%20effect.%20In%20addition%2C%20PCM%20Selector%20provides%20a%20variable%0Aselection%20procedure%20for%20intermediate%20variables%20to%20obtain%20better%20estimation%0Aaccuracy%20of%20the%20causal%20effects%20than%20does%20the%20back-door%20criterion.%0A&entry.1838667208=http%3A//arxiv.org/abs/2412.18180v2&entry.124074799=Read"},
{"title": "QuIP: Experimental design for expensive simulators with many Qualitative\n  factors via Integer Programming", "author": "Yen-Chun Liu and Simon Mak", "abstract": "  The need to explore and/or optimize expensive simulators with many\nqualitative factors arises in broad scientific and engineering problems. Our\nmotivating application lies in path planning - the exploration of feasible\npaths for navigation, which plays an important role in robotics, surgical\nplanning and assembly planning. Here, the feasibility of a path is evaluated\nvia expensive virtual experiments, and its parameter space is typically\ndiscrete and high-dimensional. A carefully selected experimental design is thus\nessential for timely decision-making. We propose here a novel framework, called\nQuIP, for experimental design of Qualitative factors via Integer Programming\nunder a Gaussian process surrogate model with an exchangeable covariance\nfunction. For initial design, we show that its asymptotic D-optimal design can\nbe formulated as a variant of the well-known assignment problem in operations\nresearch, which can be efficiently solved to global optimality using\nstate-of-the-art integer programming solvers. For sequential design\n(specifically, for active learning or black-box optimization), we show that its\ndesign criterion can similarly be formulated as an assignment problem, thus\nenabling efficient and reliable optimization with existing solvers. We then\ndemonstrate the effectiveness of QuIP over existing methods in a suite of path\nplanning experiments and an application to rover trajectory optimization.\n", "link": "http://arxiv.org/abs/2501.14616v1", "date": "2025-01-24", "relevancy": 0.8956, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4585}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4567}, {"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.4282}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20QuIP%3A%20Experimental%20design%20for%20expensive%20simulators%20with%20many%20Qualitative%0A%20%20factors%20via%20Integer%20Programming&body=Title%3A%20QuIP%3A%20Experimental%20design%20for%20expensive%20simulators%20with%20many%20Qualitative%0A%20%20factors%20via%20Integer%20Programming%0AAuthor%3A%20Yen-Chun%20Liu%20and%20Simon%20Mak%0AAbstract%3A%20%20%20The%20need%20to%20explore%20and/or%20optimize%20expensive%20simulators%20with%20many%0Aqualitative%20factors%20arises%20in%20broad%20scientific%20and%20engineering%20problems.%20Our%0Amotivating%20application%20lies%20in%20path%20planning%20-%20the%20exploration%20of%20feasible%0Apaths%20for%20navigation%2C%20which%20plays%20an%20important%20role%20in%20robotics%2C%20surgical%0Aplanning%20and%20assembly%20planning.%20Here%2C%20the%20feasibility%20of%20a%20path%20is%20evaluated%0Avia%20expensive%20virtual%20experiments%2C%20and%20its%20parameter%20space%20is%20typically%0Adiscrete%20and%20high-dimensional.%20A%20carefully%20selected%20experimental%20design%20is%20thus%0Aessential%20for%20timely%20decision-making.%20We%20propose%20here%20a%20novel%20framework%2C%20called%0AQuIP%2C%20for%20experimental%20design%20of%20Qualitative%20factors%20via%20Integer%20Programming%0Aunder%20a%20Gaussian%20process%20surrogate%20model%20with%20an%20exchangeable%20covariance%0Afunction.%20For%20initial%20design%2C%20we%20show%20that%20its%20asymptotic%20D-optimal%20design%20can%0Abe%20formulated%20as%20a%20variant%20of%20the%20well-known%20assignment%20problem%20in%20operations%0Aresearch%2C%20which%20can%20be%20efficiently%20solved%20to%20global%20optimality%20using%0Astate-of-the-art%20integer%20programming%20solvers.%20For%20sequential%20design%0A%28specifically%2C%20for%20active%20learning%20or%20black-box%20optimization%29%2C%20we%20show%20that%20its%0Adesign%20criterion%20can%20similarly%20be%20formulated%20as%20an%20assignment%20problem%2C%20thus%0Aenabling%20efficient%20and%20reliable%20optimization%20with%20existing%20solvers.%20We%20then%0Ademonstrate%20the%20effectiveness%20of%20QuIP%20over%20existing%20methods%20in%20a%20suite%20of%20path%0Aplanning%20experiments%20and%20an%20application%20to%20rover%20trajectory%20optimization.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14616v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DQuIP%253A%2520Experimental%2520design%2520for%2520expensive%2520simulators%2520with%2520many%2520Qualitative%250A%2520%2520factors%2520via%2520Integer%2520Programming%26entry.906535625%3DYen-Chun%2520Liu%2520and%2520Simon%2520Mak%26entry.1292438233%3D%2520%2520The%2520need%2520to%2520explore%2520and/or%2520optimize%2520expensive%2520simulators%2520with%2520many%250Aqualitative%2520factors%2520arises%2520in%2520broad%2520scientific%2520and%2520engineering%2520problems.%2520Our%250Amotivating%2520application%2520lies%2520in%2520path%2520planning%2520-%2520the%2520exploration%2520of%2520feasible%250Apaths%2520for%2520navigation%252C%2520which%2520plays%2520an%2520important%2520role%2520in%2520robotics%252C%2520surgical%250Aplanning%2520and%2520assembly%2520planning.%2520Here%252C%2520the%2520feasibility%2520of%2520a%2520path%2520is%2520evaluated%250Avia%2520expensive%2520virtual%2520experiments%252C%2520and%2520its%2520parameter%2520space%2520is%2520typically%250Adiscrete%2520and%2520high-dimensional.%2520A%2520carefully%2520selected%2520experimental%2520design%2520is%2520thus%250Aessential%2520for%2520timely%2520decision-making.%2520We%2520propose%2520here%2520a%2520novel%2520framework%252C%2520called%250AQuIP%252C%2520for%2520experimental%2520design%2520of%2520Qualitative%2520factors%2520via%2520Integer%2520Programming%250Aunder%2520a%2520Gaussian%2520process%2520surrogate%2520model%2520with%2520an%2520exchangeable%2520covariance%250Afunction.%2520For%2520initial%2520design%252C%2520we%2520show%2520that%2520its%2520asymptotic%2520D-optimal%2520design%2520can%250Abe%2520formulated%2520as%2520a%2520variant%2520of%2520the%2520well-known%2520assignment%2520problem%2520in%2520operations%250Aresearch%252C%2520which%2520can%2520be%2520efficiently%2520solved%2520to%2520global%2520optimality%2520using%250Astate-of-the-art%2520integer%2520programming%2520solvers.%2520For%2520sequential%2520design%250A%2528specifically%252C%2520for%2520active%2520learning%2520or%2520black-box%2520optimization%2529%252C%2520we%2520show%2520that%2520its%250Adesign%2520criterion%2520can%2520similarly%2520be%2520formulated%2520as%2520an%2520assignment%2520problem%252C%2520thus%250Aenabling%2520efficient%2520and%2520reliable%2520optimization%2520with%2520existing%2520solvers.%2520We%2520then%250Ademonstrate%2520the%2520effectiveness%2520of%2520QuIP%2520over%2520existing%2520methods%2520in%2520a%2520suite%2520of%2520path%250Aplanning%2520experiments%2520and%2520an%2520application%2520to%2520rover%2520trajectory%2520optimization.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14616v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=QuIP%3A%20Experimental%20design%20for%20expensive%20simulators%20with%20many%20Qualitative%0A%20%20factors%20via%20Integer%20Programming&entry.906535625=Yen-Chun%20Liu%20and%20Simon%20Mak&entry.1292438233=%20%20The%20need%20to%20explore%20and/or%20optimize%20expensive%20simulators%20with%20many%0Aqualitative%20factors%20arises%20in%20broad%20scientific%20and%20engineering%20problems.%20Our%0Amotivating%20application%20lies%20in%20path%20planning%20-%20the%20exploration%20of%20feasible%0Apaths%20for%20navigation%2C%20which%20plays%20an%20important%20role%20in%20robotics%2C%20surgical%0Aplanning%20and%20assembly%20planning.%20Here%2C%20the%20feasibility%20of%20a%20path%20is%20evaluated%0Avia%20expensive%20virtual%20experiments%2C%20and%20its%20parameter%20space%20is%20typically%0Adiscrete%20and%20high-dimensional.%20A%20carefully%20selected%20experimental%20design%20is%20thus%0Aessential%20for%20timely%20decision-making.%20We%20propose%20here%20a%20novel%20framework%2C%20called%0AQuIP%2C%20for%20experimental%20design%20of%20Qualitative%20factors%20via%20Integer%20Programming%0Aunder%20a%20Gaussian%20process%20surrogate%20model%20with%20an%20exchangeable%20covariance%0Afunction.%20For%20initial%20design%2C%20we%20show%20that%20its%20asymptotic%20D-optimal%20design%20can%0Abe%20formulated%20as%20a%20variant%20of%20the%20well-known%20assignment%20problem%20in%20operations%0Aresearch%2C%20which%20can%20be%20efficiently%20solved%20to%20global%20optimality%20using%0Astate-of-the-art%20integer%20programming%20solvers.%20For%20sequential%20design%0A%28specifically%2C%20for%20active%20learning%20or%20black-box%20optimization%29%2C%20we%20show%20that%20its%0Adesign%20criterion%20can%20similarly%20be%20formulated%20as%20an%20assignment%20problem%2C%20thus%0Aenabling%20efficient%20and%20reliable%20optimization%20with%20existing%20solvers.%20We%20then%0Ademonstrate%20the%20effectiveness%20of%20QuIP%20over%20existing%20methods%20in%20a%20suite%20of%20path%0Aplanning%20experiments%20and%20an%20application%20to%20rover%20trajectory%20optimization.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14616v1&entry.124074799=Read"},
{"title": "Leveraging heterogeneous spillover in maximizing contextual bandit\n  rewards", "author": "Ahmed Sayeed Faruk and Elena Zheleva", "abstract": "  Recommender systems relying on contextual multi-armed bandits continuously\nimprove relevant item recommendations by taking into account the contextual\ninformation. The objective of bandit algorithms is to learn the best arm (e.g.,\nbest item to recommend) for each user and thus maximize the cumulative rewards\nfrom user engagement with the recommendations. The context that these\nalgorithms typically consider are the user and item attributes. However, in the\ncontext of social networks where $\\textit{the action of one user can influence\nthe actions and rewards of other users,}$ neighbors' actions are also a very\nimportant context, as they can have not only predictive power but also can\nimpact future rewards through spillover. Moreover, influence susceptibility can\nvary for different people based on their preferences and the closeness of ties\nto other users which leads to heterogeneity in the spillover effects. Here, we\npresent a framework that allows contextual multi-armed bandits to account for\nsuch heterogeneous spillovers when choosing the best arm for each user. Our\nexperiments on several semi-synthetic and real-world datasets show that our\nframework leads to significantly higher rewards than existing state-of-the-art\nsolutions that ignore the network information and potential spillover.\n", "link": "http://arxiv.org/abs/2310.10259v2", "date": "2025-01-24", "relevancy": 1.3375, "topK": [{"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.474}, {"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.4437}, {"title": "Boosted dynamic neural networks", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/26302", "similarity": 0.4354}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Leveraging%20heterogeneous%20spillover%20in%20maximizing%20contextual%20bandit%0A%20%20rewards&body=Title%3A%20Leveraging%20heterogeneous%20spillover%20in%20maximizing%20contextual%20bandit%0A%20%20rewards%0AAuthor%3A%20Ahmed%20Sayeed%20Faruk%20and%20Elena%20Zheleva%0AAbstract%3A%20%20%20Recommender%20systems%20relying%20on%20contextual%20multi-armed%20bandits%20continuously%0Aimprove%20relevant%20item%20recommendations%20by%20taking%20into%20account%20the%20contextual%0Ainformation.%20The%20objective%20of%20bandit%20algorithms%20is%20to%20learn%20the%20best%20arm%20%28e.g.%2C%0Abest%20item%20to%20recommend%29%20for%20each%20user%20and%20thus%20maximize%20the%20cumulative%20rewards%0Afrom%20user%20engagement%20with%20the%20recommendations.%20The%20context%20that%20these%0Aalgorithms%20typically%20consider%20are%20the%20user%20and%20item%20attributes.%20However%2C%20in%20the%0Acontext%20of%20social%20networks%20where%20%24%5Ctextit%7Bthe%20action%20of%20one%20user%20can%20influence%0Athe%20actions%20and%20rewards%20of%20other%20users%2C%7D%24%20neighbors%27%20actions%20are%20also%20a%20very%0Aimportant%20context%2C%20as%20they%20can%20have%20not%20only%20predictive%20power%20but%20also%20can%0Aimpact%20future%20rewards%20through%20spillover.%20Moreover%2C%20influence%20susceptibility%20can%0Avary%20for%20different%20people%20based%20on%20their%20preferences%20and%20the%20closeness%20of%20ties%0Ato%20other%20users%20which%20leads%20to%20heterogeneity%20in%20the%20spillover%20effects.%20Here%2C%20we%0Apresent%20a%20framework%20that%20allows%20contextual%20multi-armed%20bandits%20to%20account%20for%0Asuch%20heterogeneous%20spillovers%20when%20choosing%20the%20best%20arm%20for%20each%20user.%20Our%0Aexperiments%20on%20several%20semi-synthetic%20and%20real-world%20datasets%20show%20that%20our%0Aframework%20leads%20to%20significantly%20higher%20rewards%20than%20existing%20state-of-the-art%0Asolutions%20that%20ignore%20the%20network%20information%20and%20potential%20spillover.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2310.10259v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLeveraging%2520heterogeneous%2520spillover%2520in%2520maximizing%2520contextual%2520bandit%250A%2520%2520rewards%26entry.906535625%3DAhmed%2520Sayeed%2520Faruk%2520and%2520Elena%2520Zheleva%26entry.1292438233%3D%2520%2520Recommender%2520systems%2520relying%2520on%2520contextual%2520multi-armed%2520bandits%2520continuously%250Aimprove%2520relevant%2520item%2520recommendations%2520by%2520taking%2520into%2520account%2520the%2520contextual%250Ainformation.%2520The%2520objective%2520of%2520bandit%2520algorithms%2520is%2520to%2520learn%2520the%2520best%2520arm%2520%2528e.g.%252C%250Abest%2520item%2520to%2520recommend%2529%2520for%2520each%2520user%2520and%2520thus%2520maximize%2520the%2520cumulative%2520rewards%250Afrom%2520user%2520engagement%2520with%2520the%2520recommendations.%2520The%2520context%2520that%2520these%250Aalgorithms%2520typically%2520consider%2520are%2520the%2520user%2520and%2520item%2520attributes.%2520However%252C%2520in%2520the%250Acontext%2520of%2520social%2520networks%2520where%2520%2524%255Ctextit%257Bthe%2520action%2520of%2520one%2520user%2520can%2520influence%250Athe%2520actions%2520and%2520rewards%2520of%2520other%2520users%252C%257D%2524%2520neighbors%2527%2520actions%2520are%2520also%2520a%2520very%250Aimportant%2520context%252C%2520as%2520they%2520can%2520have%2520not%2520only%2520predictive%2520power%2520but%2520also%2520can%250Aimpact%2520future%2520rewards%2520through%2520spillover.%2520Moreover%252C%2520influence%2520susceptibility%2520can%250Avary%2520for%2520different%2520people%2520based%2520on%2520their%2520preferences%2520and%2520the%2520closeness%2520of%2520ties%250Ato%2520other%2520users%2520which%2520leads%2520to%2520heterogeneity%2520in%2520the%2520spillover%2520effects.%2520Here%252C%2520we%250Apresent%2520a%2520framework%2520that%2520allows%2520contextual%2520multi-armed%2520bandits%2520to%2520account%2520for%250Asuch%2520heterogeneous%2520spillovers%2520when%2520choosing%2520the%2520best%2520arm%2520for%2520each%2520user.%2520Our%250Aexperiments%2520on%2520several%2520semi-synthetic%2520and%2520real-world%2520datasets%2520show%2520that%2520our%250Aframework%2520leads%2520to%2520significantly%2520higher%2520rewards%2520than%2520existing%2520state-of-the-art%250Asolutions%2520that%2520ignore%2520the%2520network%2520information%2520and%2520potential%2520spillover.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2310.10259v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Leveraging%20heterogeneous%20spillover%20in%20maximizing%20contextual%20bandit%0A%20%20rewards&entry.906535625=Ahmed%20Sayeed%20Faruk%20and%20Elena%20Zheleva&entry.1292438233=%20%20Recommender%20systems%20relying%20on%20contextual%20multi-armed%20bandits%20continuously%0Aimprove%20relevant%20item%20recommendations%20by%20taking%20into%20account%20the%20contextual%0Ainformation.%20The%20objective%20of%20bandit%20algorithms%20is%20to%20learn%20the%20best%20arm%20%28e.g.%2C%0Abest%20item%20to%20recommend%29%20for%20each%20user%20and%20thus%20maximize%20the%20cumulative%20rewards%0Afrom%20user%20engagement%20with%20the%20recommendations.%20The%20context%20that%20these%0Aalgorithms%20typically%20consider%20are%20the%20user%20and%20item%20attributes.%20However%2C%20in%20the%0Acontext%20of%20social%20networks%20where%20%24%5Ctextit%7Bthe%20action%20of%20one%20user%20can%20influence%0Athe%20actions%20and%20rewards%20of%20other%20users%2C%7D%24%20neighbors%27%20actions%20are%20also%20a%20very%0Aimportant%20context%2C%20as%20they%20can%20have%20not%20only%20predictive%20power%20but%20also%20can%0Aimpact%20future%20rewards%20through%20spillover.%20Moreover%2C%20influence%20susceptibility%20can%0Avary%20for%20different%20people%20based%20on%20their%20preferences%20and%20the%20closeness%20of%20ties%0Ato%20other%20users%20which%20leads%20to%20heterogeneity%20in%20the%20spillover%20effects.%20Here%2C%20we%0Apresent%20a%20framework%20that%20allows%20contextual%20multi-armed%20bandits%20to%20account%20for%0Asuch%20heterogeneous%20spillovers%20when%20choosing%20the%20best%20arm%20for%20each%20user.%20Our%0Aexperiments%20on%20several%20semi-synthetic%20and%20real-world%20datasets%20show%20that%20our%0Aframework%20leads%20to%20significantly%20higher%20rewards%20than%20existing%20state-of-the-art%0Asolutions%20that%20ignore%20the%20network%20information%20and%20potential%20spillover.%0A&entry.1838667208=http%3A//arxiv.org/abs/2310.10259v2&entry.124074799=Read"},
{"title": "Deep-BrownConrady: Prediction of Camera Calibration and Distortion\n  Parameters Using Deep Learning and Synthetic Data", "author": "Faiz Muhammad Chaudhry and Jarno Ralli and Jerome Leudet and Fahad Sohrab and Farhad Pakdaman and Pierre Corbani and Moncef Gabbouj", "abstract": "  This research addresses the challenge of camera calibration and distortion\nparameter prediction from a single image using deep learning models. The main\ncontributions of this work are: (1) demonstrating that a deep learning model,\ntrained on a mix of real and synthetic images, can accurately predict camera\nand lens parameters from a single image, and (2) developing a comprehensive\nsynthetic dataset using the AILiveSim simulation platform. This dataset\nincludes variations in focal length and lens distortion parameters, providing a\nrobust foundation for model training and testing. The training process\npredominantly relied on these synthetic images, complemented by a small subset\nof real images, to explore how well models trained on synthetic data can\nperform calibration tasks on real-world images. Traditional calibration methods\nrequire multiple images of a calibration object from various orientations,\nwhich is often not feasible due to the lack of such images in publicly\navailable datasets. A deep learning network based on the ResNet architecture\nwas trained on this synthetic dataset to predict camera calibration parameters\nfollowing the Brown-Conrady lens model. The ResNet architecture, adapted for\nregression tasks, is capable of predicting continuous values essential for\naccurate camera calibration in applications such as autonomous driving,\nrobotics, and augmented reality.\n  Keywords: Camera calibration, distortion, synthetic data, deep learning,\nresidual networks (ResNet), AILiveSim, horizontal field-of-view, principal\npoint, Brown-Conrady Model.\n", "link": "http://arxiv.org/abs/2501.14510v1", "date": "2025-01-24", "relevancy": 1.0877, "topK": [{"title": "CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control", "link": "http://arxiv.org/abs/2501.06006v1", "similarity": 0.574}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5326}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.525}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Deep-BrownConrady%3A%20Prediction%20of%20Camera%20Calibration%20and%20Distortion%0A%20%20Parameters%20Using%20Deep%20Learning%20and%20Synthetic%20Data&body=Title%3A%20Deep-BrownConrady%3A%20Prediction%20of%20Camera%20Calibration%20and%20Distortion%0A%20%20Parameters%20Using%20Deep%20Learning%20and%20Synthetic%20Data%0AAuthor%3A%20Faiz%20Muhammad%20Chaudhry%20and%20Jarno%20Ralli%20and%20Jerome%20Leudet%20and%20Fahad%20Sohrab%20and%20Farhad%20Pakdaman%20and%20Pierre%20Corbani%20and%20Moncef%20Gabbouj%0AAbstract%3A%20%20%20This%20research%20addresses%20the%20challenge%20of%20camera%20calibration%20and%20distortion%0Aparameter%20prediction%20from%20a%20single%20image%20using%20deep%20learning%20models.%20The%20main%0Acontributions%20of%20this%20work%20are%3A%20%281%29%20demonstrating%20that%20a%20deep%20learning%20model%2C%0Atrained%20on%20a%20mix%20of%20real%20and%20synthetic%20images%2C%20can%20accurately%20predict%20camera%0Aand%20lens%20parameters%20from%20a%20single%20image%2C%20and%20%282%29%20developing%20a%20comprehensive%0Asynthetic%20dataset%20using%20the%20AILiveSim%20simulation%20platform.%20This%20dataset%0Aincludes%20variations%20in%20focal%20length%20and%20lens%20distortion%20parameters%2C%20providing%20a%0Arobust%20foundation%20for%20model%20training%20and%20testing.%20The%20training%20process%0Apredominantly%20relied%20on%20these%20synthetic%20images%2C%20complemented%20by%20a%20small%20subset%0Aof%20real%20images%2C%20to%20explore%20how%20well%20models%20trained%20on%20synthetic%20data%20can%0Aperform%20calibration%20tasks%20on%20real-world%20images.%20Traditional%20calibration%20methods%0Arequire%20multiple%20images%20of%20a%20calibration%20object%20from%20various%20orientations%2C%0Awhich%20is%20often%20not%20feasible%20due%20to%20the%20lack%20of%20such%20images%20in%20publicly%0Aavailable%20datasets.%20A%20deep%20learning%20network%20based%20on%20the%20ResNet%20architecture%0Awas%20trained%20on%20this%20synthetic%20dataset%20to%20predict%20camera%20calibration%20parameters%0Afollowing%20the%20Brown-Conrady%20lens%20model.%20The%20ResNet%20architecture%2C%20adapted%20for%0Aregression%20tasks%2C%20is%20capable%20of%20predicting%20continuous%20values%20essential%20for%0Aaccurate%20camera%20calibration%20in%20applications%20such%20as%20autonomous%20driving%2C%0Arobotics%2C%20and%20augmented%20reality.%0A%20%20Keywords%3A%20Camera%20calibration%2C%20distortion%2C%20synthetic%20data%2C%20deep%20learning%2C%0Aresidual%20networks%20%28ResNet%29%2C%20AILiveSim%2C%20horizontal%20field-of-view%2C%20principal%0Apoint%2C%20Brown-Conrady%20Model.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14510v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DDeep-BrownConrady%253A%2520Prediction%2520of%2520Camera%2520Calibration%2520and%2520Distortion%250A%2520%2520Parameters%2520Using%2520Deep%2520Learning%2520and%2520Synthetic%2520Data%26entry.906535625%3DFaiz%2520Muhammad%2520Chaudhry%2520and%2520Jarno%2520Ralli%2520and%2520Jerome%2520Leudet%2520and%2520Fahad%2520Sohrab%2520and%2520Farhad%2520Pakdaman%2520and%2520Pierre%2520Corbani%2520and%2520Moncef%2520Gabbouj%26entry.1292438233%3D%2520%2520This%2520research%2520addresses%2520the%2520challenge%2520of%2520camera%2520calibration%2520and%2520distortion%250Aparameter%2520prediction%2520from%2520a%2520single%2520image%2520using%2520deep%2520learning%2520models.%2520The%2520main%250Acontributions%2520of%2520this%2520work%2520are%253A%2520%25281%2529%2520demonstrating%2520that%2520a%2520deep%2520learning%2520model%252C%250Atrained%2520on%2520a%2520mix%2520of%2520real%2520and%2520synthetic%2520images%252C%2520can%2520accurately%2520predict%2520camera%250Aand%2520lens%2520parameters%2520from%2520a%2520single%2520image%252C%2520and%2520%25282%2529%2520developing%2520a%2520comprehensive%250Asynthetic%2520dataset%2520using%2520the%2520AILiveSim%2520simulation%2520platform.%2520This%2520dataset%250Aincludes%2520variations%2520in%2520focal%2520length%2520and%2520lens%2520distortion%2520parameters%252C%2520providing%2520a%250Arobust%2520foundation%2520for%2520model%2520training%2520and%2520testing.%2520The%2520training%2520process%250Apredominantly%2520relied%2520on%2520these%2520synthetic%2520images%252C%2520complemented%2520by%2520a%2520small%2520subset%250Aof%2520real%2520images%252C%2520to%2520explore%2520how%2520well%2520models%2520trained%2520on%2520synthetic%2520data%2520can%250Aperform%2520calibration%2520tasks%2520on%2520real-world%2520images.%2520Traditional%2520calibration%2520methods%250Arequire%2520multiple%2520images%2520of%2520a%2520calibration%2520object%2520from%2520various%2520orientations%252C%250Awhich%2520is%2520often%2520not%2520feasible%2520due%2520to%2520the%2520lack%2520of%2520such%2520images%2520in%2520publicly%250Aavailable%2520datasets.%2520A%2520deep%2520learning%2520network%2520based%2520on%2520the%2520ResNet%2520architecture%250Awas%2520trained%2520on%2520this%2520synthetic%2520dataset%2520to%2520predict%2520camera%2520calibration%2520parameters%250Afollowing%2520the%2520Brown-Conrady%2520lens%2520model.%2520The%2520ResNet%2520architecture%252C%2520adapted%2520for%250Aregression%2520tasks%252C%2520is%2520capable%2520of%2520predicting%2520continuous%2520values%2520essential%2520for%250Aaccurate%2520camera%2520calibration%2520in%2520applications%2520such%2520as%2520autonomous%2520driving%252C%250Arobotics%252C%2520and%2520augmented%2520reality.%250A%2520%2520Keywords%253A%2520Camera%2520calibration%252C%2520distortion%252C%2520synthetic%2520data%252C%2520deep%2520learning%252C%250Aresidual%2520networks%2520%2528ResNet%2529%252C%2520AILiveSim%252C%2520horizontal%2520field-of-view%252C%2520principal%250Apoint%252C%2520Brown-Conrady%2520Model.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14510v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Deep-BrownConrady%3A%20Prediction%20of%20Camera%20Calibration%20and%20Distortion%0A%20%20Parameters%20Using%20Deep%20Learning%20and%20Synthetic%20Data&entry.906535625=Faiz%20Muhammad%20Chaudhry%20and%20Jarno%20Ralli%20and%20Jerome%20Leudet%20and%20Fahad%20Sohrab%20and%20Farhad%20Pakdaman%20and%20Pierre%20Corbani%20and%20Moncef%20Gabbouj&entry.1292438233=%20%20This%20research%20addresses%20the%20challenge%20of%20camera%20calibration%20and%20distortion%0Aparameter%20prediction%20from%20a%20single%20image%20using%20deep%20learning%20models.%20The%20main%0Acontributions%20of%20this%20work%20are%3A%20%281%29%20demonstrating%20that%20a%20deep%20learning%20model%2C%0Atrained%20on%20a%20mix%20of%20real%20and%20synthetic%20images%2C%20can%20accurately%20predict%20camera%0Aand%20lens%20parameters%20from%20a%20single%20image%2C%20and%20%282%29%20developing%20a%20comprehensive%0Asynthetic%20dataset%20using%20the%20AILiveSim%20simulation%20platform.%20This%20dataset%0Aincludes%20variations%20in%20focal%20length%20and%20lens%20distortion%20parameters%2C%20providing%20a%0Arobust%20foundation%20for%20model%20training%20and%20testing.%20The%20training%20process%0Apredominantly%20relied%20on%20these%20synthetic%20images%2C%20complemented%20by%20a%20small%20subset%0Aof%20real%20images%2C%20to%20explore%20how%20well%20models%20trained%20on%20synthetic%20data%20can%0Aperform%20calibration%20tasks%20on%20real-world%20images.%20Traditional%20calibration%20methods%0Arequire%20multiple%20images%20of%20a%20calibration%20object%20from%20various%20orientations%2C%0Awhich%20is%20often%20not%20feasible%20due%20to%20the%20lack%20of%20such%20images%20in%20publicly%0Aavailable%20datasets.%20A%20deep%20learning%20network%20based%20on%20the%20ResNet%20architecture%0Awas%20trained%20on%20this%20synthetic%20dataset%20to%20predict%20camera%20calibration%20parameters%0Afollowing%20the%20Brown-Conrady%20lens%20model.%20The%20ResNet%20architecture%2C%20adapted%20for%0Aregression%20tasks%2C%20is%20capable%20of%20predicting%20continuous%20values%20essential%20for%0Aaccurate%20camera%20calibration%20in%20applications%20such%20as%20autonomous%20driving%2C%0Arobotics%2C%20and%20augmented%20reality.%0A%20%20Keywords%3A%20Camera%20calibration%2C%20distortion%2C%20synthetic%20data%2C%20deep%20learning%2C%0Aresidual%20networks%20%28ResNet%29%2C%20AILiveSim%2C%20horizontal%20field-of-view%2C%20principal%0Apoint%2C%20Brown-Conrady%20Model.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14510v1&entry.124074799=Read"},
{"title": "CodeMonkeys: Scaling Test-Time Compute for Software Engineering", "author": "Ryan Ehrlich and Bradley Brown and Jordan Juravsky and Ronald Clark and Christopher R\u00e9 and Azalia Mirhoseini", "abstract": "  Scaling test-time compute is a promising axis for improving LLM capabilities.\nHowever, test-time compute can be scaled in a variety of ways, and effectively\ncombining different approaches remains an active area of research. Here, we\nexplore this problem in the context of solving real-world GitHub issues from\nthe SWE-bench dataset. Our system, named CodeMonkeys, allows models to\niteratively edit a codebase by jointly generating and running a testing script\nalongside their draft edit. We sample many of these multi-turn trajectories for\nevery issue to generate a collection of candidate edits. This approach lets us\nscale \"serial\" test-time compute by increasing the number of iterations per\ntrajectory and \"parallel\" test-time compute by increasing the number of\ntrajectories per problem. With parallel scaling, we can amortize up-front costs\nacross multiple downstream samples, allowing us to identify relevant codebase\ncontext using the simple method of letting an LLM read every file. In order to\nselect between candidate edits, we combine voting using model-generated tests\nwith a final multi-turn trajectory dedicated to selection. Overall, CodeMonkeys\nresolves 57.4% of issues from SWE-bench Verified using a budget of\napproximately 2300 USD. Our selection method can also be used to combine\ncandidates from different sources. Selecting over an ensemble of edits from\nexisting top SWE-bench Verified submissions obtains a score of 66.2% and\noutperforms the best member of the ensemble on its own. We fully release our\ncode and data at https://scalingintelligence.stanford.edu/pubs/codemonkeys.\n", "link": "http://arxiv.org/abs/2501.14723v1", "date": "2025-01-24", "relevancy": 1.3503, "topK": [{"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.4561}, {"title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing", "link": "http://arxiv.org/abs/2409.04559v2", "similarity": 0.4518}, {"title": "Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular\n  Videos", "link": "http://arxiv.org/abs/2404.12379v2", "similarity": 0.447}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20CodeMonkeys%3A%20Scaling%20Test-Time%20Compute%20for%20Software%20Engineering&body=Title%3A%20CodeMonkeys%3A%20Scaling%20Test-Time%20Compute%20for%20Software%20Engineering%0AAuthor%3A%20Ryan%20Ehrlich%20and%20Bradley%20Brown%20and%20Jordan%20Juravsky%20and%20Ronald%20Clark%20and%20Christopher%20R%C3%A9%20and%20Azalia%20Mirhoseini%0AAbstract%3A%20%20%20Scaling%20test-time%20compute%20is%20a%20promising%20axis%20for%20improving%20LLM%20capabilities.%0AHowever%2C%20test-time%20compute%20can%20be%20scaled%20in%20a%20variety%20of%20ways%2C%20and%20effectively%0Acombining%20different%20approaches%20remains%20an%20active%20area%20of%20research.%20Here%2C%20we%0Aexplore%20this%20problem%20in%20the%20context%20of%20solving%20real-world%20GitHub%20issues%20from%0Athe%20SWE-bench%20dataset.%20Our%20system%2C%20named%20CodeMonkeys%2C%20allows%20models%20to%0Aiteratively%20edit%20a%20codebase%20by%20jointly%20generating%20and%20running%20a%20testing%20script%0Aalongside%20their%20draft%20edit.%20We%20sample%20many%20of%20these%20multi-turn%20trajectories%20for%0Aevery%20issue%20to%20generate%20a%20collection%20of%20candidate%20edits.%20This%20approach%20lets%20us%0Ascale%20%22serial%22%20test-time%20compute%20by%20increasing%20the%20number%20of%20iterations%20per%0Atrajectory%20and%20%22parallel%22%20test-time%20compute%20by%20increasing%20the%20number%20of%0Atrajectories%20per%20problem.%20With%20parallel%20scaling%2C%20we%20can%20amortize%20up-front%20costs%0Aacross%20multiple%20downstream%20samples%2C%20allowing%20us%20to%20identify%20relevant%20codebase%0Acontext%20using%20the%20simple%20method%20of%20letting%20an%20LLM%20read%20every%20file.%20In%20order%20to%0Aselect%20between%20candidate%20edits%2C%20we%20combine%20voting%20using%20model-generated%20tests%0Awith%20a%20final%20multi-turn%20trajectory%20dedicated%20to%20selection.%20Overall%2C%20CodeMonkeys%0Aresolves%2057.4%25%20of%20issues%20from%20SWE-bench%20Verified%20using%20a%20budget%20of%0Aapproximately%202300%20USD.%20Our%20selection%20method%20can%20also%20be%20used%20to%20combine%0Acandidates%20from%20different%20sources.%20Selecting%20over%20an%20ensemble%20of%20edits%20from%0Aexisting%20top%20SWE-bench%20Verified%20submissions%20obtains%20a%20score%20of%2066.2%25%20and%0Aoutperforms%20the%20best%20member%20of%20the%20ensemble%20on%20its%20own.%20We%20fully%20release%20our%0Acode%20and%20data%20at%20https%3A//scalingintelligence.stanford.edu/pubs/codemonkeys.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2501.14723v1%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DCodeMonkeys%253A%2520Scaling%2520Test-Time%2520Compute%2520for%2520Software%2520Engineering%26entry.906535625%3DRyan%2520Ehrlich%2520and%2520Bradley%2520Brown%2520and%2520Jordan%2520Juravsky%2520and%2520Ronald%2520Clark%2520and%2520Christopher%2520R%25C3%25A9%2520and%2520Azalia%2520Mirhoseini%26entry.1292438233%3D%2520%2520Scaling%2520test-time%2520compute%2520is%2520a%2520promising%2520axis%2520for%2520improving%2520LLM%2520capabilities.%250AHowever%252C%2520test-time%2520compute%2520can%2520be%2520scaled%2520in%2520a%2520variety%2520of%2520ways%252C%2520and%2520effectively%250Acombining%2520different%2520approaches%2520remains%2520an%2520active%2520area%2520of%2520research.%2520Here%252C%2520we%250Aexplore%2520this%2520problem%2520in%2520the%2520context%2520of%2520solving%2520real-world%2520GitHub%2520issues%2520from%250Athe%2520SWE-bench%2520dataset.%2520Our%2520system%252C%2520named%2520CodeMonkeys%252C%2520allows%2520models%2520to%250Aiteratively%2520edit%2520a%2520codebase%2520by%2520jointly%2520generating%2520and%2520running%2520a%2520testing%2520script%250Aalongside%2520their%2520draft%2520edit.%2520We%2520sample%2520many%2520of%2520these%2520multi-turn%2520trajectories%2520for%250Aevery%2520issue%2520to%2520generate%2520a%2520collection%2520of%2520candidate%2520edits.%2520This%2520approach%2520lets%2520us%250Ascale%2520%2522serial%2522%2520test-time%2520compute%2520by%2520increasing%2520the%2520number%2520of%2520iterations%2520per%250Atrajectory%2520and%2520%2522parallel%2522%2520test-time%2520compute%2520by%2520increasing%2520the%2520number%2520of%250Atrajectories%2520per%2520problem.%2520With%2520parallel%2520scaling%252C%2520we%2520can%2520amortize%2520up-front%2520costs%250Aacross%2520multiple%2520downstream%2520samples%252C%2520allowing%2520us%2520to%2520identify%2520relevant%2520codebase%250Acontext%2520using%2520the%2520simple%2520method%2520of%2520letting%2520an%2520LLM%2520read%2520every%2520file.%2520In%2520order%2520to%250Aselect%2520between%2520candidate%2520edits%252C%2520we%2520combine%2520voting%2520using%2520model-generated%2520tests%250Awith%2520a%2520final%2520multi-turn%2520trajectory%2520dedicated%2520to%2520selection.%2520Overall%252C%2520CodeMonkeys%250Aresolves%252057.4%2525%2520of%2520issues%2520from%2520SWE-bench%2520Verified%2520using%2520a%2520budget%2520of%250Aapproximately%25202300%2520USD.%2520Our%2520selection%2520method%2520can%2520also%2520be%2520used%2520to%2520combine%250Acandidates%2520from%2520different%2520sources.%2520Selecting%2520over%2520an%2520ensemble%2520of%2520edits%2520from%250Aexisting%2520top%2520SWE-bench%2520Verified%2520submissions%2520obtains%2520a%2520score%2520of%252066.2%2525%2520and%250Aoutperforms%2520the%2520best%2520member%2520of%2520the%2520ensemble%2520on%2520its%2520own.%2520We%2520fully%2520release%2520our%250Acode%2520and%2520data%2520at%2520https%253A//scalingintelligence.stanford.edu/pubs/codemonkeys.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2501.14723v1%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=CodeMonkeys%3A%20Scaling%20Test-Time%20Compute%20for%20Software%20Engineering&entry.906535625=Ryan%20Ehrlich%20and%20Bradley%20Brown%20and%20Jordan%20Juravsky%20and%20Ronald%20Clark%20and%20Christopher%20R%C3%A9%20and%20Azalia%20Mirhoseini&entry.1292438233=%20%20Scaling%20test-time%20compute%20is%20a%20promising%20axis%20for%20improving%20LLM%20capabilities.%0AHowever%2C%20test-time%20compute%20can%20be%20scaled%20in%20a%20variety%20of%20ways%2C%20and%20effectively%0Acombining%20different%20approaches%20remains%20an%20active%20area%20of%20research.%20Here%2C%20we%0Aexplore%20this%20problem%20in%20the%20context%20of%20solving%20real-world%20GitHub%20issues%20from%0Athe%20SWE-bench%20dataset.%20Our%20system%2C%20named%20CodeMonkeys%2C%20allows%20models%20to%0Aiteratively%20edit%20a%20codebase%20by%20jointly%20generating%20and%20running%20a%20testing%20script%0Aalongside%20their%20draft%20edit.%20We%20sample%20many%20of%20these%20multi-turn%20trajectories%20for%0Aevery%20issue%20to%20generate%20a%20collection%20of%20candidate%20edits.%20This%20approach%20lets%20us%0Ascale%20%22serial%22%20test-time%20compute%20by%20increasing%20the%20number%20of%20iterations%20per%0Atrajectory%20and%20%22parallel%22%20test-time%20compute%20by%20increasing%20the%20number%20of%0Atrajectories%20per%20problem.%20With%20parallel%20scaling%2C%20we%20can%20amortize%20up-front%20costs%0Aacross%20multiple%20downstream%20samples%2C%20allowing%20us%20to%20identify%20relevant%20codebase%0Acontext%20using%20the%20simple%20method%20of%20letting%20an%20LLM%20read%20every%20file.%20In%20order%20to%0Aselect%20between%20candidate%20edits%2C%20we%20combine%20voting%20using%20model-generated%20tests%0Awith%20a%20final%20multi-turn%20trajectory%20dedicated%20to%20selection.%20Overall%2C%20CodeMonkeys%0Aresolves%2057.4%25%20of%20issues%20from%20SWE-bench%20Verified%20using%20a%20budget%20of%0Aapproximately%202300%20USD.%20Our%20selection%20method%20can%20also%20be%20used%20to%20combine%0Acandidates%20from%20different%20sources.%20Selecting%20over%20an%20ensemble%20of%20edits%20from%0Aexisting%20top%20SWE-bench%20Verified%20submissions%20obtains%20a%20score%20of%2066.2%25%20and%0Aoutperforms%20the%20best%20member%20of%20the%20ensemble%20on%20its%20own.%20We%20fully%20release%20our%0Acode%20and%20data%20at%20https%3A//scalingintelligence.stanford.edu/pubs/codemonkeys.%0A&entry.1838667208=http%3A//arxiv.org/abs/2501.14723v1&entry.124074799=Read"},
{"title": "Proactive and Reactive Constraint Programming for Stochastic Project\n  Scheduling with Maximal Time-Lags", "author": "Kim van den Houten and L\u00e9on Planken and Esteban Freydell and David M. J. Tax and Mathijs de Weerdt", "abstract": "  This study investigates scheduling strategies for the stochastic\nresource-constrained project scheduling problem with maximal time lags\n(SRCPSP/max)). Recent advances in Constraint Programming (CP) and Temporal\nNetworks have reinvoked interest in evaluating the advantages and drawbacks of\nvarious proactive and reactive scheduling methods. First, we present a new,\nCP-based fully proactive method. Second, we show how a reactive approach can be\nconstructed using an online rescheduling procedure. A third contribution is\nbased on partial order schedules and uses Simple Temporal Networks with\nUncertainty (STNUs). Our statistical analysis shows that the STNU-based\nalgorithm performs best in terms of solution quality, while also showing good\nrelative offline and online computation time.\n", "link": "http://arxiv.org/abs/2409.09107v3", "date": "2025-01-24", "relevancy": 1.1957, "topK": [{"title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation", "link": "http://arxiv.org/abs/2402.15487v1", "similarity": 0.433}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.3988}, {"title": "Safe and efficient training of a control agent", "link": "https://patents.google.com/patent/US11709462B2/en", "similarity": 0.3847}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Proactive%20and%20Reactive%20Constraint%20Programming%20for%20Stochastic%20Project%0A%20%20Scheduling%20with%20Maximal%20Time-Lags&body=Title%3A%20Proactive%20and%20Reactive%20Constraint%20Programming%20for%20Stochastic%20Project%0A%20%20Scheduling%20with%20Maximal%20Time-Lags%0AAuthor%3A%20Kim%20van%20den%20Houten%20and%20L%C3%A9on%20Planken%20and%20Esteban%20Freydell%20and%20David%20M.%20J.%20Tax%20and%20Mathijs%20de%20Weerdt%0AAbstract%3A%20%20%20This%20study%20investigates%20scheduling%20strategies%20for%20the%20stochastic%0Aresource-constrained%20project%20scheduling%20problem%20with%20maximal%20time%20lags%0A%28SRCPSP/max%29%29.%20Recent%20advances%20in%20Constraint%20Programming%20%28CP%29%20and%20Temporal%0ANetworks%20have%20reinvoked%20interest%20in%20evaluating%20the%20advantages%20and%20drawbacks%20of%0Avarious%20proactive%20and%20reactive%20scheduling%20methods.%20First%2C%20we%20present%20a%20new%2C%0ACP-based%20fully%20proactive%20method.%20Second%2C%20we%20show%20how%20a%20reactive%20approach%20can%20be%0Aconstructed%20using%20an%20online%20rescheduling%20procedure.%20A%20third%20contribution%20is%0Abased%20on%20partial%20order%20schedules%20and%20uses%20Simple%20Temporal%20Networks%20with%0AUncertainty%20%28STNUs%29.%20Our%20statistical%20analysis%20shows%20that%20the%20STNU-based%0Aalgorithm%20performs%20best%20in%20terms%20of%20solution%20quality%2C%20while%20also%20showing%20good%0Arelative%20offline%20and%20online%20computation%20time.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2409.09107v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DProactive%2520and%2520Reactive%2520Constraint%2520Programming%2520for%2520Stochastic%2520Project%250A%2520%2520Scheduling%2520with%2520Maximal%2520Time-Lags%26entry.906535625%3DKim%2520van%2520den%2520Houten%2520and%2520L%25C3%25A9on%2520Planken%2520and%2520Esteban%2520Freydell%2520and%2520David%2520M.%2520J.%2520Tax%2520and%2520Mathijs%2520de%2520Weerdt%26entry.1292438233%3D%2520%2520This%2520study%2520investigates%2520scheduling%2520strategies%2520for%2520the%2520stochastic%250Aresource-constrained%2520project%2520scheduling%2520problem%2520with%2520maximal%2520time%2520lags%250A%2528SRCPSP/max%2529%2529.%2520Recent%2520advances%2520in%2520Constraint%2520Programming%2520%2528CP%2529%2520and%2520Temporal%250ANetworks%2520have%2520reinvoked%2520interest%2520in%2520evaluating%2520the%2520advantages%2520and%2520drawbacks%2520of%250Avarious%2520proactive%2520and%2520reactive%2520scheduling%2520methods.%2520First%252C%2520we%2520present%2520a%2520new%252C%250ACP-based%2520fully%2520proactive%2520method.%2520Second%252C%2520we%2520show%2520how%2520a%2520reactive%2520approach%2520can%2520be%250Aconstructed%2520using%2520an%2520online%2520rescheduling%2520procedure.%2520A%2520third%2520contribution%2520is%250Abased%2520on%2520partial%2520order%2520schedules%2520and%2520uses%2520Simple%2520Temporal%2520Networks%2520with%250AUncertainty%2520%2528STNUs%2529.%2520Our%2520statistical%2520analysis%2520shows%2520that%2520the%2520STNU-based%250Aalgorithm%2520performs%2520best%2520in%2520terms%2520of%2520solution%2520quality%252C%2520while%2520also%2520showing%2520good%250Arelative%2520offline%2520and%2520online%2520computation%2520time.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2409.09107v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Proactive%20and%20Reactive%20Constraint%20Programming%20for%20Stochastic%20Project%0A%20%20Scheduling%20with%20Maximal%20Time-Lags&entry.906535625=Kim%20van%20den%20Houten%20and%20L%C3%A9on%20Planken%20and%20Esteban%20Freydell%20and%20David%20M.%20J.%20Tax%20and%20Mathijs%20de%20Weerdt&entry.1292438233=%20%20This%20study%20investigates%20scheduling%20strategies%20for%20the%20stochastic%0Aresource-constrained%20project%20scheduling%20problem%20with%20maximal%20time%20lags%0A%28SRCPSP/max%29%29.%20Recent%20advances%20in%20Constraint%20Programming%20%28CP%29%20and%20Temporal%0ANetworks%20have%20reinvoked%20interest%20in%20evaluating%20the%20advantages%20and%20drawbacks%20of%0Avarious%20proactive%20and%20reactive%20scheduling%20methods.%20First%2C%20we%20present%20a%20new%2C%0ACP-based%20fully%20proactive%20method.%20Second%2C%20we%20show%20how%20a%20reactive%20approach%20can%20be%0Aconstructed%20using%20an%20online%20rescheduling%20procedure.%20A%20third%20contribution%20is%0Abased%20on%20partial%20order%20schedules%20and%20uses%20Simple%20Temporal%20Networks%20with%0AUncertainty%20%28STNUs%29.%20Our%20statistical%20analysis%20shows%20that%20the%20STNU-based%0Aalgorithm%20performs%20best%20in%20terms%20of%20solution%20quality%2C%20while%20also%20showing%20good%0Arelative%20offline%20and%20online%20computation%20time.%0A&entry.1838667208=http%3A//arxiv.org/abs/2409.09107v3&entry.124074799=Read"},
      ];
      const content = document.getElementById('content');
      function createPostElement(post) {
        const postElement = document.createElement('div');
        postElement.className = 'post';
        const dateElem = document.createElement('p');
        dateElem.setAttribute("class", "date");
        dateElem.textContent = post.date;
        postElement.appendChild(dateElem);

        const textElem = document.createElement('p');
        textElem.setAttribute("class", "text");
        const titleElem = document.createElement('p');
        titleElem.setAttribute("class", "title");
        titleElem.textContent = post.title;
        textElem.appendChild(titleElem);
        const authorElem = document.createElement('p');
        authorElem.setAttribute("class", "author");
        authorElem.textContent = post.author;
        textElem.appendChild(authorElem);
        const abstractElem = document.createElement('p');
        abstractElem.setAttribute("class", "abstract");
        abstractElem.textContent = post.abstract;
        textElem.appendChild(abstractElem);

        const linkElement = document.createElement('a');
        linkElement.setAttribute("class", "link");
        linkElement.href = post.link;
        linkElement.target = "_blank";
        linkElement.textContent = post.link.length > 50 ? post.link.substring(0, 50) + '...' : post.link;
        textElem.appendChild(linkElement);
        postElement.appendChild(textElem);

        const linkElementContainer = document.createElement('div');
        linkElementContainer.setAttribute("class", "comment");
        const actionElement = document.createElement('a');
        actionElement.setAttribute("class", "comment");
        actionElement.href = post.form;
        actionElement.textContent = "Action";
        actionElement.target = "_blank";
        linkElementContainer.appendChild(actionElement);
        const emailElement = document.createElement('a');
        emailElement.setAttribute("class", "comment");
        emailElement.href = post.mailto;
        emailElement.textContent = "Email";
        emailElement.target = "_blank";
        linkElementContainer.appendChild(emailElement);
        postElement.appendChild(linkElementContainer);
        const e = document.createElement('div');
        e.setAttribute("class", "clear");
        postElement.appendChild(e);

        const relevancyContainer = document.createElement('div');
        const relevancyValElem = document.createElement('p');
        relevancyValElem.textContent = "Relevancy " + post.relevancy;
        relevancyContainer.appendChild(relevancyValElem);
        post.topK.forEach((sub) => {
          const topKElem = document.createElement('a');
          topKElem.setAttribute("class", "topK");
          topKElem.href = sub.link;
          topKElem.textContent = sub.title + " (" + sub.similarity + ")";
          topKElem.target = "_blank";
          relevancyContainer.appendChild(topKElem);
        });
        postElement.appendChild(relevancyContainer);
        return postElement;
      }
      function loadPosts() {
        // Simulate loading more posts
        posts.forEach((post) => {
          const postElement = createPostElement(post);
          content.appendChild(postElement);
        });
      }
      // Load initial posts
      loadPosts();
    </script>

  </body>
</html>


