<!DOCTYPE html>
<html lang="en">
  <head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V34CNNDP8V"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-V34CNNDP8V');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arxiv Paper Selection</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
    }
    header {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      background-color: #ffffff;
      color: black;
      padding: 10px;
      text-align: center;
      z-index: 1000;
      border-bottom: 1px solid #ddd;
    }
    header div {
      display: block;
      margin: 10px auto;
    }

    #home-icon {
      display: block;
      float: left;
      margin: 5px;
      text-decoration: none;
      color: black;
    }

    main {
      margin-top: 60px; /* Adjusted margin to account for fixed header */
      padding: 20px;
    }

    .post {
      background-color: white;
      border: 1px solid #ddd;
      border-radius: 5px;
      margin-bottom: 10px;
      padding: 10px 20px;
      max-height: 2000px;
      overflow: scroll;
    }
    .post img {
      display: block;
      margin-top: 5px;
      max-width: auto;
      max-height: 100px;
    }
    .post .clear {
      clear: both;
      display: block;
    }
    .post a {
      text-decoration: none;
    }
    .post a:hover {
      color: #0056b3;
    }
    .post a:visited {
      color: #0056b3;
    }
    .post div.comment {
      text-align: right;
    }
    .post div.comment a {
      margin: 1em;
    }
    .post .text {
      margin: 1em 0em;
      padding: 0;
    }
    .post .text .title {
    }
    .post .text .author {
    }
    .post .text .abstract {
    }
    .post .topK {
      display: block;
      margin: 0.5em;
    }
    .post .date {
      margin: 0;
      padding: 0;
      text-size: small; 
      color: gray;
    }
    .post .link {
      margin: 0;
      padding: 0;
    }
    @media screen and (max-width: 600px) {
      body {
        max-width: 100%; 
      }
      #home-icon {
        float: none;
        display: block;
        text-align: center;
        margin-bottom: 10px;
      }
    }
    footer {
      width: 100%;
      background-color: #ddd;
      text-align: center;
      z-index: 1000;
      padding: 20px 0px;
      margin-bottom: 20px;
      left: 0;
    }

    #next-btn,
    #prev-btn {
      background-color: #4CAF50;
      color: white;
      padding: 8px 16px;
      margin: 0 50px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }

    .links {
      padding: 20px;
    }
    .links a {
      text-decoration: none;
    }
    .links a:hover {
      color: #0056b3;
    }
    .links a:visited {
      color: #0056b3;
    }

    #page-index {
      font-size: small;
    }
    .ads {
      width: 100%;
    }
    #prev-btn {
      background-color: #4CAF50;
      color: white;
      padding: 8px 16px;
      margin: 0 50px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    </style>
  </head>
  <body>

    <header>
      <a id="prev-btn" href="daily20240919.html"><i class="fas fa-chevron-left"></i></a>
      <a href="https://haoxiang.org/">About</a>
    </header>

    <main id="content">
      <!-- Posts will be dynamically added here using JavaScript -->
    </main>

    <script>
      // Dummy data for posts
      const posts = [
{"title": "NN-Copula-CD: A Copula-Guided Interpretable Neural Network for Change\n  Detection in Heterogeneous Remote Sensing Images", "author": "Weiming Li and Xueqian Wang and Gang Li and Baocheng Geng and Pramod K. Varshney", "abstract": "  Change detection (CD) in heterogeneous remote sensing images has been widely\nused for disaster monitoring and land-use management. In the past decade, the\nheterogeneous CD problem has significantly benefited from the development of\ndeep neural networks (DNNs). However, the purely data-driven DNNs perform like\na black box where the lack of interpretability limits the trustworthiness and\ncontrollability of DNNs in most practical CD applications. As a powerful\nknowledge-driven tool, copula theory performs well in modeling relationships\namong random variables. To enhance the interpretability of existing neural\nnetworks for CD, we propose a knowledge-data-driven heterogeneous CD method\nbased on a copula-guided neural network, named NN-Copula-CD. In our\nNN-Copula-CD, the mathematical characteristics of copula are employed as the\nloss functions to supervise a neural network to learn the dependence between\nbi-temporal heterogeneous superpixel pairs, and then the changed regions are\nidentified via binary classification based on the degrees of dependence of all\nthe superpixel pairs in the bi-temporal images. We conduct in-depth experiments\non three datasets with heterogeneous images, where both quantitative and visual\nresults demonstrate the effectiveness of our proposed NN-Copula-CD method.\n", "link": "http://arxiv.org/abs/2303.17448v3", "date": "2024-09-19", "relevancy": 2.1013, "topK": [{"title": "uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties", "link": "http://arxiv.org/abs/2402.05840v1", "similarity": 0.5356}, {"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.5195}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.5143}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20NN-Copula-CD%3A%20A%20Copula-Guided%20Interpretable%20Neural%20Network%20for%20Change%0A%20%20Detection%20in%20Heterogeneous%20Remote%20Sensing%20Images&body=Title%3A%20NN-Copula-CD%3A%20A%20Copula-Guided%20Interpretable%20Neural%20Network%20for%20Change%0A%20%20Detection%20in%20Heterogeneous%20Remote%20Sensing%20Images%0AAuthor%3A%20Weiming%20Li%20and%20Xueqian%20Wang%20and%20Gang%20Li%20and%20Baocheng%20Geng%20and%20Pramod%20K.%20Varshney%0AAbstract%3A%20%20%20Change%20detection%20%28CD%29%20in%20heterogeneous%20remote%20sensing%20images%20has%20been%20widely%0Aused%20for%20disaster%20monitoring%20and%20land-use%20management.%20In%20the%20past%20decade%2C%20the%0Aheterogeneous%20CD%20problem%20has%20significantly%20benefited%20from%20the%20development%20of%0Adeep%20neural%20networks%20%28DNNs%29.%20However%2C%20the%20purely%20data-driven%20DNNs%20perform%20like%0Aa%20black%20box%20where%20the%20lack%20of%20interpretability%20limits%20the%20trustworthiness%20and%0Acontrollability%20of%20DNNs%20in%20most%20practical%20CD%20applications.%20As%20a%20powerful%0Aknowledge-driven%20tool%2C%20copula%20theory%20performs%20well%20in%20modeling%20relationships%0Aamong%20random%20variables.%20To%20enhance%20the%20interpretability%20of%20existing%20neural%0Anetworks%20for%20CD%2C%20we%20propose%20a%20knowledge-data-driven%20heterogeneous%20CD%20method%0Abased%20on%20a%20copula-guided%20neural%20network%2C%20named%20NN-Copula-CD.%20In%20our%0ANN-Copula-CD%2C%20the%20mathematical%20characteristics%20of%20copula%20are%20employed%20as%20the%0Aloss%20functions%20to%20supervise%20a%20neural%20network%20to%20learn%20the%20dependence%20between%0Abi-temporal%20heterogeneous%20superpixel%20pairs%2C%20and%20then%20the%20changed%20regions%20are%0Aidentified%20via%20binary%20classification%20based%20on%20the%20degrees%20of%20dependence%20of%20all%0Athe%20superpixel%20pairs%20in%20the%20bi-temporal%20images.%20We%20conduct%20in-depth%20experiments%0Aon%20three%20datasets%20with%20heterogeneous%20images%2C%20where%20both%20quantitative%20and%20visual%0Aresults%20demonstrate%20the%20effectiveness%20of%20our%20proposed%20NN-Copula-CD%20method.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2303.17448v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DNN-Copula-CD%253A%2520A%2520Copula-Guided%2520Interpretable%2520Neural%2520Network%2520for%2520Change%250A%2520%2520Detection%2520in%2520Heterogeneous%2520Remote%2520Sensing%2520Images%26entry.906535625%3DWeiming%2520Li%2520and%2520Xueqian%2520Wang%2520and%2520Gang%2520Li%2520and%2520Baocheng%2520Geng%2520and%2520Pramod%2520K.%2520Varshney%26entry.1292438233%3D%2520%2520Change%2520detection%2520%2528CD%2529%2520in%2520heterogeneous%2520remote%2520sensing%2520images%2520has%2520been%2520widely%250Aused%2520for%2520disaster%2520monitoring%2520and%2520land-use%2520management.%2520In%2520the%2520past%2520decade%252C%2520the%250Aheterogeneous%2520CD%2520problem%2520has%2520significantly%2520benefited%2520from%2520the%2520development%2520of%250Adeep%2520neural%2520networks%2520%2528DNNs%2529.%2520However%252C%2520the%2520purely%2520data-driven%2520DNNs%2520perform%2520like%250Aa%2520black%2520box%2520where%2520the%2520lack%2520of%2520interpretability%2520limits%2520the%2520trustworthiness%2520and%250Acontrollability%2520of%2520DNNs%2520in%2520most%2520practical%2520CD%2520applications.%2520As%2520a%2520powerful%250Aknowledge-driven%2520tool%252C%2520copula%2520theory%2520performs%2520well%2520in%2520modeling%2520relationships%250Aamong%2520random%2520variables.%2520To%2520enhance%2520the%2520interpretability%2520of%2520existing%2520neural%250Anetworks%2520for%2520CD%252C%2520we%2520propose%2520a%2520knowledge-data-driven%2520heterogeneous%2520CD%2520method%250Abased%2520on%2520a%2520copula-guided%2520neural%2520network%252C%2520named%2520NN-Copula-CD.%2520In%2520our%250ANN-Copula-CD%252C%2520the%2520mathematical%2520characteristics%2520of%2520copula%2520are%2520employed%2520as%2520the%250Aloss%2520functions%2520to%2520supervise%2520a%2520neural%2520network%2520to%2520learn%2520the%2520dependence%2520between%250Abi-temporal%2520heterogeneous%2520superpixel%2520pairs%252C%2520and%2520then%2520the%2520changed%2520regions%2520are%250Aidentified%2520via%2520binary%2520classification%2520based%2520on%2520the%2520degrees%2520of%2520dependence%2520of%2520all%250Athe%2520superpixel%2520pairs%2520in%2520the%2520bi-temporal%2520images.%2520We%2520conduct%2520in-depth%2520experiments%250Aon%2520three%2520datasets%2520with%2520heterogeneous%2520images%252C%2520where%2520both%2520quantitative%2520and%2520visual%250Aresults%2520demonstrate%2520the%2520effectiveness%2520of%2520our%2520proposed%2520NN-Copula-CD%2520method.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2303.17448v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=NN-Copula-CD%3A%20A%20Copula-Guided%20Interpretable%20Neural%20Network%20for%20Change%0A%20%20Detection%20in%20Heterogeneous%20Remote%20Sensing%20Images&entry.906535625=Weiming%20Li%20and%20Xueqian%20Wang%20and%20Gang%20Li%20and%20Baocheng%20Geng%20and%20Pramod%20K.%20Varshney&entry.1292438233=%20%20Change%20detection%20%28CD%29%20in%20heterogeneous%20remote%20sensing%20images%20has%20been%20widely%0Aused%20for%20disaster%20monitoring%20and%20land-use%20management.%20In%20the%20past%20decade%2C%20the%0Aheterogeneous%20CD%20problem%20has%20significantly%20benefited%20from%20the%20development%20of%0Adeep%20neural%20networks%20%28DNNs%29.%20However%2C%20the%20purely%20data-driven%20DNNs%20perform%20like%0Aa%20black%20box%20where%20the%20lack%20of%20interpretability%20limits%20the%20trustworthiness%20and%0Acontrollability%20of%20DNNs%20in%20most%20practical%20CD%20applications.%20As%20a%20powerful%0Aknowledge-driven%20tool%2C%20copula%20theory%20performs%20well%20in%20modeling%20relationships%0Aamong%20random%20variables.%20To%20enhance%20the%20interpretability%20of%20existing%20neural%0Anetworks%20for%20CD%2C%20we%20propose%20a%20knowledge-data-driven%20heterogeneous%20CD%20method%0Abased%20on%20a%20copula-guided%20neural%20network%2C%20named%20NN-Copula-CD.%20In%20our%0ANN-Copula-CD%2C%20the%20mathematical%20characteristics%20of%20copula%20are%20employed%20as%20the%0Aloss%20functions%20to%20supervise%20a%20neural%20network%20to%20learn%20the%20dependence%20between%0Abi-temporal%20heterogeneous%20superpixel%20pairs%2C%20and%20then%20the%20changed%20regions%20are%0Aidentified%20via%20binary%20classification%20based%20on%20the%20degrees%20of%20dependence%20of%20all%0Athe%20superpixel%20pairs%20in%20the%20bi-temporal%20images.%20We%20conduct%20in-depth%20experiments%0Aon%20three%20datasets%20with%20heterogeneous%20images%2C%20where%20both%20quantitative%20and%20visual%0Aresults%20demonstrate%20the%20effectiveness%20of%20our%20proposed%20NN-Copula-CD%20method.%0A&entry.1838667208=http%3A//arxiv.org/abs/2303.17448v3&entry.124074799=Read"},
{"title": "Skill matching at scale: freelancer-project alignment for efficient\n  multilingual candidate retrieval", "author": "Warren Jouanneau and Marc Palyart and Emma Jouffroy", "abstract": "  Finding the perfect match between a job proposal and a set of freelancers is\nnot an easy task to perform at scale, especially in multiple languages. In this\npaper, we propose a novel neural retriever architecture that tackles this\nproblem in a multilingual setting. Our method encodes project descriptions and\nfreelancer profiles by leveraging pre-trained multilingual language models. The\nlatter are used as backbone for a custom transformer architecture that aims to\nkeep the structure of the profiles and project. This model is trained with a\ncontrastive loss on historical data. Thanks to several experiments, we show\nthat this approach effectively captures skill matching similarity and\nfacilitates efficient matching, outperforming traditional methods.\n", "link": "http://arxiv.org/abs/2409.12097v2", "date": "2024-09-19", "relevancy": 1.9599, "topK": [{"title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization", "link": "https://arxiv.org/abs/2212.04575", "similarity": 0.5205}, {"title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding", "link": "http://arxiv.org/abs/2402.18490v1", "similarity": 0.4751}, {"title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for\n  Semantic and Property Prediction", "link": "http://arxiv.org/abs/2402.05872v3", "similarity": 0.4508}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20Skill%20matching%20at%20scale%3A%20freelancer-project%20alignment%20for%20efficient%0A%20%20multilingual%20candidate%20retrieval&body=Title%3A%20Skill%20matching%20at%20scale%3A%20freelancer-project%20alignment%20for%20efficient%0A%20%20multilingual%20candidate%20retrieval%0AAuthor%3A%20Warren%20Jouanneau%20and%20Marc%20Palyart%20and%20Emma%20Jouffroy%0AAbstract%3A%20%20%20Finding%20the%20perfect%20match%20between%20a%20job%20proposal%20and%20a%20set%20of%20freelancers%20is%0Anot%20an%20easy%20task%20to%20perform%20at%20scale%2C%20especially%20in%20multiple%20languages.%20In%20this%0Apaper%2C%20we%20propose%20a%20novel%20neural%20retriever%20architecture%20that%20tackles%20this%0Aproblem%20in%20a%20multilingual%20setting.%20Our%20method%20encodes%20project%20descriptions%20and%0Afreelancer%20profiles%20by%20leveraging%20pre-trained%20multilingual%20language%20models.%20The%0Alatter%20are%20used%20as%20backbone%20for%20a%20custom%20transformer%20architecture%20that%20aims%20to%0Akeep%20the%20structure%20of%20the%20profiles%20and%20project.%20This%20model%20is%20trained%20with%20a%0Acontrastive%20loss%20on%20historical%20data.%20Thanks%20to%20several%20experiments%2C%20we%20show%0Athat%20this%20approach%20effectively%20captures%20skill%20matching%20similarity%20and%0Afacilitates%20efficient%20matching%2C%20outperforming%20traditional%20methods.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2409.12097v2%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DSkill%2520matching%2520at%2520scale%253A%2520freelancer-project%2520alignment%2520for%2520efficient%250A%2520%2520multilingual%2520candidate%2520retrieval%26entry.906535625%3DWarren%2520Jouanneau%2520and%2520Marc%2520Palyart%2520and%2520Emma%2520Jouffroy%26entry.1292438233%3D%2520%2520Finding%2520the%2520perfect%2520match%2520between%2520a%2520job%2520proposal%2520and%2520a%2520set%2520of%2520freelancers%2520is%250Anot%2520an%2520easy%2520task%2520to%2520perform%2520at%2520scale%252C%2520especially%2520in%2520multiple%2520languages.%2520In%2520this%250Apaper%252C%2520we%2520propose%2520a%2520novel%2520neural%2520retriever%2520architecture%2520that%2520tackles%2520this%250Aproblem%2520in%2520a%2520multilingual%2520setting.%2520Our%2520method%2520encodes%2520project%2520descriptions%2520and%250Afreelancer%2520profiles%2520by%2520leveraging%2520pre-trained%2520multilingual%2520language%2520models.%2520The%250Alatter%2520are%2520used%2520as%2520backbone%2520for%2520a%2520custom%2520transformer%2520architecture%2520that%2520aims%2520to%250Akeep%2520the%2520structure%2520of%2520the%2520profiles%2520and%2520project.%2520This%2520model%2520is%2520trained%2520with%2520a%250Acontrastive%2520loss%2520on%2520historical%2520data.%2520Thanks%2520to%2520several%2520experiments%252C%2520we%2520show%250Athat%2520this%2520approach%2520effectively%2520captures%2520skill%2520matching%2520similarity%2520and%250Afacilitates%2520efficient%2520matching%252C%2520outperforming%2520traditional%2520methods.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2409.12097v2%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=Skill%20matching%20at%20scale%3A%20freelancer-project%20alignment%20for%20efficient%0A%20%20multilingual%20candidate%20retrieval&entry.906535625=Warren%20Jouanneau%20and%20Marc%20Palyart%20and%20Emma%20Jouffroy&entry.1292438233=%20%20Finding%20the%20perfect%20match%20between%20a%20job%20proposal%20and%20a%20set%20of%20freelancers%20is%0Anot%20an%20easy%20task%20to%20perform%20at%20scale%2C%20especially%20in%20multiple%20languages.%20In%20this%0Apaper%2C%20we%20propose%20a%20novel%20neural%20retriever%20architecture%20that%20tackles%20this%0Aproblem%20in%20a%20multilingual%20setting.%20Our%20method%20encodes%20project%20descriptions%20and%0Afreelancer%20profiles%20by%20leveraging%20pre-trained%20multilingual%20language%20models.%20The%0Alatter%20are%20used%20as%20backbone%20for%20a%20custom%20transformer%20architecture%20that%20aims%20to%0Akeep%20the%20structure%20of%20the%20profiles%20and%20project.%20This%20model%20is%20trained%20with%20a%0Acontrastive%20loss%20on%20historical%20data.%20Thanks%20to%20several%20experiments%2C%20we%20show%0Athat%20this%20approach%20effectively%20captures%20skill%20matching%20similarity%20and%0Afacilitates%20efficient%20matching%2C%20outperforming%20traditional%20methods.%0A&entry.1838667208=http%3A//arxiv.org/abs/2409.12097v2&entry.124074799=Read"},
{"title": "LaMamba-Diff: Linear-Time High-Fidelity Diffusion Models Based on Local\n  Attention and Mamba", "author": "Yunxiang Fu and Chaoqi Chen and Yizhou Yu", "abstract": "  Recent Transformer-based diffusion models have shown remarkable performance,\nlargely attributed to the ability of the self-attention mechanism to accurately\ncapture both global and local contexts by computing all-pair interactions among\ninput tokens. However, their quadratic complexity poses significant\ncomputational challenges for long-sequence inputs. Conversely, a recent state\nspace model called Mamba offers linear complexity by compressing a filtered\nglobal context into a hidden state. Despite its efficiency, compression\ninevitably leads to information loss of fine-grained local dependencies among\ntokens, which are crucial for effective visual generative modeling. Motivated\nby these observations, we introduce Local Attentional Mamba (LaMamba) blocks\nthat combine the strengths of self-attention and Mamba, capturing both global\ncontexts and local details with linear complexity. Leveraging the efficient\nU-Net architecture, our model exhibits exceptional scalability and surpasses\nthe performance of DiT across various model scales on ImageNet at 256x256\nresolution, all while utilizing substantially fewer GFLOPs and a comparable\nnumber of parameters. Compared to state-of-the-art diffusion models on ImageNet\n256x256 and 512x512, our largest model presents notable advantages, such as a\nreduction of up to 62% GFLOPs compared to DiT-XL/2, while achieving superior\nperformance with comparable or fewer parameters. Our code is available at\nhttps://github.com/yunxiangfu2001/LaMamba-Diff.\n", "link": "http://arxiv.org/abs/2408.02615v3", "date": "2024-09-19", "relevancy": 1.9299, "topK": [{"title": "SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions", "link": "http://arxiv.org/abs/2403.16627v1", "similarity": 0.6826}, {"title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution\n  Images", "link": "http://arxiv.org/abs/2402.13573v2", "similarity": 0.6351}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "link": "http://arxiv.org/abs/2403.03206v1", "similarity": 0.6246}], "mailto": "mailto:haoxiang.li.2024@gmail.com?subject=%5BarXrec%5D%20LaMamba-Diff%3A%20Linear-Time%20High-Fidelity%20Diffusion%20Models%20Based%20on%20Local%0A%20%20Attention%20and%20Mamba&body=Title%3A%20LaMamba-Diff%3A%20Linear-Time%20High-Fidelity%20Diffusion%20Models%20Based%20on%20Local%0A%20%20Attention%20and%20Mamba%0AAuthor%3A%20Yunxiang%20Fu%20and%20Chaoqi%20Chen%20and%20Yizhou%20Yu%0AAbstract%3A%20%20%20Recent%20Transformer-based%20diffusion%20models%20have%20shown%20remarkable%20performance%2C%0Alargely%20attributed%20to%20the%20ability%20of%20the%20self-attention%20mechanism%20to%20accurately%0Acapture%20both%20global%20and%20local%20contexts%20by%20computing%20all-pair%20interactions%20among%0Ainput%20tokens.%20However%2C%20their%20quadratic%20complexity%20poses%20significant%0Acomputational%20challenges%20for%20long-sequence%20inputs.%20Conversely%2C%20a%20recent%20state%0Aspace%20model%20called%20Mamba%20offers%20linear%20complexity%20by%20compressing%20a%20filtered%0Aglobal%20context%20into%20a%20hidden%20state.%20Despite%20its%20efficiency%2C%20compression%0Ainevitably%20leads%20to%20information%20loss%20of%20fine-grained%20local%20dependencies%20among%0Atokens%2C%20which%20are%20crucial%20for%20effective%20visual%20generative%20modeling.%20Motivated%0Aby%20these%20observations%2C%20we%20introduce%20Local%20Attentional%20Mamba%20%28LaMamba%29%20blocks%0Athat%20combine%20the%20strengths%20of%20self-attention%20and%20Mamba%2C%20capturing%20both%20global%0Acontexts%20and%20local%20details%20with%20linear%20complexity.%20Leveraging%20the%20efficient%0AU-Net%20architecture%2C%20our%20model%20exhibits%20exceptional%20scalability%20and%20surpasses%0Athe%20performance%20of%20DiT%20across%20various%20model%20scales%20on%20ImageNet%20at%20256x256%0Aresolution%2C%20all%20while%20utilizing%20substantially%20fewer%20GFLOPs%20and%20a%20comparable%0Anumber%20of%20parameters.%20Compared%20to%20state-of-the-art%20diffusion%20models%20on%20ImageNet%0A256x256%20and%20512x512%2C%20our%20largest%20model%20presents%20notable%20advantages%2C%20such%20as%20a%0Areduction%20of%20up%20to%2062%25%20GFLOPs%20compared%20to%20DiT-XL/2%2C%20while%20achieving%20superior%0Aperformance%20with%20comparable%20or%20fewer%20parameters.%20Our%20code%20is%20available%20at%0Ahttps%3A//github.com/yunxiangfu2001/LaMamba-Diff.%0A%0ALink%3A%20http%3A//arxiv.org/abs/2408.02615v3%0AForm%3A%20https%3A//docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform%3Fentry.1380929848%3DLaMamba-Diff%253A%2520Linear-Time%2520High-Fidelity%2520Diffusion%2520Models%2520Based%2520on%2520Local%250A%2520%2520Attention%2520and%2520Mamba%26entry.906535625%3DYunxiang%2520Fu%2520and%2520Chaoqi%2520Chen%2520and%2520Yizhou%2520Yu%26entry.1292438233%3D%2520%2520Recent%2520Transformer-based%2520diffusion%2520models%2520have%2520shown%2520remarkable%2520performance%252C%250Alargely%2520attributed%2520to%2520the%2520ability%2520of%2520the%2520self-attention%2520mechanism%2520to%2520accurately%250Acapture%2520both%2520global%2520and%2520local%2520contexts%2520by%2520computing%2520all-pair%2520interactions%2520among%250Ainput%2520tokens.%2520However%252C%2520their%2520quadratic%2520complexity%2520poses%2520significant%250Acomputational%2520challenges%2520for%2520long-sequence%2520inputs.%2520Conversely%252C%2520a%2520recent%2520state%250Aspace%2520model%2520called%2520Mamba%2520offers%2520linear%2520complexity%2520by%2520compressing%2520a%2520filtered%250Aglobal%2520context%2520into%2520a%2520hidden%2520state.%2520Despite%2520its%2520efficiency%252C%2520compression%250Ainevitably%2520leads%2520to%2520information%2520loss%2520of%2520fine-grained%2520local%2520dependencies%2520among%250Atokens%252C%2520which%2520are%2520crucial%2520for%2520effective%2520visual%2520generative%2520modeling.%2520Motivated%250Aby%2520these%2520observations%252C%2520we%2520introduce%2520Local%2520Attentional%2520Mamba%2520%2528LaMamba%2529%2520blocks%250Athat%2520combine%2520the%2520strengths%2520of%2520self-attention%2520and%2520Mamba%252C%2520capturing%2520both%2520global%250Acontexts%2520and%2520local%2520details%2520with%2520linear%2520complexity.%2520Leveraging%2520the%2520efficient%250AU-Net%2520architecture%252C%2520our%2520model%2520exhibits%2520exceptional%2520scalability%2520and%2520surpasses%250Athe%2520performance%2520of%2520DiT%2520across%2520various%2520model%2520scales%2520on%2520ImageNet%2520at%2520256x256%250Aresolution%252C%2520all%2520while%2520utilizing%2520substantially%2520fewer%2520GFLOPs%2520and%2520a%2520comparable%250Anumber%2520of%2520parameters.%2520Compared%2520to%2520state-of-the-art%2520diffusion%2520models%2520on%2520ImageNet%250A256x256%2520and%2520512x512%252C%2520our%2520largest%2520model%2520presents%2520notable%2520advantages%252C%2520such%2520as%2520a%250Areduction%2520of%2520up%2520to%252062%2525%2520GFLOPs%2520compared%2520to%2520DiT-XL/2%252C%2520while%2520achieving%2520superior%250Aperformance%2520with%2520comparable%2520or%2520fewer%2520parameters.%2520Our%2520code%2520is%2520available%2520at%250Ahttps%253A//github.com/yunxiangfu2001/LaMamba-Diff.%250A%26entry.1838667208%3Dhttp%253A//arxiv.org/abs/2408.02615v3%26entry.124074799%3DRead", "form": "https://docs.google.com/forms/d/e/1FAIpQLSfSfFqShId9ssA7GWYmvv7m_7qsIao4K__1rDj9BurNNxUPYQ/viewform?entry.1380929848=LaMamba-Diff%3A%20Linear-Time%20High-Fidelity%20Diffusion%20Models%20Based%20on%20Local%0A%20%20Attention%20and%20Mamba&entry.906535625=Yunxiang%20Fu%20and%20Chaoqi%20Chen%20and%20Yizhou%20Yu&entry.1292438233=%20%20Recent%20Transformer-based%20diffusion%20models%20have%20shown%20remarkable%20performance%2C%0Alargely%20attributed%20to%20the%20ability%20of%20the%20self-attention%20mechanism%20to%20accurately%0Acapture%20both%20global%20and%20local%20contexts%20by%20computing%20all-pair%20interactions%20among%0Ainput%20tokens.%20However%2C%20their%20quadratic%20complexity%20poses%20significant%0Acomputational%20challenges%20for%20long-sequence%20inputs.%20Conversely%2C%20a%20recent%20state%0Aspace%20model%20called%20Mamba%20offers%20linear%20complexity%20by%20compressing%20a%20filtered%0Aglobal%20context%20into%20a%20hidden%20state.%20Despite%20its%20efficiency%2C%20compression%0Ainevitably%20leads%20to%20information%20loss%20of%20fine-grained%20local%20dependencies%20among%0Atokens%2C%20which%20are%20crucial%20for%20effective%20visual%20generative%20modeling.%20Motivated%0Aby%20these%20observations%2C%20we%20introduce%20Local%20Attentional%20Mamba%20%28LaMamba%29%20blocks%0Athat%20combine%20the%20strengths%20of%20self-attention%20and%20Mamba%2C%20capturing%20both%20global%0Acontexts%20and%20local%20details%20with%20linear%20complexity.%20Leveraging%20the%20efficient%0AU-Net%20architecture%2C%20our%20model%20exhibits%20exceptional%20scalability%20and%20surpasses%0Athe%20performance%20of%20DiT%20across%20various%20model%20scales%20on%20ImageNet%20at%20256x256%0Aresolution%2C%20all%20while%20utilizing%20substantially%20fewer%20GFLOPs%20and%20a%20comparable%0Anumber%20of%20parameters.%20Compared%20to%20state-of-the-art%20diffusion%20models%20on%20ImageNet%0A256x256%20and%20512x512%2C%20our%20largest%20model%20presents%20notable%20advantages%2C%20such%20as%20a%0Areduction%20of%20up%20to%2062%25%20GFLOPs%20compared%20to%20DiT-XL/2%2C%20while%20achieving%20superior%0Aperformance%20with%20comparable%20or%20fewer%20parameters.%20Our%20code%20is%20available%20at%0Ahttps%3A//github.com/yunxiangfu2001/LaMamba-Diff.%0A&entry.1838667208=http%3A//arxiv.org/abs/2408.02615v3&entry.124074799=Read"},
      ];
      const content = document.getElementById('content');
      function createPostElement(post) {
        const postElement = document.createElement('div');
        postElement.className = 'post';
        const dateElem = document.createElement('p');
        dateElem.setAttribute("class", "date");
        dateElem.textContent = post.date;
        postElement.appendChild(dateElem);

        const textElem = document.createElement('p');
        textElem.setAttribute("class", "text");
        const titleElem = document.createElement('p');
        titleElem.setAttribute("class", "title");
        titleElem.textContent = post.title;
        textElem.appendChild(titleElem);
        const authorElem = document.createElement('p');
        authorElem.setAttribute("class", "author");
        authorElem.textContent = post.author;
        textElem.appendChild(authorElem);
        const abstractElem = document.createElement('p');
        abstractElem.setAttribute("class", "abstract");
        abstractElem.textContent = post.abstract;
        textElem.appendChild(abstractElem);

        const linkElement = document.createElement('a');
        linkElement.setAttribute("class", "link");
        linkElement.href = post.link;
        linkElement.target = "_blank";
        linkElement.textContent = post.link.length > 50 ? post.link.substring(0, 50) + '...' : post.link;
        textElem.appendChild(linkElement);
        postElement.appendChild(textElem);

        const linkElementContainer = document.createElement('div');
        linkElementContainer.setAttribute("class", "comment");
        const actionElement = document.createElement('a');
        actionElement.setAttribute("class", "comment");
        actionElement.href = post.form;
        actionElement.textContent = "Action";
        actionElement.target = "_blank";
        linkElementContainer.appendChild(actionElement);
        const emailElement = document.createElement('a');
        emailElement.setAttribute("class", "comment");
        emailElement.href = post.mailto;
        emailElement.textContent = "Email";
        emailElement.target = "_blank";
        linkElementContainer.appendChild(emailElement);
        postElement.appendChild(linkElementContainer);
        const e = document.createElement('div');
        e.setAttribute("class", "clear");
        postElement.appendChild(e);

        const relevancyContainer = document.createElement('div');
        const relevancyValElem = document.createElement('p');
        relevancyValElem.textContent = "Relevancy " + post.relevancy;
        relevancyContainer.appendChild(relevancyValElem);
        post.topK.forEach((sub) => {
          const topKElem = document.createElement('a');
          topKElem.setAttribute("class", "topK");
          topKElem.href = sub.link;
          topKElem.textContent = sub.title + " (" + sub.similarity + ")";
          topKElem.target = "_blank";
          relevancyContainer.appendChild(topKElem);
        });
        postElement.appendChild(relevancyContainer);
        return postElement;
      }
      function loadPosts() {
        // Simulate loading more posts
        posts.forEach((post) => {
          const postElement = createPostElement(post);
          content.appendChild(postElement);
        });
      }
      // Load initial posts
      loadPosts();
    </script>

  </body>
</html>


